{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "Seasonal_Forecast_CNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-tGtJj5Z7OR"
      },
      "source": [
        "# Seasonal forecasts of New Zealand's local climate conditions with limited GCM inputs using Convolutional Neural Networks\n",
        "\n",
        "**Motivation**\n",
        "\n",
        "GCM (global circulation model) rainfall and temperature predictions are of 1-degree spatial resolution, which is coarse on local (subgrid) scales. For example, the whole of New Zealand is represented by a few grid points. Downscaling seasonal forecasts help to have more precise predictions on smaller regions.\n",
        "\n",
        "We are interested in the prediction of rainfall and temperature in 6 climate regions of New Zealand: North of the North Island (NNI), East of the North Island (ENI), West of the North Island (WNI), North of the South Island (NSI), East of the South Island (ESI) and West of the South Island (WSI).\n",
        "\n",
        "A convolutional neural network (CNN) has been developed to predict temperature and rainfall for each region, where inputs to CNN are the outputs of GCM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzzqfmEzasyX"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJYGYgYZapTH"
      },
      "source": [
        "Data consists of GCM (ECMWF) outputs of 3 variables temperature 2m, geopotential height (850Hpa) and precipitation with a spatial extent of 0-359 degree (360 lines) longitude and 90S-90N (181 lines) latitude. There are a total of 181*360 grid points. \n",
        "\n",
        "The climatological mean of data is 1981 - 2010.\n",
        "\n",
        "Temporal extent is monthly frequency from April 1981 to Dec 2019, therefore the data consist of a total of 465 instances.\n",
        "\n",
        "This task is considered as a classification problem, so the target variables rainfall and temperature have been divided into quantiles with respect to the climatological mean. \n",
        "\n",
        "Quantiles labels are represented by 1 (<20%), 2 (20%-40%), 3 (40%-60%), 4 (60%-80%) and 5 (>80%) in the data. We represent Q1: (<20%), Q2: (20%-40%), Q3:(40%-60%), Q4: (60%-80%) and Q5 (>80%) in the confusion matrices.\n",
        "\n",
        "GCM provide monthly averaged variables up to 6 months in the future. We only considered forecasts at 3 months lead-time, (e.g. forecasts for the period June-July-August initialised on the 1st of May).\n",
        "\n",
        "\n",
        "**Data Split**\n",
        "\n",
        "Data consist of 3 files of GCM outputs (CNN inputs) and 12 files of temperature and rainfall labels for each region (CNN target variables).  \n",
        " \n",
        "Data are divided into training, validation and test sets. Training set consists of 324 instances (70% of the data, April 1981 - Mar 2008), the validation set consists of 71 instances (15% of the data, April  2008 - Feb 2014) and the test set consists of 70 instances (15% of the data, Mar  2014 - Dec  2019).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqb10_k24r6d"
      },
      "source": [
        "**Quadratic weighted kappa**\n",
        "\n",
        "The quadratic weighted kappa(QWK) was used as an evaluation metric (k). An experiment was done using continuous quadratic weighted kappa as a loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VJGGkKl7otA"
      },
      "source": [
        "# To install optuna library\n",
        "\n",
        "Optuna library is installed to import Optuna functions that will be used for hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxkSnA9D19NA",
        "outputId": "c9b61ed1-2ce2-47d3-edbe-7517067fb62f"
      },
      "source": [
        "pip install optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.9.1-py3-none-any.whl (302 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 40.8 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 71 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 102 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 112 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 143 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 153 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 163 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 174 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 184 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 194 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 204 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 215 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 225 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 235 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 245 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 266 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 276 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 286 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 296 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 302 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.4.1-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.6.5-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 62.3 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.22)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.9.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.6.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 76.4 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.1.2-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 90.4 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=52cb5d99bb4e00591c3d34d3ddfcf0da0818e6581127b30320d968b183bb4a88\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, colorama, stevedore, python-editor, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.5 alembic-1.6.5 autopage-0.4.0 cliff-3.9.0 cmaes-0.8.2 cmd2-2.1.2 colorama-0.4.4 colorlog-6.4.1 optuna-2.9.1 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usrDd4fDiVL7"
      },
      "source": [
        "# Importing main packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#import torch_optimizer as optim1\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import optuna\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "\n",
        "import seaborn as sn\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZn922NuHM-c",
        "outputId": "a831d17d-3a00-49d0-98ae-6d8c6b2cedae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmm9HbekdYhP"
      },
      "source": [
        "# GCM outputs\n",
        "Data-preprocessing \n",
        "\n",
        "* Uploading 3 GCM variables such as temperature, precipitation and geo-potential height. Each variable file is 2-dimensional (465*65160).\n",
        "\n",
        "* CNN accepts input of 4-dimensions  (batch_size, channels, height, weight).\n",
        "\n",
        "* Converting each GCM variable into Pytorch tensors then reshaping their shape into 3- form with respect to the number of grid points of latitude and longitude (465 * 181 * 360).\n",
        "\n",
        "* Normalising all tensors from 0 to 1 by creating a user-defined normalisation function.\n",
        "\n",
        "* Stacking 3 GCM  variables as a channel of the input tensor (465 * 3 * 181 * 360). This represents inputs (X) to the CNN. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxGaZL290fq7"
      },
      "source": [
        "# Reading GCM precipitation file\n",
        "precip1 = pd.read_csv('drive/MyDrive/DL_project/PRECIP_1981_2019_ECMWF.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlowDquX0fnY"
      },
      "source": [
        "precip1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6ecXfcuz7OT"
      },
      "source": [
        "# To check is there null value\n",
        "precip2.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTQnyKsqyp84"
      },
      "source": [
        "#Reading GCM precipitation by removing first 3 rows \n",
        "precip = pd.read_csv(\"drive/My Drive/DL_project/PRECIP_1981_2019_ECMWF.csv\", sep=\",\",skiprows=3,  header=None )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxKcWyIRyp84"
      },
      "source": [
        "# Dropping first column of dates\n",
        "precip_drop = precip.drop(precip.columns[0], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVW7xWb5yp85",
        "outputId": "ae5d80f4-c541-4534-9b65-3f52a08586aa"
      },
      "source": [
        "precip_drop.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(465, 65160)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhbOex1lyp85"
      },
      "source": [
        "# Reading GCM temp file by removing first 3 rows\n",
        "t2m = pd.read_csv(\"drive/MyDrive/DL_project/T2M_1981_2019_ECMWF.csv\", sep=\",\", skiprows=3, header=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI7tVZlryp85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b69619-5358-4ecb-ef10-2750705439fe"
      },
      "source": [
        "# Dropping first column of temp\n",
        "t2m_drop = t2m.drop(t2m.columns[0], axis=1)\n",
        "t2m_drop.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(465, 65160)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4-QeuHGyp86"
      },
      "source": [
        "# Reading GCM geo-potential height file by removing first 3 lines\n",
        "z850 = pd.read_csv(\"drive/My Drive/DL_project/Z850_1981_2019_ECMWF.csv\", sep=\",\", skiprows=3, header=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-lqrcqGyp86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2715bce-c274-49c2-e00f-6196274cc4f5"
      },
      "source": [
        "# Dropping first column of geo-potential height\n",
        "z850_drop = z850.drop(z850.columns[0], axis=1)\n",
        "z850_drop.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(465, 65160)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhLDcRqtuo2a"
      },
      "source": [
        "## Plots\n",
        "\n",
        "Converting precip, t2m and z850 variables values into Pytorch tensors and then their shape (size) from 2-dimension to 3-dimensions. Plotting for a single row of each variable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZLvxg56yp87"
      },
      "source": [
        "# Converting GCM variables values to Pytorch tensors\n",
        "precip1 = torch.as_tensor(precip_drop.values).type(torch.FloatTensor)\n",
        "t2m1 = torch.as_tensor(t2m_drop.values).type(torch.FloatTensor)\n",
        "z8501 = torch.as_tensor(z850_drop.values).type(torch.FloatTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DKFAd5Syp87"
      },
      "source": [
        "#Unflattening GCM variabels (reshaping their size)\n",
        "precip2 = precip1.reshape(465, 181, 360)\n",
        "t2m2 = t2m1.reshape(465, 181, 360)\n",
        "z8502 = z8501.reshape(465, 181, 360)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "8Wo7CIZtu1Dm",
        "outputId": "84014c85-a885-46fc-d2d1-3d364962a05b"
      },
      "source": [
        "# Plot first row of precip\n",
        "plt.imshow(precip2[0], cmap='jet')\n",
        "plt.title('Precipitaton');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAADXCAYAAADhqxGkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9a4wkWXbf94uKyIjIrMzt7Knarp7e6d1e7WjXHlMmRRGkIZq2DMGGIFGQBBikHrAeNLgyYNr+IMsWZMMWLNCWYUGyBH4R9QL9kEQBkiyBoiVKBiSSJkyRlGjTXu4uZ6he9WxPV2/VdPZmdmZGVkSGP9x77j33ZmRW9Uz3bO0wD9BdVZnxvI9zz/mf/zk3aduWvexlL3vZy4dLDr7WD7CXvexlL3t58bJX7nvZy1728iGUvXLfy172spcPoeyV+172spe9fAhlr9z3spe97OVDKHvlvpe97GUvH0LZK/e9/IqUJEl+T5IkP/aij93LXq6LJHue+16uoyRJch84ARrgGfC/A9/Xtu3sa/lcAEmStMCvbtv2zSse/4+A/6Vt27/wUh9sL3tRsrfc93Kd5be2bTsEvhn4FuC/1F8mSZJ9TZ5qL3v5OpC9ct/LtZe2bb+Msdy/IUmSNkmS/zBJkl8CfgkgSZLvTJLk55MkmSRJ8lNJkvyrcm6SJHeTJPmbSZJ8JUmS8yRJfsB+/vuTJPlJdVybJMl/nCTJLydJcpYkyf+QJMlBfGySJD9uT/m/kySZJUny3UmS3EyS5EfsPZ7Y31+zx38/8B3AD9jj5f6/PkmSn0mS5Kn9+evVs/yjJEn+eJIk/2eSJNMkSX4sSZLjl9fCe/kwyl657+XaS5Ikd4HfDPwz+9FvB74NeCNJkl8L/CXgDwJHwJ8D/k6SJEWSJCnwI8CXgHvAx4C/tuNWvwPjIXwz8NuA74kPaNv237C/fmPbtsO2bX8YM4/+MvAJ4OPAAvgBe/x/AfwEBlIatm37fUmSvAL8XeDP2mf+U8DfTZLkSN3qdwN/ALgF5MB/enlL7WUvXvbKfS/XWf63JEkmwE8C/xj4b+3n/13btu+2bbsAPgv8ubZtf7pt26Zt2x8CKuBfA74VuAP84bZtn7Vtu2zb9ic77iPy39vr/gvgfwR+11Uesm3b87Zt/0bbtvO2bafA9wP/5o5TfgvwS23b/s9t29Zt2/5V4PPAb1XH/OW2bb9o3/GvA990lWfZy15E9pjlXq6z/Pa2bf+h/iBJEoAH6qNPAL8vSZL/SH2WY5R6A3ypbdv6ivfT1/2SvcalkiTJAPjTwG8CbtqPR0mSpG3bNh2n3LHX1/IljGch8kj9PgeGV3mWvexFZG+57+XrUTTF6wHw/W3bjtW/gbWGHwAff47A6131+8eBh1c87w8BnwG+rW3bjwAC3SQdz4u97ieizz4OfPmK99vLXi6VvXLfy9e7/HngP0iS5NsSI4dJkvyWJElGwD8B3gH+hP28TJLk23dc6w/b4Ohd4D8BfnjLcafAr1J/jzA4+8Ti6f/1Jcf/KPDpJEl+d5IkWZIk3w28gYkP7GUvL0T2yn0vX9fStu3PAt+LCWA+Ad4Efr/9rsHg2K8D/wJ4G/juHZf728DPAT+PCXj+xS3H/THghyw757sw+HwfOAP+L+DvRcf/GeDftUyaP9u27TnwnRiL/xz4z4DvbNv27Movvpe9XCL7JKa97IXnT0zay16uu+wt973sZS97+RDKXrnvZS972cuHUF6ack+S5DclSfKFJEneTJLkj7ys++xlLy9C2rZN9pDMXj5M8lIwd5sZ+EXg38YEsX4G+F1t237uhd9sL3vZy172siEvK4npW4E327b9ZYAkSf4aJp27U7knR8ctr338JT3KXvayl718SOX/+Wdnbdt+tOurl6XcP0aY7fc2phaIkyRJPotJHYfX7nLwYz/xkh5lL3u5XNZ1+lzHH2Rdiad72csHK+vbwzjT2cnXrPxA27Y/CPwgQPKN37znY+6lU55X6X5Q8iKf67KF4nnutV909iLyspT7lwlTuV9jn1q9ly1yXRX4ByUv8v3ja+2V/a9ceVnK/WeAX50kyScxSv13YkqY7uVXoPxKV95fS/kg2n6/gFxPeSnKvW3bOkmS7wP+PpACf6lt2//vZdzrRQ/e/UB98XKQNR9+Bf8y3u+ysfgy2/Q55sE+XnE95aVh7m3b/iimQNILlZetJPZu7YuXa6PY4+eoo+GfXbEycNeY+FqMk233fBHtvesa7/Ndr2sMIVX3aq7LmH0f8nVXzz3u7PejOF7mwLnsufaLxkuSbe0eK/JY3o9iv27yXp/xqnNJjvsA2uK9zO/3OrdehEK/6vN+EPP/mij3xDXK8770dVOSV+3cqxx33d7tvcoHAsvo61+myOHqyrzrPh+SftmQD/K93s94uAK7SObOixh3L5LN9H7Oed55dE2Uu5eXqQS+lpb6i7rm16vC3/bcL6zdskZZlPVuBf9eFbtI/MzXpU+u0pbX4Vkve85tfSf9doUF9oNkIHUtJFeZp8/7jM97/LVT7i9TXhae/kFiyh82i/+9POvWNuhS8HUSHdNerjyeV150/7/X/nsJ/f4iYVAnup/gvUFmXc/xIt9/xwJ+lTbQ3sM26fr+ReqSX1HKPZardEDXOdddPkwWf5fsdE9jBd81wi8LpOq22qaErrIQXOU6YBYgfbmsZ3+24b3eg7J4UfLCx708a51e7mldBWaT455nge5qrzrtHh+7xtsWeS+G2IuEML/ulfvzDOiuRvt6UNYvQt7LQnad5VIFv+M8WLm/13XawaKxf19F4exSJho+0MoMYGkV+hIoMTMxwyj0bde8JJD5Mhf1572OME90kHLj+braOX53/Z14YdmOhPZlb/cx+vq6f/SzXWUxdf1Y+HO2LRY7ZH1Jn74f+bpQ7h8mpfS1kg9bG75fOl1wftaEuOk27D6GeADqnrpOpFDE4tP3zxoOyhUMdz+ze44YWtoFK8WS1RvvKRK3iaYBpkoBNupeaaR4sx1jqr6KUovhGdhU9NsUbdf168y2T7LZZlsf9D0ad9GiHRgbV2FsbSxiLz5Qf22U+wehfF4Kfvg+5KUHGb/O5CoBqedqG3ts5zlqUmo5yBrWHceZa12RFy+TOP5pj193nCLPkWZNp3LVFnDMx+70PjoUedrRpnKvLkVd1ylpVgffidLOsqbzevJMWdZsKPhwAWnMs3deYfs7dH23Yf3GEFiwKF8WrFV9tWVhjEWerVeuTD9t0zN6Mbsq9PM+9OI1Ue5fm7phLyOi/TwSQyUf5L2uu7y0wJ3g21kPyguwSkqUXFNnG0rrUiWkxSn0DstRMGFx5SFQ+NI/5hnChSN+pjSraeqMvKzMZez3olCbK1j3+h7VsthqmcdKOf4s5oeL4pbvgsVHt0+N/wcKnmrDY7P66u0PxjOysq6bbhw9ll1W9RZ2jBYZQ7IY6oVN/m7qTLXVauMa70V2tcu1UO5mb+KryzaLQUQa0A9Eb53E1sSuSdBcUSG+H0Wkle7L5oNfdwX/Uha6OHAn3V1nUGes64a8rBgMF4Dpc62sxHpdLQuQ/rmM6RHDN/rvHTDOOhq35vduiGRlF4imTq0yzQIrW491fd6mIq7dz20wS1dyj55j8ru+n1w3L6vA+/DKtuf7Qv/cEkQ+6PAUZIG7yvNeGmh9jmB113PEC2G8+GVZEyzAuk2u6q11eVHLXa+0840+IGnbBBn+sUKOOy+2LsC7iHqQabdRf9fV6PocLXoh2DWILk2YuAx/3PbFVRTccyrrF6HguyzbFy0vfKGLYJg0W9ifuy1kEAXf7H7PQIF33V9+KoXegSevraV7Qb5VoXU9N5gxKkpfz6NtSlDOkeO2Wf1d9xLRME28sIiS1/c/yBrzvuWqG06K5CCYx/454nttei6Xw1XueXZIPAa7nkXum3UsdPHzpu59Vu455Vyt9P2x3jDNyxV5WtGQsaryS+Ma10K5Jwdr515uk10DDEIFU5Shy7Na5uo64Qosf/fThtTOyoaMpklJrRUn1tvmoA8n/HNlxQWBuuekcAXXee8UredR8ru8pcs8KZHnXQTei4KP+yBWkGlWB+OjG4dunAVf1ymrZeEWRaecnKz8/cT9z+jm10OnRboRiMsaBdGkkUHSrXiz4BjvfXRBJrvmkijpbcpJJDZ89CIh19DnbMP0u7yKbX0ui4Xuv2qZs1oWNFlDsUuHqDbdJbEh2OVFZVmoQzafc9NQjL+Xa6dZQxp4Qd0QWJra8WAVe/wcXXItlPvBQXtJY2RbLQ/5fvOzzQCUt3p8o+VpxYCFU+wLBqyaYsM91+fr+3ZhjxtKSUMDEGK/7pJdbuoOWtxlconFAlfPqNumvLd5V89znS6FryfYZQvmNtZHXlbOe3P9rRbwjIaUhoaUiiK8BjVNmkEBTZNSSKDsEtGWb1OnrMWo2GItxi78trbYJd6F3+yDrqS9cF7UGxavxt71d13esH+G9+YJ6oVEz6XYaHJWOHBB7hZb83BmQV2X1SbtckefXaa0Lz9nu/e6a5x3Lbq7rivHXnZel1wL5d62SaeL8TwY4C5rVOOSEEIwKwpIvbWur59bC6GfNu47fc2mbiKcsdlU8PVm9Nwo7AxQXOcgicX+LBMobeBPpCsBJrh2ZCG643ZH/ncp+m0xDJFtUFlw+zpuP7H0ti0c3UpbP4983hUIdFZRqiZOpNhTzHcFFTWp+05+1qSkqVH0TZZuWNH62k2TkrtnM4tBrSzJmFK4zZLVx1+2oHRZ5SLbsrF1H3YFTLc9T5dc1WPTz3r5NUPYKV601rJozqwxVF7QG0/dPTrpiDvaZdc423y25/vO653Y+0o3vo+v1WVcdl1/l7xn5Z4kyV3gfwJOMHSXH2zb9s8kSfLHgO8FvmIP/aO2/O9WadvuIII4X10NECujbZannHthrSjBMpfWzc7LilWWd54nohW7ntAiGueLz5WBFfB6t1m6ovNrDHNAPlv2urm6othFtwkcsIvXC90DP7Z6ou9jqw+6ec+xKyuDNHZld1l7uxRAN5slc7BZU6cstyg2sebzchVY8e46ZDQdU0L6XxaL+DzzJc5dlnbS8MZlsKIcv0tiZRDHT2KIMIamYsx6FwsmDipfBkV0Paccq5879hS07GojgW2dV6Tm0sVk5Me9TSYKGTMK7pHfXbt0w1pd77lh5HTogkBXXKKT5Jo6bhEfp+8bn/8yMfca+ENt2/7TJElGwM8lSfIP7Hd/um3bP/k8F5PJ6fiv25SNEu2yb1PuF8tIccu1lz3WWcuyTh0/VV8njgFsa3j5Ka77poXa8ewxDSzDK3PYzh7QNLKsVd/hj4mlQ3m/F+7sepm7CSNt1WRhmzVZGNGP6WDAxqTvksusWhEdNHO+TUfSz7qs7OJkG8qOiV3u80ZsJprIYtmD9/p0/8cYdNf7XPU9t70zKKMBOr1EMWAus9J3SXxu3G8bHo36faXaWvd5N3PEs2y66KDa20uzxsxt/e6WAXVQrjbH14521QtdDAfF7/N+JV7stMRBWflMP6d+rpeGubdt+w7wjv19miTJLwIfe6/X0/ibtsJ2BdSCIBfh4NsZiJv1rLWbQF1y4QZGwnq4pKdW/W0NWEWLxlVoZ+aCTajI3QW2wC3uZ49OUQG6Xbi5ZuRszabrpPX5z9bL6G/7bGuAGtYZXOhztSWl+mhb/8bMiF2w3Nbndzx2HI+9V642Fh2tfN3jdtwvCGaJVaZuqRW7vkYXrBIHGK8KUcj14JJ09WgMdEEOV1nQdsE98Tn1FgW4beHW76yx864Acpc3r6WnYyFZgzCgtkIaQlyw7bTrmevo967FMYZqryKXQSm7xsRl4yWWF4K5J0lyD/i1wE8D3w58X5Ikvxf4WYx1/6TjnM8CnwXgtbuuAWP36LKAmh4cuuGk47sG5kXWmEQSZwE3G5Nlmxu67Zo6SeEyhsdB2ZXAsOo+b9u11EB9Xlkv8+3Q0GU1MvT3TsFmfiRp9xhCWMreO1wAmgA20LTW7dQ8f4xbtOoUx2O3bXNQroLAqrnWJvbvFxtzn6KsOvt4kM7NrUid5a4hG3/NtFMxxxIvMFqBxIomsNjVvbYl1MTXjQPLekESWcVebsd7yfNo0dZm7JnJvChUslXMQBLZNW/i5KCuuaZ1wXqZezhzB9wT900X/VnTRN+r7Fowtxkx7/eeSdu+v+zQJEmGwD8Gvr9t27+ZJMkJcIbB4f848Grbtt+z6xoHv/ab2uwf/jjQHcG/SnDJnBsqiFi2rcwQWlKXuTvbrPQ4gm8uVnusvcNl7nqHy2RXW2jLWB+7Yel2ZeRFSmOXZbOtSJW+fxwU22Y973qv95PFqy12zbvuWribOnVYPFjGjAqyu+M7KLP62bcpwF2Mom3eQ5zVGNItNz22mAESL2pdlrso9G3ejDyTvk6crCTfV8s8GHeXeWnPW//8ecZjPH4Fnt0WWI4Xo02oqYspt51IsG2RiI+L5SoKXd9jOT76ubZtv6XzuEuvtEOSJOkBfwP4X9u2/ZsAbduequ//PPAjl16o9RhpqDB9o3RZQrsCMF2UoW2RcT3wdwVT4syyYEDp37UnIBMykm3K8zImSFdA0Rx7OZ0rwGf1s3ZAI13Xi5lB8sxdz6nPv5w50+3tHGSNg8hirLmrkJRgrWAm88VkxEVZUQ7nZFnDYLggT8NYiuYNz2d9wMRP0mwHWyE1DJuMhjpNHXU2bqOusdQdHPMeg0i1LDbfWUTiL7aNZQGM+0IojMH72kWsqdMNaDF+Pvf7JTko+thwnqbd/VaH5Rx0H0MY79ILyLYFKNYNF8vcJYN1SezZVCrbV4uO1zWZ70vDtQ/bpFb9v03xd3kC8cK5Da67zODskvfDlkmAvwj8Ytu2f0p9/qrF4wF+B/D/Xn6x9hJFHdLIuni4+jjduHGAIrzupjUTT8ROuGWbkpTvdO2QuExpbE0opdQd1Nl8dw0lyOdx4lb4nio7kI4gnMbRO87d5VJeRttasTmZtGWkJ8lOjyhaPCVQ6K5lrXQwfV6UFXVtYJTBcBHSFq1Cl/5dqf4aDOfkhWnLPK0oWDk+fGPB9oqCisJZ97odJLCuMyfzcsVqmTsl0gUlxgaI6V97nFq0QCmdbBNjj9tYf17b59PSSTWMFvumzgLrNlaw0m8OQ1eK/ECMBweRNGa8CZVxuAzG8rpOWc4G7t6pMg7Ms6/UvNSGUG3nehbSkHWAPWtZZ7Vh2mCYc7Fs21VJxmoeLUTb4EOtg3ZZ+F1z/rIAdnzcNnk/lvu3A/8e8AtJkvy8/eyPAr8rSZJvwsAy94E/eNmFkqTbQhTRilU65CBrAqqkPlb+1hNMR6m3SRdFKVDs2vrQmP221HPduh1Ytq5A2GW9ikUWB5j0oNEMAj0I8o7EG3n/uN6HLmIUKpdMXa/q7KOiXJEXqwC+EKsw9nKaLN1QYp3QAx1MqGyT2hcvPFpxyeeD4YJBOqeiYPGsz3w2CBaVLGtoorHRNCl5Wik+fG3/TzcWhqJcOQu4UEq4ce9lvJz+4YL+4YKmSZnP+sG4EiU/nw02WFrlcB78XZQrmrJyC4VuX/3eui2lP8XQEet9MFy4Z5Fzu6pTNnUWJDldLKU0Qu0WL1nY5rNBAIGkWUM6XMBw4fs4q6H0nsdyMgriJDGcA9A/XLi+kc9Git9e12nQJjJm0myB1AZysSZd813Ny9ibDphg9h5p3a3Ut3lku6BJfZ3YiINuiOZ5LPj3jbm/CMl+3Te2w5/6+0B35F4G1FaO+BZGhpZdVm68QmoXe8MaEVn22KA7a+qifjb3e7PBPxaRe0iwdRceuQkv7a63000j3GzHGCvf1k6rZb7VrbwSTrylPZxoSy84fhNnjhfAePIIvKHHRBFZwvLs+ucuY0C3aZY1zCYjmJWQtRwM58HioY2LNGuYz/qslsXG88pzisSc/KZJnfUfKxIdaO2KM1zM+qb9y4peuXIBY+25bBoSnq4X9CGApZZ24dyGZqwMH31s5Ino59wWYI2pnPL+eVm5fozHY9xGG8+vc0Ei9sxVAuF6HIjo8dKt6GMPLeyjrnO6EIo4XvS0fPXlYO4vTJJuPDx23c1AC4N+XdLVKHqyVcv8UjaM7oyNBKSsNjS7aLBDONHiZ4w7Xg9mmQDrmLvbpfwIF6RubLfbatgmXUG0rvvFvwPOStfKUCedOBghpipmmfFc7L03FjYNaXUs4PJT2kA+m1u3Xq4lCk2Oj6GkNGscFLMip1JKtMtQEBhHygsclCvS469aKCgNLF3xbFzi0zBkr2isOvaW6joFq7j0550Lv22b2L3PIiUqz7YR0J6VrJeGzsp46e+jlaLtA00VdtZwWYWKXfqvtvj6snC7T62zHuvhBQwXgVLvKWhtpSCs1bJgpdqbrDGfLQun+MP5XIeLUqZiYADlpnEgEntU4uXqMeC8ANfQ/lpu/up57o+0471xyZT+mTeTzGJ53lyF66HcO0TTsuqOwdzFyhBLBzw0AKEFqieUC4LM+u6YzuBraRcW2MTalegJq59PnscrOQ/vbGV/yKSKmBGgcNH4XGURhc8VWiNdzyciVl2a+WxMnbWp4ZcAa7XvtraT1Cl18UayhvUs896OU/D2gzpjPYm4/Dt48vp9NB7qLXBvDUm7C+7cxeiYzwab3obtH4GT9H0DxZ6ZhJqLWd8pP1Gm1TJ3CwcYHD89bBy0I2M0tt7k2cTKD2AKZWSslZW8tpa5wBCSha0hrHVtKk4GhkrW2JwA+7fAG3pv18z+V2dc1N7D3KDFZtKxVpY9oBdex9JVLyYjf44zVsx8joOqrm3snFgrgyoOtMqY2IAqh/MtHqvpP52oJ9eW9teLTdA+dmcsZ6TInJXvITQExZBRnkLW8azyXiK76vxsk2uh3NdNElCyRIIGvaLE7rX8vi044YOT2+/RZVXF94uvf7HMuSAPrJxAIsveWUB1AsQJS3GCU0RjzDy8IcpIT46QfhjDD/69xM11POjGBxH1eRrbDBaS2k/+oJ6HfjfHh8dYcmWm2BhdkFsY4Fovcy6spSh85oNy5axcjQkDzmoXvHullKm24D0em/hHscrOtGvGhY6bRDCTxE807CHXX1U5wr6RsShKfTkbeMWola20nepTp1jkGcvt0zcvK7foruXaQJimHymjsrKQWEJQKNwpZFH2Pda2D7ZuBRj/rhfyDllH87VTVLuIVS0xD1nAhdUSx8h6zniL4VrTJxusrK7nizdZiZtfj40gDhce2AUBmWcLDc9NqrA3zC6DjOCaKPd2fRC40hAp9EhZhO7Mbgpg7AJ3UZXihoq52B6rrYLPzf1DJoi5XryApKEbpyaUT8KJrKTIAJJg0wbTxf5cKwWxBhq12MTLS6z447YTaqB+/m21QCQgabyGhZ8c2j2HzXeT30VJQ+jOOmVk31eu5841npROVKrr1FmDYsWKRb+q8sA6hy1WmI6b1AmuE5aJjQP07I5BLcyskhvOgzbV1DqZxNozrJa5Y4TEsIfrY0JYZL1U765FKRmBZeS+61jxBn2glL2MNRs3oLQkgaU6Xs6PPS59DX2sWziiLe7iz20WcYzLm+uqBdT+Xo6nSFJU/3DB9OmQ5dlNd711V718jLGl6Yzg52lXe+t2WXfFfiLoRdqfrDGZ3GSEC2lXJr3XLds8OHku523t8vYjuRbKHaLsMvU7sAGFaHdG/o4l/kwHXWBToe9KNNAUy/Aemnam2SdhOrWbZPHA1hCF/C6lCeLgbLRIddUUMRbBQr2Txw41XKSTTqTEqzAp4kW2S0RZ5cWKxbO+/cxj7atlYRgRdc9XvMzwSrH0GPvAskFcUE1bRyJ1GiqQ0rbLsmBdJyyzQdi2WQu1gcG0p9EdZOuoqimTV6xk3e1O4YmFXwduu5b1Mme97HGRtSzLihvHE/LCsmtknJQrE0daFqbekR4ny8jTmeGtaLGkycKg5cwMoLWwuPQ5rj07isu5PrKLVJaGrBIA7PNIldLAkiW8pp4rsaESxFKU56pF7i0n1gkHw5Wbk/PZwASynXWu7x29nyyQ9k8Hoaj54+aoLKLBQibvrbb/6/BW1srbOYhYTl0BfFHaLqM2NtrcvdQi8RwoxrVR7lp0YAUIJk5X4FW71zqiHOOrcrxesbexV+JIdhcmJrLhysXHOUtAMUBk8GjraAiOWtlR2TEugiaupIYhNhgetbFw9WdxcossTl0QUxczxy16jWUyKTZGgOfqCVIC5UXAlJBnAYvbzwbm3a01F3hsQ/+3mwwiAu+IFSvnRu/uFsau8gsd7Im19IssSGXmIQtRmhYaCbwAq2wPypXbcUj6avp0aKEY017ybG4xFIUtlrM2ANzzsDFzXbp9YFlnpmy0fo+IvWWuHcIXF9I++nj5u4spE2sRzXQSb0ja1nkpl+xVEJeuLg0Ms5HcFbOw5DnldwgNA3ne2sYC3Hn49taLkT5PL7a6cJ88p7LmNRFEs3e6stjXbjHX+iEyOqw4z+4KSv6aKPfwRbZBJrH1KSJWeZeFveF6afy3tuwAK+vywnBy8YyLtVISjs0hiqWDtsiygFniLXBR3m7AJJsTVW8MLJNSWzeCbYIfsGXlPYcs3BjCB+B245gm4aYJMPS4VoeGnTQUpRky3uIp/buKlBiLR72DWP4xFY+s5mC4cgwFR3+NF6sAymiR8SMQDRAkwsj7b2DW20Z/bZKi1tIXXUrIeSQJF9jAoPSZ9VzEM5FA73QyYj05NOdmAAUXs3LTg8s6No+usYs/3gNyz6IgK62YshqyXqCUtYQMKO+F6vwLDyeEi/JqWWzfHrL053ZaoXaRD4yqeMFWMJfG12HFVCz2OEZhx5CTWY+NxVFL4E1EnznvqON7eX7NArPPKcl02sC8UJ5a0CY6ZiEew1Dus51S7frnEgV/LZR7kqzJVOBR7wMZW9wSYIotv05udQRbOP60WF41VvlgWmLZ4yJrfPCqA/sSCcqKBspdWXYl4QQF3+JyT5kI2lqF0HKZWAUwVK52WbIkgq7ss1wscygtjbMDstJMjixrAsXtqGt20F3gsVxxI5ezwWYWbmkXJufK6xv6BogXZvkstnQulrlSxPaapbL2IovywOLejtdtn2NtswsvaFQAACAASURBVBJN3/R8f+h6+fIOmX/wC1uKIBBRoCVe0cpkDAKx5qLr2YDZMqdnDYb1bODHXQ3OqNl4FsIxEyiW6Hn08fH3WcPBOFTKXSwiSUgS5QkwtZeIk9cAW7k1ggghgP/Aesba0lSeVUytbeo0KKgn1+zZBVJYRwIDmveLFLt6b3O/qP1i6WpX5/lExykjRd5T5pb2RoWUoBPVNjJ0RWQOzTT8FhXeiySgbnbMbS3XQrlDaDmIdb1W1t5aU4kyT+0KXG2n4ORYryzdajfrwYRNxQ7WGiuNNd+1o5EsEplnpgSWoMjY/jwjnKil+mlhCul0UQAX+j2WPfNwwwvvNcwG3tUWbNtBFdaCKwmTvurEYLAdbuKKDldR44lioQlMMGy3sCkSYyXK3+CUrntu+35pVne6qk6hywCX+2iLBvz7nh26+63r1GQ6znreMi7tc9dRwpksunHAEPBeZDQ1BGYqgeEShqlfLMTq0krBMW96XMhxM/kO/4xiHcYzMSNs4yFBu/rnwj+XfK4okTqDVDOeYoWsM41Xy5yBTcaS42EzgztVSlrHwcQb68pDCTNQNzf1gLBqaWO9xOVkZIyKSQlDvTNZh/WqDaQMozxR7an7Kp7/8j2EBlh5QW+4cLkMq2Xh5ouUNEiHtQuMBhmxWmHL+F7CxgLiPAUJ3sOGBW/vF0CHW+RaKPe2PfApyBpr0i4rhJaV8KoFawSchVdjI/4eytjgUI/xShZCvE13eNZ4qCWw1FSwUAcNh+p6RH+LxTdc+oGvrBWn3ACXKCWYrHLlDobKapoc4pKBltaCrjOj5IJ2A4E0hJnisGvNDhBxVk3M4lHWorxTbDW66ySsl1YBW6v7IGtC+l8Eubjn0JbwuKU8frIZ/9BQlmbnSP8NbSfIONJ9LBIEsPHBwsiYCMoaz0pzLb04BG2XsWFVi0Eh99HKWq6hFx19rP6nPbxaLaalNwBia1vHo3TSUMglT6HA5DZESl2XHojjSy4nIouqUMbeWZBrYixczSCS7NuLDdg0NztrnfVgIgpvx9aTMZNF029lLsbKG3xf6kU3WqwvZv0tHl3mxnEX26XTEhcvXHuRwTmwgb+7oGrmlfwOuRbKnRYC3ElLsN0c3kIs2VwMtKWzVJaknCsdd2yP0W8fN7A0vCgGt7Kqa4oM43PZ9Azsz4Pxs80tw+o0cl2bYPLFKdXyuRtoM2U51kop6ueUibws3EBzmOEy8XBB3C7Spl07RZV4L0UrOzlGW5P2vdZKqet0d18My2LolpnQG0+dWy7eiMeDrTeiWS3Bs9t3FatZ/jlrjNCCk8VgAycWbNd+NuuFC4Uoa/2++vuudiH6TPeXhvPs4hbAUEu1cAuDI1DmWUdCXxEklQ2G8yConmYmYS2jIS1qFpXxtLaWk1D31Bizzv7WdfE1DVmLpiibG6bK0rXvK4bZEjPebOJQ2IYC1ymuuW7fUlnAsZ7RVrPzqq0xEsUGNvjuViRxTd7VIwkCd2bWi10ZL1biOTreqIw53xYZQRKUilt0lmLRTbLz2w9K2iRUSrrhl9Fn2rrSnbQNK4stLLGYlh3H6QkWu25deOiu1lPQi85i1NmCnoucRhMWJMVaBkJvuHCYsrN85RytLMoLxwV2noBTDKlf9LLMLwryPqKQYkWu31+O63Jx9TlDDwN1lWPQGHtdpwZKmvW9h5ThnrtfzBkXE5obKZNnY2ZnY6Ngy9ZMuLIC4hiAsnDjMTDGL/KanRRz6fU7yyJWZ+ECod9ZLzayoGjXX8ZdvPjre2X6eoSSNWGJBh1XsqI3JxGFXFlKqMjaKnttbefFCtmAZNUUm4XftEUdsZ6klPKqKaitwaFhHbCLR52SZouoVk6+EScx72otcFGkj2xbTYBhYsaXOk4Ur8P9Y0Wc+c1bpMCZeBAu70BDrBZSc3CwQJtZHQSndXb0yr5LmjWOJaUxejHktMGyPLvp3yNW4A6uy/z3zojZjbfTMXy+NrJmU9nq32PLRiwn2JxgWlnp38cYrE7DKfE94oViSOgmx66yFq081DPFgVdnAc0GrAULHLYhhDDpsc56psaHGxx1yCABo8CsktN1PzZqX4i1p7HdSeIxYJk0WsmjvtPWp24HrZz0u0dsiHI83dgMRVdIDGAaa/3KjvYXy5zJ07Ev0CWBtyjz92A4D2IH7v6CXcqiLh7KGG/9ZG00mdT7yE9Nq9PKWiBAUepxW8TXKgnHrlxDXw9CS9OxKlK3sbNmZoBniInFLsq2qcMSuuI9pVnN6MaMggrZC3beDEjTxikpodgGORVl4+rj6zIVDRlp2mzknkiJBQ3ZLJ71HUOrsIuRK++hRcWQeM323RlmrJaKLlwbdpPkWATMKPAW+DJnuczBjq3lbMByNmA4nlIO5wb+cXEj1acqEKzrFAHOO1otTZKcG4P2vN5w4fpIEwaChDohDQgyIHNsaGJW4mUtJyM7jju8kw65HspdFiFtvcQWPOqYWHkLfiUWmoZgxnj++LLnFRqEClnfU1v3eiGIGS76+xins5ajg1wsTrumF76Du1bk6tme0TUuQi69Wc17t78a4KAXk5Ff3evon1xXlLUO8On30+2eRefJ+w3tPxdbaF0gT9xxKf+6Whagqvg1dcriWd95MeBpjLIwuR3ta1g+Kv3z1bAue2D3um2UtSbWbLCNYdZayCSyyGeYhfE1wdhVACuGtjTWKc/hFgbMdwLfCR4vlrkeE3qs6HbXXqMdOwHt1maOlsdPWFoFogOmph0blTOQsyJ3ba1T78WyHAwXFFT0mbOiYNqMSNPGlUXWuHyh4J24yqUuGzIYLpwC16WEzbnmdw3VSJJZqhcQFSfbGMcAPw98E/Ca8gwxXt8FeGtfFmspgqaICqtlYcoF29r9KTXn5warFdhUoNDUEgIkm1TGcJ5WDDAkiEkzprLj1vVbx3MdZI1lTGkY1f4cX7BRaXaWsGbATLw0gQclBqh1WYe8b+WeJMl9DHOqAeq2bb8lSZJXgB8G7mFqun9X1z6qTuKAdwyTaIWqJ4e2mGQSk9jJHCUYyEA7vvD819h61w0e46XHBBPPDMYCx1xxUFEU7NFKW2Optb2mKAkdNBliF6vCB01cEE1ZkGSbAZ46mhAx26SLgRFbjtrK1KI/H6rPhhfOQtHYa1FWzv10Fl3qMdbaWpCGthnV7hFrSXscekwsi6CAlasxrhRR2C4d7/Y2Rqm/phJS4uxhsJNRQWClTSaZCUzRmM8liK3HrVxrZp9fsPn4mWw7anfb0e1sjRvhoOfRQhmLKOAAbshqsH00sMysykJZNWGFzNTeQzY5SalZNaHxocscAAwPpxSsmNRjlyOiSyxXdpGfTUYcZI3LTJZrmQeJA5H2pyYuSLvZ4DyElMuDrIHhPPRcZ9LgZiwJhdGU5jB1f4qyCmBCgVt0xraGmhbVgFVm2mQ6GXEx61OOpwyGC8PDjzJUTbayJLmpd3HzznqQkgcTzFnV9hp5GLNTXpTl/m+1bXum/v4jwP/Rtu2fSJLkj9i///OdV5DBrzHKAPdWNSjsKizWyxLgrAzOF3aFsWRlYl5049Rsubd2n53VlzEYTgCYzxoVHEE1fMTeiV19HaWvszDpSSRYIHoeXgiuozDtuP55l4LRXki8YMbW/TZ4wj2/DzjJRNXJTYJDCvtCV5js4rqHm6Kom8sgFmpkFt5bRKz4DZdcSwy3vYbxOB4lxoLPGkO1k3aKg8zOc7uwLC0f+A3aSf+tPaGAzhhdexjVWIHNHApwSVHyvQ+yr+hbyzuIywACD4yPJq4PCszYmTeDYJcoY51WHm6xxePS1P6dqWdT0pBRYZL/pDqmLNpdCYGyMUkQPwoyYqNFVqDD32B/KsVunrujsqKwxmIosQ55+mka7pYl1xAPRVcclYTJQo03WRRWy4LlbBCUCo4pyRuog+iWSUQIcHNTGX26NEIcB+uQlwXL/DZMNwD8EPCP2KXcRfGU6p+IShxY15b6NwPqHhfDkouxoRWuI/dt+egVNTAk+afnGRNdbAl93yUG3xNRi4bHiwdI6rvBfDNczRF9nn6OKPPODPgyDADGwZIs89Z84NYrrnWNxyF1tqLcW9cY0dfQyl9DCETfu7ZSEEXms/DCssp+1DVN6hR7ZvG3Bk9n7NztSi9aQ1yAOFbcMvFkUdkoqezeocYxrIbK85qVtv8w7yKQypDQ5RV47/jC5SOkWU0zVLQ3sbJnahDF7awXRvBen01u2aQn+lKyGrsVEU51phSxVP7U+Ho5nDO+MeEmE/tYdkcpPKSiFbJY9lJALi9WHptPbZ/a/pPFfDoZbdSHkcqogdhxs17mriQxNgAJivI7tHNgWRAkeznFJlsr2nLLmjyQNd5o0udJnyx7zut4ejY255UVw/HUXWepoK/+oYGwpvWINGsYH5p2rChMOWi7heNsMjLXGs7DwnBi9GmvWZ4rwxu2t3FGnY8Z2SCvQDmxgbZDXoRyb4EfS5KkBf5c27Y/CJyofVQfASfxSUmSfBb4LAAnH/dWjX6isg0L8AgLQWOYE5t0VLamcRyFkdC1EUUnyn2Mp5hpyEMSZ2SSO3y5da7xqjJR/vUyd8FMZ8lpSClWklm9EZCZzwasLe9dswtC6plWAuqaGqOTzwWLi63wDWZHx2fxz41r6AWoDhJg+sXcWeWAUzYgCr52SkUsns5NoLMmYBfofVIDrr9y7fVGzz4AqBShQBulqSoI2LwKfP9OSj82hsBtsTbkmNYFhuXZunb9ca61bj/w3kLNpgVXJpCl5MO5gzCC0g5ZbbBbR6cjCE4PD807LZbduzyNDycccU5KzYIBK0KvZjkbGMNnaMtbi8Vem+34UnzfrarcKHKr/Jo6Nclkel4CDKNKj45OqhrFGjKaOSXv5vq8rHBFzCJrVaA89xxlZRfXnp8rcQKgO9fg5pyVxhMYl8wtGiAc/YtZ32wP2KTMGbi6/LKnrogLEEuJ8smhN4K08RUnojnKZwLDZbCl4kqupxltnUl32+VFKPd/vW3bLydJcgv4B0mSfF5/2bZtaxU/0ec/CPwgQPLGt7SbitAqTR0wk47O9KoOUgoUVAEqlJWb1bja13VisO7xRcDiWC0Lk+ikGSQRN31lucJPVR2XMJtUnavfxSrFcjhndGO2gWHGBc42Snqq1RwkyBaxX3Tny9/aI9mw0BXG3FWKQY7tEmVlSmaj2StnRZPaxBdSVrWi4JWbNeE3tk6sEw7Gvj6MtlR1wFSsWLmOO65ODa4Z1+KxikXazxWiG16wwYKpTduUwznL2zgFJH03fToM9jp1u/5In2jWkcbXddujPp9gPUnf/wGkAl5BlC3rZc6ckIInSteXBagd110rdrDWptroez7rm3k0Xrp3HDCnSk0JC9lLVuCb2WRkFkLgoiz8+JF3Ut5pWFwsGkwuc7oJKoNuiP5sbNvQwjK6aquvRqrGdWkyvwUrnwsMZKVgRe+1r3Ix7jt4UYgA5n28ISYBVPF2ZG/dVW1ZMhIoDbx/pRN0zRjXFmZc9sYGMtNbKTpjMWb22dOCebpF3rdyb9v2y/bn4yRJ/hbwrcBpkiSvtm37TpIkrwKPd14kIYQLooCk3rE8qD+h3HdtsVBWJugl0Wlr8aRZA+OwcBVYK27SCy32saHj6f0mA+5sVgc0R1faIPI8xDMoh3MToLKYp7iFebminvUDLvHBMOQIg7LkhW8sUBNsWu+a1SMwgGaA6AEmWH4AUangsF4MVJxDb+wh+K1IRRFsZCysCgn0xTvXu91phquQqZD5nbaKcoXYNbquUBzYo6woh3PPLrIT7GAY7ZtqF2WpSWMW90PbZuZ9SrVzT1Ga1Px4X1lXLmPSMz7qmW1Lx4vHj20Vq/DMEK8AZPckV1ddK8SydZS59azH2rJApG3jUs2j8dTs+uSgMD8wa1IW1cB5PMPbZwwPpw42q6wCG6Rz5o2pj+Oqf4pRMRR4rucV2tjz303bRPx4aQ+h/dlxputDbYi003DpDYFxEmyCIyUBBBbqjadq7NXOSk9vNG7ep2lDTsWdo4dMhmM3lleVh/dKOw/ztKJgxYqceTOwfWWVuq4wKmhCvKBr5VyqvrdG6WC4cGiAG7cCIWsSQcy+epmYe5Ikh8BB27ZT+/u/A/w3wN8Bfh/wJ+zPv737QvikBHCWIYDsmRrsUQrhil5n6L1VS0VfWqsM1qZOXUAqTytWWcFEEmKkU449tzTmC/vnCwOJ1bIwi4/aVUjX1RiNp/QLc+yqKVjZZCb/XJnPghvOGY2nQUCreyBZrREobTahFIhgndpbs2AtrfgY61ILhmzPkwVKRKw6MApBvBGt1F0X2c/q+LsoaBXX3de15vWiLIuqTHHt1ssGImurFDTME3hG1mo0CrJwHlasOORZpd8Gw4WxeOVdNYNBKKKSKAWeBaMSyhxkIYtAWYX96wwX+/cs8QsHQFY6nFraS6h4g+GcQWqD3DSsyMlZMadPQ+r6TCzfvPQJTLIINE0KaUWeVsxrn3Z/cPzMtY3D2Ic+wK2zrzdqtFvvQyceaTqstGdQHMv2k6+EmMHwImDigK3iOuvB8MKNhf6hGauFGZ0MmDMvBsyLPg0ZGQ03OSUvKhYMTEwBX0wty0xylwSLZe6Kp72WmJvMu7hejLyzwMbW8HCvpcaVw+tjWDk2vNzJvFzljsHS/1aSJHKtv9K27d9LkuRngL+eJMm/D3wJ+K6dV0nXG4HGeLcg16BiOcfbhRHur+kj1Rh31gaW6jolrVOaNHPKfg6sxwZDHI2nDNI5OSsa63xl6ZwVuWMvHJQrjk7OGdnaeZNybOhP1o0TmEfoZIN0zogpU0YbuyKtVFp9OZ4GiSWFhTmEoRCkHovEQWNtKQSDI7IENxS+MHvMMR7f9gpPqHFNkxq8EjyOHlnqYgWJ6BK/5hgNudRuIuoFIahVUqeBMsrTiqbInIUv59cKy2dZuIV6dma06EG5UrECv6CsbfsLZOP38vQ9VlnlLkk+rp2yFsZqkgsV145RbwiY8WKyIxsGx5Og3LJpv1Wg3NZ6sotiH5p+GQznjIopeVGwsu2blytG6ZSKnAEmECgY8QJjdeasOCrOaYqUitxY8WnhPDDxLBf1gH7hF3SJB0jfzOoUMh8HWNtxL+K9bJ/QFnPui64a7VmzAU3qeAuYOIFsfrJ41rf9YO7ZP1wwYE5Kw5QRFQV95hxh5uwpJ0wZMWdASkPBiikjzs+PfWDWvpO0SUpDk2ZmPEjuBnivtqxxHgn4YK49pjeecnR05qAd7d1O9V6ypWVs6ZiY6/dlEJvaKHsSyftS7m3b/jLwjR2fnwO/8XmuJe6+zrSDMHAEtnY5sFnn3JS6TYei6GvSYU1TrpzyXD56BcoLllnD0GL0qcL8hLqXY9gBZxy7oGBl3SWhlB1bKs2UkeG5nn2Eg/EztTWfcQENU8QGuAg53qJAJMh6dGgGnwzMipwJNx1tS1fJdNZioLgzXLJOsMqL4rccfG31Cy9eFzPDlxaVLEj/LrWzCgG7AGYbil3aTVvMEG4tpq0vwYTzwvRxqqEWK3lhrK+cysMMR/jPytSlv5s2MjkPokAFf51ORlxYHr70u4wHvfhKUC8vzDZ9zpLLUreY+I2uCy5KwzgZjqeOUdXUKf1iTkZDRcHkfOzq5FfLwhkDph3CWiyzR8ehRyCJLrZCYb8wRsOIKdPC/DZI5649MhplsWf0LbCV2V6ryI2Cywy0dotTVhRMGBtrv1iZa6eQ3tisHWO8u9pBaRKL0JCdwA2CdccUys6gulZgXaI8oFWVu4WbrDXjrUmZMmKUTlk86xs2142Kh7xq+zg3VjwDGlJyViyqgWcZWaju1cOH3OUBD7jLgoFP8JJihQG+3/i4njCwbD8JRDZgQUPKtBqZcVQLjTWqNTVe+jieov3GdZi+LqpCgsbBw+3kNo+zSQrxALCDQ6wBwCXJXJAHu+LouhCaJyz48Zw+j5/dYjYZuUXnYplz43hiFFWT8iQd05AxfTrkYtbnYPzMufdhoLGiIie3FlRe+E5K04YRU+chDJgzZkJKw4Qx5xwxbwbMZ/2wHK4o72MfQTVuvgruanhGnyOsBREFw2jPR2QwXLg28pZd6hSFMC/6xZyCVQDPxHS5wm4wojF1aSdROA0NVVowSOchKyH1STdmAVxwzpF5RubGK7L3OTo6M9aowu/L8dTVFBEvrloWTgkPD6eO7aPrjoyLCQ0m2cVZhKl5roqccWFcfRmXGv/P08q1T84KSfNnVnJxVsLx0ibP+OqIeWoWruly6F1+QBKnjj7xDtOnQ1bLgkU1ICsa+sypUeVzrTEh3ueKwnmZU0Y0+DjJgDmk5ueKwli0zcAtHAsGzJ4Zy1IUm9D0euXKbW4DMD6eMEqnCudPofAb3+h5t23DeTMmm00YNvjewDpNbRbZcjw1i4dAdcuc8aHpt7xcMT8bMx8OqNOUY87duE2pTVC5GQTMLJ1gtaKgIWPybOyefQ3GihbrfWn6lOMLPvqJd5y3lFMxlY1cbNvLYqe9WFkYg/wMBSdLqWFHQiDcjnSbXAvlfpCugwJGqyp3ac1AwCaB0HV3ytp+Jq62QCtz+jSWASAp1qsqZ1wYrmpemGBJSsMpt5hWI+cmDS32Lcrt6aMjiyuuAhxe13keDE2RqxwfXZ9bdzilNpMsNQpKJtgTzEJRk3Kfe0jxJknh3iiqNF4GuPCF0DI17QpCTrWwhgIsk+Bvnayh21kU1rwZOKW7YMC8GViLxFiKCwaumqAevOLCiqUq9xJ2R9OkVGnhuPADu3CI9RlgwaRMuMkd3iHHKM8VOQ+bO+66DRnVMmd0Y+bGT5Y1nottcd7BcG76JJWtKWBV5O75R4VRVGLdrqqcUTF177uyzJOcikUxMBaZar+CFYPUWvh20buY9aG84Ma9c2fRm7FhFnpZ2KcMDVY/6cH4guHxhPHhhIqC0Y0ZjYX7+rKwNQWjdMqYCStyy5BpmDJkbJW5KByAAQsmdtyJp3jOkVkQ6pTJbMyjyd2gQFheVs6zEfqhJKT5RDUxkIxVLJtrxMo6oPp2yGWKS8YTGOUo9W6k/SsKpk+Hzou4kz60nvCY3Bohph3mTgFrQ6Za5kwL8/n903s+WVHm2KOej4Hchle+5cvcSR86g0TmfMHKtIXN94jZUMPjiXvfcjhnlUmSJsroqt1c6qnx1StXKIB2Q66Fcm/XZpWS2hZamWsXXqww87cfLK5AlQ2CyiATqy+lJqfi9fSUh9yhKCpGTJ1CMo5s37lmYpXk5YpxOmFV5M7Cm05GvPvmx0JYaNYjfe1dxjcmTjm9ykOXNPKEMeeuzjDu3mDwTXP/jAUD3v7yXWdFm2DfgkmdhpuV1KnJvJXg6CSiTEl5gI160Dh+uHMvrQhMIApY2hEIcGeRiiKITYiC0UpdL8jSRzq7zxyTOrgFsGik/7uicGkwBiftUzHiAXf5NfyC83CO0jMeZyf0izmTp2NTFEqyk6UdZolhdGQ++alg5aAwgFPMNZoiI7V9mVKzSgtIYcwT7vAOj7kFdvyIggZfU2U+G7Aa5o7/Lxab0G+FMy3tJ/cHo3BObjyGG49pPmFgg5TapPczdslEssgCjNMJBWahHWGU/H3uuTbt2zooonTm9AO4UGAx+SkwynqZswYaFSw14yXcxtERBsgdXbCi6IRdNJQgY91tUsN2q9QtEOoZXLkEYJSaeTVJb9I0qaOuvn70JnMGTJoxk7PxxsY+B8M5t05OmT0bufIIAItyYGrcZw3rs8SMpTNCVt09eOUbvszd9AEjppxz5DxME4jNLUMudUlm8n49VYvnwBoceVnRZOGuczKP3F7FNpbz9VHPPWmp65TpUxMh0PWjxTqQ3XvAdGoQuHEBMkkyqF2gKM0axumEhoyH3OEuD6xLXVBYu2/C2Fj4depcyKKsrIucOpe2SgsXgDW0MClo1boOkIl1kwm1VXozRiYr0zIXpowYYSbYlBGZfF6NXMffOjl10fmNpBwIFXucJCG9Gm3o21XHW4KOMf4n7Wh/YVUZRVWT2mCvTbkWdSzZjDbgJF5MkDlqxVm2NvlpwMIpL22tZzQWprLYvI2DzOk7JTJgzmNuMeGmPWbF+MaER2c3TVmBJTgO+xhY9lgD+fEkgH5kTEwZuaJmK3KqwgQmZQwAnHPkAnLnz47cuJSxKhDa07c/wlNwORXLyYiDckVm3f7z82MmttaLLKRCt8vTimPOnVV9xpFJpGFF39JpxdOpLMSQs3KcdmkPOf8hrwY87Ryc8TO1yH1KzXlzbJkndmwvzfOnWeNS62+dnNKQca4MLfGsMgxMtGDgxkSsqOPyvECAs+9S7LHcKk4Dr27KyMV7Bsz55I1/zhPGTJqxMcok8/y1sFyHeJwSpJWiag0ZjyTh7W28Ur8NvA6vvP5lq19Sh9/X1rtcVZ4VJ3Eo0VErfK0aKdFRlBX9wwXTp0O/cNaprx8VlQIux9ONpFct10O5W+naxUTjc10YvMfxhCVjMEYJ4jV1yqQc21XdqITP8Qav8yZ3MavtP7cWDoceJ751+JgxTzjnmDNrdQ+YMy6eMC1GTLKxq2DYGy44OTq1MJChVBnrfMWMEUOm9CWYwshZ7nNMp80xLj0Y2mS1zJk9G5kyn1LveekDnw57Hy6hLH2ZBOFSy+/6p42sC1PDu9ieqx/HCgALS5hhIpa5hm1Eoen631KcamVZBXGhKCCAzgQyAFgwcIrU0dcYOOV1wilnFmufMnIWb0FFkxl32O2zGdcoApcJKGwfUWwjpsZ7s9mG8g5ShyWnYsJNF0CuSXl4fsd4ULME66SxFiqkZLvWQNmjqTPHaQYcn1qYUOmNxlH25hbemhcL9/7GIzTsl1NOqMi5yYScFWMm9Jlzkwlja1QsGDBmwpEdHLJ4zRkwbcxY07Q+w7ypWIhXKMlYt00iUGNhg6I0wcenj45sG6/c+4yLiUmAM7xqLAAAIABJREFUUji2kzoNy18Tet1AYLnL91p0vOzAxrfOh8cO5zeB9pTJrG+CvnYTsBUF737+Yz5hTPpnbDj+wpiSn4u6z7QeMr6R8vj0xI+l22os3Yby9rvkaeU8P1HwgufnBa6stStzXXtG0TwKMlfLwnnJQdDW0ZelRPiFgxZ3yfVQ7m3iqYsQruh0JzdoxaJxdk0xunX42ClQsVLe4lOMecKUkcPfBiwYM2GOqfSWZo0LqlbLwuHoYCyThsy4/FnjeMh3eOjw0r5SOHd5wEPuOIU0YMGcPqfccpitcV89vUpwTPfey4gBI+WNZ2XIh9V8W10CocSUDy1Tl5izsu/lMEplXRvst2ZllYEvz+tpWwNbLrUoJNI/dn0lz53byVxF3HXzTjn5YcXIKjS5X03KGcdBYpRRvAO70PRZMLBwjVf+I6akqcHHx4cT+p9aMDkfW0WVuO0NbxxPSLOGm7a/wUzAaTri/PTIueyj21MDyVnP5LQxk/woPWPOmDkDa6GrrMQzPGVR2t5aihd8hGb8zGdI2kza9eSQ5fKQ5fAm5fETFyd4ejamGadwKIrZeBD3q3uAsVj7zBlhM0rJ/Ri23qFR9WNyKs455vTpLTNuz2z8xkJ3r9x7yHzW5+nZXZOOP2w9E2uZmDa0wcb5LAs8sbUdO6MbM+YMqDCGia8M6TnqusjXhjUfkR1g01o/iJQ/GBgsv2GgPJlLMgan5ciRFg6On7F+dOizho99AlVqdUVDyoPZXRc0XpQq81Tmk81huHHvEXeKh9zisY0DjZky4vTpLdeHX/nSq+7dsuHc1aOSd3fJb3bBWR8veffRkS8fnRFQxCFD5wh0GbuER3/tpW0TT0MiDJhq0bQ6wdoGw7nDNSWIAsbld4ESq2yFhjTPBtxNH3Bm8bEFffosOOKMJk2N1YHhtBoc2gRixsWEM46ZnI9tRmvPWcQ1KUNrcY6Y0sdYpRPGnHHE/fNPkmY1n7xxnxw4b46ZTkakWe2xYTuh8tvvmuetTQblmoFX8LpeuKR964QZV18dn05vr+uTu1KfPp96tzBNG4fZmlCdCQTFGyxLZu2IqVN+0mdioQhXf0URQGhyvtDp5lZRS//IZwJjHXPusHZhc+g+PeUEqZkim03c4pQJN1mUfS4Y0bv3VQcRgcFmX+Uh5xwzqcY0dcrR4TnTcmg2c6iNtTWtRwEXPi9XbmFZVXlYaMzBPqrd37YvLKWdwXCYZeN0XbtmbD2FxgfLZmdjjymnlWHsFHOOLV/btM+ZG2cTmxH1kDue5kjjlM7y7CacWevvtaWj4E7Oxqzvy1639plfiyxGDQ84KCXjoDR7oQoEUy2HPmAohc8gCOZ3KaW1sua3QTBdsloa6qaUTRDDbmSzVCeMeby8ZRR7hvFE7Hd6gXn87JbXO5Mea3o8fXSoFjnc3hDD177iFtcFfQfnVRiaqOggvadtXadUloIb0JmlzTP8eALFlxfo9wK9A9RV5Foo91i6MhxFtFsnARUwbqGuIy0JJ3laObe+wFDhxkcTMyCYMiFzGXwFK0Mrs/VR0rRmNIbJ2ditxotnfS7OPuI7YWnYKoZiZnDQvoVfJtykkAChtXSFaiZc60aKItlriQiPei5R+roXVnYEX15Ab7arezRKfQ5jGT4TMU0bx7wQ/FuCgNLmAru4bdwsRlzbQJEEIQXjndN3jB8gKAAm18zwlEKf6Vo4GASMohJl35C6Gidp1jhlJqwWgBNOLbZcMDyckr7mN5UQ5sScATO7YDR16njSsghJ0FMnUdV16rwNaZeD8TPWHJqJd5yZ7d8e2T4Qj+o29O59lYtHH2H9tkrVl750e682zGf9YAPrntQGB45Ozn1gtpgyIOVTvOVw9yPOWDDglBMmjE3AmzlPGPPoy3fsDl96vKj8jdnAeja2YuZsgKui6jxCH9B3Ac8gwOqNBCE+BIoMkA3ad20R9zzKS5TzcjIy4/kINy51cbOLZc7B7Wess0OoEzN/LSFCjIzZo2OGt89Mwlt2GHph4CHP4ZL5bMD0cGS9BUtbtrGXQkpZqOzV5TDdfDe9m1wd/YMgVmaOsUlzz9FG11K57xKdeu5wdstP1tmpJujqix+BSZFPs9phvHMGzsI858gG1zJWTeHOydOKoxODvJ9xbIJnNWYVVyWBH1cn5IXBhN/hDikNd3nAGLuQFFNqpZxG46nZYm4yQjbs6L0+dRBQZXnV89mA3nBhKE+av66hmJlnwwSMGTnOWu+SaOUpjqb7xzxxylVXu5P2zgvZqX7lqKqYv1hUA5fsYix5G5SsBoEil/PlmhKclQVRlLNPFV84a10W5wzLA89S9Q6pDyimJqfgIXc4r454+raBUiSDcjQ20M306ZDPZW+4TGIe9ZjNPkrv9lcZHE8YHpp3yewYyakY38iY02fAgkHh4yeS/JWXU5Zvv+L75DX7r2xNO4i3dYbf+MUqjN7rXzXtaReXg6xhNJ5yqzjlvDkmTRtOODWu/3IIBQyZusVNM23EUMlZ8dazTzF7+6NmuxwJuNcAiauxBHCR1TC2OPdMeYkylpZgKhcaRSMKWu+6JfNFyjmnWU0xrrpLOiuFH+wJ+17F7tuwkoxdq2BZFmbeTErWZWsWN7HExwZOczV56oTZ5z9qvhPFPsMviGAW7knJ+nbLpDSe0nIyCjZpuRguPayiiA4Chzos3T07Cm4lLAims8qVQr+qd3OtlLveZRy8IheJ3Tm30bTlj7pg1dJbnBAWTSpKSSaR6m61xb5tlTdbZqBJzTmC/d7jvqHGHc2ZH01YVTlPsxOD575d8rQ+Mnz3oypITBLqmsGVDUwxnw18LQkImDCjYuqYPlJr2mSmZt7dL/EDVaCZeFclCKx2UfBry2IRSuIgnbv31+9rAkIrKKzyKHALYb+oXXCPwnO0Byyce6opakBQ60QqzspCornerm81RNOYCpOjwiQajYqpY2RUqaedraqcWT0ylvjSVmjMYJ3l3LhteOWLauDiJSYpLXMlo4+OzhxTR7IJc6Q/zSIksNAIkwOxXuasz0qWM3H7Mcwk2Q1o1jMFyaS/lthNQkyflK+9y/GNc/fefeaONQTQpOa+R5yTU5HfWHHCY+f1jC0gIzQ8Sa1vSM0Ye5tQSdtM195w4YulgfMeTO1wwlLZgjfXCZS9YB/P+WxgLVZfGx7Y2IwFwj1ctcTzvkt2HmPnj/Eux/69ZmBq8GDmqTZ4bMxqLTuhiSJ/e/Py7pwzbGXKxENcdow5aLRW0IoL3pY0QifW8UOJh8mcHUZQmMLXu9riMrkmyj258gN3wTIpNaPCWHwA88N+UMRqPuu7Gi+iWEQ5CD9bUusLVo6zKynbBStuceoCdxUmwSH/1IqvvHU3yCY7PT+hPkq5ycRBDCNmNGQmaSRgB1gc0hbkv5j1OcuOfA0P2V3q2JaxlRozZz0/QEVp6GJVsQWvaswcWLw8xytc8WAkTiDFpcSin1ta26CYOwU8xuyaKLi68K1XFM6aB0/Fk7bV0libXdp6Re6OrcidQh2kc5rUZMVKsNp8Zxk2z/pu82zqzFAgwdXhF5aG8Jg560HWY5qZzRcYt8YlFy54M+ZhescEZGemHKwUf2vIWDzrsyptEtujHrxpX+g12+THTxgMF7z79i0/waVvLC1S5PUbb3FksyanDB3vXsanLJgjps56F4bRkKlr0wfc5T73+MLTTxvFUyfeAnXFyQgqFhpLWsZH5hVPCcFm8htbAxqsXdOVdaDwIGscV1vfqysg+r4Vu/R5VrOcDWxGecNaKI8SCzkjYMl4BWyNAL34go+LSHqKDpLPABLPeRdjy2WOq2vZc1y8Qm8gorZV3GAIRQmGWnZm7yq5Jsp9d+duiwobxsfCDXBdJEnSvqWKX1On1GnqaEsCl1TkTO3lfUKLtxqF49yQccwZFQX3uedoeLKdn65Y+Pj0hOJkxYK+fSbrEWATdmzquwQ2s/HU1BHB4IcrwT2FupUlxgLRCl0PtpghI9a9Lv1bA1lrYJ/UbhOIXwTFApYyAPK7tENTpzRF6hSLWLALG7TTQVGpVeLpaZm7rkAIKT7RbE6fCTfd4qx5yyOmHHNu+8LQzZ5YbTVtRj4pRWhjExV7mAHHFes6NSyEicWdLS6+fnTI+h70jr9KXq745S992gTKSzwmXsN6nFGVFf1izpgnpIe1wbGXhTn2dd/eveOvcnzjnD5z0k80rG6HFEGRMU8YsOAuDxybZcqQW5xywmPGGO70GUfMGPFpvsjCMr8qcmpSHnPiAqZv8Skent4xG2eIook3QBdFPutx4TbPkDGVRJBAY//OvGdZZx0Mjs2McU1x1AlJXUr6MnjhUqPPvYdJSrqQIlzaWxHFLW0yxgdJM/u9KHOx0EWk7O4xngq5VNcFP17At6d8Ls+y7IX7Jmx7fxWTeJ74Q5dcG+XeJS4BQFkBQZR7UjIvKwY3fDaj+ZlvsDuknsPg0NAexd02qdkryVGloOIBdwFPCTzizNbeyG2yR8Nn+CJThsxvDPjKl29xQc74xoSi8NbplJHjt1c2tHrCKc1hypPDMYtq4GqyzMqRsdSB9RhPv5IBJNbHI1QGKiE2OiFkzjgqpN+fU3bWMV83YEsaCxxjnnkeUMtcYJXGWtc6eSbOBm5cctDAegI6AUgWDim/IHRESeY64hwpdAVwlwfuuDkDl0DkxoIo9gmASlYCZKcuMttuM/tTJqtt04thbko/f77nYRNRdEuccjMh4IwBC165ba3tychVZ5w8G7tAeIbByW8Vp0hiz5QRjzlx8QnhoUsy3RFnnPDYZemec2TH5mOmDHmHO44JI/DRgoEJmn7prvFIdJBuaMeMjKFj+15SsXLZC5WVZYOYsaQ0UCkKtFbjqAooysaLDuvF7MpLuUy2LQ5bzxel6CAN/DyRhVoWPYFXROGLchdlL8eL1S7XEqPKeTt0BEDVd2N8KfNawUIZLlC6URb5kvaQNrmKXGvlLrKVz5kZ3F0ocKJQGlKaInM4cUpDU5hgpsneGzNgHlAXhVomikM41COm3OWBz0jkyNYVMZ0y5gmLcd9hjTmV22Mxx1jvZxw7K1QstcecMC2E5V2YnX/EsswUSwF8cEesC1Fggg/GiUvaqi9NXRJJjhikc0cblNiEfCcbEVRp4WCXOX1XCVDKNTyuTgLq5DFnmCzIO7ZNJq4AmogslBNusqCP1PQwiTV9TnhMahXilBHnHDFkyhFn3OEdHvIq/4Rv44xjzk+PvHIRZXJsKG4Xy9wrhEelgUxUDRC+CT/Jh8DngbdL1vfs57cx2y8ClBWvvH7OUXrmPDcwC9Gd9KGhjB4NuMNDHnKH9NC0xy0eu2OPOHcL0oAFtzilYMWneNMtFhVm0btp22zGiHPbLhPGDj58wF1cKWgbx1lZXrnMB6estNUuGZUOqujYY1fG2kT9rbWDoz8a4youSLFtjsaZqNuKAcYQTvy720O5TgOFbyBRUeiZN4ocPdV6c6KoH2HGxG3VPnHCn7y/o4Xa797GXCeOc2kWm/aWS/t8WYvb9k/RGbdl7srv27576QHVJEk+A/yw+uhXAf8VRu18L/AV+/kfbdv2R3dfbWMXPmALH3aZg1DKhuaYydnYpPIe1k6pCByQYoJ/R5xBCjOrvKeMXOBMFPucAQ+4GzA3jjjnM3yRL/Bp95mUS10woGDF6rBwafNjJkzt5CuoeMKYh09fZTBc2AQYAy9IYScw6eyjGzO7TdhhOPF0frFW9hP1++uEkXaxWKzFXtldqoShsmoKQ8W0tSp64ymrUkoGmKxID3Wdc/OG31i5JuVO8dC118pCBJ/iLW5xylu8Tm5rnBxZjrpQKxf2eGl/UfhSrkE+T60Ff4eHTBnxU/x6d70+c1bj3BVxo6z4VR97i4aUL731GZOshW23twkt9SEmeaW2Fu4je4wslhYbH942irl/uOAu/8J6Dyvu8oA3+RRTPsOp3Rb4DqYg1V0ecJcHAO5ZJYGuzyKoISMK/tQudKm17KWNP8cbnFuDwLThkMecuPjE6dNbhkuuKwhKcF0Uu2D9YmkKNCHjqIuhobfLc8pKMTYcHtxRIiCIJW3CLrsSbi4rIhbDOLo2/MWkVEl+uvqpPJeqhy+yxCh4aZ8zvOUu2Pxr8i54OEWuI56OUCWF/aShULlPBqbWuxdRznoTma537WqHjcVth7xn5d627RcwdhBJkqTAl4G/BfwB4E+3bfsnn+d6XW5HZ3lewf1sw4pbPpsNyO+tOE+PnNU9sKnYZouswtaVES76gmPOeMLYLQZSKe6X33oDZgn/8jf+U6Rs5+/hr/DjfAf3+SSNnYBTRo6pIItJZeudAM4zaG4I88bunGMVv2bVjJjCCSyGc0Nfe5MAH/YDBaOIZLKKNX+PgHoFoJNG4m3Y0qzmQg2k2dnYWcH5jcox/yXJZ3w44RangM8YdZuVcJMH3DVeC35neIlp6OqYAuFIqjgYCOOMY8dcSmm4w0NXynZBnwV9clZG6YkysKUfUmoeP7vl3fEzjNLWk28IHLe2xssrvv3u4d3zf8kEVu8ePuDX8Avc5QFzBg4aOuOYAQve4HO8yeuMmfBpvsBjTniTT7Gi4A4POeHUxlgyV7pB8/DnDLjPJ50nsyJ33iOYoPRD7rgx8pgTzp4emQ0y3v6oV94aP4bQ8hzj9xwVZaStdJn5sUIKLNCQY70NCxZqZNfnlwVMO63QiAsfbOJh2T29468a40QvSvfx8NI9vHc7xsNy4sWJcSRKHTahTlHmmTpeG10x2yX2AHS7itha9NJmWll3BZq1yIIQeDMbR3l5UbDMbwTeatv2S3ZXpucUc862AbCRzKQ7RgJgZcK79+8wtyncwrgwlDZjCZ5yixNOOeLcWehS+nTCXUchG94+Y3b/o/ziT38z6bcZN/kLfJpv56f4HH1GTPkOfoIf5rt50NzlKD2zi4kv7yqQg0AxUnt8yhBT7GqMlAYVuOOT/HPODo9J7zVMxyYJg/ulgQ5kUOqBKbjgbfuzxmHusqm3JF/Jdn1S/lbKpAJkllf97iOjQFZNwTmF24SEGurXUvIbBj83cMm5Y7TIYnaXB7zB5/gcb/CLvMGUoQ2/5q7EAxhLVtL/73GfW5zyRT5jE8vOmDLiiDMm3OSYM95sXudu+sAtxEeH5wwPpw6OeOfZHWZnY8rb7xquuUw4scAy3II3ujGjeS1zmyKv65SPfuwxKbWFhszPe9xnzIQ3+Jxjrjxh7KzzT/GWSxxa2AVgRWHbpWDKkIyGWzzmMbcs97ziC3yGc44CvBxw1EthCwksdsqJCZS+fejH/5t46EF7caJUJOYgs3tImD4fWOYY6xwUhFB3Wt8i8XyM6cpXxYdFaTsFpRVa7AlYVtnB+Bnj44lhIoFnq4iHJouavNNts1E2jxIPzclxE8yC8Mh+fhu/IMzUcWJEyblSP0gHR2W8BRZ8tPsZsI23rn8G0rFwftBsmd8J/FX19/clSfJ7gZ8F/lDbtk+ucpFtD+s3SjY7v/CzPeMziMIbYoMdCcvlK+bYo5qbTFwA8At8mk9ynwljhw2fc2TcfMtkEYZCdVgwK1v4kYTP3XuDyYmpF/NFPsNdHnCTCT/Bdxiru055XJ/QFCbJJaNxCmDC2CkLud/C4vaAw/dXNtgqmZjjYkIzNDzlg9efsR4feqtkhuVS4yP+Yqkfw/DeV+gfGmtWCks1pFRpzuTwJrr2usBRQkk8+dgpD6s7lsKnasNPYLl8hfNvWJEWNXPuOkaHBFfFMv0cb9jF7JhzjnjMCfe472qdHOG55LJA/CJvkFpFOGWIbBLRkPJ3+c3MZ32+gKf4HYyfcevklP7hwtSDccH2zNQQKQf0vtNYwSdHp666nwSNi6OK6XDkSg2fcMq38tPIZiOvY+iJRmHn3OcefRa8zluGOms9vD5zJtw0SVM2RmCYWrljEd3nHqfccptEPOSOyyCV2MFgaDJqhY4r1UDdptRZ40s4nyV+IdfWt4ZdxLvTrB+t6GPr3OLA26zseAegWLk3HRZ6l/ct5wYLgGW5OAWuPweVC9Lwyr2HvPvoyBQBc7sVwcG9Z6zfPPTvW+KyQ3kEB98wZ10fhu0kHp4YREvMHNMJZtJOMzaDq/JPFL32gFS1yYDXrre27NwMPF4IGtcOXfj8ZZK0bTfefVVJkiQHHgL/Stu2p0mSnGCarQX+OPBq27bf03HeZ4HPAvCxj/86fvoLW+/hBoqkRb8J/CTwG4iCPsAYeq99NdgKT6wkgV9OeOwU+znHTsmdcsul3z+uTnj6A7fNPW77zTFG42mwuYPgwhP+f+7eP0ay7Lrv+9S8V/Ve/Zp+O1073ds7TfZyhxx6ybWW5gZr0JIsRbTkGLKdH4YNGTAiJYFswAbyVyILCWAk8B/Kj38COAgiOP4hJP6RWIkTB7QVUxFhSrSZLMWVll5xqFltkz3s7Z7t3q3eqql6VfVeVf4499x73qvqntnlClrnAo3qevV+3nfvued8z/eckzF8mDEZd1z0aceHX3/so99CKjIlniWi+Sg0xevwLJP8F2N48g99J3C3h6loHvcddniLYGYPVuJAOiFwcnelGoxaDAqHKK1OMztqVKk6NoczyWPy9sm2OCItpg+C62eSUXGwde5Ty6rPQh3UqpHPaPH/8BIZQ36Kv8nf5Kc87KU1K2fOwvn9vMpzvAbAUxzzCp9hmzN+iR/jt7/9HFpaDuDWRw+9IxHw1EwIucpHZZ/t6MxHmeoY0Dw1p46xssOpW1RO2eeI2MFBMk5kUVTnu55fnb16r/81/5HrnntsuxS9Gr2qTng5ts2D2U6lTF1RRJ42qZG4o4uelINUSGAQyqwtz7oyFhRj1mb52apN9qgK+zreXmNSrc01I6yvCiTU9n7YHPXjqJ/bLBSaHlfrBeQv34CBzPUknTE+fLJq0Vrao1IbUwLcqfspm2jofjtAlCfrr1BmlWrzMQH20fNaeMZCNJhtm5ovplNcskPoi6oj2X0etL62Wq1e3HTIByHc/yTwF1er1Y9u+O0A+D9Xq9WnrzzH9312xRd+bQ1rq7QiqgYcDJEXcJvQ6drJ2YKt3XMpaed6WYW25JN5ggcPb7LdDdACSFRmwlxSuR5eh39AwO8gmG0FMFiw+9Ejrx2P6EvO6Ps3A6dVV/ICSIXNsbd9jFbxGZV9D5Xkys/VUGbFSJX6mAG7C2+e+ki2k0Y14KIHvU++RSud+8owCjf55FFFg+bgXZ9cqZXMXQ5pFyZuIyrdwGzefpft7TOeYMhTHHttXf0FGoijVoCmD9jjTd+vv8CfI0aiWRWOUOH9h+/8E57nN9njTTpMOGObv/rt/4yeSwcg546FneQWahXOn+AuOzzgiH0P54DAY2fOWtIoWm0ZQw445JxtOkx4lte5zT0KIt5kz+doOWPb0xandDhj2wl88SMcsydQnhPnWnlnQpsxfZ9/XhcZCYJLPN1TM5Senw+8haqOblvcu2nK2fmcLYaWqOmnfdNxZCEX26xQqQsOnW+P4KPXmSybNPTLymVeCkFU7jEId81pNP7Sk/DpBRw24XYO33S4iOWjW6z7xH2e1bapILbzTJ3rB2b7LUJQ0gHVFAYqtK3mvsl/gf008rZS7nKz0/iRfXSFcP8gYJmfwEAyjUbjqdVq9ab7+m8B33jsM11G/ymiEC1nqV4ZstqqCarwRN50YdFOU0znzGPRWB8gOWDa3Snf/pef9Ndq7r5bTQh24v6sMyYHXhDh+Xz3VWeWZz6dquf46r4QVvBxg8XwOt8e9untnvm8JpqHI81MbhI9TgW2DhrXJ/1bp6JlH+4Fs1vNyhzGJ0/CLXi7t+evld+/EbDDGBb5dYZFRDaQAJvBlrFydjoMH2Z+YqozNUMqTdVT9CqL46bLq/PA5Rvf400OOWBOixd4xVsTX5r9sE/spPDP6zxLx8Ec+xzxS/won/7oK2xz7mEztXZAi2KLdj11fotnuefymL/jnbS6CO1wSo8RY8eSUmxbo0G1nuaQzPFj9j2zSp9HoZ0JHV43WRjbLgp3TlLh4WtQ1h7Hnr7Ycw5SeZ4AzXVMwZQynbM8a7Kkw9hZcwuasOsEQ66CWgqP5LHB47WlRngXseT+v6LZSkmX/q6thodvcopujEvZ1Db9ZmiX+j0f9tnaPYcB3Lj1gPlAUlxc3N4WQa9RwArNqKzYRYS2WjKWJqr+mG8S5prOI0tztLRJex5Ll8TsYwW/3e4FvMHdr1r4ruq3300qJECj0egCfwT482bzf9loNF5AYJnD2m/vqXlNpIiNkCRoxYW7gjoUjba8KK7D7rvsbR9zfL4XUuueNWE3F+3XJAVa3BfHoTfTlNOqL1E95i/D+OxJ/vntHyDNRqJpqdYNhMrnBHPZeuNPGmJCItuXMSx2CZQsy3bRgaP3MGyy3I0Z4SCqs1pghJqbSvXKG4zjJ4MjycFW+jzZYMid6C57HHtnJ4jAOe7uicaZlLR9lG4oQmKLaFhWzDbnHLPHEftovnqQRSOm5E3n79D8Nnnhyo05WMyycJ7nVSa0uY1QHdtOW1ZoRGvkark5De4Z0WdKh3s8yzkDFwG67SGYZzjkJg/8MTNaDDjnVZ7nkAPe4MALdoW0NDlZSSzF088yrqVzssGQKCq5x23vtAbodUe0ncUiluHc0SNDOuOY0scbVCC4wuUssTS+GIHgLONlE1fda49hAZDtdSnEFVCBfj5CPBjNs2I1XCK0ACoF2lUZusSRq/ssC9l2Mzll9skWUVRSFJFEdet8s5Y7VCmL6njuIfNa5wEEzF3nmDpKLTNNFwNFC/R6Y3MdSz2twzSVrne8/HpfVJ750TTHx2nfk3BfrVYPwQGQYdufe+8nYt07rk0jznS11BVWV0jVbO+5/41Ztji7zlERsTzpstCOHiOmnF1JNZJP/5SC+E23/y3CS9aXdtIkj28YTrl5Hl25c3MNpU/pwqHX1f3oaWDeAAAgAElEQVQU7ompag367lUTyRssdx32uis4dLM3FVNdc9EUrj/s4EqB3op08I5PfXsQvcE2gp8/yz0f5n/EvndCQmD/KB/7CSSv/TnbZAx5nduOvvgmI/o+PcPRxT5xXPJU95hTdtCMj88m91yN0oJ4SyJdz9nmsHyGneiUKW2O2aPP2MMWIMyRH+ZXiCj5Ki8xo8VzvOZhLs37kzHkZV7ksHyG/ejI6dghT07hnJ6Ki7eY8VVeYkKbQ55hSMao7FeinEEw8vzkRhgH6ZzhWcbb+c1K7AXAOM0YuspLnWjiF8Bj9rzfYzTsC45uhYRyta2iba0zHUubZu4aBEB18a9rk4/6P65DOfXPJmAylfrWrG+oncc46+09WcplEfni4JpwbESfwdY5p+c7LE6uV+/LJjrzaTuQOazatmr3Okcs80wVuSHBeXpZnAkEC8FCxPr+baSvLgSV92X7tSboba3kq9rvJs/9A22rRs2rXPMw68uwVC+rDSt9yQpCd8zyrBvYNHYFt9Qlm94TRMC/TEjPqgNFrzc0/0PQonQfXYS03Xfb1AzUa1pKlsf3hGs9GXdYujzQaxWXnMmtOOxi3A6wlf7VMcGenDfrDj2skjGUEHlOKzzrU27yJns+v/uIPne5ww6nfHn2A5KtEuhlI3rdETs84De++wKvZ8/yfPdVj8H/6vgHYJjy2+lAfAMH4pDd2Xrg4gPGaC3UCEkbe8aAAsnPE++UDhcf+GCpfY647TJ1dZj67ImAD6qSeqNt9qJj7nCXT3DXM3C+zgsMyZwDs82b7DGizztkkljsZBA0SS2fZ4WFmbjLb3YDfKdjVMfjbpO8d4M8hbdj6f9vx8+K5Wi1Pcs/L2p/dmxZQWOddlfhu6qIUNt+GVxQ/22jwOfytsmRaK9j79M+QwpB4MVrsmB7502xisqEMnK03bwllk6WU6n3qs9sFw7VypXT7uFbqrJF34m2W1QXXghKmF5HsXy1AOrC3N5H/Q+qC2hsF8XvXTR/OIT7EirFnIGK4wHWhbuu0Bqg8kmClqIvuR64oVr/CVVNOSUkf1IPgeJ1t805hubTntc4Hj01amz202tYrrHVxHLz3SVlUtiiLGLKuGTZC4UHNF/04v71cF5lBOg9WqpWKuftdUdesGtE6IyEB+xw7oKIXuEzfPX8Je9sBVf44LDL7/ApYSkVwIvQ+qFzTr67xwl7cJYyHqf885N/HXL49I/9v3K/pML0ySWiMD+5wXlcMuu2PN9bQ/tLFz3bj0Y8u3PPB/Pc5p7Hsu/yCb7Ij7DHm2xzxiHP8ICbaHbKfY445ICSmGe5R8aQN9njW46dc8gznHKTkliyPp5cD5Gs6lsBmXQ6sXW7siZUOGiuH/te9U/hL/8OGlA0q+NHBYoVStrqsIvlU28SHLBBcGw4L1w96+vafX3/YsM2bVcxRurnjglQ4dhs6zlh5xSr3u6ZcP4jCZbLeIdp1IFdGKVSKWusBINeKXNjdwFZM8wLXaDtnNP71U+rPGH2tUwbZdT0CCSLgGZW34u37qi+l3jDtnrfgIy/97KQXrLLh6NdNWh0e4rLhZ0LXc96pq0ptWlA64vbXUia1t3aNeNVGFgQmDhqrukKrYPxDMH7MwIclLn7212QHoyCE/M21ahC1R6shpXjolFTxlkaBpfRQhZpGgaO1Tp0MbHPbQW7u868TOhEou1r0q/X+H0enjj5ruDhH39aaKkPih0R7Pe7gXXwglyj+cK7PBe9RuvpGf/3b/x41bEdwzd++V8L9+CsH12Msu7QB5Vpk2CuOaOiDxHc4Vs84CbfYZ9fOf9hv9+Xsx/0OehH9NnniLvc4XleJaY0AUJtHnCTL5c/KLxoFdD67lSg63ft10PWzXHbrMCsCwpVNKxQt+a5vm+7mNvFvz7BdT87lguzbaMmyPocssfovdjnqf9fF851aFDPYSEfpRxai1qP3aS1ax/aeaB9otc5yNnvHqHJ6RLntzhnmyKKyLZd9lFTbWviqJv9Ww+E1qv53O+5ayi8audQBRYz/XWfEEtzQHDOqtNVFwSVParQ1d/5VQLe9mN9vw1uEt9P2rdXtA+PcIcgZK3DxZpYA7hx+7vCCbf4NJhMbq5U2LC7rumnCI6nmL2HL4yVoML8FoHLqtqa1aBUo7tPmMQaLbrbJL91Aw4WvsINpOtamIV1dHAdEoSENQd9/1CdZFY46Z/1AWjwS564CF7JbX+kJd3udwMuOQB2V5yXA6kSdfaEQBMKZd3S8y+4s33X87/9ANUF006mAxdkUnSlr17IabkMiAkz7pW3pZbsdsFneIVXk+f59a99P7/+T1xf/CV5H3/6D/9tyTMz+xz3//rHuZ9B+kffprMlTJVXeEGw+9k2F4e78kz33DkOqQrw++6TCYIPnwILYAo8AN5139VMXriD26J9j2+4FzEFbsj2/Drcvx6OUaFlg4bq7/Eqba4Oz9TbpvPVf7MCetPv9X3rv0F1rLHhfDrWbJSsjme7ANYtb8XB9bnV2hkC/xA4gFs/JoJ9RssHAiqEJ4L+WOoIJMJMOo+3yQZD7yvpZSOK3oQ868iF1LdmF3kLj9UdshCEtcqQ28AryNjyyibVvrYWuxXS9nPTn86d+mJtF9m6dXRF+/AIdxWymit6XBOGmVSu347OePvsadnHmlm+Y4wzVj3imZRCW36jGxICWaxMWQlQxcWtGW6xd8XXdqkOYqsd3kcshF4z4PRWU8P8X59AVoOwuKxOJB2gmzSsyqLlPnshC2B+KDiwdxrfc/t9Hj/43r5/U+7d+iF6oAEvt54+osOEU4fY803piyc/JcFXszxhMWiLo/fsujAp1LzNhXViQ+8XL1/nJL3OP+59TK55sIDbEoXcvPUuL33fV+kz4tTRWPm0PH/+yg3+8e6/Ldf/JgEmOXPPdR/IV4gQHiHCvADedn/vuj/cPgVBqMesOwb7wHW3bwy0zT56bAw0giWFed/2u/1f39ll1utVWnm91feta/b1BcMqT/b4mtW4pi2OWT9X3XK0yokd+ydU55cqBWohH+KyVklOnud4DaW27nHMqzzvUyUPXCqRd8jYS445Y0AWDRmWkhNJ02yUn5wLq21TrWF9V6rE5Ob7wN3TNwia+yvu+F1zDquo1f0otq8tXIo5Rn/Xa+t91QV9/Zgr2odDuMdLmgOpUA/CjR0DGnrczEZk28LHfjDbCcI1B3puQRinEK8C3zaVSjLNgfDXlypwdQWGMKAKQt6IHNHYrTC3k9EuJtaEzM1virfqYLV4u335FpOzk12PtZqEFQB20tQnp+5vtRJdoFSjUotD7+knXVh7jqRHjZtyvA7iPwo3Pv1d+pEkDLvJKd9hn3mZ8PaXnoYXpLrQ8/wm426fUbdPf3vEb148T+fghCwZMtzNuPjVXYiFH/8GB5x89WMo3ezJl77DW9+9Cf8k5don5zz3Z14hFDHPeJkXQxDaJ99l8cp1+JK7R9XE7+m7fddtVE18wrrwnhI0cu34NkGAq+DW7dfdbwAdt80Kd/Merbl9mZm9adKqoK8L5Pp32+q/WS2wbgnYtkn42N+s1n3VOTZp9VCNAtW5YRey+iKimvIh8h5P8PEJGUPOGfigNQ0+A4HzlMYbUXLb+VlGUZ+73Tv0GXF88RRRXNC5dcrFeHcdth0QoFK18D7pvp+4e3rZ3bOSLFRAZ+a7Nuuwtf1ix4W1rDPzu37Wj9GWEmTeIxgz33OE6gfR4he/b3Xj5X8Uwsgd91eTXN3sPnCVbIS+pmXcylLoZIthXxyyqXlorcwTFyGy9R5VrP0VAk6uE1EXDvuiVWu25jJUBTtUV2PMvtacsh55a7rbpovBpklgMUJ7H3o+1Tj0PFDVjqzj9RXgr7oaktahPUQ04VeQQf79sPup32GHB8xpmTqfEpijuVM0SEfT1T7Ha7zK8xzPBMufjDtsb5+xx7Fz4JYcne+zuH+d3e/7HT7DK7zMiwzPM5J0Vg2+0j/Vzl9BtKkTQsShh1O+i0At7yIau2raKoj1QZvm/+vuLzb/q7A3pdGsoK4L7k3a8ibBbP+3WPymferbrtpnkyCon0ObFW5166/+e/24+h9ULRVqv1nhbRWgnCqVUMfpl5B3+qvwJz/1dz0rqs+I17nt0233kaLzY+czygjBdnu8yRH7HPMUY8eGejDb4eLeruQfOuyGMXVIoCdrX9wD/p7Cdmrh3YKB89fdouprswFU2nSu1i02q71bfL6O0WvfmfeuBe41HcPb8a3f1QjV77k1WUiOk7IvBSCiiRNwEhgxp8WwzMiioRSOvr9DMxu5cO1IBFPPCSlwaV37kDe51ptL1jnN4X2ACC59Id6RScDQtDNVm98EpWizJljvit/0WNWk61qehXygutjYxUF/U0ze/qbOIjUtY3OtE6oT8hCHZzfp3X6LXnfEya99LAzGEwRfvA1bt094giF7HDtyZBvNmz+i74tMvOEoBB/hiJuu+MYBh3wikbS4/WRkIk5j9jhmf/sItnFZNSfsccxb+U1ZsL9p8uboe1JrSC0uO5mk1j24POrS+ggubptq4irwVVvXbY3qJNT+rmvIlwnw+ra6Fr1JKG/SjO1Y2gSdXHUsVCm89ePqx9bPfZWQrys5sD5e7X3rWHwFgdSssLPwjsKcOfD5oFBsc44WAL/DXc4YuBTMor0nzOkx8mwprQ+gRVQOOaDDhONkj/JTEW9wwJu9PVrpXHxLt27IvZ0hC0uBsMK8YL8O6XZVIPeoZpK0iqH2Z26+W0vdnkf728uEajBXM52TOKhai9q3k4mnLb+94fXY1/R73pY0fJ1OgGGe+fB8kGi/soj4nV/9lF8h1WmyzFvOXHKReCTkCAe8dCldfQ74AQLXpG7fTyOCvq6x9xBGThE5wdvERw4CG5P9VKqau+1pzFpOj0qwknP+jjuQNqorvQouO2Hqgl8HidK89BkV0lEvPuY8hqnz0Ze+yenFTWZ5wvjek1Uo6ED+brz43RBKjhSb0AITWn7wLndoMecO3/KBTYnL7d5hwg/xJaa0ucdtX8Lwh/kVZi6CdUjmk3LNaQkcNzS52evQlzrDKgviBBHObyOa+tMEoW5t3CZBuLfdtk61XzcxXqwp/ShBXd/ncY/RW71M075qtlohbR+3fg67vS6I6+fjkt8tbKP71dlFMVWLMkPGlG7XRfk28P0EbfmLyCJ+C07+5ceYfarFPt9hRJ/neI0hGbaC2jtkPlnd0Il1Tb2tkM5n+Do3XbJAgfdK4m7JGxcHrugJAYKx827QBLarglzJDvppn1f/rCJgrWz7m9XadVy78aUF2TU3lqaD1qZKlT7nZe1DIdzni1RSt+Ytn2MbQrKi4UXGztYDLnadB6OX+4cfnmckg2EIRc4bEEfryYrUoal1JocESOaQ8OI8Pp6EFTQrPaZfz8cccmrMZaEpYjTCLlgXMYu85TNLgixOPtOdSw4l4d5uMeghtM2xqYupk0K1HF0ElP1jByaEhUI1ects+CFCIrG8ESrQqBC7Bekn32YvEu3neLbnM0n+JH+Tf8SfQAuK/xi/RJ8Rd7kD4CmOfcbc4S6f49foM/YRoK/yvM9WqcVNjtlj7kqE3Dg45u1vPC3P8UlkAdZ3pg5TNedzEI29Q3Bo9qEy8BUrVxim47a5CEsAJpB3AivKCvc6Tlo3nTeZ0FaQ9mq/QVUYYLbB5cLZtrp2vEn4W+F9mXZ/2TXtOa1WbuEV+1cXbHqsQi2WGqnntP17SMitfhtxqI7ht3jOW4ZH7HOb1/kIRxyzR4u5zyZ6xL7XZtVi7LjcT7Zeb8Y7Pg3Eza0HTLfaRE+XDD+b8Vtf/QOBCvsHCe9NtXPrr9OxoAuCPrfOS9uP4w3HKYutaEh1sLzJteyhl2tlGfl02hPaTGcdn4gN8IGEV7UPBebeuPPiir/xcvWlA/QkojHbGlIS89a3nxLh6RyovVtvEcWlrzK0yEXrU6GapHPphHEaKIsQMD4Vms6pFwoH630svKD2180TrvUmtJypFMdlCDYyC8qmlKmKI9umqQAAn6GxLGVxaicTxg/7zJwFs5aESXNdg2i6OpBUkEOYpLoAIM7LjHcEg/zibjULXibP3exN+fz2F/mVix/ima1DT1+c0uEH+DIlkY9stVkXRYO/yzF77HDKH/xbvwHnyLv9g7D4JBxu3eJ1nuUet3mdZzlj4At7aPrkM7aFd38vDakgvkHIa28nzYnt0QViSluHqTo/C7dNnarWcerMbwhOMrXkdHJbTJlaH2P+r0Ma1mlmBf2mVhfAdcjkMrjEXtc6+uvOw7qTVAXyZddXBUFhgzr7RQW7CnCrkarg3pUsrbO8ReIUnHYyYeBKKUqpnCNe4zm+/PAHpNpUuuBjH/0Wexz7hHOf4yu+FsGMlmRwZQ+tdawJ3zpMeZGXAfgKn6PNxKeyOOQZl/eo5cfsZ3mZN9njH/CnmJQdWtGMAeceekyYURD5SGlNzaEKipbO1MLmIKkyylLm6jxvST6pGG/1X3OKHUi9CpB6BArBRHHpZYHPHKulFTVyugA+3/hwY+7A+iADyBPmccl5MRAmTVxyLZ3TSmcyttxKph1SuqouZRGRpLNQWk6xL2tC2kjDHoLZx6WENFsnSD1JvqlepIWloyKiLKRWaWmE+rKIWI47RNnI36Pcp9yIvtRWJIOiE0mmQyIgknqtre6cqFu6qk1thjzhU8hOSlnNZ3mLPO3AOKV5+11/D1FchhwcLky7d+st9vmOL1jCJ11h6TO3n8semKRSNej3b71KjxHf4o4rVn3scM9tPoMwWt5wectVY9rmjIwhH//qffhf4Le/AB//Q8ARNP84fPxj95nvtzhj4IuIP2CHCR1fWq7FjPjpkvv5bVlwM0SLV9jJaoiqPQ2ROIb72waLV21+RJBcqrEvCPj89aBxDZAF7xZBsKmwV8uurolbyqo2FXyWwWK13E1as55jk8a3CUapn8dCdlZ5ic3v9ti6E6+uVauFq39qvZ64/DC7K7ZunTIZd9jblhKDmiROq089wVAyeiZ9n4J7ihQWf55XffnGF3iFP9v9OxzeOeAez7LDA/Y45mVe5Jg9/g5/lj/Pf+/z8r/K8y55nDhXX+RrviBPnxFf4XPc4zZ9RrzA13nNWQEHvMGUji+l2HH59P84/4hONOEOd4Vx45y0wtYRfF9rB9uqWargHLPn8/efs81hJDmWzrrbnH/q3KfDtq3D1NdanpcJExd/Ai45oPoTQUgiFr+/DFIzr/f3vlmhawbftd6EbDBknrcoi8iXhRtsnYNLIFQWImTLIhKh73D48bArgipPhDpkNfLb7gJ2sozdhK8wYAzNLQdIpBJUXHptOtqgmcfm9yWIczDDwzAQtPUoclq7f/Gtihaspqbi3QPO/QCZRh1mUYsHyQ6Fs25sgqzhLOMik9zf1+KSO3d+3WcjnJcJF/d26R1IHfNFL3c5bOQFTOKS83ibUdIXTvv5Du3tCZ/hFc7YpiTmVZ7ns3yNI/Y5ZI+73OGQA57lHs9wyOlLN/n+P/br/OYX4O1fg5feQATWT8D+3hGjSLI7nvoydAG2mtBhNOvLwsP1IGytb0Tfy9D8WY57DBSOKcV1yK9vhi5UcMfmfxXwamZbzd0u/jpeVJOyGrP+bv0m9vi678QKYWUBjak6j62zzgp26yfQe1a8F6oLDGabNn3+W3BtICUaM1cYXQuyZAy9xjv/qOipmgufBDLeYY83PesNYNtpwEMnJhUbV+hOt990lb20yHzsfDpya+/wHK/xOs9yxH6lyIsWffkE32JKm9d4jj4jH3Wt9Wlf5zYlEc9wSOSusccxBxzygJtsc+Z8SOFZ9d71+lL7d05nNqGMIyaR5O3vMHUpoSN3zYQj9nmJr/r7OHNVyc7ZZkLHp8DQTKNSHyChLGIJwKwEVsVUYnE2KcIb2ocDlvm+P7Dif/2aPICBQpq9KYthn3TwDjtbD3y1oCgSU2n4MOBOKky10AGAD4jKEyrBUdpp9UCgIaHZyacTyFatKSKuOc1d81m30lnI6Q7G4VstOtDfGofoTvDOEs37oqu5FveWYiA9l6tcBiVQyW+umr2WipPizG0fbbq/dcR5OfD3VRZSxu/3Pf0aZwyEYz5Mq5piTwLHWslcfi8iPv3RV/gcX+E/4K9zxD53ucMDbvo0v8pN/mN8gWd5nTkt/sh/+6uc/4dwYwsaPwK8hEA0n4ZXtj7t0+w+YEeySbLvS9dpObrlWTewmiyzwFBfr2UPZb9DAivJatRW0KrA9hPIbb+FZCJM53R6E1ppsKhUwxo/7JN1xWQ/fyganSoYajXp9wpkaOsSuP69FpdkLjjvCYa0na9AFr0dgSJzp2RYlpAKeP3TxWdANfncuCNmfIqHBHQuaIWjVjr3MQw7nPpqVFouckaLJ5ywUxqilqVUTXZKm20Hs6gmDvg89mcMfA6gIU+QuMLz6nSfkZAwo82EfY68A/U1nuNrvMiQzAvJAec8y+ueHg3iXH2TPXquYEqLGa/xHHMSDjh09zLz9F21DhUK1AVBUktPfKqDiIIB55U5aJ9ZU0HLYnTun9vy8DVltFjeIrOmDs4Z0eeYpzjiIyEAcNxGi61cGwgOr+kVlGiiMUHj3s0PNyzTuLaku3vmv4+HfXBOSFyVGV3pVStenF33nM8oLrzj8lo6Z5kjAt4J4GVchFzZPTez6rlkVEOywr5CP3R1D00OZo9/54nkPjNFCyInyPGQUUwUF77EmmJ5Ws1Im2rlKriDU6Xjtys1rOdKxSnrRLzoMgDBFYKIINuKiRGK6aSUIibzPPGW0HymlX38TThhKEWy1b9AEfONb79A56MTTrnJF/k8d/mEH/CqER1w6J/piH3+x7/47/CnfvIXafyy69su8Aycb21xp7zr0/Iese8yOnYq2tdop89hdsBFsesFW3NXI0uDxdTpTcl2Dpl8qu0nuNgp0jfS7xJEpcU+hmQMZ5nHN0FgMq3cFbs0x1OXKjhhzhPdI18ar9WdeW0vikpI8NASERRJ5N+fLlZ6XhVEWqKwXhawJOb8o9t+0R/fkUIjuqBPnRasglHfgZaNHHV7sAO2fqyOPRBlIuMdx26ae1hMn1OFfFA+Zt7y05z+2rcaYKRFS2ZuOdSmmTc1I2fLsan0XR/zFFM6bHPObV7nRb7EazzHA3Zou2joAw45Y5tneZ2Md/gWd5hVrtHzVoLy3G+7ReCAQ897V478zI0SfUapsvWEX2RUUdI25Am08Lm+n9CnhVfEbF3hIVmlFKTer/bz2Gn6fUYk3RlFN2KeJZJiZdhlOe5w4eRKFJeVOrb1Wrb19ljCvdFo/A3gx4EHWjKv0WjcAP4+YrweAn96tVq902g0GsB/A/wxhJ/2k6vV6tevOv+qiJnlSUX4We1imbfEmaCFfF3emOWwy7KXs6BVKfUlGrWwV5bjjmG4uM/UceLThdHyTeFhi51eyVjQSjHB1tV7EM924R2mdfaO1gDVaaDmGWYwqYd/5IpQ9BlxkwdMaDOhjdQBfeCtgIjSazNjh4NrubsZCZOyw2TcJknn9LfGzGctjh7uC1NHg77SAh/UVDSk74sILe3X7E25V97mZ6Of81CSTuIDDrnNPe5wlz9T/n1GUZ9XeEG0+u4+gz9xxlPOgTalw13ucDu6R5spd7nDKTeZkzDgzGtHQzIOOSBLhrS/b8J01mEy7ngfxmTcCfe/+zatLePbIEbru6pA06ZaW0lEK3GLQBQxKvsMLzKmaYcsGQIzhjxhMFY5j5rfIvCKiiVmhaxCa2rSK7ymuLQ648LiU1bu2Tr0VLN/4IqayDMGKqlqt4ArTlL4PrDC3cJfLWbETrhpCUMR3sIjVxqeXkfvSRcZrZKl59V+mtD22qn+rlq/Lh6S9lkE+xMMXQ7/EcfskTHk1FmELWbsc8S3+IQvej/kCXcPPd50WPfMi1EpHLPHsRfsD7jJazzHyOEZypFXAa2QivalvIvCafOyOJ5dbJOPO5cWEFf5ZQXvPG9tFMSKPth3DHCTdziPBpRZ5JKgBWfrIm/5a49sgaBL2uNq7n8L+GvAL5htfxn45dVq9XONRuMvu+8/A/wbwMfd30vAf+c+L2/LUJZrnic0nUkLBHph0XD4+SRw0E3tRy0TtnSnXKv5mK4CpLLpMwUyVyBAtfZ6bgdtNrH+huoxS/Ms1gOueHwZR8yixGvnYSIXfqJpkeaCyFULkiyO52z738f0GfIEmsK35zQ/X2zZDVYVwlFU0ulN/cCaFu3qoEtnQZvPk1B67cw5mbMmC1feb9jL6Gcj2okIXIBhknHmIk+v//ICfmTELGr5+3jATe5yhzYTYkpO2fFFM77OC8xJ2OPYBzpNaHvzVh1106TDKBENdl4mzPKEZVxCrySOS4YXGXFcMnUTahK1PcwFeKGqmrcW69CapqULFGklorWNSplEWSSY3YQ2wzJjnrdod6WC1JQOp449oVqzFGCfOo228NqxLXqyx5tecJ6y44W2xhDs8IAdTj074/fxmlsoYs8uskJdqX9a/1VZR5reWZ41KBK6v0IFWvsVoOPuQxdu6wxUrHjudNV3yLw2r0qL9rMWp1fBrlamppXIGDKjxTOOunjEPgcc8gov+IVKHKRjPsvX+Aqf8wXOn3DWnuDuruD8TIRpJ5r6MfMqz3OXT/gFGajcpz6TQJvSB/MyIYpKsWoBEpkT5OJ3u1ajNevnHDyaYCFa/b0u5FU2tNK5sxhl/rWSqlJYFqK1L4tIUIh6XMGG9ljCfbVa/TNX7Nq2Pwn8kPv/byOxXT/jtv/CSsD8f9FoNLJaXdWNbTnusHSY+9J2gBfAYdO1uGRJTYDXNOOl1apdJRe7vy4Cul07faHUx3GzymooGmFRASge3XW66FitvXTUSf+9iBnFPa/hZ9HQr+jaEuaMysTDFFGkC0Ew+XQCqJak2v2Mlh+oCTOKyP1edjCxDaoAACAASURBVGh3HZxwK2gDuhjFvYnAX3kLYtcXY5CsY7DMu1yMO4zcYtBKZ5RJxBH7fJ0X+O0f/TJzR1c74A0XXDLxwkgFhAoi4cyP/b0PeaLCUJD+EBqaltcroynRdimc4Eg+i7EIJ32f01mHYS4Cv92d+n2VtVESMyr7Eqno8PHU1DPVBXmYikCf5YmHgcoyYh61vEBUU1wLiEwdxqp55AGHM7/DjivzlzH0zjZ9v2KVPcXrTB1D6U2vzUv/dLwgSphxkwfeOgBZCDtMPGtJMW0R7KWj8wWBr4pE6TRq6RdRIBSWUCvHaseqmev+fkxTnYuAF+o6Hkf06UQTRvR95LPq+kMyjl0RFVVO1IE/JGOfI17hBf8sLea0mbDDKWfJtl+8CyIOecbBYS0PV1prc9P9em2+FGoy4BeNpWG91duyMq8306LrFrz6ZGZ5Qj+DYZQJ5OPo0LO85bV27y+ss7Iuad8L5r5jBPYJsOP+fxqcJ0bafbetItwbjcZPAz8NwN5H8EV/NQhImymSu6kCO+DLcK0V4t2gUVtBXm9RXPjo1+X9ZmAwFARnVFxW+eXufvXeNhUDXtZe9MJAL/rCVahOuk44OfNczOEnqlqE7ADAzAkDcfB0KlhgfdAKxupy9EQyiOe0vGDsZyMmY3HqqMMGEBplnIYgqgyhZzlHXxSXDLbO+RxfAYRdcZdPsMMDDjj0gjSmlBwfTqCfOaYM4DHOEuETq1CURaD0WKc+m2jBgf+vtUsTZ/Wp88maszPz3hQyA7wPQt9rbsacviPrnFykkuOjLGLmacBAW8mcM7YrQv4dMg+NKRQxoo/WerVcaYU4JnSkkDsz9mn7XD3/G/+mF0qi0U+9A1QhoHO2OXOhyapdqyWh2j0EYS1WgjgOVbPWerMyhtp+TOm9qrWlAtvWyZVjNosVb5m6sTyhwywS/8chB97P8irPewekwoszWvwgX+YlvsoX+TwzB82oY7bNhBGyWAl0k/gqW3r/3jorNwQ5uneosSY6J9QPM3Pj6zIZBHjEwQrz+ty/qpWFWPTTh20/diHE73hfmKWuXtE+EIfqarVaNRqN90S7Wa1WPw/8PEDj+RdXnstZb1bbNg7Leic/quNs8zlpTFt72T5Tm6NR2lQDtdXbCvb6C93Y7AvXT7NtniaUUUTLDVwr1Cv3GYl2Mc3bjIFJt1NxCibMHUyD01gL78hSk3dSdtiJTjku9mgnE6KtkuF55gJOZiEYrNgWWqFq8HET0oWfEKNZn68mL9Fhwmd5mSkdDjmgIHK1VXtMHJ6rmnhMiZbxmxtNMKJwsFLPm8sq6H0/6LayWuNUNW3fRXFB1Au+HLVGFrQq+OmyiCp+Hv9+lPFUxMI6cZrTctxl2YOFY1Dd2D33lsm8TGhF4i+Zz1r0kxGTskMnmnhBeMS+hzImtIMT0h0rzxh7519EyWuz55jlLQZb5z4iUzMiij/m1FtBB47vfcS+F2rKxNLvSpsFDHyS+PQSCgFa4a5OSI2xqDcbY3GZAG0nE1qJjMn5rMUbiVg1PQM5qTBWv8aUDl/k82QMef3hs94KyyJh7NhFv3D3rAuRv/9Za+M9qSUdAhI3z19L3LD71JXFClT8GE33Hw37l/YbcSGUyLhhZNLVIvd7Ee6nCrc0Go2nwGXTl5R8+2a/W27b5c2uC6ajrlol6+2xhKprc6t5m7YWAepqlZLla7CPbd6Ru2Hh2XhPCv1AxTJR6lxRRERbJX3v8Jv71VwdNkq7s3S7WeW5+hLKHM081jd12v2zvM74YZ/t7jllJJNgOxGc+8HpDstxh/7BMaUTlqNh36WFiLk2mIRCKHmTRd6EXk4rmXPKTccw+ByHPEPGkAFnTJCAFYvD6mQUB1abEX2mzk9Qd7zV82oo7KFaoLJUrKCH4JquTsTC87u9X8f5Fq45aCyK123esogpe1GgFkKIhUhheJYximXB7PQmJJE49ctYaHCdSOwrgDcuDjyuDzA8zyp4bLYtC+wib/FWvl9JYxHFBcOHQgk+L7YrgkXHRTuZ8BrPOTZK21sJqllrUNE52/QZeR+IBuHYzJ9DBCbQ8HegYhHZlBq+f80+dpuOUYlJEYx5WohC8k4kztoztr1VoePFWzplPzCFHoq/aBT1vT8lWBtBhdCxVh8b9UhxnVeqINR/009J3jWr5L6yY0nfwXuRR0szDi89pg5PP4bk/l6E+/8B/LvAz7nP/91s/0uNRuPvIY7Ui0fh7TRYg1Cgqgk/jqC/Chp5nM6umlNuY1x4521FwF8C+Vx2/bV2xfOURczoogdbeO6rbZET6nYC6TU7DisXod9mHofUyZ2uCJchGVl36LXk0azvzc5Ob8LMe/9LknROPu7QdJTS5bBbxf16QJwwuuiRbQ05vbjJcbHH0fZHeIY3OOYp5iSeaQEBLrJMCk3bqjxyvX6ZxBVYpzR4qbKDgsO48JqoUs7KMghNdZaWhdNWi2rA2WXsJj0OYJbOmPcSEfLgHP1NlnmTpdPiZ3HBLGl5B606Y48u9iVbaVxKTp9aXAfpXCoJqSDS2I28xaKQIuiLeEU6eIft7jmzpCUpGnR85GJZXGQrHvR26PQmbHeFey2OS+FxjxzUMSoF91YKqwpyxd1nDs8uaPvxpuNTefsL5+PQ8VzG1bFf12qzbWHIaL6UViI2izqbLbRYls5BGQXNXNleOl7ntNauaS0fHQP1Fm+Yf1rcQ5sV8gr3qYCP49LTtHVhtnEO8N4Uzsdq70HZhcenQv5dxHk6aDQa94G/ggj1/7nRaPz7wLeBP+12/wJCg7yHUCF/6j3dUa3ZVc22q4T9ldj8hrZptb22+1AEWQwUsQRU5Qbz3oDvfy8v0i4MAhHA6KJXMQGXRUQZR2sDc9PiZyeVLgCjWZ+byalgprM+28m5dwYqRJFkI/rZiE404fh0z2u1Po2BRj1a3K9okA/7nNy/Id6XHryVt0iennlN+5AD9jim7fjjc4epqjA+ZYfzh9suPmBunEkycbJkWIFm1DFa/x/ENE+YVTjQIAwEdYzZ1nEOVMXNIwrv01A4wgq3Tm9CYQLWdFyoFjvPE86LgYO1So4vniKOy6DpaX6QAmFnIXDXMosZxaWHw8hGLMZt0t6EOC6F8jlukp/cCGFCmi4DTHxCg2XWZVxEnmI82er4wJ3TcqeSgbXdlXzpmlelrFlMCXPm6ZzIvZNKQJa22CkZQD25HsCL2y8Lk6fcoRNJLphR0vfjTyFItS6E0ROEZeQsNF18lcprhaplo9l2uY+t9GNCm9XA9dx1uK/y6caBFfBQVxS/dwH/fs7zIYlQ/eyKL/za2vb3Ast8kM1GlQLOmdHweVfWOtpAK++31Z+15bQCYP1acXmpRWNhBTvoorigvzVGI+6OZvtun6iSE0fDzqezDhf3dsPyb6M8VYhokiiN7r1PSLSVImkf4oKt3XOvoYFqkTKhLJY7fdj2ObbruKZNgeopdo6C6fssmVc4/xZvtU0XA8VgdZLbZn+zAkS/2xwg2u+eReOc4y0v7IP1pL9HcSFa/LgZnGQ9SdhWFlHIK5IZzpvpj2ZvKuc4uVGNWrW5RzJ88j1dvO24gpASQ6GSybhdocuCWEHaH55BpXOingQtFd9Zmo38O9Qo2NvRPXoukvSAQ7Y5Z+ogOWVNefZNGYQ64O+l5TR8+y4hRF3ru7AQUuXd16AitcjKmgCv/6/vzLb67+Ea6wrpB67Fa7vV/nBHqNbb75VQ99c3aYd9M86LjYL9e2xWUMvgvOLVuIhYQKJva3x7HYTqANLJPH3YptcdSW6YIqLdnTIcZ97BvMxblHHpEhh1aO6+G6pcaW6TetIrCMJdK1fdItBHibm4vwOOG5wNhkSRodiViaNgKishCRaS1tEFLvIWzd7Ua8Pa7IQGsJn55NaUfWQmpntl7WSCKvfqcNSoxCgWLXVmzO4oLqoZOvU+i5goG1X2baWBcRHFgYbpC9DkibyvHoGBNXY+DJ8mYCUxBprn20VkL8btIMxsjhmf7M59urKTVknw8QvgGUQ6RpTmqQEyKvjrzCPyhErlrsLda1yQZqMKhKHpG246zrny0kGSg2mQUFlGHk6Zz1oedtFzzKLEB2Ppop0wZxYFa26Thm4Fr/rULCWxLrRVqCfeekwqSf/0ngpjFcm1C7NwlFUrn/dG+NjUNkG+Sgm/rH0ohfvvZVvzVhdRlSlTbx/gQlQfeNoqq35cuhQLLZclzpnGRRPimKXTzFQYxXFJ7CZpFAt22WFC0pUsddn2kPlMmCPNnuQ1efv+zcDjdziu1wihmpZBtfkzQtHxM5z27oRU0YBhk2XaZBSXlL1gwl6cZQEzLhosbc781GbDi71QUy25ZdIltyKJtIwdDl8Yip5yoZVhoy0wLGbeGtDfFQKY5SIUFnmLxdhBU5al4HBziz0vnb+jvzWW+4pcgE/UotWdiU8hnYVUGnnLsR8IUdMK25gc/hKRHVIvLIb9qkCPuZRJYXMfad9bCBAEXlJN26acVUfjGovDXtMFwPn0GrESBNq0tmZeiCtTR+mN1lE7p+WtHXBBgOZ8wziTQDz3fkH9MHEFZ48oiCN5n/oMk3G7wnTZNNf8/06BaHenXohrsxr/zBhVdgGpLDLO0t7UHkeb36ToPi4b50Mp3B/Xgfq70Tbi6qpZ/R7c0yZIZqkDJq5liysagGj1y7igTOee3meZNp0kUPJA4AzP0VWHqU0Zq2Y/BIGjTWGZHi7pFkGTL7Rc3UooXIUIpItx2zNTrsVlsD60xSXNdL4Weq3vQyySEN4N7n4d/VDZHyrgbWi/ZN8L77gwwTqKM9sgEsFwndakfRE3qjMnb3oIyuLuI6C/Nfb5YzTDZ9wtOT3fkTQQmeSkOT/dZjnuOKuxhCKtWkqaEXIIi/i6LAK2SLKz3ipWp8I7zqpTaMaGw2uQXSudkY87LB080e5KVO8sSioC8FrsAnlig7k70oEygBT2euvkKa6lwrgZx/2wECeSx0aEboDWVFMO2rDsPxl3BNrxlYlk/Gpkt02epwu2BDYJd58Ioi2NE5lvhGCsRQNULAcdg9r0vqxz1cKIFf9dXF4q4N+vYH/c9qEU7u+nfRALgp0U8mkFzmOEhH0ArV6Faq3ZgeKKh6wLeGDcZBk3yXstj9HPEUx9FPd9cix1OnZ6EwnUSRfrKRhstsyYqrDXQhT1YhZ6XIoIQ5+itAGpY5dUKlsVkLqJoJoyIZeGPncUlyF/RySfs7xFMW5TphFJMkdygQSOP2yOmpTHCYmxZi6HT8KcMoorRVhkorpFauwPNtS0BuBgFWdxzAG2xj4wySaUAhFy+3yHIz4i/Q/GIqNqIWlKX89UCo7Yupbu03fEpSTRi8uN2l7d6d5M5yycL2Eal9CtQiQVqzYuqaTELmLP047iwhWWaEpCPefDsgt2PxkxzDPft023KC3zFou4rECULQOLKKtmRuKppda/otCaf0YCZh8lhURrxyWRQm0OOotjF6hmYJzJOODzm+ixdTz/SmF9hQZ/WbtKpnmY5orjP7TC/b0K6w9c01fBbjHt3+VWZ8xcM5NS7sUIOtvUkaaTX7VrzQVNGHi501K2dwJTRtkCSSqc+GXcXC+nBlXhYis+6bX0PjCfeW27YsMq9FMRhqrJ1yP8AJ9dU4U6YFIItDyDohVpIian+RlBClUBr45Wm1CrdMAOiH/CC3aPrTfW87T38Hiz12Rd1S4rlCa0GV5knuXR6U1cLpWPiODpFrS7U+azVqgeZt+th0DMtXHXd2PzmnEOwrqisGmOrFH4PKzU8b+rhqrf/blt4j1zvUXeEl9BDj51RS9mUURSwjwbEcUdb0GsMUucIGy5d67+irIUGqfNwRLYNWXFQrNjIHy2wME3dq2PIol9uJy7Xg2Cs3DMWrtMwL9PWfZIZe+K9iER7uuMnd9Tp2pcVgW6fr6H1Xcjo+YDWLm9E6WIwj2mzoy364/NiYNdqER4KjOlE0nhgaGrybjMW+uFexUWgHUapAobCE5Xex8qyO0CYYtTgPgKitJrcFFcOr5+ywlYcXopJU2Frq+E5TSwxCXFsjx4pUQqtQ5cnhMNK48SLwgUiimLSGiHNkFcYTDwygJF2Mf3vePlq0BA4gByk7sH4LzY9snH5G8KCbSflvKKPuWBLiqWEWNnrtOKtamDVMeK9qs2Cx9YNhAYPDdvMQEvYG3zAtg8q7x/YxnUF/S8IYIeyM+e8H6hJJ2xGLdDQJRq8EaDHp5n/rmEfghJNPfOb4XeFG7TiNWyIvhFr9fEaWDSb1BCBPNYCAV1J2lSWzQ3kR2iuKCMozA3fZ9U4cb32urR7++lfUiE+3qrP0zdS/xBX2utXaapvw8h/TiMmsfl7fvALvDa7iJvhVwvVmP2Gp6GLMee5TAe9nny6QeiweqkrOTMMZ8Kz9wjVEHS3xV+OXDbTmrH1/eHqraf4xyAIukXaQrpgosN3HF9fgi+EXUUJqlEg3aiyIWsB6plmMxucrq6lO3u1O/jqXdO0Pm6AF4bhzU66FifzcATuGPimPGQCiarsRKV1LDu3jT1rs8O2hWNdRiXwVnrMW7WBPxlIfNy75bGGULobbOBXjZX06bMhnIPAqFVMH4DSQEBSoKqUlA0WKaygPSzEWk2Cu9XUz0gRRA115NeW5eoYZzRSkJkqtJp1ZqLTF9qqztiNY22jIs+83RuYhlkbEyME1/6KfRdXbMv1xS6mnitW+Dvob2XYE5tHxrhXqf6bNJYv9f2OBiWvwe7n9WS9TtU9qnf/xp+f8lxm+6trvXbiee1I7dP5LQ2KWyCm2AroCG88zGSp945NDnBVTJKfNi7vzcPQblCJgXCfFGt29YQ1dqaGtSkwmaXIPzOzPFWU9cFIzbn0haDYMmSuG0RuyIrlgGiEEgOywLytEuerrjWmzDvBaFtmw1FByqsDIBOFHKsR13lsnckS6j6NbTpwpkS6rlaCyVH+j9OycFjzRrpqyyQJJ1RJjE4/4A6doPlUZBtD5ka/vzi7HpgIWmrjdd6Gg2Fa3SMXCbgN7G07DZ1avsKZPVOttG2YKxH1otwn6QwWDA8y9jeOYetMaOLngh0byWlLHpR5Zx67VneYpg8UYletrz8TZlVIVQ70+IkMioKWrSIoo7X0rU/EmMdzrSuRO1eyiL2lojcTG1+a5Ef8NZzpVX67HIh/q+85v67CcfUheZlWGQ9uxuwlizs0hTDl/y+9nIvEfCXbfMMB9WU3DnWNDalwimM4p2aiGD3grohGqEKL08/nAneW4dbdgmC7JBQ2g2CgNZiJzqZVbtVYa9afB2q0WvEtf89h1vZKU7Axs3qcTkwbLBMu4x7XWaDd0XIJ66YuZvk8zLxaXu1RXFBpzelFYlRryyMMo6CqZ3OJNWxpYJq04VNhZd9hgLIE481N3tT+pkwZoZnGZNxR+5lm8CkcU5gDdJqJfPKYnVeBAekd1zqWHVj4jJs3cIvVsCHz81JqyoKgHOSXkvnVzj94+oC6KE4rdOLG0tNn95bsjv2xLqJy5De9qwpfhnXlkXs02NMH7Yr1pcKdIXiNOd/JwrjQEsDhoVAi+aI0G8Z47We6qB01d3kZKW3hNZgGn0PSlm2ioEVuXVl8ZJ2aTKxR7QPnXDf1DZp8+/X0bAJ4rDNMgj8b7XVdE2zt82+hE376Cp9iRZfSYFQ+63ccG6Npu25OouTcSfkfk6BbyJC3eLF6HeBDzweGq9cWcIVnDWqOLly1zP3P4SyhAdUBfUQn4bA1ynVpv9bB6wKf888IWj+uhDosfUgKvu/UgXz61yk17lwNUo1QlJ4150KZrxwkEnZi1zlJZfzxmltHRcxOkk7IaArr1277oNIV8JTHwPDgDUv7jd5eyDlISW1xYplXDCKC5KtmRfwpRNKICkobJIxLRivcM/WYMhk3PHsmGjDHLEKQr3Ob104VRcA4+B2gl0WLfGRgBmjzonsA5y0YDm4uq4EJ7G+y28At1KGqRR+UV+KYu+VADoPNzZYKPWxF6iTcVxSpiGvfxRJMF5ZRBBhIK/QP22XLLsk5pzEKwH6qbmd5nkSnOoGevLWMjIPlzq37bx1PoIAmaqCstrop9nULCz0XoT8h0K4Nxqrx1qdNuWXuWzbe0k0tqnp/WzKF7HWLhPoVoDH5cb7rd+H/b3+HJXQcTeItIj4+CThmuZgLyLIHG3vBUTAq6BUAekxb8PZzhss4xbNbCQTyDoRVTNNESGv0agpAW+HoMXmCEZfUNXoLaxjHbfKPLHXsxi+NfGtM1PvyZ4nxguTZQpjJ0jl/hrV/2myQJIgjYZ9J2TCO1DHbT8bMSwioqwMRdjTmcALIP1thZsuWEOqi9sYlr1usEh2JU+Klr7TcogaJVo6OMamR1BtVRg9UYgwLqJKoJI2S4G0sQP2GeutruRUHKXgx/ZSIctcYiz8s1v/hLKrBuZd6fvOpKj9SO81b7n8NG7xGDyU7WfdYIXqvsMuZA/DPReu2lgUgtjKImKWSE77PiNfLcs/O6HGrqeoujTM2g+aTG+hpe0MzLKoQHZKYRUIN0CzarUTlJi1cajO+3XF8f8Xmvum1ekq7uhlMMb7gXbqlLDLWAS+1V8crOcDN5p+heZVo1Y+zjMqra6VziSjoNO2F3mynl8+nRPFU5k4WRtoigCGwElXAZ8tzOSU51mM2zRdArFhlsnEGiMY/iEySXfd/xY+UcGtjjTF5BWf7xE48tZsx3yHYClAWBSslqyQkwr5elqEnGA5jHU/Ewug/gddIMYpi7EUTR+Zvi5dX3iMedgVwZMuuNabkA2GjNJ+mPS68KrmXtfw9V7sMw1T5oMW86TlnYITxx5Rq6MoIobnGUk6o9dV7T721MmiotmFcHr9rNL7qkLdBjT5AL4iInIWizZN+eybMoj0HQE+ytaOBR1rmPemC7cTdtecVdVKZ5Tp3AVelVzrTbyF4/tsTIDpYtYWrfmsxbQQwaypA6YP29CF4UxwxJvJqUtlIJWpJGo21E9ogQ92K2NJoVwUEQtXw9mTGIpIcgNZZcT6Q7yVbmEZDD244Wi0q6qAr7XLBHsU/yuYfuD9mCDaHuWYvaxd1YGwIXLV13Wlgj9vgn02c9VrK7VZsevQjGpjFTO1t1r3A9Sex8NHt2HNc+/yml9L5yyHjoucLnxCqk5vSj8awQBGOph3Iwlw6q0EblCHIuH5KwL2FkHIqqBVobqpWc2+cq8EAaLf61q6x7ipCA6gmsnSLhRrtM4Gy6JLnlYTx3kGh9fGmyx3cUm2JowKF9mrbUgQZPpctqqX7YMxXJxsE90qPTYMbgwMu4zzVoWRonnQlfEDeDaOTTmhDkA5JmQurOfisd81iOmaOuipjr/lWkTsKmjq9XeqC3wKDNx+au3VahPrveTDvmcE+Xnk2VQEi7Cy4Cdrpe80r0+vO2J4kfm8Of1sxDxvMUr63rGuUa4tJBtmTMmwzHxiuVYyZ3iRURbxuixRqEX9Shq7IW9lvZ90LNhPtZxrgWj1XFPaNqZLuKR9KIT7aiUPvulmN0IZddNF8UBg6QJi9Fht/hzjdHN2xytw9KguoK1gVzpculgTypfeu/8/rgroIrBg9BxR7HJ/a4GImlCvD7iK5WKthAofufrar2UP/XFa4ANcwWRHBXvy6QcS+v3RKUfn+yyK6/jMg4oza1O8WSewFfxqmttJajFVK4RhM7/bYvLqyO3Vfsd85ubTTkS76FQ0/6bHyT1TZ1w79qRJnt8gV4aI176owk3WQtB70kVuELpsnkvemQjJKT/PEx8kFMXOaVhI4ZQkbZF1h3S6E5+xMUlnHntPXAZNCGH0yq2vOpNLz4mX7wWJw/Btq2ToVEVEW7oy8N7KKw1+jgzlt+buu0S3JBNmmo3Ixx3S3oRObyq5jFQDdv2lcMgIB8lg3lklkK4BgwRMWciyCEnIOr2pT6swGvbJtoeeOTMsMyaRpJ22JQLVp5Gkkg7YY+7u2b22rILdW4fmfyzUYrF11pUVxeI9TLPuP3k/7ZHCvdFo/A3gx4EHq9Xq027bfwX8cSTC+nXgp1ar1dAV0f4t4K47/F+sVqu/8OhrrK9asEHr3gSL+CfRjgnOnsC/DYmpAMmBHSOOQzCrZ3gZS5OTei0FsE72M2SwDfLq9SoDoDYprDnrsvYBLB1jxVoeHhYauvvLFhXt/rLm+8/nKalaB8q3tma/TnB1QGlZMpCJNrroSU5x58xKd9+uQAA2OGeWJ0LZg6BxKVZvNXgLzygOb7V7C8Foq/+u+9Tpljr5LeUSqpi/pXTWMXx/nlr2Q70H8IwPnwbACp16UyVAm/dhrCAu10LZW+nMJM0KkkCDuUazvhfgIWWvwklRJaf5pqAbyx3XTw0cq/t96sqGRO1qn7jx3Fu49MW6KCKL00B+Fwf1jBu3HtCPRpRbJufPR13lKfVlIDh8lI24uXPKMM1Eq6/MHcy7lXoCZS+wikKEbeGtoEWe8Na4TZqNfLoB7WufxM0xyJrpnNEwqUQZV/Lwb7LCrJ8lRqDAtFkdP15Lb6xvq0Ey79eRqu1xNPe/Bfw14BfMtn8K/OxqtSoajcZ/Afws8DPut9dXq9UL7+UmVqvGxpvfiEXXowY1aEIdFHlDtPPMcG59p9UwLf+7yaltr2P/1+vmTRHqyhffXVUFuD1v5X6t07W6mEVxGRYT0zyW21s/5jKcfhPd0wcopbOQ3yMNgkJN+kXeYjTsM0sDBBXHIfxctRl1OmruDW2a8laiKt1GG41qA6t65n+o0uZ0wlhBrhMHc17M71ZAW9zXvHrfFDLwNEqq2LC9dyvwrdZoFwv7bN7crl3bwDAVh7YRHkrVnIw7np1xzb0vTXWsibkAn6uGCKJu6aGaEHBjM1vKg1w2z5qOkTNxycWWBoa0sFAFnvQWYhOfvthCFWdNmR/OUp7lCeOzjGGa0elN6HVHaBZPtmHqrA+NXJ07Nkq2JPIBpQAAIABJREFUNWSazrk42XZWlelDfV8KW8aFz266yFss8r6bt7hFqCmWMKHvc1dGMoodffGsyyJTnn8swr83cVHLzapyoGPZxmrYd2wDuWCd768F520kedGAWBRMpYpuao+CnB8p3Fer1T9zGrnd9n+Zr/8C+FOPOs97aWtwiW2eGxocgLLd5MA2uc3lN4VIyg3nK/HZFevH2eADkIGlHvsDai/Kml5lEPB12MX/L4uR14zcIqD5uv0+6qSpCf+6b2FTq+D8RSyOQ3Ac7mqeb89+gErh6Fx/0+9O2wlaXLx+zbiArITUaTpWI7eCE7f9hKoDVSmUKkwzsx+Efrd0S4V+LP3Oav4W3qnjt1YQp7VteowuINba0P+55Dz63UI6mHs4A/IUshVz05feV5InLMcxuctl389GaJWoIOADy2MWJS6dQShoMifZmNnQtmtOmE4ftsM2k07ZR63apnNKn9Vt87Q/vdSwAYOISHF8t3CMh13G8YBrvYkvENPrjryTGEJaiZiSm8kp7AqjaXnSXbeOfIqGJouxub4qf9lCFpsholEDkHh4dUmTZQreeTtOWaYLlrhIWQiFVaBqoVn/j8XUrQJi4UK9ryIGNhQ80echNguohVgfD675IDD3fw/4++b7M41G4+vAu8B/ulqtvrzpoEaj8dPATwPw9L6HPuqBRVfnajAJmyodFFcGn8+SVxOE/hrpDF+1wWrcEByY9mUOEOy7aHjWin9Zxkmq2D/UHLNFFG5W9+1NpFiGvkTzKOH/R7/US6mWvYkX4kuqEFIlwEoFvl9EaxaM2+8qL71v2q/qTFP++y5V7VqFptXaB8CB+E+W4w7cM2wX5c7r8VZQw7rGba8FYaGpC3CoTkL7v+7TWwQNtV7eDvO9vl2vZ+mo+ryFOHKXcc1Jbv4vi8jnz4G5r1CkglxK44VwfHESQieaUnYlK+XGerzOAWtz9sj2zUncbKBUnVEGGrXarPa3g++SrOr4HJ9lLIdd8l7E3DnwI6aUSVQpqTgpOxRRYPZUMG9t1pKyEdOugHnlPepxw0ZYfPXYtBE087hZHV9Ds1+vdk69B7uIQ3UspWxU1HxbY9U0oEhFtngZ52JTuDojpL30+2qNRuM/QS75P7lNbwIfWa1W541G47PAP2w0Gp9arVbv1o9drVY/D/w8QOPTL64YixPL4+AOQrhUM3WC3VO0fEc3QqdkD0l7E/H0W6HtcFRP97Iatgo7K9RtIYrbuMFScK03XwsK8Vo364K2oknXHFO6uPlEUV5Q1QZDzen6OO3KfVXLUQ1HIS+fxyT4MupFIDY6i9ei9Qy2qILcaukx1fwzFX54k+VZU3j6MWItqWBXf4cuFMrE6AG3LH8YmoN3PZ4slkdqHF8YLdN9Dsw2dZR6p2xTYIZeKSewCwRU2T7WCtDr2MmufeApgqJ9ps45WC/jppQ+G4mpjkBhe8QBqgG0WpGG79DFB3OFYhodn6lSYTb199gMkHbsKoNGWz0QaqmYsn/+BvM8IXGBdiCLVW8wDDVeXTH3dndKR5aikB0mEhbLE9EpZS/iorhehdbcOLq2K8QAHwWrzfpQtM+1bbLeIAhpHW8WerPRyPGGYwqzj333biEXGGtVnRtWCcAcA84SWrlzNNYXgUva+xbujUbjJxFH64+sXCHW1Wo1A1EfVqvV1xqNxuvAJ4CXrzzZtVV4+LFzYBWpcLjzRhBwNjsfyGIAtZUw9rQjLRvnHTVxEY6PqThw5FDVTsyKbmltt/Hmf7M3ZXtbpNR01nFYYSGh0xu04rX7NJq9h2WsAE2tQI/DsVdp79ZxWn+mTd/z5OoRYHH+uGY71jV+/d86vJQ+eEKYIMqWUU3GTgbVjrTP9bgBQqs8cDPlfhqglV1XIzS9ESAzH0wk516kkvnbU0nTFQwKWdhA6pTaYBSFwrSlC68tVeir8SpoenahsFh/UfvTfeqapDtH00XF2uLfLfBpE4oiYhpLucSQwnjmNfoWM1cevOV+kRz1bUf5K6PIp7ud0CHbHoZkWzWNUoOjtNl87FBdfNSZXmfa6DMuxx0mDv6Rc5eVwhx6rulDJ+STUHAFgjVykBxy9ILUsPVFwwEMOSBP3fiwgtv6Rur9b1t9YVbnaGaOs1ajjkN7nU3v2/qXYvAOVdNHletXrEcDNes4tYvDJe19CfdGo/FHgf8Y+MOr1Wpitj8JvL1arcpGo/Ex4OPA7zzWST2sUdUO6QWGiAg/t10/7zXhwJizJnPeNQ/HqLbuVkCTA7uqqZoMgPrXI2hyOoF7OVFceKGu5uuiMItInaGjN2XySXjIyVaR97saIf24ueQvE+x1h68976YRUBfklUXJLLKAD6OuDzSltimeblkrOtEs9zsmaD4a6HSGE+rALUM1vZXDLehlo5AAbPdt8p4TLPXslrnDYQtgkPPk0w8AeOvbTwEitBZFBLuyaC/G7YCv9lah38zCeM07wd2YhXXt7zIhrt/tQmD2VSpfTCmVkEqJkq3nVFftvc3E0/tKl/DWVpXShGiJi8zUwJ1WJPlU3ny4B4TScUk6c87xOBRxKSIf/1DJ/w6eV+/ZHc7y8IVHAIpGxRkrDuJQ9i438E/L1RWAwOsHWYwGnLEXHXPc2+Ptk22avSl728cAnD/cllTHuw9Zpt2QdsMqF5tgsbqDHKo+nzp9tqgdr+9xTFWIXzYGMN8v+z+2f0FmeMXzMbT3Rwr3RqPxd4EfAgaNRuM+8FcQdkwC/NNGowGB8viDwH/eaDQWiLL6F1ar1duPvIsGRvA0qbBg9KH8BHPb0lWgCOrDj1MRCBmQLkwypQLFxX0yH/Am5rIoWcv8Z7Fa21tu4cnHnUrkX6VVIlDX4YywApuTO750xVFqNeMNbRPH/ZH5bGqOZrnfDbDNpmvaBdFrFrqgqGVkNHirhVizWLUdq/n0nMPLCsBbBPN2LEmmtgZDnxCsRKCK8bBfzajpnU4JvnKSTro84a3v3vR9oeebZ4GpIlq5y67pohJ1LKkPwFti6lewydoug2NqQrwygV1bjMXKaCVzNNNhFJWMSi1aLdi0FgLvM6oUpLAlBGckPvJSf7f7AwzJqiUYe1MfHBXFhV9U5rk4ZqNI/qZFuwKxKIxTz8gpcE/HUzU7tcjXEHwVMH7rtC+KSMZAFGreRhRk0ZDo6ZKMd9jjTal21e0wHvbl3dr8RgMClFdQdYzXBbXCh7k51jK7crOvNqvJZ+Y89h1f8r4r57Favz2vTeVdH0tXtEcK99Vq9RMbNv8Pl+z7i8AvPuqc6wfaO3Lmhgb4bGLNFEhiqx7B6VZE1fJngM/zATJRixiYV+AQH/TjtA0N7NDm+bUQhNc49cJYm2cOgNlffzfH6zaL8evvzkMfFjLVkjdAR7zHiuqbhPqm368652WWQeXc7p7TFWSNKg3SCnXr5IqhNxjCAMbffHKdXVMAWc6tp4/QbIlab1PvWeMEfDY+Xzu0WcVPi4Y8w1kTspiLs4yRq++5GLclAtc7AsNi3zQc6qUvb2jHRXN9cmK+1815FSI94x8oAKfJzmctSPBJsFrRDHpSCFwFe+QcqZqXZk7LFaIWbV3TGQCUZgHoM2JK2++rkMg8b/mi40K/nAsnPZV3XhSRvx9tKpi1MlbirirXjJknArFozvxWNKOM4kr1LxtNW4kVKUL+dr2HSdKmgzCCJBd7zDnbAGS8w6jXI793I/hPtO9PEHC4h+RbSgnC/hZV4T40x/WAgXFoWijRCnorwC1Lhtr79owcBw/aRHT1/bVZXrx+t7DtJe19wTIfeGs4rrgPg7e1NTUMWScvst8AFBJYFqUkcPom8qIgOCF6yoMP2nQld4jjBavWsMxbQn2ygkwXGZ3MvTwwcEwLVZLqAtm8iEu159hgdk5DxHCMNzkr9R5riwx8D4L/Ub97K6C24FR8DQZ37y0gbQZopq69pkAvp92dcn66Lb/vUl2oCyBPfDTmxck2xKV3PJapY5DYhU8XzxTI6hQ2Bxndb8BQkostddy4++HE4bap9K9nOcWhqHfl3YAkD7MafN1ct2mQ9XcgwGBhAmshjxIVqIWHakSDFbFXEDGljeaqL4m8QAcJr9dCILpvRMGIPhM6FETeyeqhkMTQIKlCMLoAtNK51/C1cLU6ctWxG1HQpqAkZkKbedFiWgRMPsRYyMuppBZ2UN8yb5LHHcpsREfft1u4tGnirw4Tbm+9zvCz54xmfSlXeC8NOZHUf2OjpJVGax2wNv/RmCpsajF2O4br0It14vpPS45Qi55gGdhmHbgWqlblKS6rCuWG9qEQ7o1rS5JsRNmL1yeRnTwqQOraztCxFm7jUwH4FzIOGDyFOGBtmYZrOnGBarHppjGrmzDIafamJKZwwlpKVL1HbZfBKmssE7dfWj2+QguNSx+GDrXcMbX99f/3JOC11bXz+v1aq2LTsSBMEq9VxzIwM8PntdpsuqCXjegwYbBzxl3uSJ6WM6owx7DBW6/vy/e8ATTJh6mHTjSU3UdcOtxYIg7deXSyKnYKoZjIGUFhwN3bGBkzA+2XmGvp3KfdnYw71TFjYb3LHGTaPGWu4aJcw7WXRRTSERiN2GrpEzqO+ugErHOjakkSwOc1n9LxVYqsk3JGy6fFVWhFHZXgnJ5RKEKhgWzR/9feucdYltT3/VNzTt97p6fb2zCzXhZYB4hwIoxiAo7jSA5CedooEnGEkuUfO4oV4sRWEimRAnEUk1j8kSjYUuTIFhYEkwfg2HmgKFFix0jOHwGCY8CLbcxiVtrlscsM20M3PffePrcrf1T96vyqTp3H7cf07eF8pZm+95xzT/1Onapf/er3TMaHrlcqC4leYI64HtoRI+p0tgyJ2YIwBWoeKe6pDLvL1ZSyqJ9B3EAL9bfA7SZmO0fMX1YghV+i3DZQe75BLJHLLkvcdyWGQlQ6OkOqIJW+ZTGfkQiYLarg1AivaUlqDE9mB2FRTNcEjY1g7raqK5lsSR7nqvQBEouQiwLc9jgwNp9GgL3Y9S0w9BAEBHWSo62QUjRE4un8K5UKJYd6sYDgOpaGBOuyZHiac9kfHU2qy8OLPa6ZoL/HSarPF9/yJJChTl8Qh42vFfCQW5hyNKeRtgri9wx+4ZE+kMViljy3MPjDLQ6rW1S3CrZ37nHzkTt8tSpwPoHUki8QJV/S0v/hjPl8ynI+ZXvnyOctd7pixziIVTyiDikrt6vQ2+u5iSWxOX6n6GMRDrf52v4NZaA79r8tmzSGtqjHlN7yo55NjPy+D48Ot6kq1yeOjy1D7nEgSOiS+Gqbo+A9I+XlnAQtTK9iuZpyu7gVzomKpSh8mbr5JLhFCiR51qoswOdckdq2ANs7RyH3/L1qO0jxOSzmUxc1Wl130ytylCiJkpCpYMTUp35RTEPaXl2JKbI/FCsmDy1Y7tzjYMdn7qzU/dP8UoezWh2oVWda151GQev3nNpU5PgcnK+9d932z7w1W0Zl+SRpG4dbsTstuER15RYnnpZ56XLtHKcVuRJsBHMHx5wKr9eUgJ5rs6X3T56GWpqBsYfq6hDSuWpdl+501HEIEzHkjdbS6s7cf1bGvVlNY8oAdRBHg8Y0EChl9MGHWnvLtFwbTsfH4yhUxXhbI2MTpp8zwrbp31Pbg7qPXlhkIoZdmF7kZBErqZn83DC//QJn34Da917rqVGftd4SwuJ44hdfUO+qXLmdROntL8FDx8BTW7U0BioUvIgn7yEwd+qbMOluWWa3ng+qvYg5aYaA+g6xFIi6rrRRv4u+eeqLmB+sdpkUkyB5iwpESsUtmQSpftsXobjDrVBZasKCg6IuN/elOy5r2XS24PqNe1yfHjGZukRZi/mE0i+QUvwCvOcKcV3Rg/3dKOukpA5IMxlWVeH6SQstOpJUENk7SnQCraNDSeU7YTlzuvxt7nmmXnGEe/e7uJ3gEdvsF3uwR8jgvr3TfM6q8t46e8pbTnZuWtDT56BetLW+XTP5dCFQcyXd7Uv0rlP5lP6vEhSkb0pbJxG8CFfIc4dPHKbzSVOVnMyh2DvgkZvPcrTaDi8X4GRPEhXRZOLSwZEEFgdVhEivVLcvKqG9ZZ2TZa6MbMSJzVoLHaQBWFoPn3rPQP09+LBmXk3G172RTjhl1il9qf5f/80xeVmk0kjVzOKT5tKPdILZXUGpmLyfzKKH1O9VTx6g9vtNaFR0AKFKURhXe9TQE1C20GFCi70m8fiJjGJ14M61cuV2KqXfocwTYUPTLJAFPY1sBoK+uVyFnaJUFqJYBOn9YLEbGTNf4EvIOYbvji3YDdLtlKXL4wLs7h1wdOgiViXv+URVfFpVhfKaWQWVSh1hTag8NFcujieeUemdXAQVZxIMiqjvieAgc6woV1Ek7WLu51nhDMnaA0iiW0WNtSimIR+STram66WG8n6zwiU7k3ibr9Bk5iFO4zi4zmpBtFGxS/Tm1czvvt3vJRurnn+S1C9ytNCsYN7N0DU2g7nbmuDU6+Tuky/i7uwRsiqGnIQUBknSCemTio5UJnIkXeqIPH/TbAKwdVQeikFGbpEtTD57L/UQZb5Wpk55EOnktYokpT9jGI5+nzBP7Q2UoyEq8pCqrPT1un3dN5JSQufuyWTNixK6eZWebvvu7b069bJWlckCoo1eWjoS7PhxlO4EfTnCIrOgOFohBEEFG46pt9zyPHrXJqqdSG+f6LY9gxdvFQn00fllnLpmEioJuWOuvujKX3fENkulWhF1ozD5o8PtII1PZ3EKhNppoKCxI/SVrfA5WfJ94z0/RMiSZ9epFxKVIzjBT2dJ3N6pa6eKAVe+L5gwZcmCCfcWbnGcFAtK328VzkC9VHYB7XdflBXLnSknO9v1+xcbyS1gzwXO1Tl7iuAGWpQr7h5ed4t8qRYyeUZAp/eVCPoQK6Nsjo35GtnmLiiI6dxx7SRiFJHXyUxNgrnK+awnp5bogKA7VwYJIJ5IUE9YEkk6DSrS53R+lYSJ5bxnAmOLXpJqTwcDhfZa9PSJ5K6Lgch3gd5dREw+tyAlxxqG2MZkW0an0zwkglSKD/dOdxfpQBZVCtTbeCXJBTrnRDuiNGOhlh7rZFxqXKQh4prZpxJSqf6FZ64nZcODSE88kfrRfxPGVq7iBU793uWUcSkHKFB+7bGBVOckF5Y/UcFMezwfGJowosV8EqUPOPSqMUkeJwbQRtIxvUsM7025MbcJPtq9GWr7mEdaoCJidgpSvFr6Z6VY2XI1ZVV4jx2/s3kEF7h2xPUogjd6JCXNl+WKw6qAnVkzVcV8yjxU3XJpUqazBVMWTKcLipc6dZXLUpk0EvT+plFFSqfqrjN7VrXqD7h2a1mrPHuwGcwd03ipjdW+BHa89Kt914GGDln/RkNLDdF2P5EKxfga1D1KVaJckQIqF22aGhWjpEqBvjJehDSRQ1IMeOSqtAjSZE/ZEoFtbWTOtVWESdtOs3kG3/O2dgSJhBKrmuJ3K0z6mjDD8J5UgQ3xOvGS4MnhdmzoBO9l47/MynrSaSas9ada8vIRlNECGj1cblqZWlAJlwkzNPXuSCR4v+WfzhbB512MopOiLqatvVLAeciUXjoXHfwe+8HwuvReMwUVq+p6kFQDA1fvX5fuyy3e8k7i9BhEi3D2N3rc7OXH4SodH43zpY+mXUa/iXKgU9/jWb41pFTW41Y+SyTs4Td2Q1CXo++YKBHaIU5lcwv/Pl3k7s0bd9jmiAN2/a6oQAskIXCyUnr9+ZQ5Nd9I52ltu1iyUExeYjjEXboNG8LcHSR4QkpanehQd62HTizpglgNkTya3KeF1wA1k9FSVXS+qv9mmGBqVMzWX+01sqaqp/yE0i9V/Pa1hBUFaDVo6Fg8Whg7xAy9a1GJae1YvFomfljgk0yhWh1wIu9Jui/KCSJeU7P84A87NzUm9H2EmWvhQdGduug2njtNQpcu4mHBqJSAoXdHy2CYFKxWBcvKM40Z3FFMfVIsogRh4iEjDH3PR/TcU6qa5WoagsCiXO+KyTSk5tz7ivq1qU7RSBm+FhpCnElm93eS9LNedBZzQnRtfK4IUjv43UxVNIqi1JWqlqi1gMOnHnbvacfW40PcZiHs8mZ7Bzzy0HM8xtNB5TWZLVnMp5HAV/jylcv5NN7Jq7mczildG9e5jq5CAryoOlYLNoK5F2XFVrC4O5ImswVLQKoqNbeACVNP0WCaVb1qhmMZvVXEjHoIT3VjeoWeLRsSwkoP0gHSuaOhndlfU4NcF0XO5t8mrqQT6EjOp0iNpL1FVSKJS++GEkNrr+qH7j4KiyO1hJ1m7UsRVCBqNzCf0qiKg/rr0w+AyumSUVPoY/GuTRnWdRi5PEOmDq4IOVL8RCoFiUS5VFtyya0jagbxpBE9/B77HLATfN2PuM69xXZgaoLcTqxhcE8N6XJ9EIqScdUh/OjvrbUbaKa11QxexnzKsOV89J0KmGQkfffOXEETZTSWvDQ7KigNGqrgvYf2eTFfYpcDdjngFre5Xdzi6ZuPcXBzN3jlaL4W1Cyq+tpktgi0ybsQt9Lgtlo624GO+O3K7bIRzN1a0ygoMJ0to6xzgnSL2MpYNORFz8hIzP57xNS9+qZMJDd/r9YAIaV3lUUpx+D7Kqh0Bh8li5rW9eeZTjLIVTRgSse6NRsbtoQOWnOqHS3Z1PlJmq6eNXNMff9VWLZmzOK+qpm5Z6RaddbQW2o1jNhi5tMQjVoz7biP9fZZpEMZuwuR1FJ6A115Rqgls+V8yirpm0hF5h98tSrYLo7Y5YCKIrgEHrDL8+xx+I3dSIce2Qv8mI7ytkd9EwsxDUSLpUdbrIWaJ4OQVcsU+QWJWNippfra9RFQSdiq8Jv5/q6LaUgTgOkcSLecMXU6W3Jzeodb3A5qr10OuO6WTwCe41t5frrHYj4J/v3CPyIjfwJZsCV4beG+BJfUOkq5p9t6r7gPsCemUURAJAtt5EilRhmMfXq9RoBNen2kM4x1h/F1Tam5KYE2PShi5tWvY+xj/vresSqoNszUgR9VxGiEMfUx8rSIQ5bevm16455N5l3nMakl2Crpi0illbqT6sryaZxDUH2swruMfIzX2KVF/Z0wZF2/VMoS1s9XwcyPu7lvqCXOoNV9EJHmZHdWL5RibHUHCHp2cJ9dmoHrQQ2j0wyE2gE6R7/QlFEbdoW714b7qsm4c/OtC212GqFR3S/dWUKT8ctzA426tKF2aghmJM5/tHMcPNCK0hWQ3y6OuMkdpizY8QvohCUuvcN2yHtzwA4H7FImAqHOhS/Bm5KEcOpjC3QRFnDBZKuq4KiqDcnp7qvRjZ1n7xNsVYTCtIJjnK+sllg0k9GTINUnX4smV/wytdQi1wfVj0J6j5XSjWmdobQd5WYHJD+MVoOki1NkcE2gB21uwqe/la272Cv0b3Lb1vo+8URKGblmVI06nLnFr4U5pYxdM3P9LHoxiaT8aIemgjh0uoAWX/KGXSY8nNq99dlCNFqkxRyW86ljonLPxFZUzGLPI10JKdDrx5JOraszOYqxder9QPbYZ8GEffa8smA3UuXUi1tGJRmk7aadQf/NMdXA/EXCz+GMEnsb2uaRnuupzj5i7OA8X/aWIcUIOGYbfP9XdRtHXOcON7nOEUt0xKxjyAfs1mkfylVU8DzlY2LQDu93VURZMFerIrzzqd9BHh1u1+OqrfsG995FY16XjxJIgVip5K4lUicJJRGjZVwlpm3CpdXkcwPAndM61qIhraeuiJBxPSRmUnG60xaDXERrIgW2PAfQyPft2iij6+NETWX4XqoBn94z9ajQkmO0E+qYjG2TT7enGbu+vjdHTsrY5Z349M7aUC/3ixdeHRuQqCWCQb9s3D99N9pmJM9Qe0kYlVlwi5OQL6TeIekU0pE3zsxV/NKSqMAFIbm0ARMOWDDlAOfOuPBZIu9943p+gU9dfDP69D7jqF6YU5VbKxpulcnCqv/m1DoZOlLkPWIWjfEt98gJU1rvLbn1wXkoHSx2veR8k4OHdnkB+9zkDisK9tnjiO3IW0cMorqcod7tpdALifajX60UYz+rn7sx5r24ikvPWWtf7Y+9A/jrwFf9Zf/QWvvf/Lm3Az8MrIC/ba39H31tBDQkCRf0UQc11UyzKFchQs49Sc14l/OpnwzayFWHR2spfgha87YrNHXb7ca3PmbVJbGnEMZQtxszcIFmPJpZp5B7NVQLyf1PA80EUlpEnZF1u2tI20n7Ovd/qXORVJQ+18zCu6eFcoYJQ4raTN+PT8OsKxGlfdCgu6H2USkXIOQLmc+2A3NLd3oQq2okLzqgDHDes8ZXYApBSpIYeNHvDx3QwkzbxmFzjOXHdSMorg05lQ5kd4RtTF0z6VU0L2JmLyotnRFTHxeBUqRoya0vfVqXbITn5lPu7W1zNN0OHko6O2duhy657XXFLSCoZIDIkOrqy644KHaZzhYcl9fpY99DZun7gJ8B3p8c/2lr7b/QB4wxrwIeB74DeDHwq8aYb7fWdnMpSxzmXRIyoQENCabhBhS20nUzwpBzATapYawxKP31J4mEFiUKS5CqSPIMtjn4u/TrqcEolcKhzVOgybS7mHK6QLTdN71XI4CnxTsG8ikb5Jio4LLeGjq2oA3KWCr3PakKr+suA71RxK1c19ZmBsfzCasyyQvinzVyj9R2AQ0tKetUGDt1vvjI51xBPCykn0RdMGXB7bs3Oah22d07YFIsWK6mriZpRigJifK60Kley6vxunZaeofbyeCrol0dlhHi2tRtqUulXpS1e6GoO9xzKeZP5dIaLOqo2GJaeS8k53VT+sVeVDouwtd54zgd+iTssCS1g7Qv/SYZOCWHT91eEeX0KQq3YDup/bpbVHS8Twt6mbu19teNMS/ru87jTcAHfS3VLxhjngS+G/g/vb9M3unWzj32bu6HSi6Q6mmr7MBKdewa+qXndIYBPcw7b6Gvz4uRpM0XNTUC691E7pm9AfEjAAAXFElEQVRyA7APqX5Wo02d03wm0X1XjWNxYxm6WlQ1TWN2ESTphrSebs+j35VxMJv8XtqrilCsXKeUlajhHBpxErKoSAnG0nqDYxqIVLb400uQEt5N08TJpkpgJw5lXwShpAp+5job6GTniMceepqSFc+z5yJPH9pnRcnB3R2+dnizyfSkL3Vel1w6h6h/6/ciyHkKwTD1YuuuaI0xnbtnaguI2lPvU3vJaK8ZqCX5VeXy6azKOJ6jKFchzYE+NlGOHmLc1EZOre5c+oya4iAievO5f4YuFY3sFJbz6bDF2eMsOvcfM8b8IK6+yd+z1j4PvAT4qLrmGX+sAWPMW4G3AvDot9WUlMDMBkYu22kg5LyQzslBdyhkGFcqYfQMrjQYqE0HnpO26lqUGekgaTeVyvX9cl4mXUgZe04KXAdd10fSWG7iJhJuhC71lGay8rchCVNLv76MYqtnhjeuOoOfco/EZSFtbVu3KdGwUftJmoEchLnrilBC++0Z82pWpwb2FacKVuzP9tibugCkR3iWR/lSCJ1/msfYv7vH/PYLGqqUViabuvhGaqP+8ZVzCMh9ztLQstjn6RzG8Lt2vWLcvZaZO6k7pDBdSZwmEvJyPuXkKze49qJvuF2R3yktimmsOqlqQ6e2h+h2RUDV3joh0ZhI47MFO3sHtWrI7yxWnr5y54hFuQpCS5RGO4PTMvefBX4Sp1D5SeBdwF9b5wbW2ncD7wYw3/k6y95xJI0t5tO6+DH1YFlG7nzduvPU8yJV0TTynQj0oBGppONZpH29sxCkDL4NzYlT68T1YOxcuNS1WmJv0xOfBumiI4bmVGqO/gaCO/q4zISspww+F3egJVKpvhXOaW+a5LjKPXSyf6N5HmpGXkK6s2ycl+9pF8sxXeRBH9clCCtgf8YzPBaKfz/97GMAfKl8MR+f//G4D1MDJNQLqu7fxkIpEd+57KTDGGuOsWv1ZYPxql1Au/dSd9ttbs+ti1nlUmDMffrwSWZ+avWpzoIJcPLUDdiHk9kNFmLQLgh5fsRgen3q59e0LuAjbse5OSd8wqmIKpeNcr4Ffs5Wh3VaCL2jE7VcqGnRVamDUzJ3a+2z8tkY8/PAf/Vfvwg8pi59qT/WC1e4mrAaHR9eZ79q6jfbQnU1tEUadX3OlzzdvjWy3YWbNrepJ1XhMxHG+nXt155j6nob26e/L8oqYuLa4Kl15fJZLwBtARuujf5X37Zo6sWiweBhGIMIC0BNR2MBDffrkCrTbI86J5B+xMge4NvNnQ8MUJ3LTaIuKX3IMWiW2xPszziUQjT+tyd6AdFFGrp01HrnlFsgw2652yNG0KcW7BNg2qKme72hPNLFocuVOKCqC/Rot+ocjxBE7pElMIf5vvNXZwbbRbzTE8Pnwf5uYMgh1YBfWBpkVUWcisCr5wR67lVVXOow2P4uIreMMeZRa+2X/dcfAJ7wnz8M/HtjzE/hDKqvBD4+5J7BZUwHAR1u14npw0B0bmT4TGwQSwxdQTe5wam3b6CCOHJQi4C2yOd0kX16+fCMmQEb/6ZpRIVaiteSfE5f16ZPH+L10ta2PjdE31oTswbz19fl7p2eE2alJfmKWgqX1M7BnXG4miuS3NMu00x3HZQ0y7VFwVdyLpGwdWHknJQux9NrovN598IhboU59DLYHnQx+FywYC6AL3KR1uOsLJF0yyufc70oV6B12En65lVVuMpMcug2rmLY4cNsvejrrHaKRsUpUZ8czyeRAReI/NFPyirqL7lWS/l1GcJaW9EIoqvKpjoxwRBXyA8AbwBuGWOeAX4CeIMx5jU4tcxTwN8AsNZ+xhjzi8Bv47rmR3s9ZYBrhUusc3x4vTZkld7wNSPkYAjXqy3WkIjP9LrU6KpX8CgKL6NDzgVIpdD+5rGxNDWi9kseepDkmHcbcky9n5k3+6yLvtZzXc/U5uOcUdPU12QYVFsbWiLtQ27xEFfLwLQzSeSqls+0HNeLQ5fqRmeNzOX8bxiV+21G9T0y/dyCoZL0eSJrEF2Dlsb16aJfrqJYgfTe2rPIeVodu9q2UhrR5yw6PvwW7u59C+zMQ6rfnFoqqkIW6HAeNmGBCW1Pgp1MdPPa7TXtHwl8O3MNVWvtWzKH39Nx/TuBd/bdN/rNicnnJ85sy6+pzkldFDVSxpRK7qkxVN8ndGS5aurjyXu3pIZc3WYc5Vlk6WmjM0Wqd9fH63sM4259gUJnmuQh+Ecl6qqKdiaTY945vXHu2jbkftPXLtDpepky85w+vkqO6UyTWipPryNh7JrRp2qjQOd6fdGq785818e7jJd957t+pzHoHi0LWiT963et2ihLl3grzcuSK58Zqeektir+M8DhjOPZzNUxTXdCVREniStBYnbEs0bPYe0Kue2l8aPDpjNFznutC2e3sJ0DzDWLKVVuCoh1hsot7aRaKV/RlGEPU4W447X/s74uO8AzEyPHQHPSchpgpOkasp3VL1Rb99uu7dL1tyH7zMkkyhnDsr/X+m+BWixb7Rn62nSS6nukn4ci95uI7sxUyEUA5mZMyuBTfX+V+ZtT86RSvQ7O0jTmDKFtaOmrdRfuvuuHBuYNcZdMo76HGF0bMQay8KnxVFUF9xbbwQ2xU/0KBEN4Se3pJF5PXhfPTKpPSd1fZcBPvavY4mS+xbzcZmvvIAiE4iYpla9kfqcG4DQZWlGuzia53w8YY93Kq5m5hl6ppAqKXy3FRzTVPYslustTpDWISQd/ZPSTOUNtu2tmapRKdHuZa9K22vyLU8juJ5JgMgvTIPRc37ogdL27AfcdYu+4EKQeODCcgQJRdkr525DMOyCMvfL3yrUddj3p8ZZdTd9CfJ+QTc/RcU3u3CC6RZULjX64Vq4ST7tVps5x0oaU69yhGWQJROX3xPNpZlwO+NmCa76a2Ml80qjuJgFxS2rpfDrLJ58L5PUId43uGHTVBWNVFVjZ2pUrJAd272pfOePJ3G+rUkOGRj7qL6On08ExZfivlY5GhGN6Ptmy9qldNF1t39vaiaTmSGe76tw6n8ZjARim0qjKbqY8QCprbeusaGWKa1pHq5LatZBYKo88ctL2IeuCGT4rKbSz/VPYPgINF7dg9uWl6doNDr1XDrn4FT3+JWJUVCTaYNkUTmzNuCFWMYrqRS/oc3DV3maceHXatdmSyd5BNodQityuW/hF8LAJzifdfbIRzN0YG1avtsRVq6qI05GmktZ8i+PDmY9GrIvttqoR5lOiSj45rwfxtigzRT5029A5AdPBlg7qs3gbNBYmXZA5kf4i+8G6k/q0NIYScgN05l3SedDZX6D03tZuDtmFTTH4rPqmZyfQ8MUXZj+QyTfu10P7Ofbl2sw3833d3WWcmqNpfGwTWMSXXHIZNVQ6KXKGbHDva8fEtQP89ZInSGd7LMoVRVVELsxa4IxVuLG6uSjqtBOyIEF3/M1GMPdrxUmwOocH8VxW8mSEyiXpgNcIq6iB286VKfgHy1/tW1y2fG69rz/fKG48YNK1SBNwtokRQXt6pIbLLtUTtD9DVlfdM2yEjsbvBiwQbQw8p4dvo+80OI3aKkxytVtZS5WTu2+bzyVNoaaPvoHnhujD+5C6JXYhzcI4FOuk39DtaBpPqoJjXRy7TWLXaOv3RCeeetLlhNXJdAlTVPRpnNdJO0xoXliyoioKKNw9Vj6Q6W7H828EczfGcv3GvejYcuVzbBRK/6TVJTqKsEvPmRqz0uMpg9eeCl3ua5qxp4NuiISppKd1BnrrRNRGyxxSY+ZQJpG2M8QTJ93NVCUNL4++NtuMr130nROj78o42Ip1peo+DLnfOTxvqg9PcRqGP8S4ehrvmhyGBE61pkKAgYJKeiy/OLbRJcnEtNBaFBWronTZJ72aRevUdb7+ydQFSmm/+qKo68O2kt79ZPcHFuNSW/qqMgUrVoV/UJyO+lq54mTnONHntjD49JiGdkebqc+N62x774Rwd+Ot5GXM5NfRHXtG1ib5nKsB7DQTqrGIZAyPrb9dQ9Lsa3fI/U6pbjj1wnoWG8EZmdsQmoeMnb7d43lI9eu22Yb+mJC8mrMxn3S7bTvbNvTQnHO3jugpqBk8FUVRUdxwbpC5RH+rqmDJJKQ+0NA537OkDnmei4bBhlWoco8MuNVKp908gdq9KJWqhVGn0nuO8WsDib4HkHd/S3Shc3WvQ5yFvFRMfgg6BklXtjt9TYQ1jGd9Ezabf3sdaSeiaw2JvQ/nLB3n+nZIUNygxfcCbAPrMsN1JPH77UVzXpK7oM0luovRa3QWF8mgb+zk0n3XzhSTSJKfsqCYukLYS4bl3+9j7LAhzP3k5BrLxSSUswKnllnOXbrf4EokTFWs0vJ9hzqVahrKnVPTyO+1SqaNb1RAaeLv6T3F71V8XmWxCPdviTDswKknW5crYpV4B4Vr8raA7DVV0f4cQw1S54Gz7Apa0KXTbYsdWFeyXccz6Txw1rYuit6cKrKrna7FoMvdeN18Sl20rLMg5eJTcrr0iG4qCikSUjVTqaSJBPuwGcx9VXD39l7wWZfCBMynTlLXTD24G1Ez85Shk5zP6dtTJp26rLUx/i7/Zb1gyDUl1D7Q3uvG5wCP0Meohg6sRsbEnnZy1wylaSiG6DUbkZdn14V2oU9Pui5SJthVSOK0uAwf9fNuc9BOdA07Shtj72KAbS7RQ+jsQhq3kgs6Aup0vlL8uocW4YXHOh9/GuCWwUYwdyoDhzNOgDk3/DFq6Vz+QZ33OkjqLd4JUeg2xMmkIJLyW3XrDDPWpp/Tezb8nTN5ydlSn4lVQeuEmUf3HWKUy1yTSyU75PrTIv39eapyWjCEaZ1FdXAZjPgqoLdfUpdEv0PTyf00clW9NPoyW5416VkOOvBQS+65wjnt9yhj+sQDbW584NRWL/feDOa+AJ6kSU3KUHeoJXVhmGlVnNYoPojC4nO6eHq+dzFw/V0bbVN0eLptBIYy9HXO3y+csx/8Ou59IzM/BVrtFVU9V5WQ0xeIJ+hKv3ERzHxIO20qoS568upR/1fb/VqwGSzmGrEOHWIGqRmlnNeqGfkrAUdDfI1z95TPbUx7CFKJPTrXUkiiDxegX27FpjDqdXABxssU37TMu9P9c6CnSZd77pq/GeJpc1EM/KJsDwG9/Vi5eheSEuGw5/IzU3ce2MKV9ZA8DSmD10hXLDkfuTV2FI7N+qsPvLaN73UZZKPft1QGasNVZLTf5DirF8jGLSL6eU7joXVByEnx6ybM67r3eWGtOgfQb//SdQtS9W76k752jTHvBf4C8Jy19tX+2IeAP+Qv2QP2rbWv8YW0fwf4rD/3UWvtj/S1QWHhRcfNB6sSL5X0c5cOHNrVImXyXV/b1SPCxIcw/S4feehm7leNqbcxtIue/PdBYh+C83Tr22j1z7o+4fcRaU51iPM4Dc7PdNHocp3t8kTT1+m/XZcOIOd9wM8A75cD1tq/Ip+NMe+CKAr289ba1wy4bw1jXcmoKhPpGX0fQG7OT/08kQ14WvcePVL7gHw1p8b9ZIhD2jqVofhymPp5+2anOA+3xYu8f8A598N59Gsu2Vbq+z40mnUdF821cQpVlCAbt9DVVB8t1tpf9xJ5A8YYA/xl4E/13WcIGj616ZZwkPdH5tg5FIa+MJwXA98QKXZtXBG6r4LnTJ8B+KIXp6F03A+cVj1zln5bJ9ah6zfn1Wdn5Xp/EnjWWvs5dezlxpjfBL4O/CNr7f/uv43p75j0gdd5eVdNzTEEV4QpPijYOF14Dy6TwV4WQ79snOa51/3NOuPwrMz9LcAH1PcvA99mrb1jjHkd8J+NMd9hrf16+kNjzFuBtwLwksfWb/mbdACNGNGHb1bm+qBjXQHj1MzdGFMCfwl4nRyz1i5wXutYa3/DGPN54NuBT6S/t9a+G3g3gPnO150xT+qIEeePvrqh96utESOgvYh4G84iuf8Z4Hettc/IAWPMw8DXrLUrY8wrgFcCv99/q5G3jzh/XCTDHJnxiMvGNUmm2IIhrpAfAN4A3DLGPAP8hLX2PcDjxCoZgNcD/9QYc4wz5P6ItfZrQwlNcdX0nOeFkXGMGDHirBjiLfOWluN/NXPsl4FfPjtZDiOTGzFixIjTwVh7+SoRY8xXgW8Aty+bllPgFleTbri6tF9VuuHq0n5V6YarS/sQuv+Atfbh3ImNYO4AxphPWGu/67LpWBdXlW64urRfVbrh6tJ+VemGq0v7Wem+dp7EjBgxYsSIzcDI3EeMGDHiAcQmMfd3XzYBp8RVpRuuLu1XlW64urRfVbrh6tJ+Jro3Ruc+YsSIESPOD5skuY8YMWLEiHPCyNxHjBgx4gHEpTN3Y8z3GWM+a4x50hjztsumpw/GmKeMMb9ljPmkMeYT/tgLjTG/Yoz5nP/7gg2g873GmOeMMU+oY1k6jcO/9O/g08aY114e5a20v8MY80Xf7580xrxRnXu7p/2zxpg/fzlUgzHmMWPMR4wxv22M+Ywx5u/44xvf7x20b3S/G2NmxpiPG2M+5en+J/74y40xH/P0fcgYM/HHp/77k/78yy6D7h7a32eM+YLq89f44+uNF2vtpf0DCuDzwCuACfAp4FWXSdMAmp8CbiXH/jnwNv/5bcA/2wA6Xw+8Fniij07gjcB/x9Un/B7gYxtI+zuAv5+59lV+3EyBl/vxVFwS3Y8Cr/Wfd4Hf8/RtfL930L7R/e77bsd/3gI+5vvyF4HH/fGfA/6m//y3gJ/znx8HPnSJfd5G+/uAN2euX2u8XLbk/t3Ak9ba37fWLoEPAm+6ZJpOgzcBv+A//wLwFy+RFsAVWQHSvD5tdL4JeL91+CiwZ4x59P5Q2kQL7W14E/BBa+3CWvsF4EncuLrvsNZ+2Vr7//znA1zJyZdwBfq9g/Y2bES/+76TUtFb/p/FFRD6JX887XN5F78E/GljzAWXb8ujg/Y2rDVeLpu5vwR4Wn1/hu4BtQmwwP80xvyGcTnpAR6x1n7Zf/4K8MjlkNaLNjqvynv4Mb8dfa9SfW0k7X67/0dx0tiV6veEdtjwfjfGFMaYTwLPAb+C20XsW2ulSo+mLdDtz98Fbt5fimuktFtrpc/f6fv8p40xU39srT6/bOZ+FfG91trXAt8P/Kgx5vX6pHX7p433L70qdCr8LPAHgdfgisK863LJaYcxZgeXQO/v2qRQzab3e4b2je93a+3KurrNL8XtHv7wJZM0GCntxphXA2/HPcMfA14I/IPT3PuymfsXAV2G6aX+2MbCWvtF//c54D/hBtOzsj3yf5+7PAo70Ubnxr8Ha+2zfiKcAD9PrQLYKNqNMVs45vjvrLX/0R++Ev2eo/2q9DuAtXYf+AjwJ3AqC8l6q2kLdPvzDwF37jOpDSjav8+ryKx1xY/+Nafs88tm7v8XeKW3bE9wBo4PXzJNrTDG3DDG7Mpn4M8BT+Bo/iF/2Q8B/+VyKOxFG50fBn7QW+O/B7ir1AgbgUS3+AO4fgdH++PeC+LluAIxH7/f9EEoGP8e4HestT+lTm18v7fRvun9box52Biz5z9fB/4szl7wEeDN/rK0z+VdvBn4Nb+buu9oof13lSBgcLYC3efDx8tlWYoTC/Dv4fRkP37Z9PTQ+gqch8CngM8IvTid3f8CPgf8KvDCDaD1A7ht9DFON/fDbXTirO//yr+D3wK+awNp/zeetk/7Qf6ouv7HPe2fBb7/Eun+XpzK5dPAJ/2/N16Ffu+gfaP7HfgjwG96+p4A/rE//grcYvMk8B+AqT8+89+f9OdfcYl93kb7r/k+fwL4t9QeNWuNlzH9wIgRI0Y8gLhstcyIESNGjLgAjMx9xIgRIx5AjMx9xIgRIx5AjMx9xIgRIx5AjMx9xIgRIx5AjMx9xIgRIx5AjMx9xIgRIx5A/H9gQgIF/McARwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "xF9txCmLu0-Z",
        "outputId": "5704d9a3-f77b-434f-90b4-80a3802550f1"
      },
      "source": [
        "# Plot first row of temp\n",
        "plt.imshow(t2m2[0], cmap='jet')\n",
        "plt.title('Temperature');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "RfnbrLV8u06w",
        "outputId": "763f64af-9a50-4e41-ae87-1469d59aa46f"
      },
      "source": [
        "# Plot first row of geo-potential height\n",
        "plt.imshow(z8502[0], cmap='jet')\n",
        "plt.title('Geo-potential_height');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL_nUSt4vLtr"
      },
      "source": [
        "The user-defined normalise function was used to normalise the values 0-1. Stacking GCM variables as the channel of the input tensor and convert tensors into 4-dimensional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyNrWIk_FJyb"
      },
      "source": [
        "# Normalising function\n",
        "\n",
        "def norm_mean(a):\n",
        "\n",
        "\n",
        "  for i in range(a.shape[0]):\n",
        "\n",
        "\n",
        "     mu = torch.mean(a[i])\n",
        "     std = torch.std(a[i])\n",
        "\n",
        "     a[i] = (a[i] - mu)/std #implicit broadcasting applied on scalars\n",
        "\n",
        "  return a   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux69UDMJyp87"
      },
      "source": [
        "#normalising GCMs\n",
        "precip3 = norm_mean(precip2)\n",
        "t2m3 = norm_mean(t2m2)\n",
        "z8503 = norm_mean(z8502)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI4UhcToZopj",
        "outputId": "452b6027-384c-4894-96fe-17db6948634d"
      },
      "source": [
        "precip_norm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([465, 181, 360])"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UDA7Jj8yp87"
      },
      "source": [
        "# Stacking 3 GCM variables\n",
        "dataTensor = torch.stack([precip3, t2m3, z8503], dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqf4X9cSw7ZJ"
      },
      "source": [
        "# CNN\n",
        "\n",
        "CNN architecture setting:\n",
        "\n",
        "Convolutional layers: 6 and 12 filters of 5x5 size, padding of 0 and stride of 1; Relu activation function.  Average pooling layers: stride 2. Fully-connected layers: 120 (Relu), 60 (Relu) and 5 (Softmax) neurons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBQFUV1AsgUw"
      },
      "source": [
        "## Dropout CNN 0.5\n",
        "CNN consists of a dropout of 0.5 to the fully connected layers. This CNN is used for the evaluation of the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq02-6lTyp9E"
      },
      "source": [
        "# Building CNN network with dropouts\n",
        "\n",
        "class Network_drop(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "        #self.drop_out = nn.Dropout(p=0.5)\n",
        "        \n",
        "        #self.conv2_bn = nn.BatchNorm2d(12)\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features= 12*42*87, out_features=120)\n",
        "        self.drop_out = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "        self.drop_out = nn.Dropout(p=0.5)\n",
        "        self.out = nn.Linear(in_features=60, out_features=5)\n",
        "        #self.drop_out = nn.Dropout(p=0.5)\n",
        "        \n",
        "\n",
        "    def forward(self, t):\n",
        "    # implement the forward pass\n",
        "    \n",
        "        # (1) input layer\n",
        "        t = t #usually omitted since this is obviously trivial; size 360*131\n",
        "\n",
        "        # (2) hidden conv layer\n",
        "        t = self.conv1(t) #Haven't implemented wrapping - so after a 5x5 convolution, \n",
        "       \n",
        "        t = F.relu(t)\n",
        "        t = F.avg_pool2d(t, kernel_size=2, stride=2)\n",
        "        \n",
        "        #pooling 2x2 with stride 2 - reduces to 6 * 178 * 63\n",
        "\n",
        "        # (3) hidden conv layer\n",
        "        #t = self.conv2(t)\n",
        "        t = self.conv2(t)\n",
        "        t = F.relu(t)\n",
        "        t = F.avg_pool2d(t, kernel_size=2, stride=2)\n",
        "        #t = self.drop_out(t)\n",
        "       \n",
        "        #pooling 2x2 with stride 2 - reduces to 12 * 29 * 87\n",
        "\n",
        "        # (4) hidden linear layer\n",
        "        t = t.reshape(-1, 12 * 42 * 87)\n",
        "        t = self.fc1(t)\n",
        "        #t = self.fc1_bn(self.fc1(t))\n",
        "        t = F.relu(t)\n",
        "        t = self.drop_out(t)\n",
        "\n",
        "        # (5) hidden linear layer\n",
        "        t = self.fc2(t)\n",
        "        t = F.relu(t)\n",
        "        t = self.drop_out(t)\n",
        "\n",
        "        # (6) output layer\n",
        "        t = self.out(t)\n",
        "        #t = self.drop_out(t)\n",
        "        \n",
        "        #t = F.softmax(t, dim=1) #implicitly performed by F.cross_entropy()\n",
        "\n",
        "        return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qTJ88LlBoA1"
      },
      "source": [
        "## Dropout CNN\n",
        "\n",
        "CNN consists of dropout to the fully connected layers. It is used for Optuna hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwj3jetFyp9F"
      },
      "source": [
        "# Building CNN network with dropouts\n",
        "\n",
        "class Network_dropout(nn.Module):\n",
        "    def __init__(self, dropout):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "        \n",
        "        #self.conv2_bn = nn.BatchNorm2d(12)\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features= 12*42*87, out_features=120)\n",
        "        self.drop_out = nn.Dropout(p=dropout)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "        self.drop_out = nn.Dropout(p=dropout)\n",
        "        self.out = nn.Linear(in_features=60, out_features=5)\n",
        "        #self.drop_out = nn.Dropout(p=0.5)\n",
        "       \n",
        "\n",
        "    def forward(self, t):\n",
        "    # implement the forward pass\n",
        "    \n",
        "        # (1) input layer\n",
        "        t = t #usually omitted since this is obviously trivial; size 360*131\n",
        "\n",
        "        # (2) hidden conv layer\n",
        "        t = self.conv1(t) #Haven't implemented wrapping - so after a 5x5 convolution, \n",
        "       \n",
        "        t = F.relu(t)\n",
        "        t = F.avg_pool2d(t, kernel_size=2, stride=2)\n",
        "        \n",
        "        #pooling 2x2 with stride 2 - reduces to 6 * 178 * 63\n",
        "\n",
        "        # (3) hidden conv layer\n",
        "        #t = self.conv2(t)\n",
        "        t = self.conv2(t)\n",
        "        t = F.relu(t)\n",
        "        t = F.avg_pool2d(t, kernel_size=2, stride=2)\n",
        "       \n",
        "        #pooling 2x2 with stride 2 - reduces to 12 * 29 * 87\n",
        "\n",
        "        # (4) hidden linear layer\n",
        "        t = t.reshape(-1, 12 * 42 * 87)\n",
        "        t = self.fc1(t)\n",
        "        #t = self.fc1_bn(self.fc1(t))\n",
        "        t = F.relu(t)\n",
        "        t = self.drop_out(t)\n",
        "\n",
        "        # (5) hidden linear layer\n",
        "        t = self.fc2(t)\n",
        "        t = F.relu(t)\n",
        "        t = self.drop_out(t)\n",
        "\n",
        "        # (6) output layer\n",
        "        t = self.out(t)\n",
        "        #t = self.drop_out(t)\n",
        "        \n",
        "        #t = F.softmax(t, dim=1) #implicitly performed by F.cross_entropy()\n",
        "\n",
        "        return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmun8nxkPevn"
      },
      "source": [
        "## CNN with batch normalisation\n",
        "\n",
        "CNN consists of 2 convoutional layers followed by max pooling, 3 fully connected layers with batch normalisation.  A dropout of 0.5 is added to fully connected layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ95W9W3LhA7"
      },
      "source": [
        "# Building CNN network with dropouts\n",
        "\n",
        "class Network_drop_bn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "        #self.drop_out = nn.Dropout(p=0.5)\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features= 12 * 42 * 87, out_features=120)\n",
        "        self.fc1_bn = nn.BatchNorm1d(120)\n",
        "        self.drop_out = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "        self.conv2_bn = nn.BatchNorm2d(60)\n",
        "        self.drop_out = nn.Dropout(p=0.5)\n",
        "        self.out = nn.Linear(in_features=60, out_features=5)\n",
        "       \n",
        "        #they are dependant on the colour channels (3 since 3 GCMs) and output classes (5 since 5 classes on cat5) respectively\n",
        "\n",
        "    def forward(self, t):\n",
        "    # implement the forward pass\n",
        "    \n",
        "        # (1) input layer\n",
        "        t = t #usually omitted since this is obviously trivial; size 360*131\n",
        "\n",
        "        # (2) hidden conv layer\n",
        "        t = self.conv1(t) #Haven't implemented wrapping - so after a 5x5 convolution, \n",
        "       \n",
        "        t = F.relu(t)\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "        \n",
        "        #pooling 2x2 with stride 2 - reduces to 6 * 178 * 63\n",
        "\n",
        "        # (3) hidden conv layer\n",
        "        #t = self.conv2(t)\n",
        "        t = self.conv2(t)\n",
        "        t = F.relu(t)\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "        #t = self.drop_out(t)\n",
        "       \n",
        "        #pooling 2x2 with stride 2 - reduces to 12 * 29 * 87\n",
        "\n",
        "        # (4) hidden linear layer\n",
        "        t = t.reshape(-1, 12 * 42 * 87)\n",
        "        t = self.fc1(t)\n",
        "        t = self.fc1_bn(t)\n",
        "        t = F.relu(t)\n",
        "        t = self.drop_out(t)\n",
        "\n",
        "        # (5) hidden linear layer\n",
        "        t = self.fc2(t)\n",
        "       # t = self.conv2_bn(t)\n",
        "        t = F.relu(t)\n",
        "        t = self.drop_out(t)\n",
        "\n",
        "        # (6) output layer\n",
        "        t = self.out(t)\n",
        "        t = self.drop_out(t)\n",
        "        \n",
        "   \n",
        "        #t = F.softmax(t, dim=1) #implicitly performed by F.cross_entropy()\n",
        "\n",
        "\n",
        "        return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvU4U-XZQ25Y"
      },
      "source": [
        "# Rainfall models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWTNg7wmQ8ma"
      },
      "source": [
        "## NNI region"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pOwqSwsnAtHV"
      },
      "source": [
        "# Reading rainfall file of NNI region\n",
        "Data_rain_NNI = pd.read_csv(\"drive/My Drive/DL_project/Target_Rain_NNI_regional_ave_time_series.csv\", sep=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vUBUfwVHA28I",
        "outputId": "6b9fbcda-ad78-46f0-f96b-b0b6e61e6493"
      },
      "source": [
        "# Extracting quantiles labels from rainfall NNI data\n",
        "Labels_rain_NNI = Data_rain_NNI['cat_5'].astype(int) \n",
        "Labels_rain_NNI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      4\n",
              "1      4\n",
              "2      5\n",
              "3      4\n",
              "4      5\n",
              "      ..\n",
              "460    2\n",
              "461    3\n",
              "462    3\n",
              "463    2\n",
              "464    1\n",
              "Name: cat_5, Length: 465, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IczFPeZWY3PE"
      },
      "source": [
        "## NNI Rainfall labels\n",
        "\n",
        "NNI region quantiles labels are represented by 1, 2, 3, 4, 5 in the data set, but Pytorch accepts the labels from 0, 1, 2,3,4.\n",
        "\n",
        "Converting NNI region rainfall labels into tensors and 0, 1, 2, 3, 4. This represents target variable Y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a3zzNNQ7o_tp"
      },
      "source": [
        "# Function to convert labels into Pytorch tensors\n",
        "\n",
        "def labels_Tensors(labels):\n",
        "    return (torch.from_numpy(labels.values).type(torch.LongTensor)-1) #labels in the form of 1, 2, 3, 4, 5;\n",
        "\n",
        "# Converting labels of NNI region into tensors\n",
        "labelsTensors_NNI = labels_Tensors(Labels_rain_NNI) # This represents y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D_3tsnmxKga",
        "outputId": "60f92183-4b31-4b44-d057-4f84358a8e2b"
      },
      "source": [
        "# Distribution of original NNI region rainfall labels\n",
        "Labels_rain_NNI.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    104\n",
              "3     96\n",
              "2     91\n",
              "5     88\n",
              "4     86\n",
              "Name: cat_5, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Qpdn1GESpMAB",
        "outputId": "608bce81-6663-4320-fbfd-6702efefb5e3"
      },
      "source": [
        "# Histograms of original NNI region labels\n",
        "plt.hist(labelsTensors);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3j94cYGxtnj"
      },
      "source": [
        "## Training, validation and test split\n",
        "\n",
        "Data are divided into training set with initial 324 data points (70% of data, April 1981 - Mar 2008), validation set is next 71 data ponits (15% of the data, April 2008 - Feb 2014) and test set is last 70 data points (last 15% of data, Mar 2014 - Dec 2019 )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6q-sCyKBXm5T"
      },
      "source": [
        "# Spliting the dataTensors into training and test tensors \n",
        "\n",
        "train_Tensor = dataTensor[:324] # train set  \n",
        "valid_Tensor = dataTensor[324:395]  # Valid set\n",
        "test_Tensor = dataTensor[395:] # test set\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yKyi0izyWI7",
        "outputId": "4cc5a461-dae2-4c59-a8e0-e9b52d446b21"
      },
      "source": [
        "# Train lables distribution\n",
        "Train_labels = Labels_rain_NNI[:324]\n",
        "Train_labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    67\n",
              "2    66\n",
              "1    66\n",
              "3    63\n",
              "5    62\n",
              "Name: cat_5, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "UKPNR3R1WAW-",
        "outputId": "2fd4a6e4-4634-486d-9cfc-46b8d3d628d4"
      },
      "source": [
        "# Histograms of train labels\n",
        "plt.hist(Train_labels)\n",
        "plt.title('NNI_rain_train_valid');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMVornXvSMUl"
      },
      "source": [
        "# Optuna\n",
        "\n",
        "Optuna library was utilised for hyperparameter tuning. \n",
        "The set of values were assinged to hyperparameters as follows:\n",
        "batch size: [1, 10], learning rate: {0.1, 0.01, 0.001, 0.0001}, optimizer: {Adam, SGD, RMSprop} and dropout rate: {0.5, 0.7, 0.8, 0.9}.  The dropouts were added to the fully-connected layers.\n",
        "\n",
        "\n",
        "Steps to run the model under the Optuna framework:\n",
        "\n",
        "* Function to create data loaders.\n",
        "* Main function consists of the dictionary where all hyperparameter values are assigned, calling data loader function to have the training and validation data loaders, and a for loop that performs the training and validation steps. This function returns the validation accuracy to which we would like to maximize.\n",
        "* Final step is to define the objective function and set the number of trials.\n",
        "\n",
        "The best combination of hyperparameters that was determined for rainfall models are as follows:  batch size 10, learning rate 0.0001, RMSprops optimiser and 0.5 dropout rates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21GDId-Hp8gB"
      },
      "source": [
        "Dataloader function\n",
        "\n",
        "This function creates a training set and validation set by concatenating input values (X, GCM variables) and target values (y, rainfall dataset) like (X, y) form. Train loader and validation loader are created by using trainset and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZe6gNS0o_tv"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_valid_loaders_NNI(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "    \n",
        "    # Creating train set and validation set\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_NNI[:325])\n",
        "    validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_NNI[325:395])\n",
        "    # Creating train and validation dataloader\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "    \n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v2znZzlOMBg"
      },
      "source": [
        "Optuna framework is based on study object. It contains all of the information about the required parameter space. Maximize is assigned to direction variable as we are keen to find the maximum validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wxyvbjhE9xd",
        "outputId": "7bb982bc-14dc-4a9f-fa4d-b12fafe3f55b"
      },
      "source": [
        "study = optuna.create_study(sampler=optuna.samplers.TPESampler(), direction='maximize')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-25 23:06:09,268]\u001b[0m A new study created in memory with name: no-name-2958f9fc-1003-4635-8524-b24433b77578\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QafrOy0Rdqm"
      },
      "source": [
        "Main function:\n",
        "\n",
        "Once the study is created, the search space is incorporated via the trial.suggest_ methods. We can define different configuration to each parameter in cfg dictionary of main function (here we have train_Rain function).  We have defined the values to hyperparameter as follows:\n",
        " batch size: [1, 10], learning rate: {0.1, 0.01, 0.001, 0.0001}, optimizer: {Adam, SGD, RMSprop} and dropout rate: {0.5, 0.7, 0.9}. \n",
        "\n",
        "This function has a for loop which performs training and validation steps and returns the validation accuracy.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O8WYsoUSw18"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_NNI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "         'Batch_size' : trial.suggest_int('Batch_size', 1, 10),\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "          'save_model' : True,\n",
        "          'lr'       : trial.suggest_categorical('lr', [0.1, 0.01, 0.001, 0.0001]),          \n",
        "          'optimizer': trial.suggest_categorical('optimizer',[optim.SGD, optim.Adam, optim.RMSprop]),\n",
        "          'dropout'       : trial.suggest_categorical('dropout', [0.5, 0.7,0.9 ]),\n",
        "          'activation': F.relu}\n",
        "\n",
        "  # Loss function is defined\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # Defining device to run experiments on GPU if available\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  # Calling dataloader function\n",
        "  train_loader, valid_loader = get_valid_loaders_NNI(cfg['Batch_size'])\n",
        "  # Defining CNN model\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  # Setting optimizer\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "   \n",
        "  # Training steps\n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  \n",
        "  \n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "     \n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "       \n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           # Putting data and target on device to run on GPU \n",
        "           data, target = data.to(device), target.to(device)\n",
        "           # making zero gradient\n",
        "           optimizer.zero_grad()\n",
        "           # predicting new values by inserting input\n",
        "           output = model(data)\n",
        "           # bring model output and target back on CPU\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           # clculating loss\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           # calculate gradient\n",
        "           loss.backward()\n",
        "           # update weights\n",
        "           optimizer.step()\n",
        "           #Storing training loss \n",
        "           train_loss += loss.item()\n",
        "           # Calculating number of correct label predictions\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              # Putting data and target on device to run on GPU \n",
        "              data, target = data.to(device), target.to(device) \n",
        "              # predicting new values by inserting input        \n",
        "              output = model(data)\n",
        "              # bring model output and target back on CPU\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              # clculating loss\n",
        "              loss = criterion(output_c, target_c) \n",
        "              #Storing validation loss \n",
        "              valid_loss += loss.item()\n",
        "              # Calculating number of correct label predictions\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "\n",
        "       #calculating average training loss      \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       # calculating training accuracy \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       #calculating average validation loss \n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       #calculating validation accuracy \n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       # Combining training and validation accuracy for each epoch to plot accuracy curves\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       # Combining training and validation loss for each epoch to plot loss curves\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}% \\t Valid Loss:{: .3f} '.format(epoch, train_loss, train_acc, valid_acc, valid_loss))  \n",
        "\n",
        "\n",
        "       # Save model\n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"./check_valid_NNI_RMSprops.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjIPDW_3S_GE"
      },
      "source": [
        "The final step is to define the objective function, the output of which will be optimized over in our case we have train_NNI. A value n is assigned to the n_trails variable to have n different combinations of trials. Here, we have trials of 10  different combinations of parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vynma_6hS0Ll"
      },
      "source": [
        "import joblib\n",
        "\n",
        "study.optimize(train_NNI, n_trials=10)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"./optuna_valid_NNI_drop.torch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAdXsS0Dlf_6",
        "outputId": "56e594b8-26fe-4d8f-fdbe-4d011f5d55c3"
      },
      "source": [
        "# Data Frame which display the number of trials excluding below variables columns\n",
        "df_NNI = study.trials_dataframe().drop(['duration','state','datetime_start','datetime_complete'], axis=1)\n",
        "df_NNI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>params_Batch_size</th>\n",
              "      <th>params_dropout</th>\n",
              "      <th>params_lr</th>\n",
              "      <th>params_optimizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>25.7</td>\n",
              "      <td>10</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>22.9</td>\n",
              "      <td>2</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>12.9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>11.4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>17.1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>17.1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>27.1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>27.1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>18.6</td>\n",
              "      <td>8</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    number  value  params_Batch_size  params_dropout  params_lr  \\\n",
              "0        0    NaN                 10             0.7     0.0100   \n",
              "1        1   25.7                 10             0.5     0.0010   \n",
              "2        2   22.9                  2             0.7     0.0010   \n",
              "3        3   12.9                  1             0.7     0.0010   \n",
              "4        4   11.4                  4             0.5     0.0010   \n",
              "5        5   17.1                  6             0.7     0.0010   \n",
              "6        6   11.4                  5             0.9     0.0100   \n",
              "7        7   17.1                  2             0.5     0.0001   \n",
              "8        8   27.1                  6             0.5     0.0010   \n",
              "9        9   27.1                  3             0.5     0.1000   \n",
              "10      10   18.6                  8             0.7     0.0100   \n",
              "\n",
              "                         params_optimizer  \n",
              "0         <class 'torch.optim.adam.Adam'>  \n",
              "1           <class 'torch.optim.sgd.SGD'>  \n",
              "2           <class 'torch.optim.sgd.SGD'>  \n",
              "3   <class 'torch.optim.rmsprop.RMSprop'>  \n",
              "4         <class 'torch.optim.adam.Adam'>  \n",
              "5         <class 'torch.optim.adam.Adam'>  \n",
              "6           <class 'torch.optim.sgd.SGD'>  \n",
              "7         <class 'torch.optim.adam.Adam'>  \n",
              "8           <class 'torch.optim.sgd.SGD'>  \n",
              "9         <class 'torch.optim.adam.Adam'>  \n",
              "10        <class 'torch.optim.adam.Adam'>  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS6eIsRvo_tz",
        "outputId": "25e68c34-a596-4226-968b-b6c1f273d91d"
      },
      "source": [
        "# The best combination of parameters that provides the maximum validation accuracy \n",
        "study.best_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Batch_size': 6,\n",
              " 'lr': 0.001,\n",
              " 'optimizer': torch.optim.sgd.SGD,\n",
              " 'dropout': 0.5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXk4in6Ilqgm"
      },
      "source": [
        "We are interested in knowing the training accuracy along with the validation accuracy on each trial. So, the below table is created by looking at the output of the objective function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "wZ7YS1c6lto0",
        "outputId": "f5989ba7-a52f-4031-eb6c-8025d78da211"
      },
      "source": [
        "data = {'Batch-size':[ 10, 2, 1, 4, 6, 5, 2, 6, 3, 8], 'Learning_rate':[0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.0001, 0.001, 0.1, 0.01], 'Optimization':['SGD', 'SGD', 'RMSprop', 'Adam', 'Adam', 'SGD', 'Adam', 'SGD', 'Adam', 'Adam'], 'Dropout_rate':[0.5, 0.7, 0.7, 0.5, 0.7, 0.9, 0.5, 0.5, 0.5, 0.7], 'Training_Acc':['20%', '20%', '21%', '18%', '21%', '20%', '61%', '21%', '19%', '22%'], 'Validation_Acc':['26%', '23%', '13%', '11%', '17%', '11%', '17%', '27%', '27%', '19%']  }\n",
        "Table = pd.DataFrame(data)\n",
        "Table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Batch-size</th>\n",
              "      <th>Learning_rate</th>\n",
              "      <th>Optimization</th>\n",
              "      <th>Dropout_rate</th>\n",
              "      <th>Training_Acc</th>\n",
              "      <th>Validation_Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.5</td>\n",
              "      <td>20%</td>\n",
              "      <td>26%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.7</td>\n",
              "      <td>20%</td>\n",
              "      <td>23%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.7</td>\n",
              "      <td>21%</td>\n",
              "      <td>13%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>18%</td>\n",
              "      <td>11%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.7</td>\n",
              "      <td>21%</td>\n",
              "      <td>17%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.9</td>\n",
              "      <td>20%</td>\n",
              "      <td>11%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>61%</td>\n",
              "      <td>17%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.5</td>\n",
              "      <td>21%</td>\n",
              "      <td>27%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>19%</td>\n",
              "      <td>27%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.7</td>\n",
              "      <td>22%</td>\n",
              "      <td>19%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Batch-size  Learning_rate Optimization  Dropout_rate Training_Acc  \\\n",
              "0          10         0.0010          SGD           0.5          20%   \n",
              "1           2         0.0010          SGD           0.7          20%   \n",
              "2           1         0.0010      RMSprop           0.7          21%   \n",
              "3           4         0.0010         Adam           0.5          18%   \n",
              "4           6         0.0010         Adam           0.7          21%   \n",
              "5           5         0.0100          SGD           0.9          20%   \n",
              "6           2         0.0001         Adam           0.5          61%   \n",
              "7           6         0.0010          SGD           0.5          21%   \n",
              "8           3         0.1000         Adam           0.5          19%   \n",
              "9           8         0.0100         Adam           0.7          22%   \n",
              "\n",
              "  Validation_Acc  \n",
              "0            26%  \n",
              "1            23%  \n",
              "2            13%  \n",
              "3            11%  \n",
              "4            17%  \n",
              "5            11%  \n",
              "6            17%  \n",
              "7            27%  \n",
              "8            27%  \n",
              "9            19%  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uznnSDx5lyED"
      },
      "source": [
        "From the above table, we can see that the training accuracy is 61% at only one trial, and the other trails model is unable to learn. The combination of parameters at that trail is batch size 2, learning rate 0.0001, Adam optimizer, and drop out rate is 0.5. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnJcvAB5lfMP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KxNAcZVxMZg"
      },
      "source": [
        "The Optuna was run with the batch size {2, 10} and optimizer {Adam, RMSprop}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtdoMftCl8MD"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_NNI_1(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          #'train_batch_size' : 5,\n",
        "          'Batch_size' : trial.suggest_categorical('Batch_size', [2, 10]),\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "          'save_model' : True,\n",
        "          'lr'       :  0.0001,          \n",
        "          'optimizer': trial.suggest_categorical('optimizer',[optim.Adam, optim.RMSprop]),\n",
        "          'dropout'       : 0.5,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_NNI(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "\n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  \n",
        "  \n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}% \\t Valid Loss:{: .3f} '.format(epoch, train_loss, train_acc, valid_acc, valid_loss))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"./check_valid_NNI_RMSprops.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myqkoTaaxliM"
      },
      "source": [
        "N_trail set is to 4 to have 4 different combinations of trials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-mRetIvTmZp"
      },
      "source": [
        "import joblib\n",
        "\n",
        "study.optimize(train_NNI_1, n_trials=4)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"./optuna_valid_NNI_drop.torch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjXv-39CmIVG"
      },
      "source": [
        "Table with the training and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "wYm4WyqeqtmW",
        "outputId": "d9b3a3f6-4ba7-466e-e064-7d7dfdce188e"
      },
      "source": [
        "data_1 = {'Batch_size':[2, 10, 10, 2], 'Optimizer':['RMSprop', 'Adam', 'RMSprop', 'Adam'], 'Training_Acc':['68%', '61%', '68%', '61%'], 'Validation_Acc':['24%', '20%', '26%', '17%']  }\n",
        "Table_1 = pd.DataFrame(data_1)\n",
        "Table_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Batch_size</th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>Training_Acc</th>\n",
              "      <th>Validation_Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>68%</td>\n",
              "      <td>24%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>Adam</td>\n",
              "      <td>61%</td>\n",
              "      <td>20%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>68%</td>\n",
              "      <td>26%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Adam</td>\n",
              "      <td>61%</td>\n",
              "      <td>17%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Batch_size Optimizer Training_Acc Validation_Acc\n",
              "0           2   RMSprop          68%            24%\n",
              "1          10      Adam          61%            20%\n",
              "2          10   RMSprop          68%            26%\n",
              "3           2      Adam          61%            17%"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paj5-zwby-kV"
      },
      "source": [
        "From Table_1, we can see that the highest training and validation accuracies are 68% and 26% with batch size 10 and RMSprop optimizer. Hence, the best combination of parameters is batch size 10, learning rate 0.0001, RMSprop optimizer and 0.5 dropouts. It observes that the model overfits with the best combinations of parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTanjik4mSsU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtQCN42pGhFT"
      },
      "source": [
        "The model was run with the best combinations of parameters and evaluated on the test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mFH3xiZFIDX"
      },
      "source": [
        "## Trainig with RMSprop, batch size 10, lr 0.0001\n",
        "\n",
        "The model was run with the best combinations of parameters to save the model parameters and evaluated on the test data set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMr_llWEUuo6"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_NNI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "        'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           #'dropout'       : 0.7,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_NNI(cfg['Batch_size'])\n",
        "  model = Network_drop().to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_NNI[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_NNI[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 10\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_NNI[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_NNI[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_NNI_RMSprops_std_indv.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAIZNgYdIJlc"
      },
      "source": [
        "Only one trial was assigned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4-QbpSOURRv",
        "outputId": "c5cc90bf-14a8-4225-fd8d-f7bc3ecb2fa9"
      },
      "source": [
        "study.optimize(train_NNI, n_trials=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.689 \tTrain_Accu: 22%  \tValid_Acc:19%  \tVal_kappa : 0.123  \n",
            "Epoch: 2 \tTraining Loss:  1.589 \tTrain_Accu: 28%  \tValid_Acc:24%  \tVal_kappa : 0.168  \n",
            "Epoch: 3 \tTraining Loss:  1.581 \tTrain_Accu: 24%  \tValid_Acc:24%  \tVal_kappa : 0.229  \n",
            "Epoch: 4 \tTraining Loss:  1.564 \tTrain_Accu: 29%  \tValid_Acc:23%  \tVal_kappa : 0.246  \n",
            "Epoch: 5 \tTraining Loss:  1.540 \tTrain_Accu: 34%  \tValid_Acc:20%  \tVal_kappa : 0.129  \n",
            "Epoch: 6 \tTraining Loss:  1.539 \tTrain_Accu: 27%  \tValid_Acc:27%  \tVal_kappa : 0.071  \n",
            "Epoch: 7 \tTraining Loss:  1.488 \tTrain_Accu: 36%  \tValid_Acc:24%  \tVal_kappa : 0.123  \n",
            "Epoch: 8 \tTraining Loss:  1.481 \tTrain_Accu: 33%  \tValid_Acc:19%  \tVal_kappa : 0.204  \n",
            "Epoch: 9 \tTraining Loss:  1.431 \tTrain_Accu: 37%  \tValid_Acc:14%  \tVal_kappa : 0.186  \n",
            "Epoch: 10 \tTraining Loss:  1.389 \tTrain_Accu: 39%  \tValid_Acc:19%  \tVal_kappa : 0.289  \n",
            "Epoch: 11 \tTraining Loss:  1.360 \tTrain_Accu: 43%  \tValid_Acc:21%  \tVal_kappa : 0.183  \n",
            "Epoch: 12 \tTraining Loss:  1.335 \tTrain_Accu: 42%  \tValid_Acc:19%  \tVal_kappa : 0.195  \n",
            "Epoch: 13 \tTraining Loss:  1.258 \tTrain_Accu: 50%  \tValid_Acc:14%  \tVal_kappa : 0.103  \n",
            "Epoch: 14 \tTraining Loss:  1.220 \tTrain_Accu: 50%  \tValid_Acc:26%  \tVal_kappa : 0.206  \n",
            "Epoch: 15 \tTraining Loss:  1.214 \tTrain_Accu: 53%  \tValid_Acc:14%  \tVal_kappa : 0.000  \n",
            "Epoch: 16 \tTraining Loss:  1.102 \tTrain_Accu: 55%  \tValid_Acc:21%  \tVal_kappa : 0.282  \n",
            "Epoch: 17 \tTraining Loss:  1.092 \tTrain_Accu: 57%  \tValid_Acc:21%  \tVal_kappa : 0.017  \n",
            "Epoch: 18 \tTraining Loss:  1.003 \tTrain_Accu: 63%  \tValid_Acc:13%  \tVal_kappa : 0.103  \n",
            "Epoch: 19 \tTraining Loss:  1.023 \tTrain_Accu: 61%  \tValid_Acc:17%  \tVal_kappa : 0.092  \n",
            "Epoch: 20 \tTraining Loss:  0.920 \tTrain_Accu: 63%  \tValid_Acc:17%  \tVal_kappa : 0.096  \n",
            "Epoch: 21 \tTraining Loss:  0.932 \tTrain_Accu: 63%  \tValid_Acc:19%  \tVal_kappa : -0.059  \n",
            "Epoch: 22 \tTraining Loss:  0.933 \tTrain_Accu: 63%  \tValid_Acc:13%  \tVal_kappa : -0.100  \n",
            "Epoch: 23 \tTraining Loss:  0.890 \tTrain_Accu: 67%  \tValid_Acc:13%  \tVal_kappa : -0.015  \n",
            "Epoch: 24 \tTraining Loss:  0.817 \tTrain_Accu: 70%  \tValid_Acc:21%  \tVal_kappa : 0.053  \n",
            "Epoch: 25 \tTraining Loss:  0.719 \tTrain_Accu: 72%  \tValid_Acc:17%  \tVal_kappa : 0.209  \n",
            "Epoch: 26 \tTraining Loss:  0.694 \tTrain_Accu: 73%  \tValid_Acc:21%  \tVal_kappa : 0.008  \n",
            "Epoch: 27 \tTraining Loss:  0.671 \tTrain_Accu: 76%  \tValid_Acc:23%  \tVal_kappa : 0.100  \n",
            "Epoch: 28 \tTraining Loss:  0.620 \tTrain_Accu: 76%  \tValid_Acc:20%  \tVal_kappa : -0.016  \n",
            "Epoch: 29 \tTraining Loss:  0.669 \tTrain_Accu: 72%  \tValid_Acc:20%  \tVal_kappa : 0.015  \n",
            "Epoch: 30 \tTraining Loss:  0.538 \tTrain_Accu: 83%  \tValid_Acc:17%  \tVal_kappa : -0.008  \n",
            "Epoch: 31 \tTraining Loss:  0.577 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : 0.125  \n",
            "Epoch: 32 \tTraining Loss:  0.547 \tTrain_Accu: 80%  \tValid_Acc:19%  \tVal_kappa : -0.108  \n",
            "Epoch: 33 \tTraining Loss:  0.543 \tTrain_Accu: 78%  \tValid_Acc:17%  \tVal_kappa : 0.098  \n",
            "Epoch: 34 \tTraining Loss:  0.537 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : 0.082  \n",
            "Epoch: 35 \tTraining Loss:  0.458 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : 0.023  \n",
            "Epoch: 36 \tTraining Loss:  0.443 \tTrain_Accu: 84%  \tValid_Acc:21%  \tVal_kappa : 0.038  \n",
            "Epoch: 37 \tTraining Loss:  0.439 \tTrain_Accu: 82%  \tValid_Acc:14%  \tVal_kappa : -0.025  \n",
            "Epoch: 38 \tTraining Loss:  0.358 \tTrain_Accu: 86%  \tValid_Acc:16%  \tVal_kappa : 0.094  \n",
            "Epoch: 39 \tTraining Loss:  0.356 \tTrain_Accu: 86%  \tValid_Acc:17%  \tVal_kappa : -0.046  \n",
            "Epoch: 40 \tTraining Loss:  0.429 \tTrain_Accu: 83%  \tValid_Acc:19%  \tVal_kappa : 0.109  \n",
            "Epoch: 41 \tTraining Loss:  0.378 \tTrain_Accu: 84%  \tValid_Acc:24%  \tVal_kappa : -0.049  \n",
            "Epoch: 42 \tTraining Loss:  0.357 \tTrain_Accu: 85%  \tValid_Acc:27%  \tVal_kappa : 0.017  \n",
            "Epoch: 43 \tTraining Loss:  0.284 \tTrain_Accu: 90%  \tValid_Acc:17%  \tVal_kappa : 0.046  \n",
            "Epoch: 44 \tTraining Loss:  0.343 \tTrain_Accu: 89%  \tValid_Acc:17%  \tVal_kappa : -0.066  \n",
            "Epoch: 45 \tTraining Loss:  0.345 \tTrain_Accu: 86%  \tValid_Acc:16%  \tVal_kappa : -0.112  \n",
            "Epoch: 46 \tTraining Loss:  0.301 \tTrain_Accu: 88%  \tValid_Acc:20%  \tVal_kappa : 0.023  \n",
            "Epoch: 47 \tTraining Loss:  0.290 \tTrain_Accu: 90%  \tValid_Acc:20%  \tVal_kappa : 0.129  \n",
            "Epoch: 48 \tTraining Loss:  0.236 \tTrain_Accu: 92%  \tValid_Acc:16%  \tVal_kappa : -0.143  \n",
            "Epoch: 49 \tTraining Loss:  0.260 \tTrain_Accu: 90%  \tValid_Acc:17%  \tVal_kappa : -0.108  \n",
            "Epoch: 50 \tTraining Loss:  0.311 \tTrain_Accu: 88%  \tValid_Acc:13%  \tVal_kappa : 0.096  \n",
            "Epoch: 51 \tTraining Loss:  0.247 \tTrain_Accu: 92%  \tValid_Acc:11%  \tVal_kappa : -0.105  \n",
            "Epoch: 52 \tTraining Loss:  0.219 \tTrain_Accu: 92%  \tValid_Acc:21%  \tVal_kappa : 0.105  \n",
            "Epoch: 53 \tTraining Loss:  0.255 \tTrain_Accu: 91%  \tValid_Acc:19%  \tVal_kappa : 0.099  \n",
            "Epoch: 54 \tTraining Loss:  0.235 \tTrain_Accu: 93%  \tValid_Acc:13%  \tVal_kappa : -0.044  \n",
            "Epoch: 55 \tTraining Loss:  0.223 \tTrain_Accu: 92%  \tValid_Acc:27%  \tVal_kappa : -0.068  \n",
            "Epoch: 56 \tTraining Loss:  0.216 \tTrain_Accu: 92%  \tValid_Acc:20%  \tVal_kappa : 0.075  \n",
            "Epoch: 57 \tTraining Loss:  0.275 \tTrain_Accu: 89%  \tValid_Acc:20%  \tVal_kappa : -0.139  \n",
            "Epoch: 58 \tTraining Loss:  0.245 \tTrain_Accu: 93%  \tValid_Acc:19%  \tVal_kappa : -0.125  \n",
            "Epoch: 59 \tTraining Loss:  0.171 \tTrain_Accu: 95%  \tValid_Acc:14%  \tVal_kappa : -0.068  \n",
            "Epoch: 60 \tTraining Loss:  0.166 \tTrain_Accu: 94%  \tValid_Acc:24%  \tVal_kappa : -0.122  \n",
            "Epoch: 61 \tTraining Loss:  0.176 \tTrain_Accu: 94%  \tValid_Acc:23%  \tVal_kappa : 0.000  \n",
            "Epoch: 62 \tTraining Loss:  0.170 \tTrain_Accu: 94%  \tValid_Acc:17%  \tVal_kappa : 0.031  \n",
            "Epoch: 63 \tTraining Loss:  0.157 \tTrain_Accu: 94%  \tValid_Acc:17%  \tVal_kappa : 0.039  \n",
            "Epoch: 64 \tTraining Loss:  0.180 \tTrain_Accu: 94%  \tValid_Acc:20%  \tVal_kappa : -0.061  \n",
            "Epoch: 65 \tTraining Loss:  0.170 \tTrain_Accu: 95%  \tValid_Acc:19%  \tVal_kappa : -0.015  \n",
            "Epoch: 66 \tTraining Loss:  0.183 \tTrain_Accu: 93%  \tValid_Acc:19%  \tVal_kappa : 0.008  \n",
            "Epoch: 67 \tTraining Loss:  0.143 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : -0.007  \n",
            "Epoch: 68 \tTraining Loss:  0.161 \tTrain_Accu: 94%  \tValid_Acc:17%  \tVal_kappa : -0.034  \n",
            "Epoch: 69 \tTraining Loss:  0.143 \tTrain_Accu: 95%  \tValid_Acc:16%  \tVal_kappa : -0.051  \n",
            "Epoch: 70 \tTraining Loss:  0.207 \tTrain_Accu: 91%  \tValid_Acc:14%  \tVal_kappa : -0.102  \n",
            "Epoch: 71 \tTraining Loss:  0.122 \tTrain_Accu: 96%  \tValid_Acc:10%  \tVal_kappa : -0.164  \n",
            "Epoch: 72 \tTraining Loss:  0.155 \tTrain_Accu: 94%  \tValid_Acc:19%  \tVal_kappa : 0.040  \n",
            "Epoch: 73 \tTraining Loss:  0.185 \tTrain_Accu: 93%  \tValid_Acc:19%  \tVal_kappa : -0.140  \n",
            "Epoch: 74 \tTraining Loss:  0.191 \tTrain_Accu: 93%  \tValid_Acc:14%  \tVal_kappa : -0.166  \n",
            "Epoch: 75 \tTraining Loss:  0.113 \tTrain_Accu: 95%  \tValid_Acc:16%  \tVal_kappa : -0.035  \n",
            "Epoch: 76 \tTraining Loss:  0.171 \tTrain_Accu: 94%  \tValid_Acc:11%  \tVal_kappa : -0.147  \n",
            "Epoch: 77 \tTraining Loss:  0.147 \tTrain_Accu: 94%  \tValid_Acc:21%  \tVal_kappa : -0.030  \n",
            "Epoch: 78 \tTraining Loss:  0.134 \tTrain_Accu: 95%  \tValid_Acc:16%  \tVal_kappa : -0.175  \n",
            "Epoch: 79 \tTraining Loss:  0.110 \tTrain_Accu: 96%  \tValid_Acc:17%  \tVal_kappa : -0.008  \n",
            "Epoch: 80 \tTraining Loss:  0.149 \tTrain_Accu: 95%  \tValid_Acc:14%  \tVal_kappa : 0.141  \n",
            "Epoch: 81 \tTraining Loss:  0.128 \tTrain_Accu: 95%  \tValid_Acc:23%  \tVal_kappa : 0.096  \n",
            "Epoch: 82 \tTraining Loss:  0.175 \tTrain_Accu: 94%  \tValid_Acc:19%  \tVal_kappa : 0.008  \n",
            "Epoch: 83 \tTraining Loss:  0.086 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.037  \n",
            "Epoch: 84 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.161  \n",
            "Epoch: 85 \tTraining Loss:  0.134 \tTrain_Accu: 95%  \tValid_Acc:7%  \tVal_kappa : -0.249  \n",
            "Epoch: 86 \tTraining Loss:  0.094 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : -0.111  \n",
            "Epoch: 87 \tTraining Loss:  0.060 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.072  \n",
            "Epoch: 88 \tTraining Loss:  0.106 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : -0.017  \n",
            "Epoch: 89 \tTraining Loss:  0.120 \tTrain_Accu: 96%  \tValid_Acc:16%  \tVal_kappa : -0.047  \n",
            "Epoch: 90 \tTraining Loss:  0.092 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : -0.030  \n",
            "Epoch: 91 \tTraining Loss:  0.107 \tTrain_Accu: 96%  \tValid_Acc:17%  \tVal_kappa : -0.137  \n",
            "Epoch: 92 \tTraining Loss:  0.100 \tTrain_Accu: 96%  \tValid_Acc:13%  \tVal_kappa : -0.243  \n",
            "Epoch: 93 \tTraining Loss:  0.182 \tTrain_Accu: 95%  \tValid_Acc:11%  \tVal_kappa : -0.177  \n",
            "Epoch: 94 \tTraining Loss:  0.134 \tTrain_Accu: 95%  \tValid_Acc:9%  \tVal_kappa : -0.166  \n",
            "Epoch: 95 \tTraining Loss:  0.098 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.249  \n",
            "Epoch: 96 \tTraining Loss:  0.090 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.209  \n",
            "Epoch: 97 \tTraining Loss:  0.095 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : -0.022  \n",
            "Epoch: 98 \tTraining Loss:  0.078 \tTrain_Accu: 96%  \tValid_Acc:20%  \tVal_kappa : 0.008  \n",
            "Epoch: 99 \tTraining Loss:  0.084 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.256  \n",
            "Epoch: 100 \tTraining Loss:  0.071 \tTrain_Accu: 97%  \tValid_Acc:13%  \tVal_kappa : -0.127  \n",
            "Epoch: 101 \tTraining Loss:  0.108 \tTrain_Accu: 96%  \tValid_Acc:17%  \tVal_kappa : -0.036  \n",
            "Epoch: 102 \tTraining Loss:  0.090 \tTrain_Accu: 97%  \tValid_Acc:11%  \tVal_kappa : -0.059  \n",
            "Epoch: 103 \tTraining Loss:  0.091 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : -0.173  \n",
            "Epoch: 104 \tTraining Loss:  0.110 \tTrain_Accu: 95%  \tValid_Acc:16%  \tVal_kappa : -0.135  \n",
            "Epoch: 105 \tTraining Loss:  0.079 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.120  \n",
            "Epoch: 106 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \tValid_Acc:11%  \tVal_kappa : -0.067  \n",
            "Epoch: 107 \tTraining Loss:  0.104 \tTrain_Accu: 96%  \tValid_Acc:16%  \tVal_kappa : -0.183  \n",
            "Epoch: 108 \tTraining Loss:  0.083 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : 0.059  \n",
            "Epoch: 109 \tTraining Loss:  0.121 \tTrain_Accu: 95%  \tValid_Acc:13%  \tVal_kappa : -0.101  \n",
            "Epoch: 110 \tTraining Loss:  0.089 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : -0.095  \n",
            "Epoch: 111 \tTraining Loss:  0.076 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.016  \n",
            "Epoch: 112 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.088  \n",
            "Epoch: 113 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.031  \n",
            "Epoch: 114 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.063  \n",
            "Epoch: 115 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : 0.040  \n",
            "Epoch: 116 \tTraining Loss:  0.075 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : -0.328  \n",
            "Epoch: 117 \tTraining Loss:  0.069 \tTrain_Accu: 97%  \tValid_Acc:13%  \tVal_kappa : -0.077  \n",
            "Epoch: 118 \tTraining Loss:  0.081 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : 0.023  \n",
            "Epoch: 119 \tTraining Loss:  0.099 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.137  \n",
            "Epoch: 120 \tTraining Loss:  0.085 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.098  \n",
            "Epoch: 121 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.257  \n",
            "Epoch: 122 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.059  \n",
            "Epoch: 123 \tTraining Loss:  0.085 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.183  \n",
            "Epoch: 124 \tTraining Loss:  0.076 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.073  \n",
            "Epoch: 125 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:7%  \tVal_kappa : -0.270  \n",
            "Epoch: 126 \tTraining Loss:  0.104 \tTrain_Accu: 96%  \tValid_Acc:14%  \tVal_kappa : -0.111  \n",
            "Epoch: 127 \tTraining Loss:  0.060 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : -0.033  \n",
            "Epoch: 128 \tTraining Loss:  0.081 \tTrain_Accu: 97%  \tValid_Acc:11%  \tVal_kappa : -0.194  \n",
            "Epoch: 129 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.184  \n",
            "Epoch: 130 \tTraining Loss:  0.077 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : -0.043  \n",
            "Epoch: 131 \tTraining Loss:  0.119 \tTrain_Accu: 96%  \tValid_Acc:16%  \tVal_kappa : -0.187  \n",
            "Epoch: 132 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.114  \n",
            "Epoch: 133 \tTraining Loss:  0.061 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : -0.138  \n",
            "Epoch: 134 \tTraining Loss:  0.086 \tTrain_Accu: 96%  \tValid_Acc:11%  \tVal_kappa : -0.295  \n",
            "Epoch: 135 \tTraining Loss:  0.018 \tTrain_Accu: 100%  \tValid_Acc:11%  \tVal_kappa : -0.227  \n",
            "Epoch: 136 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.194  \n",
            "Epoch: 137 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \tValid_Acc:14%  \tVal_kappa : -0.146  \n",
            "Epoch: 138 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.280  \n",
            "Epoch: 139 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : -0.117  \n",
            "Epoch: 140 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.000  \n",
            "Epoch: 141 \tTraining Loss:  0.065 \tTrain_Accu: 97%  \tValid_Acc:13%  \tVal_kappa : -0.116  \n",
            "Epoch: 142 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.098  \n",
            "Epoch: 143 \tTraining Loss:  0.070 \tTrain_Accu: 97%  \tValid_Acc:13%  \tVal_kappa : -0.198  \n",
            "Epoch: 144 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.037  \n",
            "Epoch: 145 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.065  \n",
            "Epoch: 146 \tTraining Loss:  0.018 \tTrain_Accu: 100%  \tValid_Acc:16%  \tVal_kappa : -0.063  \n",
            "Epoch: 147 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.083  \n",
            "Epoch: 148 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.127  \n",
            "Epoch: 149 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.122  \n",
            "Epoch: 150 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.106  \n",
            "Epoch: 151 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.089  \n",
            "Epoch: 152 \tTraining Loss:  0.063 \tTrain_Accu: 97%  \tValid_Acc:11%  \tVal_kappa : -0.104  \n",
            "Epoch: 153 \tTraining Loss:  0.077 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : 0.016  \n",
            "Epoch: 154 \tTraining Loss:  0.068 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.117  \n",
            "Epoch: 155 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \tValid_Acc:10%  \tVal_kappa : -0.045  \n",
            "Epoch: 156 \tTraining Loss:  0.075 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.014  \n",
            "Epoch: 157 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.022  \n",
            "Epoch: 158 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.029  \n",
            "Epoch: 159 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.172  \n",
            "Epoch: 160 \tTraining Loss:  0.075 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.150  \n",
            "Epoch: 161 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.099  \n",
            "Epoch: 162 \tTraining Loss:  0.071 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.047  \n",
            "Epoch: 163 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.000  \n",
            "Epoch: 164 \tTraining Loss:  0.103 \tTrain_Accu: 97%  \tValid_Acc:14%  \tVal_kappa : -0.137  \n",
            "Epoch: 165 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:11%  \tVal_kappa : 0.037  \n",
            "Epoch: 166 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.056  \n",
            "Epoch: 167 \tTraining Loss:  0.045 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.068  \n",
            "Epoch: 168 \tTraining Loss:  0.080 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.112  \n",
            "Epoch: 169 \tTraining Loss:  0.076 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : 0.016  \n",
            "Epoch: 170 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.163  \n",
            "Epoch: 171 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:11%  \tVal_kappa : -0.163  \n",
            "Epoch: 172 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.073  \n",
            "Epoch: 173 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.263  \n",
            "Epoch: 174 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.167  \n",
            "Epoch: 175 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.105  \n",
            "Epoch: 176 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.142  \n",
            "Epoch: 177 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.076  \n",
            "Epoch: 178 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.119  \n",
            "Epoch: 179 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.216  \n",
            "Epoch: 180 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.176  \n",
            "Epoch: 181 \tTraining Loss:  0.045 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.290  \n",
            "Epoch: 182 \tTraining Loss:  0.079 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.256  \n",
            "Epoch: 183 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.140  \n",
            "Epoch: 184 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.083  \n",
            "Epoch: 185 \tTraining Loss:  0.073 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.098  \n",
            "Epoch: 186 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.142  \n",
            "Epoch: 187 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.124  \n",
            "Epoch: 188 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.192  \n",
            "Epoch: 189 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.134  \n",
            "Epoch: 190 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : -0.038  \n",
            "Epoch: 191 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.141  \n",
            "Epoch: 192 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.170  \n",
            "Epoch: 193 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.127  \n",
            "Epoch: 194 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.271  \n",
            "Epoch: 195 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.094  \n",
            "Epoch: 196 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:11%  \tVal_kappa : -0.123  \n",
            "Epoch: 197 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.156  \n",
            "Epoch: 198 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.246  \n",
            "Epoch: 199 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.181  \n",
            "Epoch: 200 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.125  \n",
            "Epoch: 201 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.232  \n",
            "Epoch: 202 \tTraining Loss:  0.084 \tTrain_Accu: 96%  \tValid_Acc:14%  \tVal_kappa : 0.052  \n",
            "Epoch: 203 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.082  \n",
            "Epoch: 204 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.180  \n",
            "Epoch: 205 \tTraining Loss:  0.017 \tTrain_Accu: 100%  \tValid_Acc:13%  \tVal_kappa : -0.126  \n",
            "Epoch: 206 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.117  \n",
            "Epoch: 207 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.177  \n",
            "Epoch: 208 \tTraining Loss:  0.047 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.137  \n",
            "Epoch: 209 \tTraining Loss:  0.037 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.201  \n",
            "Epoch: 210 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \tValid_Acc:11%  \tVal_kappa : -0.119  \n",
            "Epoch: 211 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.146  \n",
            "Epoch: 212 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.176  \n",
            "Epoch: 213 \tTraining Loss:  0.050 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.228  \n",
            "Epoch: 214 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.189  \n",
            "Epoch: 215 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.201  \n",
            "Epoch: 216 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.181  \n",
            "Epoch: 217 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.139  \n",
            "Epoch: 218 \tTraining Loss:  0.106 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.000  \n",
            "Epoch: 219 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.016  \n",
            "Epoch: 220 \tTraining Loss:  0.028 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.158  \n",
            "Epoch: 221 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.056  \n",
            "Epoch: 222 \tTraining Loss:  0.018 \tTrain_Accu: 100%  \tValid_Acc:14%  \tVal_kappa : -0.343  \n",
            "Epoch: 223 \tTraining Loss:  0.033 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.229  \n",
            "Epoch: 224 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:10%  \tVal_kappa : -0.381  \n",
            "Epoch: 225 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.218  \n",
            "Epoch: 226 \tTraining Loss:  0.034 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.309  \n",
            "Epoch: 227 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : -0.218  \n",
            "Epoch: 228 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.177  \n",
            "Epoch: 229 \tTraining Loss:  0.053 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.059  \n",
            "Epoch: 230 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.162  \n",
            "Epoch: 231 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.189  \n",
            "Epoch: 232 \tTraining Loss:  0.014 \tTrain_Accu: 100%  \tValid_Acc:19%  \tVal_kappa : -0.121  \n",
            "Epoch: 233 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.337  \n",
            "Epoch: 234 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.143  \n",
            "Epoch: 235 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.184  \n",
            "Epoch: 236 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.332  \n",
            "Epoch: 237 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.215  \n",
            "Epoch: 238 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.111  \n",
            "Epoch: 239 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:11%  \tVal_kappa : -0.204  \n",
            "Epoch: 240 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.152  \n",
            "Epoch: 241 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.174  \n",
            "Epoch: 242 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : -0.064  \n",
            "Epoch: 243 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.057  \n",
            "Epoch: 244 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.112  \n",
            "Epoch: 245 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:11%  \tVal_kappa : -0.233  \n",
            "Epoch: 246 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : -0.021  \n",
            "Epoch: 247 \tTraining Loss:  0.031 \tTrain_Accu: 100%  \tValid_Acc:14%  \tVal_kappa : -0.179  \n",
            "Epoch: 248 \tTraining Loss:  0.014 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : -0.021  \n",
            "Epoch: 249 \tTraining Loss:  0.024 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.022  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-19 07:32:24,528]\u001b[0m Trial 1 finished with value: 17.1 and parameters: {}. Best is trial 1 with value: 17.1.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.023  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOJAPcxxaEUY"
      },
      "source": [
        "To see plots of the training and validation loss and accuracy curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYUIA1viTm9-"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "checkpoint = torch.load(\"./check_valid_NNI_RMSprops.torch\")\n",
        "train_loss = checkpoint['train_loss']\n",
        "valid_loss = checkpoint['valid_loss']\n",
        "plt.plot(train_loss, label='Training loss')\n",
        "plt.plot(valid_loss, label='Validation loss')\n",
        "#plt.title(\"NNI_Rain_drop(0.7)_input_LR\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(frameon=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DLzeo_WTm6o"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "checkpoint = torch.load(\"./check_valid_NNI_RMSprops.torch\")\n",
        "train_acc = checkpoint['train_acc']\n",
        "valid_acc = checkpoint['valid_acc']\n",
        "plt.plot(train_acc, label='Training acc')\n",
        "plt.plot(valid_acc, label='Validation acc')\n",
        "#plt.title(\"NNI_Rain_drop(0.7)_input_LR\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(frameon=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKOq59myNGLF"
      },
      "source": [
        "### Test\n",
        "\n",
        "The model was evaluated on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "xqN4UF_IUl2B",
        "outputId": "10ad7a96-982b-41e9-e7a7-03efa701f5ad"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_NNI[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop()\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_NNI_RMSprops_std_indv.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2, 2, 2, 3, 2, 3, 2, 2, 2, 3, 1, 3, 3, 3, 3, 1, 3, 3, 0, 1, 0, 1, 1, 0,\n",
            "        3, 3, 3, 3, 4, 4, 1, 3, 3, 1, 3, 3, 2, 4, 3, 0, 1, 0, 4, 1, 2, 2, 4, 3,\n",
            "        4, 3, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 3, 1, 2, 1, 0, 2, 2, 2, 1, 2])\n",
            "labels tensor([0, 0, 0, 3, 2, 3, 2, 2, 2, 1, 0, 0, 0, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 2,\n",
            "        3, 1, 1, 2, 3, 2, 2, 2, 3, 1, 0, 0, 4, 4, 4, 4, 2, 1, 3, 3, 2, 0, 1, 4,\n",
            "        4, 4, 3, 3, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0])\n",
            "correct : 23\n",
            "test_Accuracy % : 32.9\n",
            "kappa 0.24199195953832175\n",
            "[[ 2  5  8  5  0]\n",
            " [ 1  5  1  6  1]\n",
            " [ 2  4 10  3  1]\n",
            " [ 0  1  2  4  2]\n",
            " [ 1  0  1  3  2]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0RCpe3LvUwY"
      },
      "source": [
        "## Training (no validation)\n",
        "\n",
        "Training the network with the training dataset only (no validation split) in Optuna framework with RMSprop optimizer, batch size 10 and learning rate 0.0001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU2UufxpvcFb"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_loaders_NNI(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:395], labelsTensors_NNI[:395])\n",
        "    #validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_NSI_rain[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    #valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "   \n",
        "\n",
        "    return train_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZXrq26NvgCD"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_NNI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "          'save_model' : True,\n",
        "          'lr'       :  0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "          'dropout'       : 0.5,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader = get_loaders_NNI(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "\n",
        "  train_accuracy = []\n",
        "  #valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  #valid_losses = []\n",
        "  train_label = []\n",
        "  \n",
        "  \n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "      #  valid_loss = 0\n",
        "      #  valid_correct = 0\n",
        "       train_acc = 0\n",
        "       #valid_acc = 0\n",
        "    \n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           #train_label.append(output.argmax(dim=1))\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "      #  with torch.no_grad(): \n",
        "      #     for batch_i, (data, target) in enumerate(valid_loader): \n",
        "      #         data, target = data.to(device), target.to(device)         \n",
        "      #         output = model(data)\n",
        "      #         output_c = output.cpu()\n",
        "      #         target_c = target.cpu()\n",
        "      #         loss = criterion(output_c, target_c) \n",
        "      #         valid_loss += loss.item()\n",
        "      #         valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "      #         valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "      #  valid_loss = valid_loss/len(valid_loader)\n",
        "      #  valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       #valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       #valid_losses.append(valid_loss)\n",
        "       #train_label.append(train_lab)\n",
        "       \n",
        "        \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  '.format(epoch, train_loss, train_acc))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              #'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              #'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_NNI_RMSprops_std.torch\")\n",
        "       \n",
        "  \n",
        "      \n",
        "   \n",
        "  return  round(train_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FHwbpoukwxAT",
        "outputId": "9e8e9d4c-9568-4181-ab05-441c25e44fae"
      },
      "source": [
        "import joblib\n",
        "\n",
        "study.optimize(train_NNI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"./optuna_NNI_drop.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.644 \tTrain_Accu: 22%  \n",
            "Epoch: 2 \tTraining Loss:  1.599 \tTrain_Accu: 25%  \n",
            "Epoch: 3 \tTraining Loss:  1.579 \tTrain_Accu: 29%  \n",
            "Epoch: 4 \tTraining Loss:  1.549 \tTrain_Accu: 30%  \n",
            "Epoch: 5 \tTraining Loss:  1.528 \tTrain_Accu: 34%  \n",
            "Epoch: 6 \tTraining Loss:  1.483 \tTrain_Accu: 35%  \n",
            "Epoch: 7 \tTraining Loss:  1.431 \tTrain_Accu: 45%  \n",
            "Epoch: 8 \tTraining Loss:  1.413 \tTrain_Accu: 42%  \n",
            "Epoch: 9 \tTraining Loss:  1.400 \tTrain_Accu: 44%  \n",
            "Epoch: 10 \tTraining Loss:  1.302 \tTrain_Accu: 48%  \n",
            "Epoch: 11 \tTraining Loss:  1.251 \tTrain_Accu: 50%  \n",
            "Epoch: 12 \tTraining Loss:  1.235 \tTrain_Accu: 49%  \n",
            "Epoch: 13 \tTraining Loss:  1.140 \tTrain_Accu: 55%  \n",
            "Epoch: 14 \tTraining Loss:  1.091 \tTrain_Accu: 57%  \n",
            "Epoch: 15 \tTraining Loss:  1.049 \tTrain_Accu: 61%  \n",
            "Epoch: 16 \tTraining Loss:  1.027 \tTrain_Accu: 61%  \n",
            "Epoch: 17 \tTraining Loss:  1.004 \tTrain_Accu: 59%  \n",
            "Epoch: 18 \tTraining Loss:  0.950 \tTrain_Accu: 63%  \n",
            "Epoch: 19 \tTraining Loss:  0.886 \tTrain_Accu: 69%  \n",
            "Epoch: 20 \tTraining Loss:  0.757 \tTrain_Accu: 74%  \n",
            "Epoch: 21 \tTraining Loss:  0.838 \tTrain_Accu: 69%  \n",
            "Epoch: 22 \tTraining Loss:  0.769 \tTrain_Accu: 74%  \n",
            "Epoch: 23 \tTraining Loss:  0.719 \tTrain_Accu: 74%  \n",
            "Epoch: 24 \tTraining Loss:  0.647 \tTrain_Accu: 75%  \n",
            "Epoch: 25 \tTraining Loss:  0.672 \tTrain_Accu: 73%  \n",
            "Epoch: 26 \tTraining Loss:  0.639 \tTrain_Accu: 75%  \n",
            "Epoch: 27 \tTraining Loss:  0.518 \tTrain_Accu: 82%  \n",
            "Epoch: 28 \tTraining Loss:  0.556 \tTrain_Accu: 79%  \n",
            "Epoch: 29 \tTraining Loss:  0.477 \tTrain_Accu: 83%  \n",
            "Epoch: 30 \tTraining Loss:  0.513 \tTrain_Accu: 84%  \n",
            "Epoch: 31 \tTraining Loss:  0.441 \tTrain_Accu: 83%  \n",
            "Epoch: 32 \tTraining Loss:  0.429 \tTrain_Accu: 85%  \n",
            "Epoch: 33 \tTraining Loss:  0.436 \tTrain_Accu: 84%  \n",
            "Epoch: 34 \tTraining Loss:  0.408 \tTrain_Accu: 87%  \n",
            "Epoch: 35 \tTraining Loss:  0.321 \tTrain_Accu: 88%  \n",
            "Epoch: 36 \tTraining Loss:  0.415 \tTrain_Accu: 84%  \n",
            "Epoch: 37 \tTraining Loss:  0.346 \tTrain_Accu: 88%  \n",
            "Epoch: 38 \tTraining Loss:  0.350 \tTrain_Accu: 88%  \n",
            "Epoch: 39 \tTraining Loss:  0.327 \tTrain_Accu: 89%  \n",
            "Epoch: 40 \tTraining Loss:  0.315 \tTrain_Accu: 89%  \n",
            "Epoch: 41 \tTraining Loss:  0.308 \tTrain_Accu: 91%  \n",
            "Epoch: 42 \tTraining Loss:  0.262 \tTrain_Accu: 91%  \n",
            "Epoch: 43 \tTraining Loss:  0.243 \tTrain_Accu: 92%  \n",
            "Epoch: 44 \tTraining Loss:  0.217 \tTrain_Accu: 93%  \n",
            "Epoch: 45 \tTraining Loss:  0.224 \tTrain_Accu: 93%  \n",
            "Epoch: 46 \tTraining Loss:  0.186 \tTrain_Accu: 94%  \n",
            "Epoch: 47 \tTraining Loss:  0.207 \tTrain_Accu: 93%  \n",
            "Epoch: 48 \tTraining Loss:  0.181 \tTrain_Accu: 95%  \n",
            "Epoch: 49 \tTraining Loss:  0.201 \tTrain_Accu: 92%  \n",
            "Epoch: 50 \tTraining Loss:  0.208 \tTrain_Accu: 94%  \n",
            "Epoch: 51 \tTraining Loss:  0.211 \tTrain_Accu: 92%  \n",
            "Epoch: 52 \tTraining Loss:  0.195 \tTrain_Accu: 95%  \n",
            "Epoch: 53 \tTraining Loss:  0.128 \tTrain_Accu: 97%  \n",
            "Epoch: 54 \tTraining Loss:  0.195 \tTrain_Accu: 94%  \n",
            "Epoch: 55 \tTraining Loss:  0.185 \tTrain_Accu: 94%  \n",
            "Epoch: 56 \tTraining Loss:  0.126 \tTrain_Accu: 96%  \n",
            "Epoch: 57 \tTraining Loss:  0.156 \tTrain_Accu: 96%  \n",
            "Epoch: 58 \tTraining Loss:  0.149 \tTrain_Accu: 94%  \n",
            "Epoch: 59 \tTraining Loss:  0.149 \tTrain_Accu: 95%  \n",
            "Epoch: 60 \tTraining Loss:  0.179 \tTrain_Accu: 95%  \n",
            "Epoch: 61 \tTraining Loss:  0.142 \tTrain_Accu: 95%  \n",
            "Epoch: 62 \tTraining Loss:  0.163 \tTrain_Accu: 96%  \n",
            "Epoch: 63 \tTraining Loss:  0.175 \tTrain_Accu: 94%  \n",
            "Epoch: 64 \tTraining Loss:  0.150 \tTrain_Accu: 94%  \n",
            "Epoch: 65 \tTraining Loss:  0.135 \tTrain_Accu: 96%  \n",
            "Epoch: 66 \tTraining Loss:  0.103 \tTrain_Accu: 97%  \n",
            "Epoch: 67 \tTraining Loss:  0.120 \tTrain_Accu: 95%  \n",
            "Epoch: 68 \tTraining Loss:  0.138 \tTrain_Accu: 95%  \n",
            "Epoch: 69 \tTraining Loss:  0.148 \tTrain_Accu: 96%  \n",
            "Epoch: 70 \tTraining Loss:  0.171 \tTrain_Accu: 93%  \n",
            "Epoch: 71 \tTraining Loss:  0.118 \tTrain_Accu: 96%  \n",
            "Epoch: 72 \tTraining Loss:  0.113 \tTrain_Accu: 95%  \n",
            "Epoch: 73 \tTraining Loss:  0.092 \tTrain_Accu: 97%  \n",
            "Epoch: 74 \tTraining Loss:  0.096 \tTrain_Accu: 97%  \n",
            "Epoch: 75 \tTraining Loss:  0.091 \tTrain_Accu: 98%  \n",
            "Epoch: 76 \tTraining Loss:  0.085 \tTrain_Accu: 97%  \n",
            "Epoch: 77 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \n",
            "Epoch: 78 \tTraining Loss:  0.098 \tTrain_Accu: 96%  \n",
            "Epoch: 79 \tTraining Loss:  0.081 \tTrain_Accu: 98%  \n",
            "Epoch: 80 \tTraining Loss:  0.121 \tTrain_Accu: 97%  \n",
            "Epoch: 81 \tTraining Loss:  0.107 \tTrain_Accu: 96%  \n",
            "Epoch: 82 \tTraining Loss:  0.105 \tTrain_Accu: 96%  \n",
            "Epoch: 83 \tTraining Loss:  0.066 \tTrain_Accu: 97%  \n",
            "Epoch: 84 \tTraining Loss:  0.103 \tTrain_Accu: 96%  \n",
            "Epoch: 85 \tTraining Loss:  0.094 \tTrain_Accu: 97%  \n",
            "Epoch: 86 \tTraining Loss:  0.084 \tTrain_Accu: 98%  \n",
            "Epoch: 87 \tTraining Loss:  0.084 \tTrain_Accu: 97%  \n",
            "Epoch: 88 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 89 \tTraining Loss:  0.084 \tTrain_Accu: 97%  \n",
            "Epoch: 90 \tTraining Loss:  0.096 \tTrain_Accu: 97%  \n",
            "Epoch: 91 \tTraining Loss:  0.066 \tTrain_Accu: 97%  \n",
            "Epoch: 92 \tTraining Loss:  0.075 \tTrain_Accu: 97%  \n",
            "Epoch: 93 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \n",
            "Epoch: 94 \tTraining Loss:  0.101 \tTrain_Accu: 97%  \n",
            "Epoch: 95 \tTraining Loss:  0.121 \tTrain_Accu: 96%  \n",
            "Epoch: 96 \tTraining Loss:  0.090 \tTrain_Accu: 97%  \n",
            "Epoch: 97 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \n",
            "Epoch: 98 \tTraining Loss:  0.086 \tTrain_Accu: 97%  \n",
            "Epoch: 99 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \n",
            "Epoch: 100 \tTraining Loss:  0.086 \tTrain_Accu: 97%  \n",
            "Epoch: 101 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \n",
            "Epoch: 102 \tTraining Loss:  0.075 \tTrain_Accu: 97%  \n",
            "Epoch: 103 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \n",
            "Epoch: 104 \tTraining Loss:  0.098 \tTrain_Accu: 97%  \n",
            "Epoch: 105 \tTraining Loss:  0.051 \tTrain_Accu: 99%  \n",
            "Epoch: 106 \tTraining Loss:  0.077 \tTrain_Accu: 97%  \n",
            "Epoch: 107 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \n",
            "Epoch: 108 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \n",
            "Epoch: 109 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 110 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 111 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \n",
            "Epoch: 112 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \n",
            "Epoch: 113 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \n",
            "Epoch: 114 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \n",
            "Epoch: 115 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 116 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \n",
            "Epoch: 117 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \n",
            "Epoch: 118 \tTraining Loss:  0.062 \tTrain_Accu: 97%  \n",
            "Epoch: 119 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \n",
            "Epoch: 120 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \n",
            "Epoch: 121 \tTraining Loss:  0.055 \tTrain_Accu: 97%  \n",
            "Epoch: 122 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \n",
            "Epoch: 123 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \n",
            "Epoch: 124 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 125 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \n",
            "Epoch: 126 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \n",
            "Epoch: 127 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \n",
            "Epoch: 128 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \n",
            "Epoch: 129 \tTraining Loss:  0.092 \tTrain_Accu: 97%  \n",
            "Epoch: 130 \tTraining Loss:  0.046 \tTrain_Accu: 99%  \n",
            "Epoch: 131 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \n",
            "Epoch: 132 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \n",
            "Epoch: 133 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 134 \tTraining Loss:  0.078 \tTrain_Accu: 97%  \n",
            "Epoch: 135 \tTraining Loss:  0.054 \tTrain_Accu: 97%  \n",
            "Epoch: 136 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \n",
            "Epoch: 137 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \n",
            "Epoch: 138 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \n",
            "Epoch: 139 \tTraining Loss:  0.047 \tTrain_Accu: 99%  \n",
            "Epoch: 140 \tTraining Loss:  0.083 \tTrain_Accu: 97%  \n",
            "Epoch: 141 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \n",
            "Epoch: 142 \tTraining Loss:  0.034 \tTrain_Accu: 98%  \n",
            "Epoch: 143 \tTraining Loss:  0.065 \tTrain_Accu: 97%  \n",
            "Epoch: 144 \tTraining Loss:  0.032 \tTrain_Accu: 98%  \n",
            "Epoch: 145 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \n",
            "Epoch: 146 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \n",
            "Epoch: 147 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \n",
            "Epoch: 148 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 149 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \n",
            "Epoch: 150 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 151 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 152 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \n",
            "Epoch: 153 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 154 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \n",
            "Epoch: 155 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \n",
            "Epoch: 156 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 157 \tTraining Loss:  0.055 \tTrain_Accu: 97%  \n",
            "Epoch: 158 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 159 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \n",
            "Epoch: 160 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \n",
            "Epoch: 161 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 162 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 163 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \n",
            "Epoch: 164 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 165 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \n",
            "Epoch: 166 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \n",
            "Epoch: 167 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \n",
            "Epoch: 168 \tTraining Loss:  0.047 \tTrain_Accu: 99%  \n",
            "Epoch: 169 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 170 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \n",
            "Epoch: 171 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 172 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 173 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \n",
            "Epoch: 174 \tTraining Loss:  0.013 \tTrain_Accu: 100%  \n",
            "Epoch: 175 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \n",
            "Epoch: 176 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \n",
            "Epoch: 177 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 178 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \n",
            "Epoch: 179 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \n",
            "Epoch: 180 \tTraining Loss:  0.014 \tTrain_Accu: 100%  \n",
            "Epoch: 181 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \n",
            "Epoch: 182 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 183 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 184 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 185 \tTraining Loss:  0.012 \tTrain_Accu: 100%  \n",
            "Epoch: 186 \tTraining Loss:  0.014 \tTrain_Accu: 100%  \n",
            "Epoch: 187 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 188 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \n",
            "Epoch: 189 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \n",
            "Epoch: 190 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \n",
            "Epoch: 191 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 192 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \n",
            "Epoch: 193 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \n",
            "Epoch: 194 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \n",
            "Epoch: 195 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 196 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 197 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \n",
            "Epoch: 198 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \n",
            "Epoch: 199 \tTraining Loss:  0.012 \tTrain_Accu: 99%  \n",
            "Epoch: 200 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \n",
            "Epoch: 201 \tTraining Loss:  0.011 \tTrain_Accu: 99%  \n",
            "Epoch: 202 \tTraining Loss:  0.014 \tTrain_Accu: 99%  \n",
            "Epoch: 203 \tTraining Loss:  0.014 \tTrain_Accu: 100%  \n",
            "Epoch: 204 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \n",
            "Epoch: 205 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \n",
            "Epoch: 206 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \n",
            "Epoch: 207 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 208 \tTraining Loss:  0.009 \tTrain_Accu: 100%  \n",
            "Epoch: 209 \tTraining Loss:  0.029 \tTrain_Accu: 98%  \n",
            "Epoch: 210 \tTraining Loss:  0.016 \tTrain_Accu: 99%  \n",
            "Epoch: 211 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \n",
            "Epoch: 212 \tTraining Loss:  0.010 \tTrain_Accu: 100%  \n",
            "Epoch: 213 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \n",
            "Epoch: 214 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \n",
            "Epoch: 215 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 216 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 217 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 218 \tTraining Loss:  0.010 \tTrain_Accu: 100%  \n",
            "Epoch: 219 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \n",
            "Epoch: 220 \tTraining Loss:  0.043 \tTrain_Accu: 99%  \n",
            "Epoch: 221 \tTraining Loss:  0.015 \tTrain_Accu: 99%  \n",
            "Epoch: 222 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \n",
            "Epoch: 223 \tTraining Loss:  0.011 \tTrain_Accu: 100%  \n",
            "Epoch: 224 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 225 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 226 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 227 \tTraining Loss:  0.013 \tTrain_Accu: 100%  \n",
            "Epoch: 228 \tTraining Loss:  0.009 \tTrain_Accu: 99%  \n",
            "Epoch: 229 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \n",
            "Epoch: 230 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 231 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 232 \tTraining Loss:  0.029 \tTrain_Accu: 98%  \n",
            "Epoch: 233 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \n",
            "Epoch: 234 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 235 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 236 \tTraining Loss:  0.030 \tTrain_Accu: 98%  \n",
            "Epoch: 237 \tTraining Loss:  0.015 \tTrain_Accu: 99%  \n",
            "Epoch: 238 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 239 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \n",
            "Epoch: 240 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \n",
            "Epoch: 241 \tTraining Loss:  0.014 \tTrain_Accu: 99%  \n",
            "Epoch: 242 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \n",
            "Epoch: 243 \tTraining Loss:  0.016 \tTrain_Accu: 99%  \n",
            "Epoch: 244 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 245 \tTraining Loss:  0.037 \tTrain_Accu: 98%  \n",
            "Epoch: 246 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 247 \tTraining Loss:  0.008 \tTrain_Accu: 100%  \n",
            "Epoch: 248 \tTraining Loss:  0.010 \tTrain_Accu: 99%  \n",
            "Epoch: 249 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m[W 2021-08-19 19:07:18,075]\u001b[0m Trial 3 failed because of the following error: ValueError('Found input variables with inconsistent numbers of samples: [395, 10000]')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-36-7faf1e2c5143>\", line 100, in train_NNI\n",
            "    cf_matrix = confusion_matrix(labels_actual, train_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 268, in confusion_matrix\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 80, in _check_targets\n",
            "    check_consistent_length(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 212, in check_consistent_length\n",
            "    \" samples: %r\" % [int(l) for l in lengths])\n",
            "ValueError: Found input variables with inconsistent numbers of samples: [395, 10000]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-56b5e642a769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_NNI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-7faf1e2c5143>\u001b[0m in \u001b[0;36mtrain_NNI\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0mlabels_actual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelsTensors_NNI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m395\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   \u001b[0mcf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_actual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Q1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Q2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Q3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Q4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Q5\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [395, 10000]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej4Y1vmwwq9x"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "GBjMUS460eUp",
        "outputId": "b91d7bdc-b84c-48fd-a383-6991baf69959"
      },
      "source": [
        "# # Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_NNI[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop()\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_NNI_RMSprops_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 3, 0, 2, 2, 1, 2, 2, 2, 1, 1, 3, 0, 3, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 4, 4, 3, 3, 2, 3, 3, 3, 4, 3, 3, 3, 0, 0, 3, 2, 1, 2, 3, 3,\n",
            "        3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 3, 2, 1, 0, 2, 2, 2, 1, 1])\n",
            "labels tensor([0, 0, 0, 3, 2, 3, 2, 2, 2, 1, 0, 0, 0, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 2,\n",
            "        3, 1, 1, 2, 3, 2, 2, 2, 3, 1, 0, 0, 4, 4, 4, 4, 2, 1, 3, 3, 2, 0, 1, 4,\n",
            "        4, 4, 3, 3, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0])\n",
            "correct : 22\n",
            "test_Accuracy % : 31.4\n",
            "kappa 0.3248917464899619\n",
            "[[5 5 5 5 0]\n",
            " [4 6 1 3 0]\n",
            " [6 2 9 2 1]\n",
            " [1 2 4 1 1]\n",
            " [0 0 0 6 1]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTivlyGpTm3Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBZU2A3Yyp9D"
      },
      "source": [
        "## NSI_Rain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INanNK_pyp9D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "7acd058e-1edc-4196-a5a9-99eb082a0ed6"
      },
      "source": [
        "# Reading rainfall file of NSI region \n",
        "Data_Rain_NSI = pd.read_csv(\"drive/My Drive/DL_project/Target_Rain_NSI_regional_ave_time_series.csv\")\n",
        "Data_Rain_NSI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>Rain_bc</th>\n",
              "      <th>cat_3</th>\n",
              "      <th>cat_5</th>\n",
              "      <th>anomalies</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-04-01</td>\n",
              "      <td>518.489941</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>85.363579</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-05-01</td>\n",
              "      <td>638.632523</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>152.135448</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-06-01</td>\n",
              "      <td>632.856496</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>82.627150</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-07-01</td>\n",
              "      <td>728.721291</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>148.135826</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-08-01</td>\n",
              "      <td>630.912992</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>33.379050</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>2019-08-01</td>\n",
              "      <td>450.869153</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-146.664789</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>582.496815</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-10.172375</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>2019-10-01</td>\n",
              "      <td>521.115842</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-113.011313</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>595.341576</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-29.604627</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>771.852137</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>155.011559</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>465 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           time     Rain_bc  cat_3  cat_5   anomalies region\n",
              "0    1981-04-01  518.489941      3      4   85.363579    NSI\n",
              "1    1981-05-01  638.632523      3      5  152.135448    NSI\n",
              "2    1981-06-01  632.856496      3      4   82.627150    NSI\n",
              "3    1981-07-01  728.721291      3      5  148.135826    NSI\n",
              "4    1981-08-01  630.912992      2      4   33.379050    NSI\n",
              "..          ...         ...    ...    ...         ...    ...\n",
              "460  2019-08-01  450.869153      1      1 -146.664789    NSI\n",
              "461  2019-09-01  582.496815      2      3  -10.172375    NSI\n",
              "462  2019-10-01  521.115842      1      1 -113.011313    NSI\n",
              "463  2019-11-01  595.341576      2      3  -29.604627    NSI\n",
              "464  2019-12-01  771.852137      3      5  155.011559    NSI\n",
              "\n",
              "[465 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjGpXOw_yp9E"
      },
      "source": [
        "# Extracting label column from NSI region dataframe\n",
        "labels_Rain_NSI = Data_Rain_NSI['cat_5'].astype(int) #cat5 column - so 5 prediction classes \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX8viA_myp9F"
      },
      "source": [
        "### Training\n",
        "Training the network with the training and validation dataset in Optuna frame work with RMSprop optimizer, batch size 10 and learning rate 0.0001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLnSXq7syp9E"
      },
      "source": [
        "# Function that will convert labels into Pytorch tensors\n",
        "\n",
        "def labels_Tensors(labels):\n",
        "    return (torch.from_numpy(labels.values).type(torch.LongTensor)-1) #cat5 in form 1, 2, 3, 4, 5;\n",
        "\n",
        "# Converting labels of rainfall_NSI region into tensors\n",
        "labelsTensors_NSI_rain = labels_Tensors(labels_Rain_NSI) # This represents y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIv6buO3yp9E"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_valid_loaders_NSI(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_NSI_rain[:325])\n",
        "    validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_NSI_rain[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "   \n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbmFQW9NTrCm"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_Rain_NSI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           #'dropout'       : 0.7,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_NSI(cfg['Batch_size'])\n",
        "  model = Network_drop().to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_NSI_rain[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_NSI_rain[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 10\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_NSI_rain[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_NSI_rain[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_NSI_RMSprops_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhkHxEE0yp9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de9d9ea-6200-4111-b62f-4263f0641cc6"
      },
      "source": [
        "study = optuna.create_study(sampler=optuna.samplers.TPESampler(), direction='maximize')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-25 02:01:48,291]\u001b[0m A new study created in memory with name: no-name-a40c4110-19c2-48ce-8306-5fc823cc9d27\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T6bfflIWpol",
        "outputId": "74ca299f-b08a-47d4-95df-f3636513baf1"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_Rain_NSI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"drive/MyDrive/DL_project/optimise_valid_NSI\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.687 \tTrain_Accu: 18%  \tValid_Acc:24%  \tVal_kappa : 0.123  \n",
            "Epoch: 2 \tTraining Loss:  1.609 \tTrain_Accu: 23%  \tValid_Acc:23%  \tVal_kappa : -0.014  \n",
            "Epoch: 3 \tTraining Loss:  1.594 \tTrain_Accu: 26%  \tValid_Acc:14%  \tVal_kappa : -0.023  \n",
            "Epoch: 4 \tTraining Loss:  1.596 \tTrain_Accu: 26%  \tValid_Acc:27%  \tVal_kappa : 0.178  \n",
            "Epoch: 5 \tTraining Loss:  1.552 \tTrain_Accu: 32%  \tValid_Acc:11%  \tVal_kappa : 0.006  \n",
            "Epoch: 6 \tTraining Loss:  1.542 \tTrain_Accu: 30%  \tValid_Acc:13%  \tVal_kappa : -0.121  \n",
            "Epoch: 7 \tTraining Loss:  1.518 \tTrain_Accu: 32%  \tValid_Acc:20%  \tVal_kappa : -0.002  \n",
            "Epoch: 8 \tTraining Loss:  1.483 \tTrain_Accu: 37%  \tValid_Acc:14%  \tVal_kappa : 0.118  \n",
            "Epoch: 9 \tTraining Loss:  1.455 \tTrain_Accu: 39%  \tValid_Acc:24%  \tVal_kappa : 0.092  \n",
            "Epoch: 10 \tTraining Loss:  1.386 \tTrain_Accu: 42%  \tValid_Acc:16%  \tVal_kappa : 0.112  \n",
            "Epoch: 11 \tTraining Loss:  1.356 \tTrain_Accu: 43%  \tValid_Acc:20%  \tVal_kappa : 0.033  \n",
            "Epoch: 12 \tTraining Loss:  1.272 \tTrain_Accu: 49%  \tValid_Acc:16%  \tVal_kappa : -0.059  \n",
            "Epoch: 13 \tTraining Loss:  1.286 \tTrain_Accu: 46%  \tValid_Acc:21%  \tVal_kappa : 0.133  \n",
            "Epoch: 14 \tTraining Loss:  1.271 \tTrain_Accu: 49%  \tValid_Acc:14%  \tVal_kappa : 0.086  \n",
            "Epoch: 15 \tTraining Loss:  1.158 \tTrain_Accu: 51%  \tValid_Acc:19%  \tVal_kappa : 0.025  \n",
            "Epoch: 16 \tTraining Loss:  1.149 \tTrain_Accu: 53%  \tValid_Acc:17%  \tVal_kappa : 0.020  \n",
            "Epoch: 17 \tTraining Loss:  1.068 \tTrain_Accu: 58%  \tValid_Acc:21%  \tVal_kappa : 0.213  \n",
            "Epoch: 18 \tTraining Loss:  1.005 \tTrain_Accu: 63%  \tValid_Acc:13%  \tVal_kappa : -0.127  \n",
            "Epoch: 19 \tTraining Loss:  0.996 \tTrain_Accu: 60%  \tValid_Acc:20%  \tVal_kappa : -0.155  \n",
            "Epoch: 20 \tTraining Loss:  0.963 \tTrain_Accu: 62%  \tValid_Acc:13%  \tVal_kappa : 0.035  \n",
            "Epoch: 21 \tTraining Loss:  0.912 \tTrain_Accu: 68%  \tValid_Acc:19%  \tVal_kappa : -0.030  \n",
            "Epoch: 22 \tTraining Loss:  0.854 \tTrain_Accu: 67%  \tValid_Acc:19%  \tVal_kappa : 0.021  \n",
            "Epoch: 23 \tTraining Loss:  0.789 \tTrain_Accu: 70%  \tValid_Acc:17%  \tVal_kappa : -0.097  \n",
            "Epoch: 24 \tTraining Loss:  0.791 \tTrain_Accu: 70%  \tValid_Acc:10%  \tVal_kappa : -0.063  \n",
            "Epoch: 25 \tTraining Loss:  0.751 \tTrain_Accu: 71%  \tValid_Acc:19%  \tVal_kappa : -0.127  \n",
            "Epoch: 26 \tTraining Loss:  0.738 \tTrain_Accu: 71%  \tValid_Acc:21%  \tVal_kappa : 0.006  \n",
            "Epoch: 27 \tTraining Loss:  0.645 \tTrain_Accu: 77%  \tValid_Acc:14%  \tVal_kappa : 0.018  \n",
            "Epoch: 28 \tTraining Loss:  0.697 \tTrain_Accu: 75%  \tValid_Acc:10%  \tVal_kappa : 0.047  \n",
            "Epoch: 29 \tTraining Loss:  0.617 \tTrain_Accu: 79%  \tValid_Acc:13%  \tVal_kappa : -0.081  \n",
            "Epoch: 30 \tTraining Loss:  0.511 \tTrain_Accu: 81%  \tValid_Acc:20%  \tVal_kappa : 0.125  \n",
            "Epoch: 31 \tTraining Loss:  0.538 \tTrain_Accu: 77%  \tValid_Acc:23%  \tVal_kappa : 0.040  \n",
            "Epoch: 32 \tTraining Loss:  0.497 \tTrain_Accu: 82%  \tValid_Acc:16%  \tVal_kappa : 0.089  \n",
            "Epoch: 33 \tTraining Loss:  0.534 \tTrain_Accu: 82%  \tValid_Acc:21%  \tVal_kappa : -0.003  \n",
            "Epoch: 34 \tTraining Loss:  0.466 \tTrain_Accu: 83%  \tValid_Acc:19%  \tVal_kappa : 0.168  \n",
            "Epoch: 35 \tTraining Loss:  0.431 \tTrain_Accu: 84%  \tValid_Acc:19%  \tVal_kappa : 0.004  \n",
            "Epoch: 36 \tTraining Loss:  0.428 \tTrain_Accu: 85%  \tValid_Acc:16%  \tVal_kappa : -0.074  \n",
            "Epoch: 37 \tTraining Loss:  0.417 \tTrain_Accu: 85%  \tValid_Acc:14%  \tVal_kappa : 0.113  \n",
            "Epoch: 38 \tTraining Loss:  0.428 \tTrain_Accu: 85%  \tValid_Acc:14%  \tVal_kappa : 0.018  \n",
            "Epoch: 39 \tTraining Loss:  0.371 \tTrain_Accu: 88%  \tValid_Acc:19%  \tVal_kappa : 0.023  \n",
            "Epoch: 40 \tTraining Loss:  0.381 \tTrain_Accu: 86%  \tValid_Acc:20%  \tVal_kappa : 0.030  \n",
            "Epoch: 41 \tTraining Loss:  0.348 \tTrain_Accu: 89%  \tValid_Acc:20%  \tVal_kappa : 0.075  \n",
            "Epoch: 42 \tTraining Loss:  0.340 \tTrain_Accu: 86%  \tValid_Acc:19%  \tVal_kappa : 0.055  \n",
            "Epoch: 43 \tTraining Loss:  0.353 \tTrain_Accu: 86%  \tValid_Acc:20%  \tVal_kappa : 0.154  \n",
            "Epoch: 44 \tTraining Loss:  0.340 \tTrain_Accu: 86%  \tValid_Acc:13%  \tVal_kappa : -0.122  \n",
            "Epoch: 45 \tTraining Loss:  0.260 \tTrain_Accu: 90%  \tValid_Acc:21%  \tVal_kappa : 0.015  \n",
            "Epoch: 46 \tTraining Loss:  0.311 \tTrain_Accu: 89%  \tValid_Acc:14%  \tVal_kappa : -0.019  \n",
            "Epoch: 47 \tTraining Loss:  0.261 \tTrain_Accu: 93%  \tValid_Acc:26%  \tVal_kappa : 0.146  \n",
            "Epoch: 48 \tTraining Loss:  0.261 \tTrain_Accu: 90%  \tValid_Acc:19%  \tVal_kappa : 0.162  \n",
            "Epoch: 49 \tTraining Loss:  0.263 \tTrain_Accu: 91%  \tValid_Acc:10%  \tVal_kappa : 0.002  \n",
            "Epoch: 50 \tTraining Loss:  0.279 \tTrain_Accu: 91%  \tValid_Acc:29%  \tVal_kappa : 0.039  \n",
            "Epoch: 51 \tTraining Loss:  0.230 \tTrain_Accu: 92%  \tValid_Acc:17%  \tVal_kappa : -0.057  \n",
            "Epoch: 52 \tTraining Loss:  0.213 \tTrain_Accu: 91%  \tValid_Acc:19%  \tVal_kappa : 0.028  \n",
            "Epoch: 53 \tTraining Loss:  0.210 \tTrain_Accu: 93%  \tValid_Acc:17%  \tVal_kappa : 0.196  \n",
            "Epoch: 54 \tTraining Loss:  0.259 \tTrain_Accu: 91%  \tValid_Acc:17%  \tVal_kappa : 0.120  \n",
            "Epoch: 55 \tTraining Loss:  0.209 \tTrain_Accu: 94%  \tValid_Acc:16%  \tVal_kappa : -0.144  \n",
            "Epoch: 56 \tTraining Loss:  0.199 \tTrain_Accu: 93%  \tValid_Acc:20%  \tVal_kappa : 0.070  \n",
            "Epoch: 57 \tTraining Loss:  0.237 \tTrain_Accu: 92%  \tValid_Acc:16%  \tVal_kappa : 0.008  \n",
            "Epoch: 58 \tTraining Loss:  0.191 \tTrain_Accu: 94%  \tValid_Acc:21%  \tVal_kappa : 0.071  \n",
            "Epoch: 59 \tTraining Loss:  0.184 \tTrain_Accu: 96%  \tValid_Acc:14%  \tVal_kappa : 0.072  \n",
            "Epoch: 60 \tTraining Loss:  0.163 \tTrain_Accu: 94%  \tValid_Acc:14%  \tVal_kappa : -0.108  \n",
            "Epoch: 61 \tTraining Loss:  0.180 \tTrain_Accu: 93%  \tValid_Acc:20%  \tVal_kappa : 0.081  \n",
            "Epoch: 62 \tTraining Loss:  0.220 \tTrain_Accu: 92%  \tValid_Acc:23%  \tVal_kappa : 0.108  \n",
            "Epoch: 63 \tTraining Loss:  0.150 \tTrain_Accu: 96%  \tValid_Acc:16%  \tVal_kappa : -0.018  \n",
            "Epoch: 64 \tTraining Loss:  0.216 \tTrain_Accu: 92%  \tValid_Acc:19%  \tVal_kappa : 0.110  \n",
            "Epoch: 65 \tTraining Loss:  0.190 \tTrain_Accu: 94%  \tValid_Acc:14%  \tVal_kappa : 0.088  \n",
            "Epoch: 66 \tTraining Loss:  0.199 \tTrain_Accu: 93%  \tValid_Acc:20%  \tVal_kappa : -0.114  \n",
            "Epoch: 67 \tTraining Loss:  0.150 \tTrain_Accu: 94%  \tValid_Acc:20%  \tVal_kappa : 0.046  \n",
            "Epoch: 68 \tTraining Loss:  0.147 \tTrain_Accu: 95%  \tValid_Acc:20%  \tVal_kappa : -0.079  \n",
            "Epoch: 69 \tTraining Loss:  0.142 \tTrain_Accu: 93%  \tValid_Acc:20%  \tVal_kappa : 0.050  \n",
            "Epoch: 70 \tTraining Loss:  0.177 \tTrain_Accu: 93%  \tValid_Acc:17%  \tVal_kappa : 0.073  \n",
            "Epoch: 71 \tTraining Loss:  0.141 \tTrain_Accu: 95%  \tValid_Acc:20%  \tVal_kappa : 0.156  \n",
            "Epoch: 72 \tTraining Loss:  0.171 \tTrain_Accu: 94%  \tValid_Acc:20%  \tVal_kappa : 0.087  \n",
            "Epoch: 73 \tTraining Loss:  0.155 \tTrain_Accu: 95%  \tValid_Acc:24%  \tVal_kappa : 0.011  \n",
            "Epoch: 74 \tTraining Loss:  0.154 \tTrain_Accu: 95%  \tValid_Acc:19%  \tVal_kappa : -0.042  \n",
            "Epoch: 75 \tTraining Loss:  0.131 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : 0.100  \n",
            "Epoch: 76 \tTraining Loss:  0.109 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : 0.035  \n",
            "Epoch: 77 \tTraining Loss:  0.117 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : 0.055  \n",
            "Epoch: 78 \tTraining Loss:  0.150 \tTrain_Accu: 93%  \tValid_Acc:21%  \tVal_kappa : 0.121  \n",
            "Epoch: 79 \tTraining Loss:  0.113 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : 0.054  \n",
            "Epoch: 80 \tTraining Loss:  0.147 \tTrain_Accu: 94%  \tValid_Acc:24%  \tVal_kappa : 0.190  \n",
            "Epoch: 81 \tTraining Loss:  0.100 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : 0.178  \n",
            "Epoch: 82 \tTraining Loss:  0.101 \tTrain_Accu: 96%  \tValid_Acc:11%  \tVal_kappa : -0.070  \n",
            "Epoch: 83 \tTraining Loss:  0.086 \tTrain_Accu: 97%  \tValid_Acc:26%  \tVal_kappa : 0.151  \n",
            "Epoch: 84 \tTraining Loss:  0.112 \tTrain_Accu: 95%  \tValid_Acc:19%  \tVal_kappa : -0.050  \n",
            "Epoch: 85 \tTraining Loss:  0.114 \tTrain_Accu: 95%  \tValid_Acc:20%  \tVal_kappa : 0.026  \n",
            "Epoch: 86 \tTraining Loss:  0.124 \tTrain_Accu: 96%  \tValid_Acc:14%  \tVal_kappa : -0.093  \n",
            "Epoch: 87 \tTraining Loss:  0.082 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.003  \n",
            "Epoch: 88 \tTraining Loss:  0.092 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : 0.149  \n",
            "Epoch: 89 \tTraining Loss:  0.100 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : 0.186  \n",
            "Epoch: 90 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : 0.003  \n",
            "Epoch: 91 \tTraining Loss:  0.112 \tTrain_Accu: 95%  \tValid_Acc:17%  \tVal_kappa : 0.017  \n",
            "Epoch: 92 \tTraining Loss:  0.074 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.022  \n",
            "Epoch: 93 \tTraining Loss:  0.118 \tTrain_Accu: 95%  \tValid_Acc:14%  \tVal_kappa : -0.082  \n",
            "Epoch: 94 \tTraining Loss:  0.135 \tTrain_Accu: 96%  \tValid_Acc:24%  \tVal_kappa : 0.137  \n",
            "Epoch: 95 \tTraining Loss:  0.108 \tTrain_Accu: 95%  \tValid_Acc:19%  \tVal_kappa : -0.182  \n",
            "Epoch: 96 \tTraining Loss:  0.105 \tTrain_Accu: 96%  \tValid_Acc:17%  \tVal_kappa : -0.052  \n",
            "Epoch: 97 \tTraining Loss:  0.095 \tTrain_Accu: 97%  \tValid_Acc:26%  \tVal_kappa : 0.046  \n",
            "Epoch: 98 \tTraining Loss:  0.076 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.068  \n",
            "Epoch: 99 \tTraining Loss:  0.090 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : 0.013  \n",
            "Epoch: 100 \tTraining Loss:  0.105 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : -0.033  \n",
            "Epoch: 101 \tTraining Loss:  0.099 \tTrain_Accu: 96%  \tValid_Acc:14%  \tVal_kappa : -0.060  \n",
            "Epoch: 102 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.043  \n",
            "Epoch: 103 \tTraining Loss:  0.103 \tTrain_Accu: 96%  \tValid_Acc:20%  \tVal_kappa : 0.062  \n",
            "Epoch: 104 \tTraining Loss:  0.084 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.000  \n",
            "Epoch: 105 \tTraining Loss:  0.088 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.079  \n",
            "Epoch: 106 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.005  \n",
            "Epoch: 107 \tTraining Loss:  0.102 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.147  \n",
            "Epoch: 108 \tTraining Loss:  0.108 \tTrain_Accu: 95%  \tValid_Acc:17%  \tVal_kappa : 0.159  \n",
            "Epoch: 109 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.026  \n",
            "Epoch: 110 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.054  \n",
            "Epoch: 111 \tTraining Loss:  0.098 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : 0.056  \n",
            "Epoch: 112 \tTraining Loss:  0.080 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : 0.041  \n",
            "Epoch: 113 \tTraining Loss:  0.079 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.095  \n",
            "Epoch: 114 \tTraining Loss:  0.086 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.157  \n",
            "Epoch: 115 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : 0.004  \n",
            "Epoch: 116 \tTraining Loss:  0.088 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : -0.048  \n",
            "Epoch: 117 \tTraining Loss:  0.099 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : 0.028  \n",
            "Epoch: 118 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.049  \n",
            "Epoch: 119 \tTraining Loss:  0.071 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.005  \n",
            "Epoch: 120 \tTraining Loss:  0.124 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : 0.080  \n",
            "Epoch: 121 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.048  \n",
            "Epoch: 122 \tTraining Loss:  0.080 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.064  \n",
            "Epoch: 123 \tTraining Loss:  0.083 \tTrain_Accu: 96%  \tValid_Acc:14%  \tVal_kappa : -0.048  \n",
            "Epoch: 124 \tTraining Loss:  0.081 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.089  \n",
            "Epoch: 125 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : 0.143  \n",
            "Epoch: 126 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \tValid_Acc:11%  \tVal_kappa : -0.025  \n",
            "Epoch: 127 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \tValid_Acc:10%  \tVal_kappa : -0.107  \n",
            "Epoch: 128 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.067  \n",
            "Epoch: 129 \tTraining Loss:  0.083 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.118  \n",
            "Epoch: 130 \tTraining Loss:  0.063 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : 0.104  \n",
            "Epoch: 131 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \tValid_Acc:10%  \tVal_kappa : -0.083  \n",
            "Epoch: 132 \tTraining Loss:  0.067 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : 0.030  \n",
            "Epoch: 133 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.029  \n",
            "Epoch: 134 \tTraining Loss:  0.108 \tTrain_Accu: 95%  \tValid_Acc:17%  \tVal_kappa : -0.064  \n",
            "Epoch: 135 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.053  \n",
            "Epoch: 136 \tTraining Loss:  0.085 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : 0.098  \n",
            "Epoch: 137 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : 0.052  \n",
            "Epoch: 138 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.074  \n",
            "Epoch: 139 \tTraining Loss:  0.085 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.054  \n",
            "Epoch: 140 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.107  \n",
            "Epoch: 141 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.152  \n",
            "Epoch: 142 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.102  \n",
            "Epoch: 143 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.059  \n",
            "Epoch: 144 \tTraining Loss:  0.082 \tTrain_Accu: 96%  \tValid_Acc:26%  \tVal_kappa : -0.113  \n",
            "Epoch: 145 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.083  \n",
            "Epoch: 146 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.094  \n",
            "Epoch: 147 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.058  \n",
            "Epoch: 148 \tTraining Loss:  0.063 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.059  \n",
            "Epoch: 149 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.064  \n",
            "Epoch: 150 \tTraining Loss:  0.071 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : -0.073  \n",
            "Epoch: 151 \tTraining Loss:  0.047 \tTrain_Accu: 97%  \tValid_Acc:11%  \tVal_kappa : -0.129  \n",
            "Epoch: 152 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.102  \n",
            "Epoch: 153 \tTraining Loss:  0.065 \tTrain_Accu: 97%  \tValid_Acc:11%  \tVal_kappa : -0.067  \n",
            "Epoch: 154 \tTraining Loss:  0.069 \tTrain_Accu: 96%  \tValid_Acc:10%  \tVal_kappa : -0.145  \n",
            "Epoch: 155 \tTraining Loss:  0.012 \tTrain_Accu: 100%  \tValid_Acc:23%  \tVal_kappa : -0.008  \n",
            "Epoch: 156 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.144  \n",
            "Epoch: 157 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.112  \n",
            "Epoch: 158 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.156  \n",
            "Epoch: 159 \tTraining Loss:  0.060 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : -0.038  \n",
            "Epoch: 160 \tTraining Loss:  0.047 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.021  \n",
            "Epoch: 161 \tTraining Loss:  0.047 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.106  \n",
            "Epoch: 162 \tTraining Loss:  0.069 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : 0.000  \n",
            "Epoch: 163 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.123  \n",
            "Epoch: 164 \tTraining Loss:  0.034 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.053  \n",
            "Epoch: 165 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.112  \n",
            "Epoch: 166 \tTraining Loss:  0.104 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.085  \n",
            "Epoch: 167 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.023  \n",
            "Epoch: 168 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.046  \n",
            "Epoch: 169 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:10%  \tVal_kappa : -0.055  \n",
            "Epoch: 170 \tTraining Loss:  0.056 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.025  \n",
            "Epoch: 171 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.036  \n",
            "Epoch: 172 \tTraining Loss:  0.034 \tTrain_Accu: 98%  \tValid_Acc:11%  \tVal_kappa : -0.105  \n",
            "Epoch: 173 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.065  \n",
            "Epoch: 174 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.061  \n",
            "Epoch: 175 \tTraining Loss:  0.019 \tTrain_Accu: 100%  \tValid_Acc:14%  \tVal_kappa : -0.004  \n",
            "Epoch: 176 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.036  \n",
            "Epoch: 177 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.075  \n",
            "Epoch: 178 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.031  \n",
            "Epoch: 179 \tTraining Loss:  0.068 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.011  \n",
            "Epoch: 180 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:9%  \tVal_kappa : -0.166  \n",
            "Epoch: 181 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \tValid_Acc:11%  \tVal_kappa : -0.002  \n",
            "Epoch: 182 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:6%  \tVal_kappa : -0.095  \n",
            "Epoch: 183 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : 0.054  \n",
            "Epoch: 184 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.115  \n",
            "Epoch: 185 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.081  \n",
            "Epoch: 186 \tTraining Loss:  0.037 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.119  \n",
            "Epoch: 187 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.026  \n",
            "Epoch: 188 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.102  \n",
            "Epoch: 189 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.047  \n",
            "Epoch: 190 \tTraining Loss:  0.045 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.047  \n",
            "Epoch: 191 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.062  \n",
            "Epoch: 192 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : 0.014  \n",
            "Epoch: 193 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.044  \n",
            "Epoch: 194 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \tValid_Acc:9%  \tVal_kappa : -0.082  \n",
            "Epoch: 195 \tTraining Loss:  0.059 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : 0.023  \n",
            "Epoch: 196 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.048  \n",
            "Epoch: 197 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.028  \n",
            "Epoch: 198 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : 0.002  \n",
            "Epoch: 199 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.073  \n",
            "Epoch: 200 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.081  \n",
            "Epoch: 201 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.001  \n",
            "Epoch: 202 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.012  \n",
            "Epoch: 203 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.128  \n",
            "Epoch: 204 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.078  \n",
            "Epoch: 205 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.113  \n",
            "Epoch: 206 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.011  \n",
            "Epoch: 207 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.013  \n",
            "Epoch: 208 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.115  \n",
            "Epoch: 209 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.031  \n",
            "Epoch: 210 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : 0.013  \n",
            "Epoch: 211 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.010  \n",
            "Epoch: 212 \tTraining Loss:  0.085 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.018  \n",
            "Epoch: 213 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.065  \n",
            "Epoch: 214 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.000  \n",
            "Epoch: 215 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.003  \n",
            "Epoch: 216 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.037  \n",
            "Epoch: 217 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : 0.087  \n",
            "Epoch: 218 \tTraining Loss:  0.008 \tTrain_Accu: 100%  \tValid_Acc:14%  \tVal_kappa : -0.017  \n",
            "Epoch: 219 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.021  \n",
            "Epoch: 220 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.101  \n",
            "Epoch: 221 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.009  \n",
            "Epoch: 222 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.095  \n",
            "Epoch: 223 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \tValid_Acc:11%  \tVal_kappa : -0.009  \n",
            "Epoch: 224 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.003  \n",
            "Epoch: 225 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \tValid_Acc:9%  \tVal_kappa : -0.256  \n",
            "Epoch: 226 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.046  \n",
            "Epoch: 227 \tTraining Loss:  0.011 \tTrain_Accu: 100%  \tValid_Acc:20%  \tVal_kappa : 0.066  \n",
            "Epoch: 228 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.074  \n",
            "Epoch: 229 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.151  \n",
            "Epoch: 230 \tTraining Loss:  0.030 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.104  \n",
            "Epoch: 231 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.088  \n",
            "Epoch: 232 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : 0.070  \n",
            "Epoch: 233 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.035  \n",
            "Epoch: 234 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.071  \n",
            "Epoch: 235 \tTraining Loss:  0.022 \tTrain_Accu: 100%  \tValid_Acc:21%  \tVal_kappa : -0.088  \n",
            "Epoch: 236 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.020  \n",
            "Epoch: 237 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.027  \n",
            "Epoch: 238 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.078  \n",
            "Epoch: 239 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.027  \n",
            "Epoch: 240 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.047  \n",
            "Epoch: 241 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.114  \n",
            "Epoch: 242 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.024  \n",
            "Epoch: 243 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : -0.056  \n",
            "Epoch: 244 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.136  \n",
            "Epoch: 245 \tTraining Loss:  0.025 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.106  \n",
            "Epoch: 246 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.039  \n",
            "Epoch: 247 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.036  \n",
            "Epoch: 248 \tTraining Loss:  0.049 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : -0.030  \n",
            "Epoch: 249 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \tValid_Acc:29%  \tVal_kappa : 0.105  \n",
            "Epoch: 250 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.104  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-25 02:05:25,466]\u001b[0m Trial 2 finished with value: 18.6 and parameters: {}. Best is trial 2 with value: 18.6.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/DL_project/optimise_valid_NSI']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y4KssNUVFxb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF8aiBqCWzBV"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "jyMG4PGOEaWQ",
        "outputId": "b834bcc4-be2b-4f32-f910-fad7f3ca14c6"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_NSI_rain[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop()\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_NSI_RMSprops_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 4, 0, 4, 2, 4, 3, 0, 0, 0, 1, 3, 3, 1, 1, 0, 1, 0, 2, 2, 0, 3,\n",
            "        2, 1, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 4, 3, 3, 2, 2, 2, 2, 1])\n",
            "labels tensor([0, 2, 4, 4, 2, 1, 0, 0, 0, 1, 0, 0, 0, 2, 3, 4, 2, 2, 1, 0, 0, 0, 1, 3,\n",
            "        4, 1, 3, 4, 4, 1, 1, 0, 2, 2, 3, 2, 2, 2, 3, 1, 0, 0, 2, 1, 0, 0, 0, 4,\n",
            "        4, 4, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 2, 0, 2, 4])\n",
            "correct : 24\n",
            "test_Accuracy % : 34.3\n",
            "kappa 0.1950718685831624\n",
            "[[19  1  6  1  1]\n",
            " [ 6  1  3  0  1]\n",
            " [ 6  2  2  4  0]\n",
            " [ 4  0  1  1  1]\n",
            " [ 4  2  1  2  1]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqcK7f-x6sY9"
      },
      "source": [
        "### Training (no validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57SKRQxq6zn6"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_loaders_NSI(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:395], labelsTensors_NSI_rain[:395])\n",
        "    #validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_NSI_rain[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    #valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "   \n",
        "\n",
        "    return train_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iwxuwfH6wxS"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_NSI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "          'save_model' : True,\n",
        "          'lr'       :  0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "          'dropout'       : 0.5,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader = get_loaders_NSI(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "\n",
        "  train_accuracy = []\n",
        "  #valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  #valid_losses = []\n",
        "  \n",
        "  \n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "      #  valid_loss = 0\n",
        "      #  valid_correct = 0\n",
        "       train_acc = 0\n",
        "       #valid_acc = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "      #  with torch.no_grad(): \n",
        "      #     for batch_i, (data, target) in enumerate(valid_loader): \n",
        "      #         data, target = data.to(device), target.to(device)         \n",
        "      #         output = model(data)\n",
        "      #         output_c = output.cpu()\n",
        "      #         target_c = target.cpu()\n",
        "      #         loss = criterion(output_c, target_c) \n",
        "      #         valid_loss += loss.item()\n",
        "      #         valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "      #         valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "      #  valid_loss = valid_loss/len(valid_loader)\n",
        "      #  valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       #valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       #valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  '.format(epoch, train_loss, train_acc))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              #'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              #'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_NSI_RMSprops.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(train_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wlY-MV66wt0",
        "outputId": "6f87445d-b6af-4b08-e12d-129a39eacd93"
      },
      "source": [
        "import joblib\n",
        "\n",
        "study.optimize(train_NSI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"./optuna_NSI_drop.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.665 \tTrain_Accu: 21%  \n",
            "Epoch: 2 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \n",
            "Epoch: 3 \tTraining Loss:  1.587 \tTrain_Accu: 22%  \n",
            "Epoch: 4 \tTraining Loss:  1.588 \tTrain_Accu: 24%  \n",
            "Epoch: 5 \tTraining Loss:  1.548 \tTrain_Accu: 31%  \n",
            "Epoch: 6 \tTraining Loss:  1.551 \tTrain_Accu: 30%  \n",
            "Epoch: 7 \tTraining Loss:  1.515 \tTrain_Accu: 34%  \n",
            "Epoch: 8 \tTraining Loss:  1.487 \tTrain_Accu: 33%  \n",
            "Epoch: 9 \tTraining Loss:  1.455 \tTrain_Accu: 40%  \n",
            "Epoch: 10 \tTraining Loss:  1.407 \tTrain_Accu: 41%  \n",
            "Epoch: 11 \tTraining Loss:  1.325 \tTrain_Accu: 43%  \n",
            "Epoch: 12 \tTraining Loss:  1.305 \tTrain_Accu: 47%  \n",
            "Epoch: 13 \tTraining Loss:  1.269 \tTrain_Accu: 48%  \n",
            "Epoch: 14 \tTraining Loss:  1.219 \tTrain_Accu: 48%  \n",
            "Epoch: 15 \tTraining Loss:  1.095 \tTrain_Accu: 56%  \n",
            "Epoch: 16 \tTraining Loss:  1.116 \tTrain_Accu: 57%  \n",
            "Epoch: 17 \tTraining Loss:  1.076 \tTrain_Accu: 57%  \n",
            "Epoch: 18 \tTraining Loss:  0.976 \tTrain_Accu: 61%  \n",
            "Epoch: 19 \tTraining Loss:  0.966 \tTrain_Accu: 63%  \n",
            "Epoch: 20 \tTraining Loss:  0.888 \tTrain_Accu: 67%  \n",
            "Epoch: 21 \tTraining Loss:  0.890 \tTrain_Accu: 66%  \n",
            "Epoch: 22 \tTraining Loss:  0.869 \tTrain_Accu: 65%  \n",
            "Epoch: 23 \tTraining Loss:  0.769 \tTrain_Accu: 74%  \n",
            "Epoch: 24 \tTraining Loss:  0.775 \tTrain_Accu: 73%  \n",
            "Epoch: 25 \tTraining Loss:  0.720 \tTrain_Accu: 73%  \n",
            "Epoch: 26 \tTraining Loss:  0.675 \tTrain_Accu: 76%  \n",
            "Epoch: 27 \tTraining Loss:  0.607 \tTrain_Accu: 77%  \n",
            "Epoch: 28 \tTraining Loss:  0.597 \tTrain_Accu: 78%  \n",
            "Epoch: 29 \tTraining Loss:  0.560 \tTrain_Accu: 80%  \n",
            "Epoch: 30 \tTraining Loss:  0.495 \tTrain_Accu: 82%  \n",
            "Epoch: 31 \tTraining Loss:  0.530 \tTrain_Accu: 81%  \n",
            "Epoch: 32 \tTraining Loss:  0.546 \tTrain_Accu: 81%  \n",
            "Epoch: 33 \tTraining Loss:  0.476 \tTrain_Accu: 83%  \n",
            "Epoch: 34 \tTraining Loss:  0.516 \tTrain_Accu: 79%  \n",
            "Epoch: 35 \tTraining Loss:  0.413 \tTrain_Accu: 85%  \n",
            "Epoch: 36 \tTraining Loss:  0.423 \tTrain_Accu: 84%  \n",
            "Epoch: 37 \tTraining Loss:  0.378 \tTrain_Accu: 88%  \n",
            "Epoch: 38 \tTraining Loss:  0.376 \tTrain_Accu: 87%  \n",
            "Epoch: 39 \tTraining Loss:  0.308 \tTrain_Accu: 88%  \n",
            "Epoch: 40 \tTraining Loss:  0.396 \tTrain_Accu: 88%  \n",
            "Epoch: 41 \tTraining Loss:  0.354 \tTrain_Accu: 88%  \n",
            "Epoch: 42 \tTraining Loss:  0.332 \tTrain_Accu: 86%  \n",
            "Epoch: 43 \tTraining Loss:  0.317 \tTrain_Accu: 91%  \n",
            "Epoch: 44 \tTraining Loss:  0.316 \tTrain_Accu: 89%  \n",
            "Epoch: 45 \tTraining Loss:  0.262 \tTrain_Accu: 91%  \n",
            "Epoch: 46 \tTraining Loss:  0.268 \tTrain_Accu: 92%  \n",
            "Epoch: 47 \tTraining Loss:  0.229 \tTrain_Accu: 91%  \n",
            "Epoch: 48 \tTraining Loss:  0.268 \tTrain_Accu: 91%  \n",
            "Epoch: 49 \tTraining Loss:  0.252 \tTrain_Accu: 91%  \n",
            "Epoch: 50 \tTraining Loss:  0.196 \tTrain_Accu: 93%  \n",
            "Epoch: 51 \tTraining Loss:  0.259 \tTrain_Accu: 89%  \n",
            "Epoch: 52 \tTraining Loss:  0.213 \tTrain_Accu: 92%  \n",
            "Epoch: 53 \tTraining Loss:  0.186 \tTrain_Accu: 94%  \n",
            "Epoch: 54 \tTraining Loss:  0.194 \tTrain_Accu: 94%  \n",
            "Epoch: 55 \tTraining Loss:  0.252 \tTrain_Accu: 91%  \n",
            "Epoch: 56 \tTraining Loss:  0.212 \tTrain_Accu: 92%  \n",
            "Epoch: 57 \tTraining Loss:  0.181 \tTrain_Accu: 94%  \n",
            "Epoch: 58 \tTraining Loss:  0.170 \tTrain_Accu: 94%  \n",
            "Epoch: 59 \tTraining Loss:  0.245 \tTrain_Accu: 91%  \n",
            "Epoch: 60 \tTraining Loss:  0.177 \tTrain_Accu: 94%  \n",
            "Epoch: 61 \tTraining Loss:  0.153 \tTrain_Accu: 95%  \n",
            "Epoch: 62 \tTraining Loss:  0.171 \tTrain_Accu: 93%  \n",
            "Epoch: 63 \tTraining Loss:  0.156 \tTrain_Accu: 95%  \n",
            "Epoch: 64 \tTraining Loss:  0.169 \tTrain_Accu: 94%  \n",
            "Epoch: 65 \tTraining Loss:  0.167 \tTrain_Accu: 94%  \n",
            "Epoch: 66 \tTraining Loss:  0.158 \tTrain_Accu: 94%  \n",
            "Epoch: 67 \tTraining Loss:  0.193 \tTrain_Accu: 93%  \n",
            "Epoch: 68 \tTraining Loss:  0.141 \tTrain_Accu: 94%  \n",
            "Epoch: 69 \tTraining Loss:  0.140 \tTrain_Accu: 95%  \n",
            "Epoch: 70 \tTraining Loss:  0.116 \tTrain_Accu: 95%  \n",
            "Epoch: 71 \tTraining Loss:  0.117 \tTrain_Accu: 95%  \n",
            "Epoch: 72 \tTraining Loss:  0.126 \tTrain_Accu: 95%  \n",
            "Epoch: 73 \tTraining Loss:  0.126 \tTrain_Accu: 95%  \n",
            "Epoch: 74 \tTraining Loss:  0.119 \tTrain_Accu: 95%  \n",
            "Epoch: 75 \tTraining Loss:  0.125 \tTrain_Accu: 96%  \n",
            "Epoch: 76 \tTraining Loss:  0.114 \tTrain_Accu: 96%  \n",
            "Epoch: 77 \tTraining Loss:  0.130 \tTrain_Accu: 94%  \n",
            "Epoch: 78 \tTraining Loss:  0.137 \tTrain_Accu: 95%  \n",
            "Epoch: 79 \tTraining Loss:  0.110 \tTrain_Accu: 97%  \n",
            "Epoch: 80 \tTraining Loss:  0.100 \tTrain_Accu: 97%  \n",
            "Epoch: 81 \tTraining Loss:  0.151 \tTrain_Accu: 95%  \n",
            "Epoch: 82 \tTraining Loss:  0.091 \tTrain_Accu: 96%  \n",
            "Epoch: 83 \tTraining Loss:  0.098 \tTrain_Accu: 97%  \n",
            "Epoch: 84 \tTraining Loss:  0.116 \tTrain_Accu: 96%  \n",
            "Epoch: 85 \tTraining Loss:  0.095 \tTrain_Accu: 96%  \n",
            "Epoch: 86 \tTraining Loss:  0.113 \tTrain_Accu: 97%  \n",
            "Epoch: 87 \tTraining Loss:  0.085 \tTrain_Accu: 97%  \n",
            "Epoch: 88 \tTraining Loss:  0.097 \tTrain_Accu: 96%  \n",
            "Epoch: 89 \tTraining Loss:  0.095 \tTrain_Accu: 97%  \n",
            "Epoch: 90 \tTraining Loss:  0.078 \tTrain_Accu: 97%  \n",
            "Epoch: 91 \tTraining Loss:  0.066 \tTrain_Accu: 98%  \n",
            "Epoch: 92 \tTraining Loss:  0.080 \tTrain_Accu: 97%  \n",
            "Epoch: 93 \tTraining Loss:  0.090 \tTrain_Accu: 96%  \n",
            "Epoch: 94 \tTraining Loss:  0.087 \tTrain_Accu: 96%  \n",
            "Epoch: 95 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \n",
            "Epoch: 96 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \n",
            "Epoch: 97 \tTraining Loss:  0.098 \tTrain_Accu: 97%  \n",
            "Epoch: 98 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 99 \tTraining Loss:  0.095 \tTrain_Accu: 97%  \n",
            "Epoch: 100 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \n",
            "Epoch: 101 \tTraining Loss:  0.063 \tTrain_Accu: 97%  \n",
            "Epoch: 102 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \n",
            "Epoch: 103 \tTraining Loss:  0.074 \tTrain_Accu: 97%  \n",
            "Epoch: 104 \tTraining Loss:  0.071 \tTrain_Accu: 97%  \n",
            "Epoch: 105 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \n",
            "Epoch: 106 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \n",
            "Epoch: 107 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 108 \tTraining Loss:  0.067 \tTrain_Accu: 97%  \n",
            "Epoch: 109 \tTraining Loss:  0.060 \tTrain_Accu: 99%  \n",
            "Epoch: 110 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \n",
            "Epoch: 111 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \n",
            "Epoch: 112 \tTraining Loss:  0.059 \tTrain_Accu: 97%  \n",
            "Epoch: 113 \tTraining Loss:  0.059 \tTrain_Accu: 99%  \n",
            "Epoch: 114 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \n",
            "Epoch: 115 \tTraining Loss:  0.049 \tTrain_Accu: 99%  \n",
            "Epoch: 116 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \n",
            "Epoch: 117 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 118 \tTraining Loss:  0.069 \tTrain_Accu: 97%  \n",
            "Epoch: 119 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \n",
            "Epoch: 120 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \n",
            "Epoch: 121 \tTraining Loss:  0.078 \tTrain_Accu: 97%  \n",
            "Epoch: 122 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \n",
            "Epoch: 123 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \n",
            "Epoch: 124 \tTraining Loss:  0.054 \tTrain_Accu: 97%  \n",
            "Epoch: 125 \tTraining Loss:  0.052 \tTrain_Accu: 97%  \n",
            "Epoch: 126 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \n",
            "Epoch: 127 \tTraining Loss:  0.054 \tTrain_Accu: 99%  \n",
            "Epoch: 128 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \n",
            "Epoch: 129 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 130 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \n",
            "Epoch: 131 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \n",
            "Epoch: 132 \tTraining Loss:  0.047 \tTrain_Accu: 99%  \n",
            "Epoch: 133 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \n",
            "Epoch: 134 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 135 \tTraining Loss:  0.085 \tTrain_Accu: 98%  \n",
            "Epoch: 136 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \n",
            "Epoch: 137 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \n",
            "Epoch: 138 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 139 \tTraining Loss:  0.047 \tTrain_Accu: 99%  \n",
            "Epoch: 140 \tTraining Loss:  0.056 \tTrain_Accu: 97%  \n",
            "Epoch: 141 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \n",
            "Epoch: 142 \tTraining Loss:  0.056 \tTrain_Accu: 97%  \n",
            "Epoch: 143 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 144 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 145 \tTraining Loss:  0.068 \tTrain_Accu: 97%  \n",
            "Epoch: 146 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 147 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 148 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \n",
            "Epoch: 149 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \n",
            "Epoch: 150 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 151 \tTraining Loss:  0.064 \tTrain_Accu: 97%  \n",
            "Epoch: 152 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \n",
            "Epoch: 153 \tTraining Loss:  0.061 \tTrain_Accu: 99%  \n",
            "Epoch: 154 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 155 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \n",
            "Epoch: 156 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \n",
            "Epoch: 157 \tTraining Loss:  0.101 \tTrain_Accu: 96%  \n",
            "Epoch: 158 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 159 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \n",
            "Epoch: 160 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \n",
            "Epoch: 161 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \n",
            "Epoch: 162 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 163 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \n",
            "Epoch: 164 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \n",
            "Epoch: 165 \tTraining Loss:  0.023 \tTrain_Accu: 100%  \n",
            "Epoch: 166 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 167 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \n",
            "Epoch: 168 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 169 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \n",
            "Epoch: 170 \tTraining Loss:  0.054 \tTrain_Accu: 99%  \n",
            "Epoch: 171 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \n",
            "Epoch: 172 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \n",
            "Epoch: 173 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \n",
            "Epoch: 174 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 175 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 176 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 177 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \n",
            "Epoch: 178 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \n",
            "Epoch: 179 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 180 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \n",
            "Epoch: 181 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \n",
            "Epoch: 182 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \n",
            "Epoch: 183 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \n",
            "Epoch: 184 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 185 \tTraining Loss:  0.051 \tTrain_Accu: 99%  \n",
            "Epoch: 186 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 187 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \n",
            "Epoch: 188 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \n",
            "Epoch: 189 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \n",
            "Epoch: 190 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \n",
            "Epoch: 191 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \n",
            "Epoch: 192 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \n",
            "Epoch: 193 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \n",
            "Epoch: 194 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \n",
            "Epoch: 195 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 196 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \n",
            "Epoch: 197 \tTraining Loss:  0.062 \tTrain_Accu: 97%  \n",
            "Epoch: 198 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 199 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \n",
            "Epoch: 200 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \n",
            "Epoch: 201 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \n",
            "Epoch: 202 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 203 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 204 \tTraining Loss:  0.077 \tTrain_Accu: 97%  \n",
            "Epoch: 205 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \n",
            "Epoch: 206 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 207 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \n",
            "Epoch: 208 \tTraining Loss:  0.027 \tTrain_Accu: 98%  \n",
            "Epoch: 209 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 210 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \n",
            "Epoch: 211 \tTraining Loss:  0.012 \tTrain_Accu: 99%  \n",
            "Epoch: 212 \tTraining Loss:  0.005 \tTrain_Accu: 100%  \n",
            "Epoch: 213 \tTraining Loss:  0.013 \tTrain_Accu: 99%  \n",
            "Epoch: 214 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 215 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \n",
            "Epoch: 216 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \n",
            "Epoch: 217 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 218 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 219 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \n",
            "Epoch: 220 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \n",
            "Epoch: 221 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 222 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 223 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 224 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 225 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \n",
            "Epoch: 226 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \n",
            "Epoch: 227 \tTraining Loss:  0.013 \tTrain_Accu: 100%  \n",
            "Epoch: 228 \tTraining Loss:  0.008 \tTrain_Accu: 100%  \n",
            "Epoch: 229 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \n",
            "Epoch: 230 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 231 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \n",
            "Epoch: 232 \tTraining Loss:  0.052 \tTrain_Accu: 99%  \n",
            "Epoch: 233 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \n",
            "Epoch: 234 \tTraining Loss:  0.016 \tTrain_Accu: 100%  \n",
            "Epoch: 235 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 236 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \n",
            "Epoch: 237 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \n",
            "Epoch: 238 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 239 \tTraining Loss:  0.024 \tTrain_Accu: 98%  \n",
            "Epoch: 240 \tTraining Loss:  0.012 \tTrain_Accu: 100%  \n",
            "Epoch: 241 \tTraining Loss:  0.011 \tTrain_Accu: 100%  \n",
            "Epoch: 242 \tTraining Loss:  0.045 \tTrain_Accu: 99%  \n",
            "Epoch: 243 \tTraining Loss:  0.011 \tTrain_Accu: 99%  \n",
            "Epoch: 244 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 245 \tTraining Loss:  0.009 \tTrain_Accu: 100%  \n",
            "Epoch: 246 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \n",
            "Epoch: 247 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 248 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 249 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-25 23:14:54,938]\u001b[0m Trial 2 finished with value: 99.5 and parameters: {}. Best is trial 2 with value: 99.5.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.015 \tTrain_Accu: 99%  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./optuna_NSI_drop.torch']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QCt1_Mt8Slt"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "eNeo8XD-l5rv",
        "outputId": "487646b4-4d5f-4596-c4ce-5a9955bf5052"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_NSI_rain[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop()\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_NSI_RMSprops.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 2,\n",
            "        0, 0, 0, 4, 4, 4, 3, 4, 2, 0, 0, 2, 0, 3, 3, 3, 1, 1, 0, 3, 0, 0, 2, 3,\n",
            "        3, 1, 1, 2, 4, 2, 2, 3, 0, 0, 0, 0, 0, 0, 3, 3, 1, 1, 3, 2, 2, 4])\n",
            "labels tensor([0, 2, 4, 4, 2, 1, 0, 0, 0, 1, 0, 0, 0, 2, 3, 4, 2, 2, 1, 0, 0, 0, 1, 3,\n",
            "        4, 1, 3, 4, 4, 1, 1, 0, 2, 2, 3, 2, 2, 2, 3, 1, 0, 0, 2, 1, 0, 0, 0, 4,\n",
            "        4, 4, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 2, 0, 2, 4])\n",
            "correct : 23\n",
            "test_Accuracy % : 32.9\n",
            "kappa 0.21990049751243768\n",
            "[[15  6  4  2  1]\n",
            " [ 4  0  1  4  2]\n",
            " [ 6  2  3  3  0]\n",
            " [ 3  1  1  2  0]\n",
            " [ 3  2  0  2  3]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMRq_8-pyp9H"
      },
      "source": [
        "## WSI_Rain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QZbtwiTyp9H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "68fb0d78-7f2c-4db0-a28b-48bf82e06141"
      },
      "source": [
        "# Reading rainfall file of NNI region \n",
        "Data_Rain_WSI = pd.read_csv(\"drive/My Drive/DL_project/Target_Rain_WSI_regional_ave_time_series.csv\")\n",
        "Data_Rain_WSI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>Rain_bc</th>\n",
              "      <th>cat_3</th>\n",
              "      <th>cat_5</th>\n",
              "      <th>anomalies</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-04-01</td>\n",
              "      <td>754.639738</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>149.581434</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-05-01</td>\n",
              "      <td>715.682957</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>54.732620</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-06-01</td>\n",
              "      <td>649.918240</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-20.089857</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-07-01</td>\n",
              "      <td>609.927346</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-40.021983</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-08-01</td>\n",
              "      <td>513.748260</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-107.608177</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>2019-08-01</td>\n",
              "      <td>512.908271</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-108.448166</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>585.456530</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-44.543182</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>2019-10-01</td>\n",
              "      <td>628.058786</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-78.309772</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>809.331997</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>87.511779</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>1057.779644</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>294.894489</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>465 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           time      Rain_bc  cat_3  cat_5   anomalies region\n",
              "0    1981-04-01   754.639738      3      5  149.581434    WSI\n",
              "1    1981-05-01   715.682957      2      4   54.732620    WSI\n",
              "2    1981-06-01   649.918240      2      3  -20.089857    WSI\n",
              "3    1981-07-01   609.927346      2      2  -40.021983    WSI\n",
              "4    1981-08-01   513.748260      1      1 -107.608177    WSI\n",
              "..          ...          ...    ...    ...         ...    ...\n",
              "460  2019-08-01   512.908271      1      1 -108.448166    WSI\n",
              "461  2019-09-01   585.456530      2      2  -44.543182    WSI\n",
              "462  2019-10-01   628.058786      1      2  -78.309772    WSI\n",
              "463  2019-11-01   809.331997      3      4   87.511779    WSI\n",
              "464  2019-12-01  1057.779644      3      5  294.894489    WSI\n",
              "\n",
              "[465 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugI9X58Xyp9H"
      },
      "source": [
        "# Extracting label column\n",
        "labels_Rain_WSI = Data_Rain_WSI['cat_5'].astype(int) #cat5 column - so 5 prediction classes "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMrc44v9yp9I"
      },
      "source": [
        "# Function that will convert labels into Pytorch tensors\n",
        "\n",
        "def labels_Tensors(labels):\n",
        "    return (torch.from_numpy(labels.values).type(torch.LongTensor)-1) #cat5 in form 1, 2, 3, 4, 5;\n",
        "\n",
        "# Converting labels of rainfall_WSI region into tensors\n",
        "labelsTensors_WSI_rain = labels_Tensors(labels_Rain_WSI) # This represents y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tbKdEcPjNY2"
      },
      "source": [
        "### Training\n",
        "Training the network with the training and validation dataset in Optuna frame work with RMSprop optimizer, batch size 10 and learning rate 0.0001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-jbMvIQyp9I"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_valid_loaders_WSI(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_WSI_rain[:325])\n",
        "    validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_WSI_rain[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "  \n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TthF6dbm0TD"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_Rain_WSI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           #'dropout'       : 0.7,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_WSI(cfg['Batch_size'])\n",
        "  model = Network_drop().to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_WSI_rain[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_WSI_rain[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 10\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_WSI_rain[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_WSI_rain[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_WSI_RMSprops_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNzuuugPyp9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5b819d-5507-4dad-dec3-4ca5b60e1c93"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_Rain_WSI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"optimise_valid_WSI_drop(0.5).torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.705 \tTrain_Accu: 21%  \tValid_Acc:23%  \tVal_kappa : -0.238  \n",
            "Epoch: 2 \tTraining Loss:  1.613 \tTrain_Accu: 26%  \tValid_Acc:16%  \tVal_kappa : -0.176  \n",
            "Epoch: 3 \tTraining Loss:  1.600 \tTrain_Accu: 21%  \tValid_Acc:29%  \tVal_kappa : 0.143  \n",
            "Epoch: 4 \tTraining Loss:  1.579 \tTrain_Accu: 27%  \tValid_Acc:30%  \tVal_kappa : 0.090  \n",
            "Epoch: 5 \tTraining Loss:  1.580 \tTrain_Accu: 28%  \tValid_Acc:24%  \tVal_kappa : 0.041  \n",
            "Epoch: 6 \tTraining Loss:  1.558 \tTrain_Accu: 27%  \tValid_Acc:20%  \tVal_kappa : 0.147  \n",
            "Epoch: 7 \tTraining Loss:  1.522 \tTrain_Accu: 34%  \tValid_Acc:23%  \tVal_kappa : 0.129  \n",
            "Epoch: 8 \tTraining Loss:  1.523 \tTrain_Accu: 31%  \tValid_Acc:24%  \tVal_kappa : 0.233  \n",
            "Epoch: 9 \tTraining Loss:  1.489 \tTrain_Accu: 34%  \tValid_Acc:21%  \tVal_kappa : 0.019  \n",
            "Epoch: 10 \tTraining Loss:  1.443 \tTrain_Accu: 41%  \tValid_Acc:19%  \tVal_kappa : -0.053  \n",
            "Epoch: 11 \tTraining Loss:  1.404 \tTrain_Accu: 39%  \tValid_Acc:27%  \tVal_kappa : 0.146  \n",
            "Epoch: 12 \tTraining Loss:  1.396 \tTrain_Accu: 42%  \tValid_Acc:30%  \tVal_kappa : 0.247  \n",
            "Epoch: 13 \tTraining Loss:  1.323 \tTrain_Accu: 44%  \tValid_Acc:14%  \tVal_kappa : -0.094  \n",
            "Epoch: 14 \tTraining Loss:  1.325 \tTrain_Accu: 45%  \tValid_Acc:17%  \tVal_kappa : -0.028  \n",
            "Epoch: 15 \tTraining Loss:  1.220 \tTrain_Accu: 47%  \tValid_Acc:20%  \tVal_kappa : 0.107  \n",
            "Epoch: 16 \tTraining Loss:  1.190 \tTrain_Accu: 49%  \tValid_Acc:24%  \tVal_kappa : -0.145  \n",
            "Epoch: 17 \tTraining Loss:  1.127 \tTrain_Accu: 54%  \tValid_Acc:24%  \tVal_kappa : 0.151  \n",
            "Epoch: 18 \tTraining Loss:  1.140 \tTrain_Accu: 51%  \tValid_Acc:30%  \tVal_kappa : 0.003  \n",
            "Epoch: 19 \tTraining Loss:  1.081 \tTrain_Accu: 55%  \tValid_Acc:16%  \tVal_kappa : -0.032  \n",
            "Epoch: 20 \tTraining Loss:  1.031 \tTrain_Accu: 58%  \tValid_Acc:20%  \tVal_kappa : -0.093  \n",
            "Epoch: 21 \tTraining Loss:  0.939 \tTrain_Accu: 62%  \tValid_Acc:20%  \tVal_kappa : 0.086  \n",
            "Epoch: 22 \tTraining Loss:  0.952 \tTrain_Accu: 62%  \tValid_Acc:20%  \tVal_kappa : -0.051  \n",
            "Epoch: 23 \tTraining Loss:  0.932 \tTrain_Accu: 62%  \tValid_Acc:20%  \tVal_kappa : 0.025  \n",
            "Epoch: 24 \tTraining Loss:  0.821 \tTrain_Accu: 68%  \tValid_Acc:23%  \tVal_kappa : 0.072  \n",
            "Epoch: 25 \tTraining Loss:  0.810 \tTrain_Accu: 70%  \tValid_Acc:21%  \tVal_kappa : 0.113  \n",
            "Epoch: 26 \tTraining Loss:  0.802 \tTrain_Accu: 69%  \tValid_Acc:21%  \tVal_kappa : 0.077  \n",
            "Epoch: 27 \tTraining Loss:  0.709 \tTrain_Accu: 76%  \tValid_Acc:14%  \tVal_kappa : -0.039  \n",
            "Epoch: 28 \tTraining Loss:  0.702 \tTrain_Accu: 74%  \tValid_Acc:21%  \tVal_kappa : 0.076  \n",
            "Epoch: 29 \tTraining Loss:  0.680 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : -0.074  \n",
            "Epoch: 30 \tTraining Loss:  0.614 \tTrain_Accu: 75%  \tValid_Acc:23%  \tVal_kappa : 0.082  \n",
            "Epoch: 31 \tTraining Loss:  0.600 \tTrain_Accu: 77%  \tValid_Acc:21%  \tVal_kappa : -0.020  \n",
            "Epoch: 32 \tTraining Loss:  0.551 \tTrain_Accu: 78%  \tValid_Acc:23%  \tVal_kappa : 0.100  \n",
            "Epoch: 33 \tTraining Loss:  0.554 \tTrain_Accu: 80%  \tValid_Acc:26%  \tVal_kappa : 0.076  \n",
            "Epoch: 34 \tTraining Loss:  0.532 \tTrain_Accu: 80%  \tValid_Acc:11%  \tVal_kappa : 0.056  \n",
            "Epoch: 35 \tTraining Loss:  0.493 \tTrain_Accu: 82%  \tValid_Acc:14%  \tVal_kappa : -0.247  \n",
            "Epoch: 36 \tTraining Loss:  0.474 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : 0.092  \n",
            "Epoch: 37 \tTraining Loss:  0.481 \tTrain_Accu: 83%  \tValid_Acc:19%  \tVal_kappa : -0.150  \n",
            "Epoch: 38 \tTraining Loss:  0.475 \tTrain_Accu: 83%  \tValid_Acc:17%  \tVal_kappa : 0.056  \n",
            "Epoch: 39 \tTraining Loss:  0.464 \tTrain_Accu: 84%  \tValid_Acc:31%  \tVal_kappa : 0.276  \n",
            "Epoch: 40 \tTraining Loss:  0.473 \tTrain_Accu: 85%  \tValid_Acc:23%  \tVal_kappa : 0.037  \n",
            "Epoch: 41 \tTraining Loss:  0.399 \tTrain_Accu: 86%  \tValid_Acc:20%  \tVal_kappa : 0.231  \n",
            "Epoch: 42 \tTraining Loss:  0.426 \tTrain_Accu: 86%  \tValid_Acc:23%  \tVal_kappa : 0.092  \n",
            "Epoch: 43 \tTraining Loss:  0.368 \tTrain_Accu: 88%  \tValid_Acc:21%  \tVal_kappa : 0.074  \n",
            "Epoch: 44 \tTraining Loss:  0.335 \tTrain_Accu: 89%  \tValid_Acc:17%  \tVal_kappa : 0.073  \n",
            "Epoch: 45 \tTraining Loss:  0.344 \tTrain_Accu: 88%  \tValid_Acc:21%  \tVal_kappa : -0.148  \n",
            "Epoch: 46 \tTraining Loss:  0.333 \tTrain_Accu: 87%  \tValid_Acc:21%  \tVal_kappa : 0.032  \n",
            "Epoch: 47 \tTraining Loss:  0.354 \tTrain_Accu: 86%  \tValid_Acc:21%  \tVal_kappa : 0.090  \n",
            "Epoch: 48 \tTraining Loss:  0.306 \tTrain_Accu: 90%  \tValid_Acc:23%  \tVal_kappa : 0.017  \n",
            "Epoch: 49 \tTraining Loss:  0.317 \tTrain_Accu: 89%  \tValid_Acc:21%  \tVal_kappa : 0.029  \n",
            "Epoch: 50 \tTraining Loss:  0.256 \tTrain_Accu: 91%  \tValid_Acc:23%  \tVal_kappa : 0.099  \n",
            "Epoch: 51 \tTraining Loss:  0.286 \tTrain_Accu: 91%  \tValid_Acc:20%  \tVal_kappa : -0.052  \n",
            "Epoch: 52 \tTraining Loss:  0.303 \tTrain_Accu: 90%  \tValid_Acc:24%  \tVal_kappa : 0.078  \n",
            "Epoch: 53 \tTraining Loss:  0.281 \tTrain_Accu: 89%  \tValid_Acc:21%  \tVal_kappa : 0.047  \n",
            "Epoch: 54 \tTraining Loss:  0.246 \tTrain_Accu: 90%  \tValid_Acc:23%  \tVal_kappa : -0.073  \n",
            "Epoch: 55 \tTraining Loss:  0.205 \tTrain_Accu: 93%  \tValid_Acc:23%  \tVal_kappa : -0.009  \n",
            "Epoch: 56 \tTraining Loss:  0.231 \tTrain_Accu: 94%  \tValid_Acc:24%  \tVal_kappa : -0.073  \n",
            "Epoch: 57 \tTraining Loss:  0.184 \tTrain_Accu: 95%  \tValid_Acc:21%  \tVal_kappa : 0.027  \n",
            "Epoch: 58 \tTraining Loss:  0.281 \tTrain_Accu: 89%  \tValid_Acc:27%  \tVal_kappa : 0.003  \n",
            "Epoch: 59 \tTraining Loss:  0.262 \tTrain_Accu: 91%  \tValid_Acc:27%  \tVal_kappa : 0.081  \n",
            "Epoch: 60 \tTraining Loss:  0.210 \tTrain_Accu: 93%  \tValid_Acc:23%  \tVal_kappa : 0.022  \n",
            "Epoch: 61 \tTraining Loss:  0.222 \tTrain_Accu: 91%  \tValid_Acc:17%  \tVal_kappa : -0.045  \n",
            "Epoch: 62 \tTraining Loss:  0.185 \tTrain_Accu: 93%  \tValid_Acc:23%  \tVal_kappa : -0.027  \n",
            "Epoch: 63 \tTraining Loss:  0.218 \tTrain_Accu: 93%  \tValid_Acc:21%  \tVal_kappa : 0.012  \n",
            "Epoch: 64 \tTraining Loss:  0.244 \tTrain_Accu: 92%  \tValid_Acc:19%  \tVal_kappa : 0.160  \n",
            "Epoch: 65 \tTraining Loss:  0.176 \tTrain_Accu: 93%  \tValid_Acc:24%  \tVal_kappa : 0.065  \n",
            "Epoch: 66 \tTraining Loss:  0.175 \tTrain_Accu: 94%  \tValid_Acc:19%  \tVal_kappa : 0.016  \n",
            "Epoch: 67 \tTraining Loss:  0.188 \tTrain_Accu: 94%  \tValid_Acc:29%  \tVal_kappa : 0.061  \n",
            "Epoch: 68 \tTraining Loss:  0.124 \tTrain_Accu: 96%  \tValid_Acc:24%  \tVal_kappa : -0.067  \n",
            "Epoch: 69 \tTraining Loss:  0.159 \tTrain_Accu: 94%  \tValid_Acc:19%  \tVal_kappa : -0.089  \n",
            "Epoch: 70 \tTraining Loss:  0.154 \tTrain_Accu: 95%  \tValid_Acc:23%  \tVal_kappa : -0.047  \n",
            "Epoch: 71 \tTraining Loss:  0.183 \tTrain_Accu: 92%  \tValid_Acc:20%  \tVal_kappa : 0.030  \n",
            "Epoch: 72 \tTraining Loss:  0.107 \tTrain_Accu: 96%  \tValid_Acc:24%  \tVal_kappa : 0.007  \n",
            "Epoch: 73 \tTraining Loss:  0.174 \tTrain_Accu: 95%  \tValid_Acc:16%  \tVal_kappa : 0.099  \n",
            "Epoch: 74 \tTraining Loss:  0.186 \tTrain_Accu: 93%  \tValid_Acc:24%  \tVal_kappa : 0.003  \n",
            "Epoch: 75 \tTraining Loss:  0.148 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : 0.013  \n",
            "Epoch: 76 \tTraining Loss:  0.222 \tTrain_Accu: 91%  \tValid_Acc:20%  \tVal_kappa : -0.039  \n",
            "Epoch: 77 \tTraining Loss:  0.093 \tTrain_Accu: 97%  \tValid_Acc:27%  \tVal_kappa : 0.110  \n",
            "Epoch: 78 \tTraining Loss:  0.141 \tTrain_Accu: 94%  \tValid_Acc:17%  \tVal_kappa : -0.096  \n",
            "Epoch: 79 \tTraining Loss:  0.124 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : -0.180  \n",
            "Epoch: 80 \tTraining Loss:  0.146 \tTrain_Accu: 96%  \tValid_Acc:17%  \tVal_kappa : -0.013  \n",
            "Epoch: 81 \tTraining Loss:  0.126 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : 0.039  \n",
            "Epoch: 82 \tTraining Loss:  0.152 \tTrain_Accu: 95%  \tValid_Acc:21%  \tVal_kappa : -0.112  \n",
            "Epoch: 83 \tTraining Loss:  0.112 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : 0.132  \n",
            "Epoch: 84 \tTraining Loss:  0.147 \tTrain_Accu: 95%  \tValid_Acc:27%  \tVal_kappa : 0.105  \n",
            "Epoch: 85 \tTraining Loss:  0.125 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : 0.047  \n",
            "Epoch: 86 \tTraining Loss:  0.109 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : 0.080  \n",
            "Epoch: 87 \tTraining Loss:  0.097 \tTrain_Accu: 95%  \tValid_Acc:24%  \tVal_kappa : 0.103  \n",
            "Epoch: 88 \tTraining Loss:  0.078 \tTrain_Accu: 97%  \tValid_Acc:33%  \tVal_kappa : 0.152  \n",
            "Epoch: 89 \tTraining Loss:  0.094 \tTrain_Accu: 98%  \tValid_Acc:29%  \tVal_kappa : 0.058  \n",
            "Epoch: 90 \tTraining Loss:  0.125 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : -0.028  \n",
            "Epoch: 91 \tTraining Loss:  0.159 \tTrain_Accu: 94%  \tValid_Acc:19%  \tVal_kappa : -0.046  \n",
            "Epoch: 92 \tTraining Loss:  0.127 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : 0.055  \n",
            "Epoch: 93 \tTraining Loss:  0.132 \tTrain_Accu: 95%  \tValid_Acc:29%  \tVal_kappa : 0.117  \n",
            "Epoch: 94 \tTraining Loss:  0.079 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : -0.179  \n",
            "Epoch: 95 \tTraining Loss:  0.170 \tTrain_Accu: 94%  \tValid_Acc:31%  \tVal_kappa : 0.015  \n",
            "Epoch: 96 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.045  \n",
            "Epoch: 97 \tTraining Loss:  0.097 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : 0.165  \n",
            "Epoch: 98 \tTraining Loss:  0.079 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : -0.018  \n",
            "Epoch: 99 \tTraining Loss:  0.150 \tTrain_Accu: 94%  \tValid_Acc:26%  \tVal_kappa : 0.066  \n",
            "Epoch: 100 \tTraining Loss:  0.110 \tTrain_Accu: 95%  \tValid_Acc:26%  \tVal_kappa : -0.024  \n",
            "Epoch: 101 \tTraining Loss:  0.125 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : -0.013  \n",
            "Epoch: 102 \tTraining Loss:  0.119 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.053  \n",
            "Epoch: 103 \tTraining Loss:  0.078 \tTrain_Accu: 98%  \tValid_Acc:27%  \tVal_kappa : 0.016  \n",
            "Epoch: 104 \tTraining Loss:  0.112 \tTrain_Accu: 96%  \tValid_Acc:24%  \tVal_kappa : 0.179  \n",
            "Epoch: 105 \tTraining Loss:  0.103 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : 0.109  \n",
            "Epoch: 106 \tTraining Loss:  0.119 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : -0.001  \n",
            "Epoch: 107 \tTraining Loss:  0.074 \tTrain_Accu: 98%  \tValid_Acc:27%  \tVal_kappa : 0.132  \n",
            "Epoch: 108 \tTraining Loss:  0.075 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.174  \n",
            "Epoch: 109 \tTraining Loss:  0.095 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : 0.010  \n",
            "Epoch: 110 \tTraining Loss:  0.054 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.166  \n",
            "Epoch: 111 \tTraining Loss:  0.057 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : -0.054  \n",
            "Epoch: 112 \tTraining Loss:  0.087 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : 0.110  \n",
            "Epoch: 113 \tTraining Loss:  0.086 \tTrain_Accu: 96%  \tValid_Acc:26%  \tVal_kappa : 0.013  \n",
            "Epoch: 114 \tTraining Loss:  0.105 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : -0.075  \n",
            "Epoch: 115 \tTraining Loss:  0.107 \tTrain_Accu: 95%  \tValid_Acc:19%  \tVal_kappa : -0.007  \n",
            "Epoch: 116 \tTraining Loss:  0.092 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : 0.017  \n",
            "Epoch: 117 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \tValid_Acc:34%  \tVal_kappa : 0.097  \n",
            "Epoch: 118 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.117  \n",
            "Epoch: 119 \tTraining Loss:  0.076 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.097  \n",
            "Epoch: 120 \tTraining Loss:  0.056 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.000  \n",
            "Epoch: 121 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.023  \n",
            "Epoch: 122 \tTraining Loss:  0.055 \tTrain_Accu: 100%  \tValid_Acc:21%  \tVal_kappa : -0.022  \n",
            "Epoch: 123 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:30%  \tVal_kappa : 0.215  \n",
            "Epoch: 124 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.133  \n",
            "Epoch: 125 \tTraining Loss:  0.082 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : 0.251  \n",
            "Epoch: 126 \tTraining Loss:  0.077 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.187  \n",
            "Epoch: 127 \tTraining Loss:  0.086 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : 0.110  \n",
            "Epoch: 128 \tTraining Loss:  0.092 \tTrain_Accu: 96%  \tValid_Acc:13%  \tVal_kappa : -0.149  \n",
            "Epoch: 129 \tTraining Loss:  0.102 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.047  \n",
            "Epoch: 130 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.063  \n",
            "Epoch: 131 \tTraining Loss:  0.020 \tTrain_Accu: 100%  \tValid_Acc:23%  \tVal_kappa : 0.015  \n",
            "Epoch: 132 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:30%  \tVal_kappa : 0.230  \n",
            "Epoch: 133 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.077  \n",
            "Epoch: 134 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.027  \n",
            "Epoch: 135 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.095  \n",
            "Epoch: 136 \tTraining Loss:  0.090 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.031  \n",
            "Epoch: 137 \tTraining Loss:  0.084 \tTrain_Accu: 96%  \tValid_Acc:24%  \tVal_kappa : -0.129  \n",
            "Epoch: 138 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : -0.063  \n",
            "Epoch: 139 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.162  \n",
            "Epoch: 140 \tTraining Loss:  0.037 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.021  \n",
            "Epoch: 141 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : 0.043  \n",
            "Epoch: 142 \tTraining Loss:  0.091 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : 0.058  \n",
            "Epoch: 143 \tTraining Loss:  0.068 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.005  \n",
            "Epoch: 144 \tTraining Loss:  0.070 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.109  \n",
            "Epoch: 145 \tTraining Loss:  0.073 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.044  \n",
            "Epoch: 146 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.042  \n",
            "Epoch: 147 \tTraining Loss:  0.080 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.041  \n",
            "Epoch: 148 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.270  \n",
            "Epoch: 149 \tTraining Loss:  0.084 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.017  \n",
            "Epoch: 150 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : 0.013  \n",
            "Epoch: 151 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.060  \n",
            "Epoch: 152 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.006  \n",
            "Epoch: 153 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.236  \n",
            "Epoch: 154 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : -0.094  \n",
            "Epoch: 155 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.145  \n",
            "Epoch: 156 \tTraining Loss:  0.099 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : 0.079  \n",
            "Epoch: 157 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:27%  \tVal_kappa : -0.059  \n",
            "Epoch: 158 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.033  \n",
            "Epoch: 159 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : -0.031  \n",
            "Epoch: 160 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : -0.016  \n",
            "Epoch: 161 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.010  \n",
            "Epoch: 162 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:27%  \tVal_kappa : 0.255  \n",
            "Epoch: 163 \tTraining Loss:  0.070 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : 0.053  \n",
            "Epoch: 164 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.046  \n",
            "Epoch: 165 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:29%  \tVal_kappa : 0.139  \n",
            "Epoch: 166 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.073  \n",
            "Epoch: 167 \tTraining Loss:  0.061 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : 0.128  \n",
            "Epoch: 168 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : 0.068  \n",
            "Epoch: 169 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.162  \n",
            "Epoch: 170 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.050  \n",
            "Epoch: 171 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : -0.071  \n",
            "Epoch: 172 \tTraining Loss:  0.059 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.145  \n",
            "Epoch: 173 \tTraining Loss:  0.094 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : -0.043  \n",
            "Epoch: 174 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : -0.023  \n",
            "Epoch: 175 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : -0.007  \n",
            "Epoch: 176 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.059  \n",
            "Epoch: 177 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.120  \n",
            "Epoch: 178 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.092  \n",
            "Epoch: 179 \tTraining Loss:  0.073 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.011  \n",
            "Epoch: 180 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \tValid_Acc:27%  \tVal_kappa : 0.085  \n",
            "Epoch: 181 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : -0.009  \n",
            "Epoch: 182 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.115  \n",
            "Epoch: 183 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.014  \n",
            "Epoch: 184 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.180  \n",
            "Epoch: 185 \tTraining Loss:  0.081 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.129  \n",
            "Epoch: 186 \tTraining Loss:  0.020 \tTrain_Accu: 100%  \tValid_Acc:17%  \tVal_kappa : 0.078  \n",
            "Epoch: 187 \tTraining Loss:  0.060 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : 0.034  \n",
            "Epoch: 188 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.076  \n",
            "Epoch: 189 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:27%  \tVal_kappa : 0.064  \n",
            "Epoch: 190 \tTraining Loss:  0.034 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.123  \n",
            "Epoch: 191 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.086  \n",
            "Epoch: 192 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.145  \n",
            "Epoch: 193 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:29%  \tVal_kappa : 0.143  \n",
            "Epoch: 194 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \tValid_Acc:27%  \tVal_kappa : 0.056  \n",
            "Epoch: 195 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.158  \n",
            "Epoch: 196 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.021  \n",
            "Epoch: 197 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.001  \n",
            "Epoch: 198 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.016  \n",
            "Epoch: 199 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.022  \n",
            "Epoch: 200 \tTraining Loss:  0.052 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.158  \n",
            "Epoch: 201 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.107  \n",
            "Epoch: 202 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : 0.065  \n",
            "Epoch: 203 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.002  \n",
            "Epoch: 204 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.077  \n",
            "Epoch: 205 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : 0.025  \n",
            "Epoch: 206 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.081  \n",
            "Epoch: 207 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.000  \n",
            "Epoch: 208 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:33%  \tVal_kappa : 0.180  \n",
            "Epoch: 209 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.010  \n",
            "Epoch: 210 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.079  \n",
            "Epoch: 211 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.126  \n",
            "Epoch: 212 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.011  \n",
            "Epoch: 213 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : 0.276  \n",
            "Epoch: 214 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.090  \n",
            "Epoch: 215 \tTraining Loss:  0.015 \tTrain_Accu: 100%  \tValid_Acc:20%  \tVal_kappa : 0.014  \n",
            "Epoch: 216 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.033  \n",
            "Epoch: 217 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.213  \n",
            "Epoch: 218 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : -0.045  \n",
            "Epoch: 219 \tTraining Loss:  0.050 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.093  \n",
            "Epoch: 220 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.164  \n",
            "Epoch: 221 \tTraining Loss:  0.016 \tTrain_Accu: 100%  \tValid_Acc:16%  \tVal_kappa : -0.177  \n",
            "Epoch: 222 \tTraining Loss:  0.021 \tTrain_Accu: 100%  \tValid_Acc:24%  \tVal_kappa : 0.143  \n",
            "Epoch: 223 \tTraining Loss:  0.017 \tTrain_Accu: 100%  \tValid_Acc:21%  \tVal_kappa : 0.033  \n",
            "Epoch: 224 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.126  \n",
            "Epoch: 225 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:29%  \tVal_kappa : -0.077  \n",
            "Epoch: 226 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.229  \n",
            "Epoch: 227 \tTraining Loss:  0.037 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.129  \n",
            "Epoch: 228 \tTraining Loss:  0.023 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.126  \n",
            "Epoch: 229 \tTraining Loss:  0.017 \tTrain_Accu: 100%  \tValid_Acc:33%  \tVal_kappa : 0.199  \n",
            "Epoch: 230 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.100  \n",
            "Epoch: 231 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \tValid_Acc:27%  \tVal_kappa : 0.032  \n",
            "Epoch: 232 \tTraining Loss:  0.068 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : -0.027  \n",
            "Epoch: 233 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : -0.039  \n",
            "Epoch: 234 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:31%  \tVal_kappa : 0.041  \n",
            "Epoch: 235 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.082  \n",
            "Epoch: 236 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.080  \n",
            "Epoch: 237 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.097  \n",
            "Epoch: 238 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.195  \n",
            "Epoch: 239 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.096  \n",
            "Epoch: 240 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.079  \n",
            "Epoch: 241 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.141  \n",
            "Epoch: 242 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:31%  \tVal_kappa : 0.156  \n",
            "Epoch: 243 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.046  \n",
            "Epoch: 244 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \tValid_Acc:31%  \tVal_kappa : 0.078  \n",
            "Epoch: 245 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.080  \n",
            "Epoch: 246 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.047  \n",
            "Epoch: 247 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.117  \n",
            "Epoch: 248 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.138  \n",
            "Epoch: 249 \tTraining Loss:  0.032 \tTrain_Accu: 100%  \tValid_Acc:23%  \tVal_kappa : 0.081  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-25 23:27:22,359]\u001b[0m Trial 4 finished with value: 22.9 and parameters: {}. Best is trial 2 with value: 99.5.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.104  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['optimise_valid_WSI_drop(0.5).torch']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhrIQxNdyp9I"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "5PK_bvTnooDn",
        "outputId": "ee6d2cfe-1a0c-4387-99f3-8b5bf1082c98"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_WSI_rain[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop()\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_WSI_RMSprops_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 3, 4, 4, 1, 0, 0, 0, 0, 4, 0, 0, 2, 0, 3, 1, 1, 1, 1, 2, 4, 4, 0,\n",
            "        4, 4, 2, 3, 3, 4, 4, 2, 0, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
            "        2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 0, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2])\n",
            "labels tensor([0, 0, 3, 4, 4, 1, 0, 1, 3, 3, 2, 0, 0, 3, 3, 4, 4, 4, 1, 1, 1, 1, 2, 3,\n",
            "        4, 4, 4, 4, 4, 2, 1, 0, 2, 3, 4, 4, 3, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2,\n",
            "        3, 4, 3, 1, 1, 0, 1, 0, 1, 0, 2, 1, 4, 4, 4, 2, 3, 0, 1, 1, 3, 4])\n",
            "correct : 17\n",
            "test_Accuracy % : 24.3\n",
            "kappa 0.20479416362688896\n",
            "[[ 6  0 11  1  0]\n",
            " [ 1  4  7  1  2]\n",
            " [ 3  0  2  0  3]\n",
            " [ 4  1  6  1  0]\n",
            " [ 1  2  7  3  4]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu4ZkE4XFQWI"
      },
      "source": [
        "### Training (no validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mz6cGW3FXOV"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_loaders_WSI(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:395], labelsTensors_WSI_rain[:395])\n",
        "    #validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_NSI_rain[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    #valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "   \n",
        "\n",
        "    return train_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIZ_LcpAGyg4"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_WSI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "          'save_model' : True,\n",
        "          'lr'       :  0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "          'dropout'       : 0.5,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader = get_loaders_WSI(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "\n",
        "  train_accuracy = []\n",
        "  #valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  #valid_losses = []\n",
        "  \n",
        "  \n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "      #  valid_loss = 0\n",
        "      #  valid_correct = 0\n",
        "       train_acc = 0\n",
        "       #valid_acc = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "      #  with torch.no_grad(): \n",
        "      #     for batch_i, (data, target) in enumerate(valid_loader): \n",
        "      #         data, target = data.to(device), target.to(device)         \n",
        "      #         output = model(data)\n",
        "      #         output_c = output.cpu()\n",
        "      #         target_c = target.cpu()\n",
        "      #         loss = criterion(output_c, target_c) \n",
        "      #         valid_loss += loss.item()\n",
        "      #         valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "      #         valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "      #  valid_loss = valid_loss/len(valid_loader)\n",
        "      #  valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       #valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       #valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  '.format(epoch, train_loss, train_acc))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              #'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              #'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_WSI_RMSprops_std_indv.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(train_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os_-WUTJHT9i",
        "outputId": "0e1f837a-198a-4de7-dbe1-67b5c98f8d83"
      },
      "source": [
        "import joblib\n",
        "\n",
        "study.optimize(train_WSI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"./optuna_WSI_drop.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.637 \tTrain_Accu: 19%  \n",
            "Epoch: 2 \tTraining Loss:  1.603 \tTrain_Accu: 25%  \n",
            "Epoch: 3 \tTraining Loss:  1.598 \tTrain_Accu: 24%  \n",
            "Epoch: 4 \tTraining Loss:  1.570 \tTrain_Accu: 27%  \n",
            "Epoch: 5 \tTraining Loss:  1.573 \tTrain_Accu: 25%  \n",
            "Epoch: 6 \tTraining Loss:  1.538 \tTrain_Accu: 29%  \n",
            "Epoch: 7 \tTraining Loss:  1.505 \tTrain_Accu: 33%  \n",
            "Epoch: 8 \tTraining Loss:  1.478 \tTrain_Accu: 34%  \n",
            "Epoch: 9 \tTraining Loss:  1.489 \tTrain_Accu: 34%  \n",
            "Epoch: 10 \tTraining Loss:  1.424 \tTrain_Accu: 46%  \n",
            "Epoch: 11 \tTraining Loss:  1.353 \tTrain_Accu: 43%  \n",
            "Epoch: 12 \tTraining Loss:  1.332 \tTrain_Accu: 44%  \n",
            "Epoch: 13 \tTraining Loss:  1.276 \tTrain_Accu: 47%  \n",
            "Epoch: 14 \tTraining Loss:  1.245 \tTrain_Accu: 51%  \n",
            "Epoch: 15 \tTraining Loss:  1.207 \tTrain_Accu: 55%  \n",
            "Epoch: 16 \tTraining Loss:  1.149 \tTrain_Accu: 53%  \n",
            "Epoch: 17 \tTraining Loss:  1.170 \tTrain_Accu: 51%  \n",
            "Epoch: 18 \tTraining Loss:  1.028 \tTrain_Accu: 59%  \n",
            "Epoch: 19 \tTraining Loss:  1.037 \tTrain_Accu: 57%  \n",
            "Epoch: 20 \tTraining Loss:  0.996 \tTrain_Accu: 59%  \n",
            "Epoch: 21 \tTraining Loss:  0.872 \tTrain_Accu: 70%  \n",
            "Epoch: 22 \tTraining Loss:  0.904 \tTrain_Accu: 63%  \n",
            "Epoch: 23 \tTraining Loss:  0.850 \tTrain_Accu: 67%  \n",
            "Epoch: 24 \tTraining Loss:  0.733 \tTrain_Accu: 73%  \n",
            "Epoch: 25 \tTraining Loss:  0.792 \tTrain_Accu: 70%  \n",
            "Epoch: 26 \tTraining Loss:  0.766 \tTrain_Accu: 70%  \n",
            "Epoch: 27 \tTraining Loss:  0.739 \tTrain_Accu: 72%  \n",
            "Epoch: 28 \tTraining Loss:  0.719 \tTrain_Accu: 77%  \n",
            "Epoch: 29 \tTraining Loss:  0.667 \tTrain_Accu: 75%  \n",
            "Epoch: 30 \tTraining Loss:  0.597 \tTrain_Accu: 79%  \n",
            "Epoch: 31 \tTraining Loss:  0.632 \tTrain_Accu: 77%  \n",
            "Epoch: 32 \tTraining Loss:  0.567 \tTrain_Accu: 78%  \n",
            "Epoch: 33 \tTraining Loss:  0.552 \tTrain_Accu: 80%  \n",
            "Epoch: 34 \tTraining Loss:  0.543 \tTrain_Accu: 81%  \n",
            "Epoch: 35 \tTraining Loss:  0.534 \tTrain_Accu: 81%  \n",
            "Epoch: 36 \tTraining Loss:  0.513 \tTrain_Accu: 82%  \n",
            "Epoch: 37 \tTraining Loss:  0.439 \tTrain_Accu: 86%  \n",
            "Epoch: 38 \tTraining Loss:  0.453 \tTrain_Accu: 83%  \n",
            "Epoch: 39 \tTraining Loss:  0.376 \tTrain_Accu: 87%  \n",
            "Epoch: 40 \tTraining Loss:  0.390 \tTrain_Accu: 86%  \n",
            "Epoch: 41 \tTraining Loss:  0.389 \tTrain_Accu: 87%  \n",
            "Epoch: 42 \tTraining Loss:  0.330 \tTrain_Accu: 88%  \n",
            "Epoch: 43 \tTraining Loss:  0.323 \tTrain_Accu: 89%  \n",
            "Epoch: 44 \tTraining Loss:  0.376 \tTrain_Accu: 85%  \n",
            "Epoch: 45 \tTraining Loss:  0.349 \tTrain_Accu: 88%  \n",
            "Epoch: 46 \tTraining Loss:  0.293 \tTrain_Accu: 89%  \n",
            "Epoch: 47 \tTraining Loss:  0.325 \tTrain_Accu: 88%  \n",
            "Epoch: 48 \tTraining Loss:  0.295 \tTrain_Accu: 91%  \n",
            "Epoch: 49 \tTraining Loss:  0.325 \tTrain_Accu: 90%  \n",
            "Epoch: 50 \tTraining Loss:  0.301 \tTrain_Accu: 88%  \n",
            "Epoch: 51 \tTraining Loss:  0.263 \tTrain_Accu: 90%  \n",
            "Epoch: 52 \tTraining Loss:  0.282 \tTrain_Accu: 90%  \n",
            "Epoch: 53 \tTraining Loss:  0.251 \tTrain_Accu: 91%  \n",
            "Epoch: 54 \tTraining Loss:  0.280 \tTrain_Accu: 90%  \n",
            "Epoch: 55 \tTraining Loss:  0.219 \tTrain_Accu: 92%  \n",
            "Epoch: 56 \tTraining Loss:  0.246 \tTrain_Accu: 91%  \n",
            "Epoch: 57 \tTraining Loss:  0.246 \tTrain_Accu: 90%  \n",
            "Epoch: 58 \tTraining Loss:  0.303 \tTrain_Accu: 87%  \n",
            "Epoch: 59 \tTraining Loss:  0.219 \tTrain_Accu: 92%  \n",
            "Epoch: 60 \tTraining Loss:  0.205 \tTrain_Accu: 92%  \n",
            "Epoch: 61 \tTraining Loss:  0.175 \tTrain_Accu: 94%  \n",
            "Epoch: 62 \tTraining Loss:  0.185 \tTrain_Accu: 94%  \n",
            "Epoch: 63 \tTraining Loss:  0.222 \tTrain_Accu: 90%  \n",
            "Epoch: 64 \tTraining Loss:  0.182 \tTrain_Accu: 94%  \n",
            "Epoch: 65 \tTraining Loss:  0.219 \tTrain_Accu: 92%  \n",
            "Epoch: 66 \tTraining Loss:  0.187 \tTrain_Accu: 92%  \n",
            "Epoch: 67 \tTraining Loss:  0.193 \tTrain_Accu: 93%  \n",
            "Epoch: 68 \tTraining Loss:  0.163 \tTrain_Accu: 94%  \n",
            "Epoch: 69 \tTraining Loss:  0.157 \tTrain_Accu: 93%  \n",
            "Epoch: 70 \tTraining Loss:  0.210 \tTrain_Accu: 91%  \n",
            "Epoch: 71 \tTraining Loss:  0.141 \tTrain_Accu: 94%  \n",
            "Epoch: 72 \tTraining Loss:  0.150 \tTrain_Accu: 95%  \n",
            "Epoch: 73 \tTraining Loss:  0.216 \tTrain_Accu: 92%  \n",
            "Epoch: 74 \tTraining Loss:  0.147 \tTrain_Accu: 95%  \n",
            "Epoch: 75 \tTraining Loss:  0.140 \tTrain_Accu: 95%  \n",
            "Epoch: 76 \tTraining Loss:  0.165 \tTrain_Accu: 95%  \n",
            "Epoch: 77 \tTraining Loss:  0.143 \tTrain_Accu: 95%  \n",
            "Epoch: 78 \tTraining Loss:  0.107 \tTrain_Accu: 96%  \n",
            "Epoch: 79 \tTraining Loss:  0.126 \tTrain_Accu: 96%  \n",
            "Epoch: 80 \tTraining Loss:  0.126 \tTrain_Accu: 95%  \n",
            "Epoch: 81 \tTraining Loss:  0.165 \tTrain_Accu: 93%  \n",
            "Epoch: 82 \tTraining Loss:  0.163 \tTrain_Accu: 94%  \n",
            "Epoch: 83 \tTraining Loss:  0.078 \tTrain_Accu: 98%  \n",
            "Epoch: 84 \tTraining Loss:  0.139 \tTrain_Accu: 95%  \n",
            "Epoch: 85 \tTraining Loss:  0.134 \tTrain_Accu: 96%  \n",
            "Epoch: 86 \tTraining Loss:  0.160 \tTrain_Accu: 94%  \n",
            "Epoch: 87 \tTraining Loss:  0.153 \tTrain_Accu: 96%  \n",
            "Epoch: 88 \tTraining Loss:  0.091 \tTrain_Accu: 96%  \n",
            "Epoch: 89 \tTraining Loss:  0.154 \tTrain_Accu: 94%  \n",
            "Epoch: 90 \tTraining Loss:  0.121 \tTrain_Accu: 96%  \n",
            "Epoch: 91 \tTraining Loss:  0.122 \tTrain_Accu: 95%  \n",
            "Epoch: 92 \tTraining Loss:  0.073 \tTrain_Accu: 98%  \n",
            "Epoch: 93 \tTraining Loss:  0.089 \tTrain_Accu: 95%  \n",
            "Epoch: 94 \tTraining Loss:  0.109 \tTrain_Accu: 96%  \n",
            "Epoch: 95 \tTraining Loss:  0.111 \tTrain_Accu: 96%  \n",
            "Epoch: 96 \tTraining Loss:  0.085 \tTrain_Accu: 97%  \n",
            "Epoch: 97 \tTraining Loss:  0.091 \tTrain_Accu: 98%  \n",
            "Epoch: 98 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 99 \tTraining Loss:  0.152 \tTrain_Accu: 94%  \n",
            "Epoch: 100 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 101 \tTraining Loss:  0.154 \tTrain_Accu: 95%  \n",
            "Epoch: 102 \tTraining Loss:  0.114 \tTrain_Accu: 96%  \n",
            "Epoch: 103 \tTraining Loss:  0.105 \tTrain_Accu: 96%  \n",
            "Epoch: 104 \tTraining Loss:  0.112 \tTrain_Accu: 95%  \n",
            "Epoch: 105 \tTraining Loss:  0.131 \tTrain_Accu: 96%  \n",
            "Epoch: 106 \tTraining Loss:  0.094 \tTrain_Accu: 97%  \n",
            "Epoch: 107 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \n",
            "Epoch: 108 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \n",
            "Epoch: 109 \tTraining Loss:  0.080 \tTrain_Accu: 97%  \n",
            "Epoch: 110 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \n",
            "Epoch: 111 \tTraining Loss:  0.076 \tTrain_Accu: 98%  \n",
            "Epoch: 112 \tTraining Loss:  0.104 \tTrain_Accu: 96%  \n",
            "Epoch: 113 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \n",
            "Epoch: 114 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 115 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \n",
            "Epoch: 116 \tTraining Loss:  0.086 \tTrain_Accu: 96%  \n",
            "Epoch: 117 \tTraining Loss:  0.081 \tTrain_Accu: 98%  \n",
            "Epoch: 118 \tTraining Loss:  0.097 \tTrain_Accu: 97%  \n",
            "Epoch: 119 \tTraining Loss:  0.090 \tTrain_Accu: 96%  \n",
            "Epoch: 120 \tTraining Loss:  0.082 \tTrain_Accu: 98%  \n",
            "Epoch: 121 \tTraining Loss:  0.075 \tTrain_Accu: 98%  \n",
            "Epoch: 122 \tTraining Loss:  0.063 \tTrain_Accu: 97%  \n",
            "Epoch: 123 \tTraining Loss:  0.082 \tTrain_Accu: 97%  \n",
            "Epoch: 124 \tTraining Loss:  0.084 \tTrain_Accu: 97%  \n",
            "Epoch: 125 \tTraining Loss:  0.085 \tTrain_Accu: 97%  \n",
            "Epoch: 126 \tTraining Loss:  0.098 \tTrain_Accu: 96%  \n",
            "Epoch: 127 \tTraining Loss:  0.068 \tTrain_Accu: 98%  \n",
            "Epoch: 128 \tTraining Loss:  0.071 \tTrain_Accu: 98%  \n",
            "Epoch: 129 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \n",
            "Epoch: 130 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \n",
            "Epoch: 131 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 132 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \n",
            "Epoch: 133 \tTraining Loss:  0.078 \tTrain_Accu: 98%  \n",
            "Epoch: 134 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \n",
            "Epoch: 135 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \n",
            "Epoch: 136 \tTraining Loss:  0.067 \tTrain_Accu: 97%  \n",
            "Epoch: 137 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \n",
            "Epoch: 138 \tTraining Loss:  0.059 \tTrain_Accu: 97%  \n",
            "Epoch: 139 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \n",
            "Epoch: 140 \tTraining Loss:  0.090 \tTrain_Accu: 98%  \n",
            "Epoch: 141 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 142 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \n",
            "Epoch: 143 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \n",
            "Epoch: 144 \tTraining Loss:  0.105 \tTrain_Accu: 96%  \n",
            "Epoch: 145 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \n",
            "Epoch: 146 \tTraining Loss:  0.061 \tTrain_Accu: 99%  \n",
            "Epoch: 147 \tTraining Loss:  0.079 \tTrain_Accu: 97%  \n",
            "Epoch: 148 \tTraining Loss:  0.079 \tTrain_Accu: 98%  \n",
            "Epoch: 149 \tTraining Loss:  0.111 \tTrain_Accu: 95%  \n",
            "Epoch: 150 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \n",
            "Epoch: 151 \tTraining Loss:  0.068 \tTrain_Accu: 98%  \n",
            "Epoch: 152 \tTraining Loss:  0.083 \tTrain_Accu: 98%  \n",
            "Epoch: 153 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \n",
            "Epoch: 154 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \n",
            "Epoch: 155 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 156 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \n",
            "Epoch: 157 \tTraining Loss:  0.073 \tTrain_Accu: 99%  \n",
            "Epoch: 158 \tTraining Loss:  0.062 \tTrain_Accu: 97%  \n",
            "Epoch: 159 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 160 \tTraining Loss:  0.077 \tTrain_Accu: 97%  \n",
            "Epoch: 161 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \n",
            "Epoch: 162 \tTraining Loss:  0.054 \tTrain_Accu: 99%  \n",
            "Epoch: 163 \tTraining Loss:  0.087 \tTrain_Accu: 98%  \n",
            "Epoch: 164 \tTraining Loss:  0.079 \tTrain_Accu: 98%  \n",
            "Epoch: 165 \tTraining Loss:  0.069 \tTrain_Accu: 97%  \n",
            "Epoch: 166 \tTraining Loss:  0.051 \tTrain_Accu: 97%  \n",
            "Epoch: 167 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 168 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \n",
            "Epoch: 169 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \n",
            "Epoch: 170 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \n",
            "Epoch: 171 \tTraining Loss:  0.077 \tTrain_Accu: 97%  \n",
            "Epoch: 172 \tTraining Loss:  0.050 \tTrain_Accu: 99%  \n",
            "Epoch: 173 \tTraining Loss:  0.057 \tTrain_Accu: 97%  \n",
            "Epoch: 174 \tTraining Loss:  0.064 \tTrain_Accu: 97%  \n",
            "Epoch: 175 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \n",
            "Epoch: 176 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \n",
            "Epoch: 177 \tTraining Loss:  0.059 \tTrain_Accu: 97%  \n",
            "Epoch: 178 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \n",
            "Epoch: 179 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \n",
            "Epoch: 180 \tTraining Loss:  0.053 \tTrain_Accu: 99%  \n",
            "Epoch: 181 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \n",
            "Epoch: 182 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \n",
            "Epoch: 183 \tTraining Loss:  0.111 \tTrain_Accu: 97%  \n",
            "Epoch: 184 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \n",
            "Epoch: 185 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 186 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 187 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \n",
            "Epoch: 188 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \n",
            "Epoch: 189 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \n",
            "Epoch: 190 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \n",
            "Epoch: 191 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \n",
            "Epoch: 192 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \n",
            "Epoch: 193 \tTraining Loss:  0.027 \tTrain_Accu: 98%  \n",
            "Epoch: 194 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \n",
            "Epoch: 195 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \n",
            "Epoch: 196 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 197 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \n",
            "Epoch: 198 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 199 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \n",
            "Epoch: 200 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \n",
            "Epoch: 201 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \n",
            "Epoch: 202 \tTraining Loss:  0.057 \tTrain_Accu: 99%  \n",
            "Epoch: 203 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 204 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \n",
            "Epoch: 205 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \n",
            "Epoch: 206 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \n",
            "Epoch: 207 \tTraining Loss:  0.088 \tTrain_Accu: 97%  \n",
            "Epoch: 208 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \n",
            "Epoch: 209 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \n",
            "Epoch: 210 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \n",
            "Epoch: 211 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \n",
            "Epoch: 212 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \n",
            "Epoch: 213 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \n",
            "Epoch: 214 \tTraining Loss:  0.053 \tTrain_Accu: 99%  \n",
            "Epoch: 215 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \n",
            "Epoch: 216 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 217 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 218 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \n",
            "Epoch: 219 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \n",
            "Epoch: 220 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \n",
            "Epoch: 221 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 222 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \n",
            "Epoch: 223 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \n",
            "Epoch: 224 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 225 \tTraining Loss:  0.055 \tTrain_Accu: 97%  \n",
            "Epoch: 226 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 227 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \n",
            "Epoch: 228 \tTraining Loss:  0.015 \tTrain_Accu: 99%  \n",
            "Epoch: 229 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 230 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 231 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \n",
            "Epoch: 232 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \n",
            "Epoch: 233 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 234 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \n",
            "Epoch: 235 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 236 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 237 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 238 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 239 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 240 \tTraining Loss:  0.065 \tTrain_Accu: 97%  \n",
            "Epoch: 241 \tTraining Loss:  0.048 \tTrain_Accu: 97%  \n",
            "Epoch: 242 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \n",
            "Epoch: 243 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \n",
            "Epoch: 244 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \n",
            "Epoch: 245 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 246 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 247 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \n",
            "Epoch: 248 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 249 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 250 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-25 23:53:33,371]\u001b[0m Trial 5 finished with value: 98.0 and parameters: {}. Best is trial 2 with value: 99.5.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./optuna_WSI_drop.torch']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9zYlsiYFdlS"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "wZ3IACizvedZ",
        "outputId": "2543c9df-4635-49ef-8c1e-3b7d032b73b7"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_NSI_rain[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop()\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_WSI_RMSprops_std_indv.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2, 2, 3, 0, 4, 2, 0, 0, 3, 0, 0, 4, 0, 2, 3, 3, 2, 4, 1, 2, 2, 4, 4, 3,\n",
            "        4, 4, 2, 0, 3, 4, 4, 2, 3, 2, 2, 2, 1, 4, 2, 2, 2, 2, 3, 3, 0, 2, 0, 0,\n",
            "        3, 0, 2, 2, 4, 0, 0, 3, 0, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 2])\n",
            "labels tensor([0, 2, 4, 4, 2, 1, 0, 0, 0, 1, 0, 0, 0, 2, 3, 4, 2, 2, 1, 0, 0, 0, 1, 3,\n",
            "        4, 1, 3, 4, 4, 1, 1, 0, 2, 2, 3, 2, 2, 2, 3, 1, 0, 0, 2, 1, 0, 0, 0, 4,\n",
            "        4, 4, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 2, 0, 2, 4])\n",
            "correct : 20\n",
            "test_Accuracy % : 28.6\n",
            "kappa 0.06406685236768783\n",
            "[[9 1 7 9 2]\n",
            " [1 1 3 1 5]\n",
            " [0 1 6 4 3]\n",
            " [0 0 4 3 0]\n",
            " [4 0 1 4 1]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixq3CImTyp9P"
      },
      "source": [
        "## ESI_rain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Tmzidbrey1X1",
        "outputId": "3de588ec-3241-4075-dbdd-b031e6c04aa2"
      },
      "source": [
        "# Reading rainfall file of ESI region \n",
        "Data_Rain_ESI = pd.read_csv(\"drive/My Drive/DL_project/Target_Rain_ESI_regional_ave_time_series.csv\")\n",
        "Data_Rain_ESI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>Rain_bc</th>\n",
              "      <th>cat_3</th>\n",
              "      <th>cat_5</th>\n",
              "      <th>anomalies</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-04-01</td>\n",
              "      <td>154.501766</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-8.231351</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-05-01</td>\n",
              "      <td>156.471221</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-9.666739</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-06-01</td>\n",
              "      <td>168.750909</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5.076587</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-07-01</td>\n",
              "      <td>200.079117</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>27.608178</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-08-01</td>\n",
              "      <td>225.323325</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>54.264734</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>2019-08-01</td>\n",
              "      <td>144.404312</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-26.654279</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>165.436987</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-1.495053</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>2019-10-01</td>\n",
              "      <td>160.811636</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-9.769120</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>174.390909</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4.433875</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>201.459948</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>14.064339</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>465 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           time     Rain_bc  cat_3  cat_5  anomalies region\n",
              "0    1981-04-01  154.501766      2      3  -8.231351    ESI\n",
              "1    1981-05-01  156.471221      2      3  -9.666739    ESI\n",
              "2    1981-06-01  168.750909      2      4   5.076587    ESI\n",
              "3    1981-07-01  200.079117      3      4  27.608178    ESI\n",
              "4    1981-08-01  225.323325      3      5  54.264734    ESI\n",
              "..          ...         ...    ...    ...        ...    ...\n",
              "460  2019-08-01  144.404312      1      2 -26.654279    ESI\n",
              "461  2019-09-01  165.436987      2      3  -1.495053    ESI\n",
              "462  2019-10-01  160.811636      2      3  -9.769120    ESI\n",
              "463  2019-11-01  174.390909      2      4   4.433875    ESI\n",
              "464  2019-12-01  201.459948      2      4  14.064339    ESI\n",
              "\n",
              "[465 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDrp06ECy1bI"
      },
      "source": [
        "# Extracting quantiles from the ESI dataset\n",
        "labels_Rain_ESI = Data_Rain_ESI['cat_5'].astype(int) #cat5 column - so 5 prediction classes "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLTui2O13eru"
      },
      "source": [
        "# Function that will convert labels into Pytorch tensors\n",
        "\n",
        "def labels_Tensors(labels):\n",
        "    return (torch.from_numpy(labels.values).type(torch.LongTensor)-1) #cat5 in form 1, 2, 3, 4, 5;\n",
        "\n",
        "# Converting labels of rainfall_ESI region into tensors\n",
        "labelsTensors_ESI_rain = labels_Tensors(labels_Rain_ESI) # This represents y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wP1KIeDCV_P",
        "outputId": "32d24c6a-e0ee-4d92-9064-3a53851798cc"
      },
      "source": [
        "# Training data lables distribution\n",
        "Train_labels = labels_Rain_ESI[:324]\n",
        "Train_labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    70\n",
              "4    66\n",
              "2    64\n",
              "5    62\n",
              "1    62\n",
              "Name: cat_5, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwcBounl4eXm"
      },
      "source": [
        "### Training \n",
        "\n",
        "Training the network with the training and validation dataset in Optuna frame work with RMSprop optimizer, batch size 10 and learning rate 0.0001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O89P3dH4gHm"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_valid_loaders_ESI(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_ESI_rain[:325])\n",
        "    validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_ESI_rain[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "  \n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWZrChYFnVQ3"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_Rain_ESI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           #'dropout'       : 0.7,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_ESI(cfg['Batch_size'])\n",
        "  model = Network_drop().to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_ESI_rain[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_ESI_rain[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 10\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_ESI_rain[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_ESI_rain[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_ESI_RMSprops_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCYoOE5BRd_F",
        "outputId": "7f97bd62-c4c6-4efb-cf86-56c3a5853b5a"
      },
      "source": [
        "study = optuna.create_study(sampler=optuna.samplers.TPESampler(), direction='maximize')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-04-06 22:28:22,461]\u001b[0m A new study created in memory with name: no-name-f209b415-e09f-4d3b-b524-a956d7c97d11\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00121-ec980368-2739-4663-93c2-d074a6506bde",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "29bfc289",
        "execution_start": 1621987760236,
        "execution_millis": 423629,
        "deepnote_cell_type": "code",
        "id": "qjXtx6RZIYxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ec6ce4-3b6e-4e37-f4b8-c249a4b0e292"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_Rain_ESI, n_trials=1)\n",
        "\n",
        "joblib.dump(study, \"drive/MyDrive/DL_project/optimise_valid_ESI.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.695 \tTrain_Accu: 21%  \tValid_Acc:20%  \tVal_kappa : -0.032  \n",
            "Epoch: 2 \tTraining Loss:  1.615 \tTrain_Accu: 22%  \tValid_Acc:23%  \tVal_kappa : 0.145  \n",
            "Epoch: 3 \tTraining Loss:  1.595 \tTrain_Accu: 23%  \tValid_Acc:16%  \tVal_kappa : 0.042  \n",
            "Epoch: 4 \tTraining Loss:  1.591 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.053  \n",
            "Epoch: 5 \tTraining Loss:  1.559 \tTrain_Accu: 30%  \tValid_Acc:20%  \tVal_kappa : -0.092  \n",
            "Epoch: 6 \tTraining Loss:  1.564 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : 0.064  \n",
            "Epoch: 7 \tTraining Loss:  1.542 \tTrain_Accu: 29%  \tValid_Acc:14%  \tVal_kappa : -0.073  \n",
            "Epoch: 8 \tTraining Loss:  1.517 \tTrain_Accu: 36%  \tValid_Acc:16%  \tVal_kappa : -0.157  \n",
            "Epoch: 9 \tTraining Loss:  1.474 \tTrain_Accu: 39%  \tValid_Acc:24%  \tVal_kappa : 0.164  \n",
            "Epoch: 10 \tTraining Loss:  1.447 \tTrain_Accu: 38%  \tValid_Acc:21%  \tVal_kappa : -0.025  \n",
            "Epoch: 11 \tTraining Loss:  1.395 \tTrain_Accu: 43%  \tValid_Acc:16%  \tVal_kappa : -0.007  \n",
            "Epoch: 12 \tTraining Loss:  1.373 \tTrain_Accu: 41%  \tValid_Acc:17%  \tVal_kappa : 0.021  \n",
            "Epoch: 13 \tTraining Loss:  1.340 \tTrain_Accu: 43%  \tValid_Acc:29%  \tVal_kappa : 0.066  \n",
            "Epoch: 14 \tTraining Loss:  1.253 \tTrain_Accu: 47%  \tValid_Acc:19%  \tVal_kappa : -0.057  \n",
            "Epoch: 15 \tTraining Loss:  1.240 \tTrain_Accu: 53%  \tValid_Acc:21%  \tVal_kappa : -0.040  \n",
            "Epoch: 16 \tTraining Loss:  1.185 \tTrain_Accu: 50%  \tValid_Acc:17%  \tVal_kappa : -0.011  \n",
            "Epoch: 17 \tTraining Loss:  1.156 \tTrain_Accu: 52%  \tValid_Acc:21%  \tVal_kappa : 0.088  \n",
            "Epoch: 18 \tTraining Loss:  1.091 \tTrain_Accu: 56%  \tValid_Acc:23%  \tVal_kappa : -0.073  \n",
            "Epoch: 19 \tTraining Loss:  1.045 \tTrain_Accu: 57%  \tValid_Acc:16%  \tVal_kappa : 0.087  \n",
            "Epoch: 20 \tTraining Loss:  1.002 \tTrain_Accu: 62%  \tValid_Acc:37%  \tVal_kappa : 0.100  \n",
            "Epoch: 21 \tTraining Loss:  0.976 \tTrain_Accu: 64%  \tValid_Acc:26%  \tVal_kappa : 0.028  \n",
            "Epoch: 22 \tTraining Loss:  0.996 \tTrain_Accu: 62%  \tValid_Acc:19%  \tVal_kappa : 0.149  \n",
            "Epoch: 23 \tTraining Loss:  0.878 \tTrain_Accu: 65%  \tValid_Acc:23%  \tVal_kappa : -0.087  \n",
            "Epoch: 24 \tTraining Loss:  0.918 \tTrain_Accu: 65%  \tValid_Acc:19%  \tVal_kappa : -0.108  \n",
            "Epoch: 25 \tTraining Loss:  0.781 \tTrain_Accu: 69%  \tValid_Acc:20%  \tVal_kappa : 0.043  \n",
            "Epoch: 26 \tTraining Loss:  0.773 \tTrain_Accu: 72%  \tValid_Acc:24%  \tVal_kappa : 0.035  \n",
            "Epoch: 27 \tTraining Loss:  0.699 \tTrain_Accu: 73%  \tValid_Acc:17%  \tVal_kappa : 0.246  \n",
            "Epoch: 28 \tTraining Loss:  0.714 \tTrain_Accu: 72%  \tValid_Acc:16%  \tVal_kappa : -0.131  \n",
            "Epoch: 29 \tTraining Loss:  0.704 \tTrain_Accu: 72%  \tValid_Acc:19%  \tVal_kappa : -0.023  \n",
            "Epoch: 30 \tTraining Loss:  0.641 \tTrain_Accu: 75%  \tValid_Acc:26%  \tVal_kappa : 0.027  \n",
            "Epoch: 31 \tTraining Loss:  0.670 \tTrain_Accu: 72%  \tValid_Acc:23%  \tVal_kappa : 0.130  \n",
            "Epoch: 32 \tTraining Loss:  0.640 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : -0.090  \n",
            "Epoch: 33 \tTraining Loss:  0.529 \tTrain_Accu: 82%  \tValid_Acc:24%  \tVal_kappa : -0.035  \n",
            "Epoch: 34 \tTraining Loss:  0.531 \tTrain_Accu: 78%  \tValid_Acc:20%  \tVal_kappa : 0.248  \n",
            "Epoch: 35 \tTraining Loss:  0.511 \tTrain_Accu: 82%  \tValid_Acc:19%  \tVal_kappa : -0.032  \n",
            "Epoch: 36 \tTraining Loss:  0.450 \tTrain_Accu: 83%  \tValid_Acc:17%  \tVal_kappa : 0.084  \n",
            "Epoch: 37 \tTraining Loss:  0.481 \tTrain_Accu: 83%  \tValid_Acc:19%  \tVal_kappa : -0.056  \n",
            "Epoch: 38 \tTraining Loss:  0.492 \tTrain_Accu: 81%  \tValid_Acc:16%  \tVal_kappa : -0.064  \n",
            "Epoch: 39 \tTraining Loss:  0.449 \tTrain_Accu: 84%  \tValid_Acc:24%  \tVal_kappa : 0.087  \n",
            "Epoch: 40 \tTraining Loss:  0.382 \tTrain_Accu: 85%  \tValid_Acc:31%  \tVal_kappa : 0.150  \n",
            "Epoch: 41 \tTraining Loss:  0.409 \tTrain_Accu: 83%  \tValid_Acc:21%  \tVal_kappa : -0.053  \n",
            "Epoch: 42 \tTraining Loss:  0.371 \tTrain_Accu: 87%  \tValid_Acc:26%  \tVal_kappa : -0.031  \n",
            "Epoch: 43 \tTraining Loss:  0.369 \tTrain_Accu: 87%  \tValid_Acc:24%  \tVal_kappa : 0.007  \n",
            "Epoch: 44 \tTraining Loss:  0.361 \tTrain_Accu: 88%  \tValid_Acc:19%  \tVal_kappa : -0.066  \n",
            "Epoch: 45 \tTraining Loss:  0.337 \tTrain_Accu: 89%  \tValid_Acc:17%  \tVal_kappa : 0.086  \n",
            "Epoch: 46 \tTraining Loss:  0.350 \tTrain_Accu: 86%  \tValid_Acc:17%  \tVal_kappa : -0.041  \n",
            "Epoch: 47 \tTraining Loss:  0.351 \tTrain_Accu: 86%  \tValid_Acc:16%  \tVal_kappa : -0.091  \n",
            "Epoch: 48 \tTraining Loss:  0.339 \tTrain_Accu: 88%  \tValid_Acc:20%  \tVal_kappa : 0.042  \n",
            "Epoch: 49 \tTraining Loss:  0.264 \tTrain_Accu: 91%  \tValid_Acc:24%  \tVal_kappa : 0.070  \n",
            "Epoch: 50 \tTraining Loss:  0.310 \tTrain_Accu: 90%  \tValid_Acc:30%  \tVal_kappa : 0.106  \n",
            "Epoch: 51 \tTraining Loss:  0.265 \tTrain_Accu: 91%  \tValid_Acc:20%  \tVal_kappa : 0.088  \n",
            "Epoch: 52 \tTraining Loss:  0.333 \tTrain_Accu: 90%  \tValid_Acc:16%  \tVal_kappa : 0.051  \n",
            "Epoch: 53 \tTraining Loss:  0.209 \tTrain_Accu: 94%  \tValid_Acc:13%  \tVal_kappa : -0.121  \n",
            "Epoch: 54 \tTraining Loss:  0.261 \tTrain_Accu: 90%  \tValid_Acc:11%  \tVal_kappa : -0.113  \n",
            "Epoch: 55 \tTraining Loss:  0.283 \tTrain_Accu: 89%  \tValid_Acc:21%  \tVal_kappa : 0.039  \n",
            "Epoch: 56 \tTraining Loss:  0.248 \tTrain_Accu: 92%  \tValid_Acc:19%  \tVal_kappa : 0.036  \n",
            "Epoch: 57 \tTraining Loss:  0.255 \tTrain_Accu: 90%  \tValid_Acc:17%  \tVal_kappa : 0.034  \n",
            "Epoch: 58 \tTraining Loss:  0.262 \tTrain_Accu: 89%  \tValid_Acc:20%  \tVal_kappa : -0.162  \n",
            "Epoch: 59 \tTraining Loss:  0.257 \tTrain_Accu: 91%  \tValid_Acc:29%  \tVal_kappa : 0.002  \n",
            "Epoch: 60 \tTraining Loss:  0.181 \tTrain_Accu: 94%  \tValid_Acc:21%  \tVal_kappa : -0.041  \n",
            "Epoch: 61 \tTraining Loss:  0.208 \tTrain_Accu: 92%  \tValid_Acc:24%  \tVal_kappa : 0.240  \n",
            "Epoch: 62 \tTraining Loss:  0.200 \tTrain_Accu: 93%  \tValid_Acc:21%  \tVal_kappa : 0.057  \n",
            "Epoch: 63 \tTraining Loss:  0.188 \tTrain_Accu: 93%  \tValid_Acc:21%  \tVal_kappa : -0.077  \n",
            "Epoch: 64 \tTraining Loss:  0.204 \tTrain_Accu: 92%  \tValid_Acc:19%  \tVal_kappa : -0.015  \n",
            "Epoch: 65 \tTraining Loss:  0.224 \tTrain_Accu: 95%  \tValid_Acc:14%  \tVal_kappa : -0.102  \n",
            "Epoch: 66 \tTraining Loss:  0.194 \tTrain_Accu: 94%  \tValid_Acc:27%  \tVal_kappa : 0.132  \n",
            "Epoch: 67 \tTraining Loss:  0.172 \tTrain_Accu: 94%  \tValid_Acc:21%  \tVal_kappa : -0.053  \n",
            "Epoch: 68 \tTraining Loss:  0.213 \tTrain_Accu: 91%  \tValid_Acc:19%  \tVal_kappa : -0.030  \n",
            "Epoch: 69 \tTraining Loss:  0.226 \tTrain_Accu: 92%  \tValid_Acc:21%  \tVal_kappa : 0.083  \n",
            "Epoch: 70 \tTraining Loss:  0.184 \tTrain_Accu: 94%  \tValid_Acc:23%  \tVal_kappa : -0.019  \n",
            "Epoch: 71 \tTraining Loss:  0.174 \tTrain_Accu: 94%  \tValid_Acc:20%  \tVal_kappa : -0.034  \n",
            "Epoch: 72 \tTraining Loss:  0.141 \tTrain_Accu: 96%  \tValid_Acc:20%  \tVal_kappa : 0.008  \n",
            "Epoch: 73 \tTraining Loss:  0.142 \tTrain_Accu: 95%  \tValid_Acc:27%  \tVal_kappa : 0.035  \n",
            "Epoch: 74 \tTraining Loss:  0.201 \tTrain_Accu: 93%  \tValid_Acc:21%  \tVal_kappa : 0.030  \n",
            "Epoch: 75 \tTraining Loss:  0.139 \tTrain_Accu: 95%  \tValid_Acc:20%  \tVal_kappa : -0.088  \n",
            "Epoch: 76 \tTraining Loss:  0.167 \tTrain_Accu: 94%  \tValid_Acc:16%  \tVal_kappa : 0.006  \n",
            "Epoch: 77 \tTraining Loss:  0.135 \tTrain_Accu: 95%  \tValid_Acc:23%  \tVal_kappa : 0.088  \n",
            "Epoch: 78 \tTraining Loss:  0.136 \tTrain_Accu: 95%  \tValid_Acc:20%  \tVal_kappa : 0.088  \n",
            "Epoch: 79 \tTraining Loss:  0.111 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : -0.033  \n",
            "Epoch: 80 \tTraining Loss:  0.165 \tTrain_Accu: 94%  \tValid_Acc:19%  \tVal_kappa : -0.032  \n",
            "Epoch: 81 \tTraining Loss:  0.114 \tTrain_Accu: 96%  \tValid_Acc:20%  \tVal_kappa : 0.059  \n",
            "Epoch: 82 \tTraining Loss:  0.145 \tTrain_Accu: 94%  \tValid_Acc:17%  \tVal_kappa : -0.002  \n",
            "Epoch: 83 \tTraining Loss:  0.101 \tTrain_Accu: 95%  \tValid_Acc:26%  \tVal_kappa : 0.040  \n",
            "Epoch: 84 \tTraining Loss:  0.149 \tTrain_Accu: 94%  \tValid_Acc:21%  \tVal_kappa : 0.036  \n",
            "Epoch: 85 \tTraining Loss:  0.109 \tTrain_Accu: 95%  \tValid_Acc:19%  \tVal_kappa : -0.013  \n",
            "Epoch: 86 \tTraining Loss:  0.107 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : -0.048  \n",
            "Epoch: 87 \tTraining Loss:  0.112 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : -0.058  \n",
            "Epoch: 88 \tTraining Loss:  0.153 \tTrain_Accu: 93%  \tValid_Acc:20%  \tVal_kappa : 0.085  \n",
            "Epoch: 89 \tTraining Loss:  0.103 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.056  \n",
            "Epoch: 90 \tTraining Loss:  0.111 \tTrain_Accu: 96%  \tValid_Acc:20%  \tVal_kappa : 0.033  \n",
            "Epoch: 91 \tTraining Loss:  0.159 \tTrain_Accu: 95%  \tValid_Acc:13%  \tVal_kappa : -0.102  \n",
            "Epoch: 92 \tTraining Loss:  0.110 \tTrain_Accu: 97%  \tValid_Acc:27%  \tVal_kappa : 0.056  \n",
            "Epoch: 93 \tTraining Loss:  0.099 \tTrain_Accu: 98%  \tValid_Acc:27%  \tVal_kappa : 0.068  \n",
            "Epoch: 94 \tTraining Loss:  0.103 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : -0.020  \n",
            "Epoch: 95 \tTraining Loss:  0.087 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.087  \n",
            "Epoch: 96 \tTraining Loss:  0.123 \tTrain_Accu: 94%  \tValid_Acc:21%  \tVal_kappa : 0.134  \n",
            "Epoch: 97 \tTraining Loss:  0.101 \tTrain_Accu: 96%  \tValid_Acc:17%  \tVal_kappa : -0.077  \n",
            "Epoch: 98 \tTraining Loss:  0.107 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.128  \n",
            "Epoch: 99 \tTraining Loss:  0.101 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.103  \n",
            "Epoch: 100 \tTraining Loss:  0.122 \tTrain_Accu: 95%  \tValid_Acc:19%  \tVal_kappa : 0.101  \n",
            "Epoch: 101 \tTraining Loss:  0.087 \tTrain_Accu: 96%  \tValid_Acc:20%  \tVal_kappa : -0.091  \n",
            "Epoch: 102 \tTraining Loss:  0.116 \tTrain_Accu: 95%  \tValid_Acc:24%  \tVal_kappa : 0.150  \n",
            "Epoch: 103 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.099  \n",
            "Epoch: 104 \tTraining Loss:  0.110 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : 0.015  \n",
            "Epoch: 105 \tTraining Loss:  0.077 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.177  \n",
            "Epoch: 106 \tTraining Loss:  0.098 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : -0.068  \n",
            "Epoch: 107 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.084  \n",
            "Epoch: 108 \tTraining Loss:  0.078 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.017  \n",
            "Epoch: 109 \tTraining Loss:  0.112 \tTrain_Accu: 95%  \tValid_Acc:24%  \tVal_kappa : -0.112  \n",
            "Epoch: 110 \tTraining Loss:  0.074 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.054  \n",
            "Epoch: 111 \tTraining Loss:  0.122 \tTrain_Accu: 96%  \tValid_Acc:27%  \tVal_kappa : 0.110  \n",
            "Epoch: 112 \tTraining Loss:  0.081 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : -0.012  \n",
            "Epoch: 113 \tTraining Loss:  0.085 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.044  \n",
            "Epoch: 114 \tTraining Loss:  0.080 \tTrain_Accu: 97%  \tValid_Acc:27%  \tVal_kappa : 0.137  \n",
            "Epoch: 115 \tTraining Loss:  0.092 \tTrain_Accu: 97%  \tValid_Acc:27%  \tVal_kappa : 0.203  \n",
            "Epoch: 116 \tTraining Loss:  0.099 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : 0.019  \n",
            "Epoch: 117 \tTraining Loss:  0.078 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.028  \n",
            "Epoch: 118 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.074  \n",
            "Epoch: 119 \tTraining Loss:  0.100 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.113  \n",
            "Epoch: 120 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.030  \n",
            "Epoch: 121 \tTraining Loss:  0.052 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.056  \n",
            "Epoch: 122 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : 0.081  \n",
            "Epoch: 123 \tTraining Loss:  0.078 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.018  \n",
            "Epoch: 124 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : -0.008  \n",
            "Epoch: 125 \tTraining Loss:  0.084 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.166  \n",
            "Epoch: 126 \tTraining Loss:  0.097 \tTrain_Accu: 96%  \tValid_Acc:17%  \tVal_kappa : 0.056  \n",
            "Epoch: 127 \tTraining Loss:  0.070 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : -0.058  \n",
            "Epoch: 128 \tTraining Loss:  0.055 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.082  \n",
            "Epoch: 129 \tTraining Loss:  0.050 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : 0.051  \n",
            "Epoch: 130 \tTraining Loss:  0.071 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : -0.062  \n",
            "Epoch: 131 \tTraining Loss:  0.060 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : 0.006  \n",
            "Epoch: 132 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.133  \n",
            "Epoch: 133 \tTraining Loss:  0.068 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.019  \n",
            "Epoch: 134 \tTraining Loss:  0.082 \tTrain_Accu: 97%  \tValid_Acc:29%  \tVal_kappa : -0.016  \n",
            "Epoch: 135 \tTraining Loss:  0.082 \tTrain_Accu: 96%  \tValid_Acc:17%  \tVal_kappa : -0.078  \n",
            "Epoch: 136 \tTraining Loss:  0.124 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : 0.128  \n",
            "Epoch: 137 \tTraining Loss:  0.043 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.068  \n",
            "Epoch: 138 \tTraining Loss:  0.119 \tTrain_Accu: 96%  \tValid_Acc:11%  \tVal_kappa : 0.105  \n",
            "Epoch: 139 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.044  \n",
            "Epoch: 140 \tTraining Loss:  0.064 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : 0.174  \n",
            "Epoch: 141 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.092  \n",
            "Epoch: 142 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.045  \n",
            "Epoch: 143 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.033  \n",
            "Epoch: 144 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.006  \n",
            "Epoch: 145 \tTraining Loss:  0.077 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.105  \n",
            "Epoch: 146 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.236  \n",
            "Epoch: 147 \tTraining Loss:  0.106 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : 0.103  \n",
            "Epoch: 148 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.061  \n",
            "Epoch: 149 \tTraining Loss:  0.078 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.144  \n",
            "Epoch: 150 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : -0.023  \n",
            "Epoch: 151 \tTraining Loss:  0.110 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.110  \n",
            "Epoch: 152 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.022  \n",
            "Epoch: 153 \tTraining Loss:  0.068 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.053  \n",
            "Epoch: 154 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.154  \n",
            "Epoch: 155 \tTraining Loss:  0.073 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.122  \n",
            "Epoch: 156 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.039  \n",
            "Epoch: 157 \tTraining Loss:  0.050 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.034  \n",
            "Epoch: 158 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : -0.071  \n",
            "Epoch: 159 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.115  \n",
            "Epoch: 160 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.046  \n",
            "Epoch: 161 \tTraining Loss:  0.060 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : -0.095  \n",
            "Epoch: 162 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.127  \n",
            "Epoch: 163 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.148  \n",
            "Epoch: 164 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.010  \n",
            "Epoch: 165 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.051  \n",
            "Epoch: 166 \tTraining Loss:  0.080 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.109  \n",
            "Epoch: 167 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.110  \n",
            "Epoch: 168 \tTraining Loss:  0.074 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : 0.116  \n",
            "Epoch: 169 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \tValid_Acc:27%  \tVal_kappa : 0.233  \n",
            "Epoch: 170 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \tValid_Acc:30%  \tVal_kappa : 0.098  \n",
            "Epoch: 171 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.152  \n",
            "Epoch: 172 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.111  \n",
            "Epoch: 173 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.109  \n",
            "Epoch: 174 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.107  \n",
            "Epoch: 175 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.003  \n",
            "Epoch: 176 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:30%  \tVal_kappa : 0.147  \n",
            "Epoch: 177 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.013  \n",
            "Epoch: 178 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.075  \n",
            "Epoch: 179 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : 0.144  \n",
            "Epoch: 180 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.040  \n",
            "Epoch: 181 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.054  \n",
            "Epoch: 182 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.058  \n",
            "Epoch: 183 \tTraining Loss:  0.066 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : 0.011  \n",
            "Epoch: 184 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.051  \n",
            "Epoch: 185 \tTraining Loss:  0.074 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.148  \n",
            "Epoch: 186 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.098  \n",
            "Epoch: 187 \tTraining Loss:  0.046 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.074  \n",
            "Epoch: 188 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.104  \n",
            "Epoch: 189 \tTraining Loss:  0.078 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.105  \n",
            "Epoch: 190 \tTraining Loss:  0.064 \tTrain_Accu: 97%  \tValid_Acc:29%  \tVal_kappa : 0.203  \n",
            "Epoch: 191 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.068  \n",
            "Epoch: 192 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.086  \n",
            "Epoch: 193 \tTraining Loss:  0.016 \tTrain_Accu: 100%  \tValid_Acc:23%  \tVal_kappa : -0.032  \n",
            "Epoch: 194 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \tValid_Acc:27%  \tVal_kappa : 0.033  \n",
            "Epoch: 195 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.062  \n",
            "Epoch: 196 \tTraining Loss:  0.059 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.137  \n",
            "Epoch: 197 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:31%  \tVal_kappa : 0.124  \n",
            "Epoch: 198 \tTraining Loss:  0.014 \tTrain_Accu: 100%  \tValid_Acc:29%  \tVal_kappa : 0.068  \n",
            "Epoch: 199 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:30%  \tVal_kappa : 0.176  \n",
            "Epoch: 200 \tTraining Loss:  0.045 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : -0.020  \n",
            "Epoch: 201 \tTraining Loss:  0.080 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : 0.079  \n",
            "Epoch: 202 \tTraining Loss:  0.033 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.007  \n",
            "Epoch: 203 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : -0.058  \n",
            "Epoch: 204 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : 0.013  \n",
            "Epoch: 205 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : 0.022  \n",
            "Epoch: 206 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.059  \n",
            "Epoch: 207 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.052  \n",
            "Epoch: 208 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.053  \n",
            "Epoch: 209 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:29%  \tVal_kappa : 0.019  \n",
            "Epoch: 210 \tTraining Loss:  0.027 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.057  \n",
            "Epoch: 211 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.152  \n",
            "Epoch: 212 \tTraining Loss:  0.043 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.071  \n",
            "Epoch: 213 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.092  \n",
            "Epoch: 214 \tTraining Loss:  0.052 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.055  \n",
            "Epoch: 215 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.124  \n",
            "Epoch: 216 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.001  \n",
            "Epoch: 217 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : -0.040  \n",
            "Epoch: 218 \tTraining Loss:  0.032 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.070  \n",
            "Epoch: 219 \tTraining Loss:  0.016 \tTrain_Accu: 100%  \tValid_Acc:16%  \tVal_kappa : 0.042  \n",
            "Epoch: 220 \tTraining Loss:  0.029 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.134  \n",
            "Epoch: 221 \tTraining Loss:  0.020 \tTrain_Accu: 100%  \tValid_Acc:23%  \tVal_kappa : 0.066  \n",
            "Epoch: 222 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.118  \n",
            "Epoch: 223 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.049  \n",
            "Epoch: 224 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.055  \n",
            "Epoch: 225 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.127  \n",
            "Epoch: 226 \tTraining Loss:  0.030 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.108  \n",
            "Epoch: 227 \tTraining Loss:  0.016 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.043  \n",
            "Epoch: 228 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : -0.010  \n",
            "Epoch: 229 \tTraining Loss:  0.030 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : -0.021  \n",
            "Epoch: 230 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : 0.070  \n",
            "Epoch: 231 \tTraining Loss:  0.051 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.014  \n",
            "Epoch: 232 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.057  \n",
            "Epoch: 233 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.095  \n",
            "Epoch: 234 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.028  \n",
            "Epoch: 235 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.014  \n",
            "Epoch: 236 \tTraining Loss:  0.012 \tTrain_Accu: 100%  \tValid_Acc:19%  \tVal_kappa : 0.138  \n",
            "Epoch: 237 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.142  \n",
            "Epoch: 238 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.027  \n",
            "Epoch: 239 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.046  \n",
            "Epoch: 240 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:11%  \tVal_kappa : -0.005  \n",
            "Epoch: 241 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.145  \n",
            "Epoch: 242 \tTraining Loss:  0.013 \tTrain_Accu: 100%  \tValid_Acc:21%  \tVal_kappa : 0.062  \n",
            "Epoch: 243 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : 0.044  \n",
            "Epoch: 244 \tTraining Loss:  0.007 \tTrain_Accu: 100%  \tValid_Acc:24%  \tVal_kappa : -0.066  \n",
            "Epoch: 245 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.065  \n",
            "Epoch: 246 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.075  \n",
            "Epoch: 247 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.093  \n",
            "Epoch: 248 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.022  \n",
            "Epoch: 249 \tTraining Loss:  0.012 \tTrain_Accu: 100%  \tValid_Acc:17%  \tVal_kappa : -0.105  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 00:02:24,074]\u001b[0m Trial 6 finished with value: 20.0 and parameters: {}. Best is trial 2 with value: 99.5.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.113  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/DL_project/optimise_valid_ESI.torch']"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDGeMlv3HaBh"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "YK8V8Oszx0KG",
        "outputId": "22052bb9-8892-4366-d5eb-81ec3d5848f3"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_ESI_rain[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop()\n",
        "\n",
        "checkpoint = torch.load( \"drive/MyDrive/DL_project/check_valid_ESI_RMSprops_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 1, 1, 1, 1, 3, 3, 1, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 0, 1, 1,\n",
            "        0, 1, 0, 0, 4, 1, 1, 1, 0, 3, 3, 1, 0, 3, 3, 3, 1, 1, 0, 1, 0, 0, 0, 0,\n",
            "        0, 1, 2, 2, 4, 2, 4, 1, 2, 4, 4, 3, 1, 3, 3, 3, 4, 1, 4, 3, 3, 0])\n",
            "labels tensor([1, 4, 4, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 3, 1, 2, 0, 0, 0, 0, 2, 1,\n",
            "        2, 0, 2, 1, 2, 0, 1, 2, 4, 3, 3, 1, 3, 4, 4, 4, 4, 3, 4, 3, 0, 0, 1, 4,\n",
            "        4, 4, 4, 4, 0, 0, 0, 1, 4, 4, 4, 1, 1, 1, 3, 2, 2, 1, 2, 2, 3, 3])\n",
            "correct : 18\n",
            "test_Accuracy % : 25.7\n",
            "kappa 0.036308623298033305\n",
            "[[3 7 3 4 2]\n",
            " [2 9 0 2 0]\n",
            " [2 5 0 2 3]\n",
            " [2 3 0 4 0]\n",
            " [4 4 4 3 2]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiRawYwfFjNs"
      },
      "source": [
        "### Training (no validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUieCg93FmGo"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_loaders_ESI(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:395], labelsTensors_ESI_rain[:395])\n",
        "    #validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_NSI_rain[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    #valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "   \n",
        "\n",
        "    return train_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "204UJS4uG52b"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_ESI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "          'save_model' : True,\n",
        "          'lr'       :  0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "          'dropout'       : 0.5,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader = get_loaders_ESI(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "\n",
        "  train_accuracy = []\n",
        "  #valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  #valid_losses = []\n",
        "  \n",
        "  \n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "      #  valid_loss = 0\n",
        "      #  valid_correct = 0\n",
        "       train_acc = 0\n",
        "       #valid_acc = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "      #  with torch.no_grad(): \n",
        "      #     for batch_i, (data, target) in enumerate(valid_loader): \n",
        "      #         data, target = data.to(device), target.to(device)         \n",
        "      #         output = model(data)\n",
        "      #         output_c = output.cpu()\n",
        "      #         target_c = target.cpu()\n",
        "      #         loss = criterion(output_c, target_c) \n",
        "      #         valid_loss += loss.item()\n",
        "      #         valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "      #         valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "      #  valid_loss = valid_loss/len(valid_loader)\n",
        "      #  valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       #valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       #valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  '.format(epoch, train_loss, train_acc))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              #'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              #'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_ESI_RMSprops_indv.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(train_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9onsLivtIJta",
        "outputId": "d7fb342f-ccb0-4590-9510-1049caf23f29"
      },
      "source": [
        "import joblib\n",
        "\n",
        "study.optimize(train_ESI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"./optuna_ESI_drop.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.674 \tTrain_Accu: 21%  \n",
            "Epoch: 2 \tTraining Loss:  1.618 \tTrain_Accu: 23%  \n",
            "Epoch: 3 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \n",
            "Epoch: 4 \tTraining Loss:  1.596 \tTrain_Accu: 23%  \n",
            "Epoch: 5 \tTraining Loss:  1.584 \tTrain_Accu: 26%  \n",
            "Epoch: 6 \tTraining Loss:  1.581 \tTrain_Accu: 24%  \n",
            "Epoch: 7 \tTraining Loss:  1.563 \tTrain_Accu: 27%  \n",
            "Epoch: 8 \tTraining Loss:  1.536 \tTrain_Accu: 32%  \n",
            "Epoch: 9 \tTraining Loss:  1.504 \tTrain_Accu: 35%  \n",
            "Epoch: 10 \tTraining Loss:  1.481 \tTrain_Accu: 36%  \n",
            "Epoch: 11 \tTraining Loss:  1.378 \tTrain_Accu: 46%  \n",
            "Epoch: 12 \tTraining Loss:  1.393 \tTrain_Accu: 42%  \n",
            "Epoch: 13 \tTraining Loss:  1.333 \tTrain_Accu: 42%  \n",
            "Epoch: 14 \tTraining Loss:  1.270 \tTrain_Accu: 50%  \n",
            "Epoch: 15 \tTraining Loss:  1.248 \tTrain_Accu: 47%  \n",
            "Epoch: 16 \tTraining Loss:  1.196 \tTrain_Accu: 52%  \n",
            "Epoch: 17 \tTraining Loss:  1.144 \tTrain_Accu: 55%  \n",
            "Epoch: 18 \tTraining Loss:  1.077 \tTrain_Accu: 55%  \n",
            "Epoch: 19 \tTraining Loss:  1.006 \tTrain_Accu: 59%  \n",
            "Epoch: 20 \tTraining Loss:  1.010 \tTrain_Accu: 61%  \n",
            "Epoch: 21 \tTraining Loss:  0.949 \tTrain_Accu: 66%  \n",
            "Epoch: 22 \tTraining Loss:  0.894 \tTrain_Accu: 68%  \n",
            "Epoch: 23 \tTraining Loss:  0.886 \tTrain_Accu: 67%  \n",
            "Epoch: 24 \tTraining Loss:  0.775 \tTrain_Accu: 70%  \n",
            "Epoch: 25 \tTraining Loss:  0.798 \tTrain_Accu: 70%  \n",
            "Epoch: 26 \tTraining Loss:  0.680 \tTrain_Accu: 75%  \n",
            "Epoch: 27 \tTraining Loss:  0.670 \tTrain_Accu: 75%  \n",
            "Epoch: 28 \tTraining Loss:  0.682 \tTrain_Accu: 76%  \n",
            "Epoch: 29 \tTraining Loss:  0.572 \tTrain_Accu: 78%  \n",
            "Epoch: 30 \tTraining Loss:  0.560 \tTrain_Accu: 77%  \n",
            "Epoch: 31 \tTraining Loss:  0.550 \tTrain_Accu: 81%  \n",
            "Epoch: 32 \tTraining Loss:  0.511 \tTrain_Accu: 83%  \n",
            "Epoch: 33 \tTraining Loss:  0.488 \tTrain_Accu: 83%  \n",
            "Epoch: 34 \tTraining Loss:  0.468 \tTrain_Accu: 86%  \n",
            "Epoch: 35 \tTraining Loss:  0.440 \tTrain_Accu: 85%  \n",
            "Epoch: 36 \tTraining Loss:  0.409 \tTrain_Accu: 85%  \n",
            "Epoch: 37 \tTraining Loss:  0.384 \tTrain_Accu: 88%  \n",
            "Epoch: 38 \tTraining Loss:  0.367 \tTrain_Accu: 85%  \n",
            "Epoch: 39 \tTraining Loss:  0.365 \tTrain_Accu: 88%  \n",
            "Epoch: 40 \tTraining Loss:  0.365 \tTrain_Accu: 86%  \n",
            "Epoch: 41 \tTraining Loss:  0.382 \tTrain_Accu: 87%  \n",
            "Epoch: 42 \tTraining Loss:  0.323 \tTrain_Accu: 89%  \n",
            "Epoch: 43 \tTraining Loss:  0.320 \tTrain_Accu: 87%  \n",
            "Epoch: 44 \tTraining Loss:  0.310 \tTrain_Accu: 90%  \n",
            "Epoch: 45 \tTraining Loss:  0.271 \tTrain_Accu: 90%  \n",
            "Epoch: 46 \tTraining Loss:  0.292 \tTrain_Accu: 90%  \n",
            "Epoch: 47 \tTraining Loss:  0.255 \tTrain_Accu: 91%  \n",
            "Epoch: 48 \tTraining Loss:  0.236 \tTrain_Accu: 91%  \n",
            "Epoch: 49 \tTraining Loss:  0.257 \tTrain_Accu: 91%  \n",
            "Epoch: 50 \tTraining Loss:  0.237 \tTrain_Accu: 91%  \n",
            "Epoch: 51 \tTraining Loss:  0.170 \tTrain_Accu: 95%  \n",
            "Epoch: 52 \tTraining Loss:  0.213 \tTrain_Accu: 92%  \n",
            "Epoch: 53 \tTraining Loss:  0.190 \tTrain_Accu: 93%  \n",
            "Epoch: 54 \tTraining Loss:  0.212 \tTrain_Accu: 92%  \n",
            "Epoch: 55 \tTraining Loss:  0.186 \tTrain_Accu: 92%  \n",
            "Epoch: 56 \tTraining Loss:  0.203 \tTrain_Accu: 93%  \n",
            "Epoch: 57 \tTraining Loss:  0.161 \tTrain_Accu: 96%  \n",
            "Epoch: 58 \tTraining Loss:  0.176 \tTrain_Accu: 93%  \n",
            "Epoch: 59 \tTraining Loss:  0.215 \tTrain_Accu: 92%  \n",
            "Epoch: 60 \tTraining Loss:  0.175 \tTrain_Accu: 95%  \n",
            "Epoch: 61 \tTraining Loss:  0.173 \tTrain_Accu: 93%  \n",
            "Epoch: 62 \tTraining Loss:  0.186 \tTrain_Accu: 94%  \n",
            "Epoch: 63 \tTraining Loss:  0.188 \tTrain_Accu: 93%  \n",
            "Epoch: 64 \tTraining Loss:  0.171 \tTrain_Accu: 95%  \n",
            "Epoch: 65 \tTraining Loss:  0.180 \tTrain_Accu: 95%  \n",
            "Epoch: 66 \tTraining Loss:  0.155 \tTrain_Accu: 94%  \n",
            "Epoch: 67 \tTraining Loss:  0.153 \tTrain_Accu: 95%  \n",
            "Epoch: 68 \tTraining Loss:  0.150 \tTrain_Accu: 94%  \n",
            "Epoch: 69 \tTraining Loss:  0.103 \tTrain_Accu: 96%  \n",
            "Epoch: 70 \tTraining Loss:  0.141 \tTrain_Accu: 95%  \n",
            "Epoch: 71 \tTraining Loss:  0.123 \tTrain_Accu: 96%  \n",
            "Epoch: 72 \tTraining Loss:  0.111 \tTrain_Accu: 97%  \n",
            "Epoch: 73 \tTraining Loss:  0.141 \tTrain_Accu: 94%  \n",
            "Epoch: 74 \tTraining Loss:  0.134 \tTrain_Accu: 96%  \n",
            "Epoch: 75 \tTraining Loss:  0.172 \tTrain_Accu: 94%  \n",
            "Epoch: 76 \tTraining Loss:  0.098 \tTrain_Accu: 97%  \n",
            "Epoch: 77 \tTraining Loss:  0.143 \tTrain_Accu: 95%  \n",
            "Epoch: 78 \tTraining Loss:  0.112 \tTrain_Accu: 96%  \n",
            "Epoch: 79 \tTraining Loss:  0.109 \tTrain_Accu: 96%  \n",
            "Epoch: 80 \tTraining Loss:  0.090 \tTrain_Accu: 97%  \n",
            "Epoch: 81 \tTraining Loss:  0.083 \tTrain_Accu: 98%  \n",
            "Epoch: 82 \tTraining Loss:  0.142 \tTrain_Accu: 95%  \n",
            "Epoch: 83 \tTraining Loss:  0.099 \tTrain_Accu: 97%  \n",
            "Epoch: 84 \tTraining Loss:  0.120 \tTrain_Accu: 96%  \n",
            "Epoch: 85 \tTraining Loss:  0.145 \tTrain_Accu: 96%  \n",
            "Epoch: 86 \tTraining Loss:  0.095 \tTrain_Accu: 96%  \n",
            "Epoch: 87 \tTraining Loss:  0.104 \tTrain_Accu: 97%  \n",
            "Epoch: 88 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \n",
            "Epoch: 89 \tTraining Loss:  0.089 \tTrain_Accu: 96%  \n",
            "Epoch: 90 \tTraining Loss:  0.125 \tTrain_Accu: 95%  \n",
            "Epoch: 91 \tTraining Loss:  0.100 \tTrain_Accu: 96%  \n",
            "Epoch: 92 \tTraining Loss:  0.071 \tTrain_Accu: 97%  \n",
            "Epoch: 93 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \n",
            "Epoch: 94 \tTraining Loss:  0.109 \tTrain_Accu: 95%  \n",
            "Epoch: 95 \tTraining Loss:  0.089 \tTrain_Accu: 96%  \n",
            "Epoch: 96 \tTraining Loss:  0.093 \tTrain_Accu: 96%  \n",
            "Epoch: 97 \tTraining Loss:  0.066 \tTrain_Accu: 97%  \n",
            "Epoch: 98 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \n",
            "Epoch: 99 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \n",
            "Epoch: 100 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \n",
            "Epoch: 101 \tTraining Loss:  0.069 \tTrain_Accu: 97%  \n",
            "Epoch: 102 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \n",
            "Epoch: 103 \tTraining Loss:  0.082 \tTrain_Accu: 98%  \n",
            "Epoch: 104 \tTraining Loss:  0.104 \tTrain_Accu: 97%  \n",
            "Epoch: 105 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 106 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \n",
            "Epoch: 107 \tTraining Loss:  0.081 \tTrain_Accu: 97%  \n",
            "Epoch: 108 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \n",
            "Epoch: 109 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \n",
            "Epoch: 110 \tTraining Loss:  0.087 \tTrain_Accu: 97%  \n",
            "Epoch: 111 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \n",
            "Epoch: 112 \tTraining Loss:  0.049 \tTrain_Accu: 99%  \n",
            "Epoch: 113 \tTraining Loss:  0.084 \tTrain_Accu: 97%  \n",
            "Epoch: 114 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 115 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \n",
            "Epoch: 116 \tTraining Loss:  0.074 \tTrain_Accu: 97%  \n",
            "Epoch: 117 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \n",
            "Epoch: 118 \tTraining Loss:  0.075 \tTrain_Accu: 97%  \n",
            "Epoch: 119 \tTraining Loss:  0.071 \tTrain_Accu: 97%  \n",
            "Epoch: 120 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 121 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \n",
            "Epoch: 122 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \n",
            "Epoch: 123 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \n",
            "Epoch: 124 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 125 \tTraining Loss:  0.051 \tTrain_Accu: 99%  \n",
            "Epoch: 126 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \n",
            "Epoch: 127 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 128 \tTraining Loss:  0.105 \tTrain_Accu: 97%  \n",
            "Epoch: 129 \tTraining Loss:  0.065 \tTrain_Accu: 97%  \n",
            "Epoch: 130 \tTraining Loss:  0.070 \tTrain_Accu: 97%  \n",
            "Epoch: 131 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \n",
            "Epoch: 132 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \n",
            "Epoch: 133 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 134 \tTraining Loss:  0.066 \tTrain_Accu: 98%  \n",
            "Epoch: 135 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \n",
            "Epoch: 136 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 137 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \n",
            "Epoch: 138 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \n",
            "Epoch: 139 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \n",
            "Epoch: 140 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \n",
            "Epoch: 141 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \n",
            "Epoch: 142 \tTraining Loss:  0.080 \tTrain_Accu: 97%  \n",
            "Epoch: 143 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \n",
            "Epoch: 144 \tTraining Loss:  0.127 \tTrain_Accu: 97%  \n",
            "Epoch: 145 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \n",
            "Epoch: 146 \tTraining Loss:  0.053 \tTrain_Accu: 99%  \n",
            "Epoch: 147 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \n",
            "Epoch: 148 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 149 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \n",
            "Epoch: 150 \tTraining Loss:  0.107 \tTrain_Accu: 98%  \n",
            "Epoch: 151 \tTraining Loss:  0.053 \tTrain_Accu: 99%  \n",
            "Epoch: 152 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \n",
            "Epoch: 153 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \n",
            "Epoch: 154 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \n",
            "Epoch: 155 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \n",
            "Epoch: 156 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 157 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \n",
            "Epoch: 158 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 159 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \n",
            "Epoch: 160 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \n",
            "Epoch: 161 \tTraining Loss:  0.032 \tTrain_Accu: 98%  \n",
            "Epoch: 162 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \n",
            "Epoch: 163 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 164 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 165 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \n",
            "Epoch: 166 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \n",
            "Epoch: 167 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 168 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 169 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \n",
            "Epoch: 170 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \n",
            "Epoch: 171 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 172 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \n",
            "Epoch: 173 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \n",
            "Epoch: 174 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 175 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 176 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 177 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 178 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \n",
            "Epoch: 179 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \n",
            "Epoch: 180 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 181 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \n",
            "Epoch: 182 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \n",
            "Epoch: 183 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 184 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 185 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \n",
            "Epoch: 186 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 187 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \n",
            "Epoch: 188 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \n",
            "Epoch: 189 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 190 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \n",
            "Epoch: 191 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 192 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 193 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \n",
            "Epoch: 194 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \n",
            "Epoch: 195 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \n",
            "Epoch: 196 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \n",
            "Epoch: 197 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 198 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \n",
            "Epoch: 199 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 200 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \n",
            "Epoch: 201 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 202 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 203 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 204 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \n",
            "Epoch: 205 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \n",
            "Epoch: 206 \tTraining Loss:  0.015 \tTrain_Accu: 100%  \n",
            "Epoch: 207 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 208 \tTraining Loss:  0.016 \tTrain_Accu: 100%  \n",
            "Epoch: 209 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 210 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 211 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 212 \tTraining Loss:  0.046 \tTrain_Accu: 99%  \n",
            "Epoch: 213 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \n",
            "Epoch: 214 \tTraining Loss:  0.030 \tTrain_Accu: 98%  \n",
            "Epoch: 215 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \n",
            "Epoch: 216 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \n",
            "Epoch: 217 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \n",
            "Epoch: 218 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 219 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 220 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \n",
            "Epoch: 221 \tTraining Loss:  0.031 \tTrain_Accu: 98%  \n",
            "Epoch: 222 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \n",
            "Epoch: 223 \tTraining Loss:  0.015 \tTrain_Accu: 99%  \n",
            "Epoch: 224 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 225 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \n",
            "Epoch: 226 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 227 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 228 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 229 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \n",
            "Epoch: 230 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 231 \tTraining Loss:  0.051 \tTrain_Accu: 99%  \n",
            "Epoch: 232 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 233 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 234 \tTraining Loss:  0.012 \tTrain_Accu: 99%  \n",
            "Epoch: 235 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \n",
            "Epoch: 236 \tTraining Loss:  0.012 \tTrain_Accu: 99%  \n",
            "Epoch: 237 \tTraining Loss:  0.024 \tTrain_Accu: 98%  \n",
            "Epoch: 238 \tTraining Loss:  0.034 \tTrain_Accu: 98%  \n",
            "Epoch: 239 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \n",
            "Epoch: 240 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 241 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \n",
            "Epoch: 242 \tTraining Loss:  0.008 \tTrain_Accu: 100%  \n",
            "Epoch: 243 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 244 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \n",
            "Epoch: 245 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \n",
            "Epoch: 246 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \n",
            "Epoch: 247 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 248 \tTraining Loss:  0.008 \tTrain_Accu: 100%  \n",
            "Epoch: 249 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 00:17:22,968]\u001b[0m Trial 7 finished with value: 99.2 and parameters: {}. Best is trial 2 with value: 99.5.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./optuna_ESI_drop.torch']"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qynYuu0ENA8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THCBIpPaFp5S"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "HzABseJl0X8B",
        "outputId": "6bd245c7-c5f7-40f4-9014-3440444a0fbd"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_ESI_rain[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop()\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_ESI_RMSprops_indv.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 1, 1, 1, 0, 1, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 0, 1,\n",
            "        0, 0, 0, 0, 2, 4, 1, 1, 2, 2, 2, 2, 0, 2, 0, 3, 0, 0, 0, 0, 2, 2, 0, 0,\n",
            "        0, 2, 2, 2, 2, 0, 4, 4, 2, 2, 0, 2, 1, 2, 0, 2, 0, 0, 4, 3, 3, 1])\n",
            "labels tensor([1, 4, 4, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 3, 1, 2, 0, 0, 0, 0, 2, 1,\n",
            "        2, 0, 2, 1, 2, 0, 1, 2, 4, 3, 3, 1, 3, 4, 4, 4, 4, 3, 4, 3, 0, 0, 1, 4,\n",
            "        4, 4, 4, 4, 0, 0, 0, 1, 4, 4, 4, 1, 1, 1, 3, 2, 2, 1, 2, 2, 3, 3])\n",
            "correct : 17\n",
            "test_Accuracy % : 24.3\n",
            "kappa 0.003350083752093891\n",
            "[[8 4 5 0 2]\n",
            " [3 6 3 0 1]\n",
            " [4 4 2 1 1]\n",
            " [4 2 2 1 0]\n",
            " [6 2 8 1 0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqqdM2DEIp0V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwC3C5u3yp9Q"
      },
      "source": [
        "## WNI_rain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VFE_4Meryp9R",
        "outputId": "2694ce28-7f23-4b16-9372-e677b7176341"
      },
      "source": [
        "# Reading rainfall file of ESI region \n",
        "Data_Rain_WNI = pd.read_csv(\"drive/My Drive/DL_project/Target_Rain_WNI_regional_ave_time_series.csv\")\n",
        "Data_Rain_WNI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>Rain_bc</th>\n",
              "      <th>cat_3</th>\n",
              "      <th>cat_5</th>\n",
              "      <th>anomalies</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-04-01</td>\n",
              "      <td>294.134750</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-24.330236</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-05-01</td>\n",
              "      <td>332.026667</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-23.756928</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-06-01</td>\n",
              "      <td>461.024500</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>46.977206</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-07-01</td>\n",
              "      <td>550.865250</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>90.264794</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-08-01</td>\n",
              "      <td>575.374250</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>102.447406</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>2019-08-01</td>\n",
              "      <td>442.008667</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-30.918178</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>476.844000</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>15.506572</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>2019-10-01</td>\n",
              "      <td>403.274333</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-60.727456</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>357.037750</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-87.472006</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>389.841333</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-46.964603</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>465 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           time     Rain_bc  cat_3  cat_5   anomalies region\n",
              "0    1981-04-01  294.134750      2      3  -24.330236    WNI\n",
              "1    1981-05-01  332.026667      2      3  -23.756928    WNI\n",
              "2    1981-06-01  461.024500      3      5   46.977206    WNI\n",
              "3    1981-07-01  550.865250      3      5   90.264794    WNI\n",
              "4    1981-08-01  575.374250      3      5  102.447406    WNI\n",
              "..          ...         ...    ...    ...         ...    ...\n",
              "460  2019-08-01  442.008667      2      2  -30.918178    WNI\n",
              "461  2019-09-01  476.844000      2      3   15.506572    WNI\n",
              "462  2019-10-01  403.274333      1      2  -60.727456    WNI\n",
              "463  2019-11-01  357.037750      1      1  -87.472006    WNI\n",
              "464  2019-12-01  389.841333      1      2  -46.964603    WNI\n",
              "\n",
              "[465 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbEnNSg9JwCL"
      },
      "source": [
        "# Extracting quantiles from the ESI dataset\n",
        "labels_Rain_WNI = Data_Rain_WNI['cat_5'].astype(int) #cat5 column - so 5 prediction classes "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDU1ZjXxJv-v"
      },
      "source": [
        "# Function that will convert labels into Pytorch tensors\n",
        "\n",
        "def labels_Tensors(labels):\n",
        "    return (torch.from_numpy(labels.values).type(torch.LongTensor)-1) #cat5 in form 1, 2, 3, 4, 5;\n",
        "\n",
        "# Converting labels of rainfall_WNI region into tensors\n",
        "labelsTensors_WNI_rain = labels_Tensors(labels_Rain_WNI) # This represents y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afdC801hJ7Gs",
        "outputId": "53d9334b-a738-483d-8be6-b4fca1e84431"
      },
      "source": [
        "# Training data lables distribution\n",
        "Train_labels = labels_Rain_WNI[:324]\n",
        "Train_labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    67\n",
              "5    65\n",
              "4    65\n",
              "2    65\n",
              "3    62\n",
              "Name: cat_5, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7dfUalzLIAF"
      },
      "source": [
        "### Training \n",
        "\n",
        "Training the network with the training and validation dataset in Optuna frame work with RMSprop optimizer, batch size 10 and learning rate 0.0001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T6sQTnkLPEh"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_valid_loaders_WNI(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_WNI_rain[:325])\n",
        "    validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_WNI_rain[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "  \n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7xJoUa0nZPG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aANkOSN9nZyf"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_Rain_WNI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           #'dropout'       : 0.7,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_WNI(cfg['Batch_size'])\n",
        "  model = Network_drop().to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_WNI_rain[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_WNI_rain[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 10\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_WNI_rain[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_WNI_rain[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_WNI_RMSprops_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QphVNnHdLuDt",
        "outputId": "1c4edbdd-c3e7-4622-b0e9-aff39c2780b1"
      },
      "source": [
        "study = optuna.create_study(sampler=optuna.samplers.TPESampler(), direction='maximize')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-06-15 01:01:28,935]\u001b[0m A new study created in memory with name: no-name-6791f3d4-abd7-433a-a951-1b1c4674c130\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH857BmfMKd-",
        "outputId": "2cc0b1d9-88bf-40f1-e7a8-6187f26c29a9"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_Rain_WNI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"drive/MyDrive/DL_project/optimise_valid_ESI.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.704 \tTrain_Accu: 18%  \tValid_Acc:21%  \tVal_kappa : 0.030  \n",
            "Epoch: 2 \tTraining Loss:  1.611 \tTrain_Accu: 23%  \tValid_Acc:14%  \tVal_kappa : -0.040  \n",
            "Epoch: 3 \tTraining Loss:  1.597 \tTrain_Accu: 25%  \tValid_Acc:20%  \tVal_kappa : 0.045  \n",
            "Epoch: 4 \tTraining Loss:  1.587 \tTrain_Accu: 25%  \tValid_Acc:21%  \tVal_kappa : 0.022  \n",
            "Epoch: 5 \tTraining Loss:  1.563 \tTrain_Accu: 29%  \tValid_Acc:20%  \tVal_kappa : 0.031  \n",
            "Epoch: 6 \tTraining Loss:  1.552 \tTrain_Accu: 33%  \tValid_Acc:23%  \tVal_kappa : -0.019  \n",
            "Epoch: 7 \tTraining Loss:  1.558 \tTrain_Accu: 31%  \tValid_Acc:17%  \tVal_kappa : 0.059  \n",
            "Epoch: 8 \tTraining Loss:  1.522 \tTrain_Accu: 33%  \tValid_Acc:29%  \tVal_kappa : 0.207  \n",
            "Epoch: 9 \tTraining Loss:  1.492 \tTrain_Accu: 40%  \tValid_Acc:21%  \tVal_kappa : -0.120  \n",
            "Epoch: 10 \tTraining Loss:  1.471 \tTrain_Accu: 36%  \tValid_Acc:21%  \tVal_kappa : 0.051  \n",
            "Epoch: 11 \tTraining Loss:  1.405 \tTrain_Accu: 42%  \tValid_Acc:23%  \tVal_kappa : 0.175  \n",
            "Epoch: 12 \tTraining Loss:  1.384 \tTrain_Accu: 42%  \tValid_Acc:19%  \tVal_kappa : 0.074  \n",
            "Epoch: 13 \tTraining Loss:  1.329 \tTrain_Accu: 47%  \tValid_Acc:23%  \tVal_kappa : 0.142  \n",
            "Epoch: 14 \tTraining Loss:  1.284 \tTrain_Accu: 48%  \tValid_Acc:33%  \tVal_kappa : 0.313  \n",
            "Epoch: 15 \tTraining Loss:  1.220 \tTrain_Accu: 52%  \tValid_Acc:19%  \tVal_kappa : -0.082  \n",
            "Epoch: 16 \tTraining Loss:  1.245 \tTrain_Accu: 50%  \tValid_Acc:30%  \tVal_kappa : 0.204  \n",
            "Epoch: 17 \tTraining Loss:  1.152 \tTrain_Accu: 51%  \tValid_Acc:23%  \tVal_kappa : 0.073  \n",
            "Epoch: 18 \tTraining Loss:  1.090 \tTrain_Accu: 58%  \tValid_Acc:11%  \tVal_kappa : 0.118  \n",
            "Epoch: 19 \tTraining Loss:  1.113 \tTrain_Accu: 54%  \tValid_Acc:21%  \tVal_kappa : 0.074  \n",
            "Epoch: 20 \tTraining Loss:  0.993 \tTrain_Accu: 60%  \tValid_Acc:21%  \tVal_kappa : -0.057  \n",
            "Epoch: 21 \tTraining Loss:  1.053 \tTrain_Accu: 56%  \tValid_Acc:19%  \tVal_kappa : -0.003  \n",
            "Epoch: 22 \tTraining Loss:  0.920 \tTrain_Accu: 66%  \tValid_Acc:16%  \tVal_kappa : 0.026  \n",
            "Epoch: 23 \tTraining Loss:  0.853 \tTrain_Accu: 68%  \tValid_Acc:23%  \tVal_kappa : -0.025  \n",
            "Epoch: 24 \tTraining Loss:  0.836 \tTrain_Accu: 70%  \tValid_Acc:27%  \tVal_kappa : -0.007  \n",
            "Epoch: 25 \tTraining Loss:  0.795 \tTrain_Accu: 69%  \tValid_Acc:23%  \tVal_kappa : 0.172  \n",
            "Epoch: 26 \tTraining Loss:  0.793 \tTrain_Accu: 72%  \tValid_Acc:20%  \tVal_kappa : 0.110  \n",
            "Epoch: 27 \tTraining Loss:  0.721 \tTrain_Accu: 74%  \tValid_Acc:24%  \tVal_kappa : 0.117  \n",
            "Epoch: 28 \tTraining Loss:  0.779 \tTrain_Accu: 71%  \tValid_Acc:23%  \tVal_kappa : -0.078  \n",
            "Epoch: 29 \tTraining Loss:  0.652 \tTrain_Accu: 75%  \tValid_Acc:23%  \tVal_kappa : 0.054  \n",
            "Epoch: 30 \tTraining Loss:  0.617 \tTrain_Accu: 76%  \tValid_Acc:16%  \tVal_kappa : -0.007  \n",
            "Epoch: 31 \tTraining Loss:  0.635 \tTrain_Accu: 77%  \tValid_Acc:21%  \tVal_kappa : -0.033  \n",
            "Epoch: 32 \tTraining Loss:  0.596 \tTrain_Accu: 77%  \tValid_Acc:21%  \tVal_kappa : 0.030  \n",
            "Epoch: 33 \tTraining Loss:  0.554 \tTrain_Accu: 81%  \tValid_Acc:19%  \tVal_kappa : 0.049  \n",
            "Epoch: 34 \tTraining Loss:  0.539 \tTrain_Accu: 76%  \tValid_Acc:19%  \tVal_kappa : 0.034  \n",
            "Epoch: 35 \tTraining Loss:  0.556 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : 0.005  \n",
            "Epoch: 36 \tTraining Loss:  0.455 \tTrain_Accu: 84%  \tValid_Acc:21%  \tVal_kappa : 0.026  \n",
            "Epoch: 37 \tTraining Loss:  0.493 \tTrain_Accu: 82%  \tValid_Acc:19%  \tVal_kappa : 0.057  \n",
            "Epoch: 38 \tTraining Loss:  0.496 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : 0.080  \n",
            "Epoch: 39 \tTraining Loss:  0.428 \tTrain_Accu: 86%  \tValid_Acc:24%  \tVal_kappa : 0.104  \n",
            "Epoch: 40 \tTraining Loss:  0.399 \tTrain_Accu: 86%  \tValid_Acc:30%  \tVal_kappa : 0.233  \n",
            "Epoch: 41 \tTraining Loss:  0.442 \tTrain_Accu: 83%  \tValid_Acc:20%  \tVal_kappa : 0.083  \n",
            "Epoch: 42 \tTraining Loss:  0.394 \tTrain_Accu: 86%  \tValid_Acc:19%  \tVal_kappa : -0.104  \n",
            "Epoch: 43 \tTraining Loss:  0.327 \tTrain_Accu: 88%  \tValid_Acc:16%  \tVal_kappa : -0.035  \n",
            "Epoch: 44 \tTraining Loss:  0.343 \tTrain_Accu: 89%  \tValid_Acc:26%  \tVal_kappa : 0.053  \n",
            "Epoch: 45 \tTraining Loss:  0.320 \tTrain_Accu: 89%  \tValid_Acc:21%  \tVal_kappa : 0.029  \n",
            "Epoch: 46 \tTraining Loss:  0.303 \tTrain_Accu: 90%  \tValid_Acc:17%  \tVal_kappa : -0.028  \n",
            "Epoch: 47 \tTraining Loss:  0.329 \tTrain_Accu: 88%  \tValid_Acc:21%  \tVal_kappa : 0.002  \n",
            "Epoch: 48 \tTraining Loss:  0.293 \tTrain_Accu: 90%  \tValid_Acc:23%  \tVal_kappa : 0.164  \n",
            "Epoch: 49 \tTraining Loss:  0.309 \tTrain_Accu: 88%  \tValid_Acc:26%  \tVal_kappa : 0.151  \n",
            "Epoch: 50 \tTraining Loss:  0.290 \tTrain_Accu: 91%  \tValid_Acc:23%  \tVal_kappa : 0.251  \n",
            "Epoch: 51 \tTraining Loss:  0.289 \tTrain_Accu: 89%  \tValid_Acc:23%  \tVal_kappa : 0.120  \n",
            "Epoch: 52 \tTraining Loss:  0.311 \tTrain_Accu: 89%  \tValid_Acc:21%  \tVal_kappa : 0.107  \n",
            "Epoch: 53 \tTraining Loss:  0.280 \tTrain_Accu: 89%  \tValid_Acc:20%  \tVal_kappa : -0.079  \n",
            "Epoch: 54 \tTraining Loss:  0.288 \tTrain_Accu: 88%  \tValid_Acc:17%  \tVal_kappa : 0.148  \n",
            "Epoch: 55 \tTraining Loss:  0.219 \tTrain_Accu: 94%  \tValid_Acc:24%  \tVal_kappa : 0.083  \n",
            "Epoch: 56 \tTraining Loss:  0.264 \tTrain_Accu: 90%  \tValid_Acc:17%  \tVal_kappa : -0.059  \n",
            "Epoch: 57 \tTraining Loss:  0.316 \tTrain_Accu: 89%  \tValid_Acc:23%  \tVal_kappa : 0.067  \n",
            "Epoch: 58 \tTraining Loss:  0.222 \tTrain_Accu: 93%  \tValid_Acc:17%  \tVal_kappa : -0.055  \n",
            "Epoch: 59 \tTraining Loss:  0.251 \tTrain_Accu: 90%  \tValid_Acc:29%  \tVal_kappa : 0.349  \n",
            "Epoch: 60 \tTraining Loss:  0.295 \tTrain_Accu: 90%  \tValid_Acc:21%  \tVal_kappa : 0.038  \n",
            "Epoch: 61 \tTraining Loss:  0.194 \tTrain_Accu: 94%  \tValid_Acc:24%  \tVal_kappa : 0.059  \n",
            "Epoch: 62 \tTraining Loss:  0.293 \tTrain_Accu: 90%  \tValid_Acc:27%  \tVal_kappa : 0.156  \n",
            "Epoch: 63 \tTraining Loss:  0.201 \tTrain_Accu: 94%  \tValid_Acc:21%  \tVal_kappa : 0.020  \n",
            "Epoch: 64 \tTraining Loss:  0.185 \tTrain_Accu: 93%  \tValid_Acc:16%  \tVal_kappa : -0.065  \n",
            "Epoch: 65 \tTraining Loss:  0.189 \tTrain_Accu: 92%  \tValid_Acc:23%  \tVal_kappa : 0.001  \n",
            "Epoch: 66 \tTraining Loss:  0.191 \tTrain_Accu: 94%  \tValid_Acc:20%  \tVal_kappa : -0.097  \n",
            "Epoch: 67 \tTraining Loss:  0.137 \tTrain_Accu: 95%  \tValid_Acc:21%  \tVal_kappa : 0.148  \n",
            "Epoch: 68 \tTraining Loss:  0.154 \tTrain_Accu: 95%  \tValid_Acc:26%  \tVal_kappa : 0.182  \n",
            "Epoch: 69 \tTraining Loss:  0.179 \tTrain_Accu: 92%  \tValid_Acc:21%  \tVal_kappa : 0.088  \n",
            "Epoch: 70 \tTraining Loss:  0.157 \tTrain_Accu: 94%  \tValid_Acc:19%  \tVal_kappa : -0.126  \n",
            "Epoch: 71 \tTraining Loss:  0.109 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.021  \n",
            "Epoch: 72 \tTraining Loss:  0.186 \tTrain_Accu: 93%  \tValid_Acc:24%  \tVal_kappa : -0.036  \n",
            "Epoch: 73 \tTraining Loss:  0.195 \tTrain_Accu: 93%  \tValid_Acc:20%  \tVal_kappa : 0.069  \n",
            "Epoch: 74 \tTraining Loss:  0.208 \tTrain_Accu: 94%  \tValid_Acc:23%  \tVal_kappa : 0.107  \n",
            "Epoch: 75 \tTraining Loss:  0.174 \tTrain_Accu: 94%  \tValid_Acc:23%  \tVal_kappa : 0.162  \n",
            "Epoch: 76 \tTraining Loss:  0.169 \tTrain_Accu: 93%  \tValid_Acc:24%  \tVal_kappa : 0.094  \n",
            "Epoch: 77 \tTraining Loss:  0.128 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : 0.052  \n",
            "Epoch: 78 \tTraining Loss:  0.139 \tTrain_Accu: 96%  \tValid_Acc:24%  \tVal_kappa : 0.271  \n",
            "Epoch: 79 \tTraining Loss:  0.143 \tTrain_Accu: 94%  \tValid_Acc:17%  \tVal_kappa : 0.059  \n",
            "Epoch: 80 \tTraining Loss:  0.160 \tTrain_Accu: 94%  \tValid_Acc:29%  \tVal_kappa : 0.089  \n",
            "Epoch: 81 \tTraining Loss:  0.099 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.102  \n",
            "Epoch: 82 \tTraining Loss:  0.159 \tTrain_Accu: 94%  \tValid_Acc:23%  \tVal_kappa : 0.345  \n",
            "Epoch: 83 \tTraining Loss:  0.111 \tTrain_Accu: 95%  \tValid_Acc:27%  \tVal_kappa : 0.256  \n",
            "Epoch: 84 \tTraining Loss:  0.158 \tTrain_Accu: 95%  \tValid_Acc:20%  \tVal_kappa : 0.167  \n",
            "Epoch: 85 \tTraining Loss:  0.142 \tTrain_Accu: 95%  \tValid_Acc:21%  \tVal_kappa : -0.091  \n",
            "Epoch: 86 \tTraining Loss:  0.127 \tTrain_Accu: 95%  \tValid_Acc:24%  \tVal_kappa : 0.120  \n",
            "Epoch: 87 \tTraining Loss:  0.111 \tTrain_Accu: 96%  \tValid_Acc:26%  \tVal_kappa : 0.064  \n",
            "Epoch: 88 \tTraining Loss:  0.147 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : 0.176  \n",
            "Epoch: 89 \tTraining Loss:  0.140 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : 0.091  \n",
            "Epoch: 90 \tTraining Loss:  0.098 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : 0.080  \n",
            "Epoch: 91 \tTraining Loss:  0.113 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : 0.067  \n",
            "Epoch: 92 \tTraining Loss:  0.102 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.059  \n",
            "Epoch: 93 \tTraining Loss:  0.152 \tTrain_Accu: 94%  \tValid_Acc:26%  \tVal_kappa : 0.064  \n",
            "Epoch: 94 \tTraining Loss:  0.151 \tTrain_Accu: 95%  \tValid_Acc:14%  \tVal_kappa : -0.014  \n",
            "Epoch: 95 \tTraining Loss:  0.135 \tTrain_Accu: 94%  \tValid_Acc:24%  \tVal_kappa : 0.143  \n",
            "Epoch: 96 \tTraining Loss:  0.103 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.084  \n",
            "Epoch: 97 \tTraining Loss:  0.073 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.065  \n",
            "Epoch: 98 \tTraining Loss:  0.119 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.050  \n",
            "Epoch: 99 \tTraining Loss:  0.118 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : -0.116  \n",
            "Epoch: 100 \tTraining Loss:  0.149 \tTrain_Accu: 94%  \tValid_Acc:27%  \tVal_kappa : 0.025  \n",
            "Epoch: 101 \tTraining Loss:  0.100 \tTrain_Accu: 96%  \tValid_Acc:27%  \tVal_kappa : 0.118  \n",
            "Epoch: 102 \tTraining Loss:  0.101 \tTrain_Accu: 95%  \tValid_Acc:21%  \tVal_kappa : 0.004  \n",
            "Epoch: 103 \tTraining Loss:  0.081 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.078  \n",
            "Epoch: 104 \tTraining Loss:  0.084 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.054  \n",
            "Epoch: 105 \tTraining Loss:  0.083 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : -0.011  \n",
            "Epoch: 106 \tTraining Loss:  0.109 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : 0.107  \n",
            "Epoch: 107 \tTraining Loss:  0.108 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : 0.168  \n",
            "Epoch: 108 \tTraining Loss:  0.133 \tTrain_Accu: 95%  \tValid_Acc:26%  \tVal_kappa : 0.102  \n",
            "Epoch: 109 \tTraining Loss:  0.091 \tTrain_Accu: 96%  \tValid_Acc:16%  \tVal_kappa : 0.106  \n",
            "Epoch: 110 \tTraining Loss:  0.127 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : 0.009  \n",
            "Epoch: 111 \tTraining Loss:  0.100 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.145  \n",
            "Epoch: 112 \tTraining Loss:  0.087 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.141  \n",
            "Epoch: 113 \tTraining Loss:  0.067 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : 0.085  \n",
            "Epoch: 114 \tTraining Loss:  0.107 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : 0.047  \n",
            "Epoch: 115 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.030  \n",
            "Epoch: 116 \tTraining Loss:  0.074 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.088  \n",
            "Epoch: 117 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.031  \n",
            "Epoch: 118 \tTraining Loss:  0.093 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.081  \n",
            "Epoch: 119 \tTraining Loss:  0.088 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : 0.078  \n",
            "Epoch: 120 \tTraining Loss:  0.083 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : 0.070  \n",
            "Epoch: 121 \tTraining Loss:  0.088 \tTrain_Accu: 96%  \tValid_Acc:19%  \tVal_kappa : 0.113  \n",
            "Epoch: 122 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : 0.044  \n",
            "Epoch: 123 \tTraining Loss:  0.112 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : 0.050  \n",
            "Epoch: 124 \tTraining Loss:  0.102 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : 0.008  \n",
            "Epoch: 125 \tTraining Loss:  0.115 \tTrain_Accu: 95%  \tValid_Acc:26%  \tVal_kappa : 0.200  \n",
            "Epoch: 126 \tTraining Loss:  0.072 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.115  \n",
            "Epoch: 127 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.011  \n",
            "Epoch: 128 \tTraining Loss:  0.081 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.187  \n",
            "Epoch: 129 \tTraining Loss:  0.075 \tTrain_Accu: 97%  \tValid_Acc:31%  \tVal_kappa : 0.323  \n",
            "Epoch: 130 \tTraining Loss:  0.084 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : 0.129  \n",
            "Epoch: 131 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.007  \n",
            "Epoch: 132 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.056  \n",
            "Epoch: 133 \tTraining Loss:  0.067 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.096  \n",
            "Epoch: 134 \tTraining Loss:  0.112 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : 0.039  \n",
            "Epoch: 135 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.136  \n",
            "Epoch: 136 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.130  \n",
            "Epoch: 137 \tTraining Loss:  0.084 \tTrain_Accu: 96%  \tValid_Acc:26%  \tVal_kappa : 0.092  \n",
            "Epoch: 138 \tTraining Loss:  0.081 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.016  \n",
            "Epoch: 139 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.058  \n",
            "Epoch: 140 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \tValid_Acc:29%  \tVal_kappa : 0.161  \n",
            "Epoch: 141 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.035  \n",
            "Epoch: 142 \tTraining Loss:  0.055 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.064  \n",
            "Epoch: 143 \tTraining Loss:  0.106 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.173  \n",
            "Epoch: 144 \tTraining Loss:  0.071 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.186  \n",
            "Epoch: 145 \tTraining Loss:  0.074 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : -0.012  \n",
            "Epoch: 146 \tTraining Loss:  0.107 \tTrain_Accu: 96%  \tValid_Acc:29%  \tVal_kappa : 0.190  \n",
            "Epoch: 147 \tTraining Loss:  0.022 \tTrain_Accu: 100%  \tValid_Acc:24%  \tVal_kappa : 0.054  \n",
            "Epoch: 148 \tTraining Loss:  0.113 \tTrain_Accu: 97%  \tValid_Acc:26%  \tVal_kappa : 0.127  \n",
            "Epoch: 149 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.115  \n",
            "Epoch: 150 \tTraining Loss:  0.046 \tTrain_Accu: 99%  \tValid_Acc:27%  \tVal_kappa : 0.044  \n",
            "Epoch: 151 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:29%  \tVal_kappa : 0.167  \n",
            "Epoch: 152 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.096  \n",
            "Epoch: 153 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.038  \n",
            "Epoch: 154 \tTraining Loss:  0.074 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : 0.111  \n",
            "Epoch: 155 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.092  \n",
            "Epoch: 156 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.172  \n",
            "Epoch: 157 \tTraining Loss:  0.077 \tTrain_Accu: 96%  \tValid_Acc:23%  \tVal_kappa : 0.140  \n",
            "Epoch: 158 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \tValid_Acc:31%  \tVal_kappa : 0.256  \n",
            "Epoch: 159 \tTraining Loss:  0.096 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : 0.166  \n",
            "Epoch: 160 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \tValid_Acc:30%  \tVal_kappa : 0.173  \n",
            "Epoch: 161 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.141  \n",
            "Epoch: 162 \tTraining Loss:  0.071 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.246  \n",
            "Epoch: 163 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.064  \n",
            "Epoch: 164 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \tValid_Acc:29%  \tVal_kappa : 0.212  \n",
            "Epoch: 165 \tTraining Loss:  0.113 \tTrain_Accu: 96%  \tValid_Acc:21%  \tVal_kappa : -0.037  \n",
            "Epoch: 166 \tTraining Loss:  0.067 \tTrain_Accu: 97%  \tValid_Acc:23%  \tVal_kappa : -0.042  \n",
            "Epoch: 167 \tTraining Loss:  0.043 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : 0.066  \n",
            "Epoch: 168 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.026  \n",
            "Epoch: 169 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.043  \n",
            "Epoch: 170 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:27%  \tVal_kappa : 0.047  \n",
            "Epoch: 171 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : 0.036  \n",
            "Epoch: 172 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.071  \n",
            "Epoch: 173 \tTraining Loss:  0.084 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : 0.117  \n",
            "Epoch: 174 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.158  \n",
            "Epoch: 175 \tTraining Loss:  0.062 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : -0.051  \n",
            "Epoch: 176 \tTraining Loss:  0.090 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.081  \n",
            "Epoch: 177 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.087  \n",
            "Epoch: 178 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:27%  \tVal_kappa : 0.132  \n",
            "Epoch: 179 \tTraining Loss:  0.076 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.027  \n",
            "Epoch: 180 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.064  \n",
            "Epoch: 181 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.192  \n",
            "Epoch: 182 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.067  \n",
            "Epoch: 183 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \tValid_Acc:24%  \tVal_kappa : 0.130  \n",
            "Epoch: 184 \tTraining Loss:  0.071 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.268  \n",
            "Epoch: 185 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.107  \n",
            "Epoch: 186 \tTraining Loss:  0.052 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.071  \n",
            "Epoch: 187 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.096  \n",
            "Epoch: 188 \tTraining Loss:  0.068 \tTrain_Accu: 97%  \tValid_Acc:26%  \tVal_kappa : 0.210  \n",
            "Epoch: 189 \tTraining Loss:  0.032 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.026  \n",
            "Epoch: 190 \tTraining Loss:  0.080 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.003  \n",
            "Epoch: 191 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.084  \n",
            "Epoch: 192 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.064  \n",
            "Epoch: 193 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.057  \n",
            "Epoch: 194 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.150  \n",
            "Epoch: 195 \tTraining Loss:  0.100 \tTrain_Accu: 96%  \tValid_Acc:26%  \tVal_kappa : 0.101  \n",
            "Epoch: 196 \tTraining Loss:  0.074 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : -0.048  \n",
            "Epoch: 197 \tTraining Loss:  0.043 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.141  \n",
            "Epoch: 198 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.089  \n",
            "Epoch: 199 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.225  \n",
            "Epoch: 200 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.035  \n",
            "Epoch: 201 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:29%  \tVal_kappa : 0.185  \n",
            "Epoch: 202 \tTraining Loss:  0.029 \tTrain_Accu: 100%  \tValid_Acc:19%  \tVal_kappa : -0.006  \n",
            "Epoch: 203 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.035  \n",
            "Epoch: 204 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : -0.071  \n",
            "Epoch: 205 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.064  \n",
            "Epoch: 206 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.031  \n",
            "Epoch: 207 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : -0.002  \n",
            "Epoch: 208 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.045  \n",
            "Epoch: 209 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.143  \n",
            "Epoch: 210 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \tValid_Acc:31%  \tVal_kappa : 0.264  \n",
            "Epoch: 211 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.089  \n",
            "Epoch: 212 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.039  \n",
            "Epoch: 213 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.005  \n",
            "Epoch: 214 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.028  \n",
            "Epoch: 215 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.006  \n",
            "Epoch: 216 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.027  \n",
            "Epoch: 217 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.086  \n",
            "Epoch: 218 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.085  \n",
            "Epoch: 219 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.106  \n",
            "Epoch: 220 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.131  \n",
            "Epoch: 221 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.101  \n",
            "Epoch: 222 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.038  \n",
            "Epoch: 223 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.068  \n",
            "Epoch: 224 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.070  \n",
            "Epoch: 225 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : 0.049  \n",
            "Epoch: 226 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.115  \n",
            "Epoch: 227 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : 0.041  \n",
            "Epoch: 228 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.038  \n",
            "Epoch: 229 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : 0.111  \n",
            "Epoch: 230 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.034  \n",
            "Epoch: 231 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.001  \n",
            "Epoch: 232 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : 0.037  \n",
            "Epoch: 233 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.113  \n",
            "Epoch: 234 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.007  \n",
            "Epoch: 235 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.139  \n",
            "Epoch: 236 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : 0.009  \n",
            "Epoch: 237 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.030  \n",
            "Epoch: 238 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.027  \n",
            "Epoch: 239 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \tValid_Acc:27%  \tVal_kappa : 0.116  \n",
            "Epoch: 240 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.031  \n",
            "Epoch: 241 \tTraining Loss:  0.031 \tTrain_Accu: 98%  \tValid_Acc:27%  \tVal_kappa : 0.062  \n",
            "Epoch: 242 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.042  \n",
            "Epoch: 243 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.112  \n",
            "Epoch: 244 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \tValid_Acc:27%  \tVal_kappa : 0.079  \n",
            "Epoch: 245 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : 0.110  \n",
            "Epoch: 246 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.011  \n",
            "Epoch: 247 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \tValid_Acc:27%  \tVal_kappa : 0.150  \n",
            "Epoch: 248 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.003  \n",
            "Epoch: 249 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : 0.121  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 00:54:08,740]\u001b[0m Trial 8 finished with value: 25.7 and parameters: {}. Best is trial 2 with value: 99.5.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.166  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/DL_project/optimise_valid_ESI.torch']"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_c4d8q0MlaI"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "fPHpPgvI9c8H",
        "outputId": "506d5ece-45d2-49e4-ca90-6b07ba9585d5"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_WNI_rain[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop()\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_WNI_RMSprops_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 4, 2, 2, 2, 3, 3, 2, 4, 2, 4, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 0, 0,\n",
            "        0, 0, 0, 4, 4, 4, 4, 1, 1, 1, 3, 2, 2, 1, 3, 1, 1, 2, 2, 0, 1, 0, 3, 3,\n",
            "        4, 2, 2, 2, 3, 2, 3, 3, 1, 0, 0, 2, 1, 3, 4, 0, 1, 3, 2, 2, 4, 4])\n",
            "labels tensor([0, 1, 3, 4, 0, 1, 1, 1, 2, 1, 0, 0, 0, 4, 4, 4, 4, 4, 2, 1, 0, 0, 0, 0,\n",
            "        2, 0, 3, 4, 4, 2, 3, 1, 4, 2, 3, 2, 3, 4, 4, 4, 1, 2, 4, 4, 1, 0, 0, 2,\n",
            "        4, 4, 4, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1, 2, 1, 0, 1])\n",
            "correct : 21\n",
            "test_Accuracy % : 30.0\n",
            "kappa 0.2044658055472114\n",
            "[[7 2 6 2 2]\n",
            " [2 4 3 5 2]\n",
            " [1 1 5 2 2]\n",
            " [1 0 1 2 2]\n",
            " [1 3 9 2 3]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv9cvGqF9a85"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hdvjFGnFtuH"
      },
      "source": [
        "### Training (no validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygKPMgVDFxLx"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_loaders_WNI(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:395], labelsTensors_WNI_rain[:395])\n",
        "    #validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_NSI_rain[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    #valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "   \n",
        "\n",
        "    return train_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_BlnsAeG__w"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_WNI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "          'save_model' : True,\n",
        "          'lr'       :  0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "          'dropout'       : 0.5,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader = get_loaders_WNI(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "\n",
        "  train_accuracy = []\n",
        "  #valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  #valid_losses = []\n",
        "  \n",
        "  \n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "      #  valid_loss = 0\n",
        "      #  valid_correct = 0\n",
        "       train_acc = 0\n",
        "       #valid_acc = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "      #  with torch.no_grad(): \n",
        "      #     for batch_i, (data, target) in enumerate(valid_loader): \n",
        "      #         data, target = data.to(device), target.to(device)         \n",
        "      #         output = model(data)\n",
        "      #         output_c = output.cpu()\n",
        "      #         target_c = target.cpu()\n",
        "      #         loss = criterion(output_c, target_c) \n",
        "      #         valid_loss += loss.item()\n",
        "      #         valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "      #         valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "      #  valid_loss = valid_loss/len(valid_loader)\n",
        "      #  valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       #valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       #valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  '.format(epoch, train_loss, train_acc))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              #'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              #'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_WNI_RMSprops_indv_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(train_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj08EAPbIYjb",
        "outputId": "ab968bbd-70ce-49bd-d54f-acd732b18d7d"
      },
      "source": [
        "import joblib\n",
        "\n",
        "study.optimize(train_WNI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"./optuna_WNI_drop.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.645 \tTrain_Accu: 18%  \n",
            "Epoch: 2 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \n",
            "Epoch: 3 \tTraining Loss:  1.596 \tTrain_Accu: 23%  \n",
            "Epoch: 4 \tTraining Loss:  1.597 \tTrain_Accu: 23%  \n",
            "Epoch: 5 \tTraining Loss:  1.571 \tTrain_Accu: 28%  \n",
            "Epoch: 6 \tTraining Loss:  1.547 \tTrain_Accu: 30%  \n",
            "Epoch: 7 \tTraining Loss:  1.541 \tTrain_Accu: 33%  \n",
            "Epoch: 8 \tTraining Loss:  1.506 \tTrain_Accu: 35%  \n",
            "Epoch: 9 \tTraining Loss:  1.479 \tTrain_Accu: 36%  \n",
            "Epoch: 10 \tTraining Loss:  1.420 \tTrain_Accu: 39%  \n",
            "Epoch: 11 \tTraining Loss:  1.402 \tTrain_Accu: 43%  \n",
            "Epoch: 12 \tTraining Loss:  1.355 \tTrain_Accu: 48%  \n",
            "Epoch: 13 \tTraining Loss:  1.333 \tTrain_Accu: 43%  \n",
            "Epoch: 14 \tTraining Loss:  1.235 \tTrain_Accu: 51%  \n",
            "Epoch: 15 \tTraining Loss:  1.271 \tTrain_Accu: 48%  \n",
            "Epoch: 16 \tTraining Loss:  1.181 \tTrain_Accu: 52%  \n",
            "Epoch: 17 \tTraining Loss:  1.182 \tTrain_Accu: 53%  \n",
            "Epoch: 18 \tTraining Loss:  1.072 \tTrain_Accu: 59%  \n",
            "Epoch: 19 \tTraining Loss:  1.003 \tTrain_Accu: 64%  \n",
            "Epoch: 20 \tTraining Loss:  1.017 \tTrain_Accu: 61%  \n",
            "Epoch: 21 \tTraining Loss:  1.010 \tTrain_Accu: 60%  \n",
            "Epoch: 22 \tTraining Loss:  0.935 \tTrain_Accu: 65%  \n",
            "Epoch: 23 \tTraining Loss:  0.833 \tTrain_Accu: 70%  \n",
            "Epoch: 24 \tTraining Loss:  0.854 \tTrain_Accu: 68%  \n",
            "Epoch: 25 \tTraining Loss:  0.827 \tTrain_Accu: 70%  \n",
            "Epoch: 26 \tTraining Loss:  0.774 \tTrain_Accu: 69%  \n",
            "Epoch: 27 \tTraining Loss:  0.769 \tTrain_Accu: 72%  \n",
            "Epoch: 28 \tTraining Loss:  0.751 \tTrain_Accu: 74%  \n",
            "Epoch: 29 \tTraining Loss:  0.670 \tTrain_Accu: 76%  \n",
            "Epoch: 30 \tTraining Loss:  0.579 \tTrain_Accu: 78%  \n",
            "Epoch: 31 \tTraining Loss:  0.638 \tTrain_Accu: 76%  \n",
            "Epoch: 32 \tTraining Loss:  0.563 \tTrain_Accu: 82%  \n",
            "Epoch: 33 \tTraining Loss:  0.569 \tTrain_Accu: 78%  \n",
            "Epoch: 34 \tTraining Loss:  0.499 \tTrain_Accu: 82%  \n",
            "Epoch: 35 \tTraining Loss:  0.514 \tTrain_Accu: 82%  \n",
            "Epoch: 36 \tTraining Loss:  0.459 \tTrain_Accu: 86%  \n",
            "Epoch: 37 \tTraining Loss:  0.419 \tTrain_Accu: 84%  \n",
            "Epoch: 38 \tTraining Loss:  0.505 \tTrain_Accu: 81%  \n",
            "Epoch: 39 \tTraining Loss:  0.370 \tTrain_Accu: 87%  \n",
            "Epoch: 40 \tTraining Loss:  0.427 \tTrain_Accu: 86%  \n",
            "Epoch: 41 \tTraining Loss:  0.405 \tTrain_Accu: 84%  \n",
            "Epoch: 42 \tTraining Loss:  0.400 \tTrain_Accu: 85%  \n",
            "Epoch: 43 \tTraining Loss:  0.333 \tTrain_Accu: 89%  \n",
            "Epoch: 44 \tTraining Loss:  0.361 \tTrain_Accu: 86%  \n",
            "Epoch: 45 \tTraining Loss:  0.347 \tTrain_Accu: 87%  \n",
            "Epoch: 46 \tTraining Loss:  0.302 \tTrain_Accu: 88%  \n",
            "Epoch: 47 \tTraining Loss:  0.321 \tTrain_Accu: 89%  \n",
            "Epoch: 48 \tTraining Loss:  0.282 \tTrain_Accu: 91%  \n",
            "Epoch: 49 \tTraining Loss:  0.264 \tTrain_Accu: 91%  \n",
            "Epoch: 50 \tTraining Loss:  0.290 \tTrain_Accu: 89%  \n",
            "Epoch: 51 \tTraining Loss:  0.264 \tTrain_Accu: 89%  \n",
            "Epoch: 52 \tTraining Loss:  0.238 \tTrain_Accu: 92%  \n",
            "Epoch: 53 \tTraining Loss:  0.255 \tTrain_Accu: 91%  \n",
            "Epoch: 54 \tTraining Loss:  0.224 \tTrain_Accu: 92%  \n",
            "Epoch: 55 \tTraining Loss:  0.212 \tTrain_Accu: 92%  \n",
            "Epoch: 56 \tTraining Loss:  0.193 \tTrain_Accu: 94%  \n",
            "Epoch: 57 \tTraining Loss:  0.229 \tTrain_Accu: 92%  \n",
            "Epoch: 58 \tTraining Loss:  0.199 \tTrain_Accu: 94%  \n",
            "Epoch: 59 \tTraining Loss:  0.192 \tTrain_Accu: 94%  \n",
            "Epoch: 60 \tTraining Loss:  0.257 \tTrain_Accu: 90%  \n",
            "Epoch: 61 \tTraining Loss:  0.171 \tTrain_Accu: 94%  \n",
            "Epoch: 62 \tTraining Loss:  0.212 \tTrain_Accu: 93%  \n",
            "Epoch: 63 \tTraining Loss:  0.235 \tTrain_Accu: 92%  \n",
            "Epoch: 64 \tTraining Loss:  0.178 \tTrain_Accu: 94%  \n",
            "Epoch: 65 \tTraining Loss:  0.212 \tTrain_Accu: 93%  \n",
            "Epoch: 66 \tTraining Loss:  0.131 \tTrain_Accu: 96%  \n",
            "Epoch: 67 \tTraining Loss:  0.126 \tTrain_Accu: 96%  \n",
            "Epoch: 68 \tTraining Loss:  0.120 \tTrain_Accu: 95%  \n",
            "Epoch: 69 \tTraining Loss:  0.157 \tTrain_Accu: 95%  \n",
            "Epoch: 70 \tTraining Loss:  0.165 \tTrain_Accu: 95%  \n",
            "Epoch: 71 \tTraining Loss:  0.160 \tTrain_Accu: 93%  \n",
            "Epoch: 72 \tTraining Loss:  0.176 \tTrain_Accu: 94%  \n",
            "Epoch: 73 \tTraining Loss:  0.160 \tTrain_Accu: 95%  \n",
            "Epoch: 74 \tTraining Loss:  0.171 \tTrain_Accu: 93%  \n",
            "Epoch: 75 \tTraining Loss:  0.134 \tTrain_Accu: 95%  \n",
            "Epoch: 76 \tTraining Loss:  0.162 \tTrain_Accu: 94%  \n",
            "Epoch: 77 \tTraining Loss:  0.122 \tTrain_Accu: 96%  \n",
            "Epoch: 78 \tTraining Loss:  0.085 \tTrain_Accu: 98%  \n",
            "Epoch: 79 \tTraining Loss:  0.159 \tTrain_Accu: 94%  \n",
            "Epoch: 80 \tTraining Loss:  0.118 \tTrain_Accu: 96%  \n",
            "Epoch: 81 \tTraining Loss:  0.106 \tTrain_Accu: 96%  \n",
            "Epoch: 82 \tTraining Loss:  0.131 \tTrain_Accu: 96%  \n",
            "Epoch: 83 \tTraining Loss:  0.115 \tTrain_Accu: 97%  \n",
            "Epoch: 84 \tTraining Loss:  0.120 \tTrain_Accu: 95%  \n",
            "Epoch: 85 \tTraining Loss:  0.098 \tTrain_Accu: 96%  \n",
            "Epoch: 86 \tTraining Loss:  0.108 \tTrain_Accu: 96%  \n",
            "Epoch: 87 \tTraining Loss:  0.133 \tTrain_Accu: 94%  \n",
            "Epoch: 88 \tTraining Loss:  0.096 \tTrain_Accu: 97%  \n",
            "Epoch: 89 \tTraining Loss:  0.097 \tTrain_Accu: 95%  \n",
            "Epoch: 90 \tTraining Loss:  0.074 \tTrain_Accu: 98%  \n",
            "Epoch: 91 \tTraining Loss:  0.113 \tTrain_Accu: 95%  \n",
            "Epoch: 92 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \n",
            "Epoch: 93 \tTraining Loss:  0.088 \tTrain_Accu: 96%  \n",
            "Epoch: 94 \tTraining Loss:  0.151 \tTrain_Accu: 95%  \n",
            "Epoch: 95 \tTraining Loss:  0.119 \tTrain_Accu: 95%  \n",
            "Epoch: 96 \tTraining Loss:  0.107 \tTrain_Accu: 96%  \n",
            "Epoch: 97 \tTraining Loss:  0.129 \tTrain_Accu: 95%  \n",
            "Epoch: 98 \tTraining Loss:  0.079 \tTrain_Accu: 97%  \n",
            "Epoch: 99 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \n",
            "Epoch: 100 \tTraining Loss:  0.101 \tTrain_Accu: 97%  \n",
            "Epoch: 101 \tTraining Loss:  0.098 \tTrain_Accu: 97%  \n",
            "Epoch: 102 \tTraining Loss:  0.087 \tTrain_Accu: 96%  \n",
            "Epoch: 103 \tTraining Loss:  0.103 \tTrain_Accu: 97%  \n",
            "Epoch: 104 \tTraining Loss:  0.114 \tTrain_Accu: 96%  \n",
            "Epoch: 105 \tTraining Loss:  0.084 \tTrain_Accu: 97%  \n",
            "Epoch: 106 \tTraining Loss:  0.075 \tTrain_Accu: 97%  \n",
            "Epoch: 107 \tTraining Loss:  0.080 \tTrain_Accu: 97%  \n",
            "Epoch: 108 \tTraining Loss:  0.121 \tTrain_Accu: 95%  \n",
            "Epoch: 109 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \n",
            "Epoch: 110 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 111 \tTraining Loss:  0.100 \tTrain_Accu: 95%  \n",
            "Epoch: 112 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \n",
            "Epoch: 113 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \n",
            "Epoch: 114 \tTraining Loss:  0.085 \tTrain_Accu: 97%  \n",
            "Epoch: 115 \tTraining Loss:  0.090 \tTrain_Accu: 96%  \n",
            "Epoch: 116 \tTraining Loss:  0.082 \tTrain_Accu: 97%  \n",
            "Epoch: 117 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \n",
            "Epoch: 118 \tTraining Loss:  0.069 \tTrain_Accu: 97%  \n",
            "Epoch: 119 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \n",
            "Epoch: 120 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 121 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \n",
            "Epoch: 122 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \n",
            "Epoch: 123 \tTraining Loss:  0.088 \tTrain_Accu: 96%  \n",
            "Epoch: 124 \tTraining Loss:  0.096 \tTrain_Accu: 96%  \n",
            "Epoch: 125 \tTraining Loss:  0.103 \tTrain_Accu: 96%  \n",
            "Epoch: 126 \tTraining Loss:  0.097 \tTrain_Accu: 97%  \n",
            "Epoch: 127 \tTraining Loss:  0.105 \tTrain_Accu: 96%  \n",
            "Epoch: 128 \tTraining Loss:  0.113 \tTrain_Accu: 96%  \n",
            "Epoch: 129 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \n",
            "Epoch: 130 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \n",
            "Epoch: 131 \tTraining Loss:  0.055 \tTrain_Accu: 99%  \n",
            "Epoch: 132 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 133 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \n",
            "Epoch: 134 \tTraining Loss:  0.033 \tTrain_Accu: 98%  \n",
            "Epoch: 135 \tTraining Loss:  0.066 \tTrain_Accu: 98%  \n",
            "Epoch: 136 \tTraining Loss:  0.096 \tTrain_Accu: 95%  \n",
            "Epoch: 137 \tTraining Loss:  0.094 \tTrain_Accu: 97%  \n",
            "Epoch: 138 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \n",
            "Epoch: 139 \tTraining Loss:  0.066 \tTrain_Accu: 98%  \n",
            "Epoch: 140 \tTraining Loss:  0.071 \tTrain_Accu: 98%  \n",
            "Epoch: 141 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \n",
            "Epoch: 142 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \n",
            "Epoch: 143 \tTraining Loss:  0.077 \tTrain_Accu: 96%  \n",
            "Epoch: 144 \tTraining Loss:  0.088 \tTrain_Accu: 97%  \n",
            "Epoch: 145 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \n",
            "Epoch: 146 \tTraining Loss:  0.089 \tTrain_Accu: 98%  \n",
            "Epoch: 147 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \n",
            "Epoch: 148 \tTraining Loss:  0.078 \tTrain_Accu: 97%  \n",
            "Epoch: 149 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \n",
            "Epoch: 150 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \n",
            "Epoch: 151 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \n",
            "Epoch: 152 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \n",
            "Epoch: 153 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \n",
            "Epoch: 154 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 155 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \n",
            "Epoch: 156 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \n",
            "Epoch: 157 \tTraining Loss:  0.070 \tTrain_Accu: 97%  \n",
            "Epoch: 158 \tTraining Loss:  0.069 \tTrain_Accu: 97%  \n",
            "Epoch: 159 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 160 \tTraining Loss:  0.061 \tTrain_Accu: 97%  \n",
            "Epoch: 161 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 162 \tTraining Loss:  0.080 \tTrain_Accu: 97%  \n",
            "Epoch: 163 \tTraining Loss:  0.049 \tTrain_Accu: 97%  \n",
            "Epoch: 164 \tTraining Loss:  0.076 \tTrain_Accu: 98%  \n",
            "Epoch: 165 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \n",
            "Epoch: 166 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 167 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \n",
            "Epoch: 168 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \n",
            "Epoch: 169 \tTraining Loss:  0.065 \tTrain_Accu: 97%  \n",
            "Epoch: 170 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \n",
            "Epoch: 171 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \n",
            "Epoch: 172 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \n",
            "Epoch: 173 \tTraining Loss:  0.068 \tTrain_Accu: 97%  \n",
            "Epoch: 174 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 175 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 176 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \n",
            "Epoch: 177 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 178 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \n",
            "Epoch: 179 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 180 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \n",
            "Epoch: 181 \tTraining Loss:  0.066 \tTrain_Accu: 98%  \n",
            "Epoch: 182 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \n",
            "Epoch: 183 \tTraining Loss:  0.059 \tTrain_Accu: 99%  \n",
            "Epoch: 184 \tTraining Loss:  0.043 \tTrain_Accu: 99%  \n",
            "Epoch: 185 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \n",
            "Epoch: 186 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \n",
            "Epoch: 187 \tTraining Loss:  0.045 \tTrain_Accu: 99%  \n",
            "Epoch: 188 \tTraining Loss:  0.091 \tTrain_Accu: 97%  \n",
            "Epoch: 189 \tTraining Loss:  0.038 \tTrain_Accu: 99%  \n",
            "Epoch: 190 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \n",
            "Epoch: 191 \tTraining Loss:  0.043 \tTrain_Accu: 99%  \n",
            "Epoch: 192 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 193 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \n",
            "Epoch: 194 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \n",
            "Epoch: 195 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \n",
            "Epoch: 196 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 197 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 198 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \n",
            "Epoch: 199 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \n",
            "Epoch: 200 \tTraining Loss:  0.054 \tTrain_Accu: 97%  \n",
            "Epoch: 201 \tTraining Loss:  0.061 \tTrain_Accu: 97%  \n",
            "Epoch: 202 \tTraining Loss:  0.082 \tTrain_Accu: 97%  \n",
            "Epoch: 203 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \n",
            "Epoch: 204 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 205 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \n",
            "Epoch: 206 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 207 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \n",
            "Epoch: 208 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \n",
            "Epoch: 209 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \n",
            "Epoch: 210 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 211 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 212 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 213 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \n",
            "Epoch: 214 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 215 \tTraining Loss:  0.049 \tTrain_Accu: 99%  \n",
            "Epoch: 216 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \n",
            "Epoch: 217 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 218 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 219 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 220 \tTraining Loss:  0.015 \tTrain_Accu: 99%  \n",
            "Epoch: 221 \tTraining Loss:  0.049 \tTrain_Accu: 99%  \n",
            "Epoch: 222 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \n",
            "Epoch: 223 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \n",
            "Epoch: 224 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \n",
            "Epoch: 225 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 226 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 227 \tTraining Loss:  0.037 \tTrain_Accu: 98%  \n",
            "Epoch: 228 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \n",
            "Epoch: 229 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \n",
            "Epoch: 230 \tTraining Loss:  0.034 \tTrain_Accu: 98%  \n",
            "Epoch: 231 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \n",
            "Epoch: 232 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 233 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \n",
            "Epoch: 234 \tTraining Loss:  0.016 \tTrain_Accu: 99%  \n",
            "Epoch: 235 \tTraining Loss:  0.032 \tTrain_Accu: 98%  \n",
            "Epoch: 236 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 237 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \n",
            "Epoch: 238 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \n",
            "Epoch: 239 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \n",
            "Epoch: 240 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \n",
            "Epoch: 241 \tTraining Loss:  0.014 \tTrain_Accu: 100%  \n",
            "Epoch: 242 \tTraining Loss:  0.052 \tTrain_Accu: 99%  \n",
            "Epoch: 243 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \n",
            "Epoch: 244 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 245 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \n",
            "Epoch: 246 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \n",
            "Epoch: 247 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \n",
            "Epoch: 248 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \n",
            "Epoch: 249 \tTraining Loss:  0.012 \tTrain_Accu: 100%  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 01:04:49,451]\u001b[0m Trial 9 finished with value: 99.7 and parameters: {}. Best is trial 9 with value: 99.7.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.016 \tTrain_Accu: 100%  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./optuna_WNI_drop.torch']"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifcytCkrFw1o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPkTZdB1F02-"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "vkPZr60npEiG",
        "outputId": "40eaf4d6-2c1a-4136-9786-8141c3cc6f56"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_WNI_rain[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop()\n",
        "\n",
        "checkpoint = torch.load( \"drive/MyDrive/DL_project/check_WNI_RMSprops_indv_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 0, 2, 3, 3, 2, 2, 2, 2, 2, 0, 0,\n",
            "        0, 0, 0, 0, 4, 4, 4, 1, 1, 1, 0, 1, 2, 4, 1, 1, 1, 1, 4, 1, 1, 1, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 4, 3, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 3, 2, 4, 2])\n",
            "labels tensor([0, 1, 3, 4, 0, 1, 1, 1, 2, 1, 0, 0, 0, 4, 4, 4, 4, 4, 2, 1, 0, 0, 0, 0,\n",
            "        2, 0, 3, 4, 4, 2, 3, 1, 4, 2, 3, 2, 3, 4, 4, 4, 1, 2, 4, 4, 1, 0, 0, 2,\n",
            "        4, 4, 4, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1, 2, 1, 0, 1])\n",
            "correct : 18\n",
            "test_Accuracy % : 25.7\n",
            "kappa 0.13368312991901454\n",
            "[[3 6 8 1 1]\n",
            " [0 8 7 0 1]\n",
            " [1 3 4 2 1]\n",
            " [2 0 3 0 1]\n",
            " [2 5 6 2 3]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_cXpiXpyp9R"
      },
      "source": [
        "## ENI_rain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "axkaplShSGuL",
        "outputId": "3398f047-62da-4ac7-a59c-90caedcbf0d0"
      },
      "source": [
        "# Reading rainfall file of ESI region \n",
        "Data_Rain_ENI = pd.read_csv(\"drive/My Drive/DL_project/Target_Rain_ENI_regional_ave_time_series.csv\")\n",
        "Data_Rain_ENI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>Rain_bc</th>\n",
              "      <th>cat_3</th>\n",
              "      <th>cat_5</th>\n",
              "      <th>anomalies</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-04-01</td>\n",
              "      <td>271.002261</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-35.277979</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-05-01</td>\n",
              "      <td>372.490293</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>38.612542</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-06-01</td>\n",
              "      <td>519.262965</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>149.049311</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-07-01</td>\n",
              "      <td>576.990359</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>150.647631</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-08-01</td>\n",
              "      <td>629.490758</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>198.167742</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>2019-08-01</td>\n",
              "      <td>321.622739</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-109.700277</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>316.468218</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-85.917467</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>2019-10-01</td>\n",
              "      <td>321.417686</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-37.320809</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>283.191689</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-48.170731</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>291.894614</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-20.869426</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>465 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           time     Rain_bc  cat_3  cat_5   anomalies region\n",
              "0    1981-04-01  271.002261      2      2  -35.277979    ENI\n",
              "1    1981-05-01  372.490293      3      4   38.612542    ENI\n",
              "2    1981-06-01  519.262965      3      5  149.049311    ENI\n",
              "3    1981-07-01  576.990359      3      5  150.647631    ENI\n",
              "4    1981-08-01  629.490758      3      5  198.167742    ENI\n",
              "..          ...         ...    ...    ...         ...    ...\n",
              "460  2019-08-01  321.622739      1      1 -109.700277    ENI\n",
              "461  2019-09-01  316.468218      1      2  -85.917467    ENI\n",
              "462  2019-10-01  321.417686      2      2  -37.320809    ENI\n",
              "463  2019-11-01  283.191689      1      2  -48.170731    ENI\n",
              "464  2019-12-01  291.894614      2      3  -20.869426    ENI\n",
              "\n",
              "[465 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVmnBpZMSNL-"
      },
      "source": [
        "# Extracting quantiles from the ESI dataset\n",
        "labels_Rain_ENI = Data_Rain_ENI['cat_5'].astype(int) #cat5 column - so 5 prediction classes "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvipIT49SSNX"
      },
      "source": [
        "# Function that will convert labels into Pytorch tensors\n",
        "\n",
        "def labels_Tensors(labels):\n",
        "    return (torch.from_numpy(labels.values).type(torch.LongTensor)-1) #cat5 in form 1, 2, 3, 4, 5;\n",
        "\n",
        "# Converting labels of rainfall_ENI region into tensors\n",
        "labelsTensors_ENI_rain = labels_Tensors(labels_Rain_ENI) # This represents y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHcvouRsSXxR",
        "outputId": "b4a059e2-c7f9-4282-d382-0e3bbdffabca"
      },
      "source": [
        "# Training data lables distribution\n",
        "Train_labels = labels_Rain_ENI[:324]\n",
        "Train_labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    69\n",
              "1    67\n",
              "2    66\n",
              "5    61\n",
              "4    61\n",
              "Name: cat_5, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdNU8EczSfx6"
      },
      "source": [
        "### Training \n",
        "\n",
        "Training the network with the training and validation dataset in Optuna frame work with RMSprop optimizer, batch size 10 and learning rate 0.0001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jed9dJo-SjdG"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_valid_loaders_ENI(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_ENI_rain[:325])\n",
        "    validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_ENI_rain[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "  \n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLEmO-cqndlt"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_Rain_ENI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           #'dropout'       : 0.7,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_ENI(cfg['Batch_size'])\n",
        "  model = Network_drop().to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_ENI_rain[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_ENI_rain[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 10\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_ENI_rain[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_ENI_rain[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_ENI_RMSprops_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWAwoNS9S1Ea",
        "outputId": "63b098fa-8faf-497f-e22b-adef0f6f65b5"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_Rain_ENI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"drive/MyDrive/DL_project/optimise_valid_ENI\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.732 \tTrain_Accu: 18%  \tValid_Acc:20%  \tVal_kappa : 0.185  \n",
            "Epoch: 2 \tTraining Loss:  1.604 \tTrain_Accu: 25%  \tValid_Acc:21%  \tVal_kappa : 0.035  \n",
            "Epoch: 3 \tTraining Loss:  1.599 \tTrain_Accu: 24%  \tValid_Acc:14%  \tVal_kappa : -0.055  \n",
            "Epoch: 4 \tTraining Loss:  1.580 \tTrain_Accu: 29%  \tValid_Acc:10%  \tVal_kappa : -0.267  \n",
            "Epoch: 5 \tTraining Loss:  1.561 \tTrain_Accu: 28%  \tValid_Acc:21%  \tVal_kappa : -0.011  \n",
            "Epoch: 6 \tTraining Loss:  1.540 \tTrain_Accu: 33%  \tValid_Acc:19%  \tVal_kappa : -0.058  \n",
            "Epoch: 7 \tTraining Loss:  1.507 \tTrain_Accu: 34%  \tValid_Acc:13%  \tVal_kappa : 0.131  \n",
            "Epoch: 8 \tTraining Loss:  1.477 \tTrain_Accu: 35%  \tValid_Acc:13%  \tVal_kappa : -0.002  \n",
            "Epoch: 9 \tTraining Loss:  1.428 \tTrain_Accu: 38%  \tValid_Acc:14%  \tVal_kappa : -0.190  \n",
            "Epoch: 10 \tTraining Loss:  1.443 \tTrain_Accu: 38%  \tValid_Acc:19%  \tVal_kappa : 0.045  \n",
            "Epoch: 11 \tTraining Loss:  1.365 \tTrain_Accu: 41%  \tValid_Acc:17%  \tVal_kappa : -0.063  \n",
            "Epoch: 12 \tTraining Loss:  1.357 \tTrain_Accu: 40%  \tValid_Acc:14%  \tVal_kappa : -0.110  \n",
            "Epoch: 13 \tTraining Loss:  1.263 \tTrain_Accu: 48%  \tValid_Acc:14%  \tVal_kappa : -0.112  \n",
            "Epoch: 14 \tTraining Loss:  1.207 \tTrain_Accu: 48%  \tValid_Acc:10%  \tVal_kappa : 0.022  \n",
            "Epoch: 15 \tTraining Loss:  1.213 \tTrain_Accu: 47%  \tValid_Acc:14%  \tVal_kappa : 0.065  \n",
            "Epoch: 16 \tTraining Loss:  1.167 \tTrain_Accu: 56%  \tValid_Acc:7%  \tVal_kappa : -0.246  \n",
            "Epoch: 17 \tTraining Loss:  1.154 \tTrain_Accu: 55%  \tValid_Acc:21%  \tVal_kappa : 0.043  \n",
            "Epoch: 18 \tTraining Loss:  1.082 \tTrain_Accu: 58%  \tValid_Acc:21%  \tVal_kappa : -0.006  \n",
            "Epoch: 19 \tTraining Loss:  0.961 \tTrain_Accu: 65%  \tValid_Acc:17%  \tVal_kappa : -0.089  \n",
            "Epoch: 20 \tTraining Loss:  0.989 \tTrain_Accu: 59%  \tValid_Acc:14%  \tVal_kappa : -0.192  \n",
            "Epoch: 21 \tTraining Loss:  0.972 \tTrain_Accu: 62%  \tValid_Acc:20%  \tVal_kappa : -0.166  \n",
            "Epoch: 22 \tTraining Loss:  0.999 \tTrain_Accu: 63%  \tValid_Acc:19%  \tVal_kappa : 0.059  \n",
            "Epoch: 23 \tTraining Loss:  0.883 \tTrain_Accu: 67%  \tValid_Acc:19%  \tVal_kappa : -0.107  \n",
            "Epoch: 24 \tTraining Loss:  0.829 \tTrain_Accu: 70%  \tValid_Acc:21%  \tVal_kappa : -0.203  \n",
            "Epoch: 25 \tTraining Loss:  0.707 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : -0.004  \n",
            "Epoch: 26 \tTraining Loss:  0.719 \tTrain_Accu: 72%  \tValid_Acc:13%  \tVal_kappa : 0.010  \n",
            "Epoch: 27 \tTraining Loss:  0.685 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : -0.029  \n",
            "Epoch: 28 \tTraining Loss:  0.667 \tTrain_Accu: 74%  \tValid_Acc:13%  \tVal_kappa : -0.312  \n",
            "Epoch: 29 \tTraining Loss:  0.560 \tTrain_Accu: 81%  \tValid_Acc:19%  \tVal_kappa : -0.006  \n",
            "Epoch: 30 \tTraining Loss:  0.666 \tTrain_Accu: 75%  \tValid_Acc:13%  \tVal_kappa : -0.259  \n",
            "Epoch: 31 \tTraining Loss:  0.661 \tTrain_Accu: 74%  \tValid_Acc:16%  \tVal_kappa : -0.048  \n",
            "Epoch: 32 \tTraining Loss:  0.585 \tTrain_Accu: 77%  \tValid_Acc:16%  \tVal_kappa : -0.258  \n",
            "Epoch: 33 \tTraining Loss:  0.456 \tTrain_Accu: 84%  \tValid_Acc:17%  \tVal_kappa : -0.198  \n",
            "Epoch: 34 \tTraining Loss:  0.506 \tTrain_Accu: 81%  \tValid_Acc:13%  \tVal_kappa : -0.204  \n",
            "Epoch: 35 \tTraining Loss:  0.395 \tTrain_Accu: 85%  \tValid_Acc:16%  \tVal_kappa : -0.106  \n",
            "Epoch: 36 \tTraining Loss:  0.397 \tTrain_Accu: 86%  \tValid_Acc:21%  \tVal_kappa : -0.103  \n",
            "Epoch: 37 \tTraining Loss:  0.437 \tTrain_Accu: 83%  \tValid_Acc:20%  \tVal_kappa : -0.099  \n",
            "Epoch: 38 \tTraining Loss:  0.412 \tTrain_Accu: 85%  \tValid_Acc:17%  \tVal_kappa : -0.060  \n",
            "Epoch: 39 \tTraining Loss:  0.382 \tTrain_Accu: 86%  \tValid_Acc:13%  \tVal_kappa : -0.078  \n",
            "Epoch: 40 \tTraining Loss:  0.390 \tTrain_Accu: 86%  \tValid_Acc:16%  \tVal_kappa : -0.228  \n",
            "Epoch: 41 \tTraining Loss:  0.373 \tTrain_Accu: 87%  \tValid_Acc:17%  \tVal_kappa : -0.150  \n",
            "Epoch: 42 \tTraining Loss:  0.317 \tTrain_Accu: 88%  \tValid_Acc:11%  \tVal_kappa : -0.162  \n",
            "Epoch: 43 \tTraining Loss:  0.285 \tTrain_Accu: 90%  \tValid_Acc:13%  \tVal_kappa : -0.099  \n",
            "Epoch: 44 \tTraining Loss:  0.375 \tTrain_Accu: 87%  \tValid_Acc:13%  \tVal_kappa : -0.413  \n",
            "Epoch: 45 \tTraining Loss:  0.297 \tTrain_Accu: 90%  \tValid_Acc:20%  \tVal_kappa : 0.051  \n",
            "Epoch: 46 \tTraining Loss:  0.380 \tTrain_Accu: 86%  \tValid_Acc:19%  \tVal_kappa : -0.132  \n",
            "Epoch: 47 \tTraining Loss:  0.338 \tTrain_Accu: 87%  \tValid_Acc:21%  \tVal_kappa : -0.057  \n",
            "Epoch: 48 \tTraining Loss:  0.296 \tTrain_Accu: 90%  \tValid_Acc:19%  \tVal_kappa : 0.006  \n",
            "Epoch: 49 \tTraining Loss:  0.263 \tTrain_Accu: 90%  \tValid_Acc:19%  \tVal_kappa : -0.037  \n",
            "Epoch: 50 \tTraining Loss:  0.253 \tTrain_Accu: 91%  \tValid_Acc:14%  \tVal_kappa : -0.181  \n",
            "Epoch: 51 \tTraining Loss:  0.248 \tTrain_Accu: 91%  \tValid_Acc:13%  \tVal_kappa : 0.004  \n",
            "Epoch: 52 \tTraining Loss:  0.237 \tTrain_Accu: 90%  \tValid_Acc:14%  \tVal_kappa : -0.210  \n",
            "Epoch: 53 \tTraining Loss:  0.237 \tTrain_Accu: 92%  \tValid_Acc:20%  \tVal_kappa : -0.018  \n",
            "Epoch: 54 \tTraining Loss:  0.220 \tTrain_Accu: 90%  \tValid_Acc:23%  \tVal_kappa : -0.200  \n",
            "Epoch: 55 \tTraining Loss:  0.274 \tTrain_Accu: 90%  \tValid_Acc:13%  \tVal_kappa : -0.193  \n",
            "Epoch: 56 \tTraining Loss:  0.253 \tTrain_Accu: 91%  \tValid_Acc:21%  \tVal_kappa : 0.031  \n",
            "Epoch: 57 \tTraining Loss:  0.248 \tTrain_Accu: 92%  \tValid_Acc:16%  \tVal_kappa : -0.124  \n",
            "Epoch: 58 \tTraining Loss:  0.214 \tTrain_Accu: 92%  \tValid_Acc:16%  \tVal_kappa : -0.009  \n",
            "Epoch: 59 \tTraining Loss:  0.148 \tTrain_Accu: 94%  \tValid_Acc:16%  \tVal_kappa : -0.080  \n",
            "Epoch: 60 \tTraining Loss:  0.189 \tTrain_Accu: 93%  \tValid_Acc:13%  \tVal_kappa : -0.037  \n",
            "Epoch: 61 \tTraining Loss:  0.185 \tTrain_Accu: 93%  \tValid_Acc:16%  \tVal_kappa : -0.142  \n",
            "Epoch: 62 \tTraining Loss:  0.215 \tTrain_Accu: 95%  \tValid_Acc:17%  \tVal_kappa : -0.219  \n",
            "Epoch: 63 \tTraining Loss:  0.198 \tTrain_Accu: 92%  \tValid_Acc:16%  \tVal_kappa : -0.161  \n",
            "Epoch: 64 \tTraining Loss:  0.156 \tTrain_Accu: 94%  \tValid_Acc:10%  \tVal_kappa : -0.331  \n",
            "Epoch: 65 \tTraining Loss:  0.191 \tTrain_Accu: 92%  \tValid_Acc:21%  \tVal_kappa : -0.127  \n",
            "Epoch: 66 \tTraining Loss:  0.183 \tTrain_Accu: 94%  \tValid_Acc:14%  \tVal_kappa : -0.198  \n",
            "Epoch: 67 \tTraining Loss:  0.125 \tTrain_Accu: 96%  \tValid_Acc:14%  \tVal_kappa : -0.180  \n",
            "Epoch: 68 \tTraining Loss:  0.177 \tTrain_Accu: 94%  \tValid_Acc:19%  \tVal_kappa : -0.044  \n",
            "Epoch: 69 \tTraining Loss:  0.123 \tTrain_Accu: 95%  \tValid_Acc:11%  \tVal_kappa : -0.126  \n",
            "Epoch: 70 \tTraining Loss:  0.127 \tTrain_Accu: 95%  \tValid_Acc:17%  \tVal_kappa : -0.291  \n",
            "Epoch: 71 \tTraining Loss:  0.178 \tTrain_Accu: 94%  \tValid_Acc:17%  \tVal_kappa : -0.203  \n",
            "Epoch: 72 \tTraining Loss:  0.163 \tTrain_Accu: 95%  \tValid_Acc:19%  \tVal_kappa : -0.010  \n",
            "Epoch: 73 \tTraining Loss:  0.162 \tTrain_Accu: 94%  \tValid_Acc:13%  \tVal_kappa : -0.134  \n",
            "Epoch: 74 \tTraining Loss:  0.184 \tTrain_Accu: 94%  \tValid_Acc:11%  \tVal_kappa : -0.356  \n",
            "Epoch: 75 \tTraining Loss:  0.121 \tTrain_Accu: 97%  \tValid_Acc:9%  \tVal_kappa : -0.271  \n",
            "Epoch: 76 \tTraining Loss:  0.123 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.188  \n",
            "Epoch: 77 \tTraining Loss:  0.153 \tTrain_Accu: 95%  \tValid_Acc:13%  \tVal_kappa : -0.140  \n",
            "Epoch: 78 \tTraining Loss:  0.155 \tTrain_Accu: 93%  \tValid_Acc:19%  \tVal_kappa : -0.080  \n",
            "Epoch: 79 \tTraining Loss:  0.104 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.246  \n",
            "Epoch: 80 \tTraining Loss:  0.129 \tTrain_Accu: 95%  \tValid_Acc:19%  \tVal_kappa : -0.128  \n",
            "Epoch: 81 \tTraining Loss:  0.129 \tTrain_Accu: 94%  \tValid_Acc:16%  \tVal_kappa : -0.204  \n",
            "Epoch: 82 \tTraining Loss:  0.086 \tTrain_Accu: 98%  \tValid_Acc:10%  \tVal_kappa : -0.199  \n",
            "Epoch: 83 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.086  \n",
            "Epoch: 84 \tTraining Loss:  0.083 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : -0.029  \n",
            "Epoch: 85 \tTraining Loss:  0.094 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : -0.099  \n",
            "Epoch: 86 \tTraining Loss:  0.164 \tTrain_Accu: 94%  \tValid_Acc:16%  \tVal_kappa : -0.124  \n",
            "Epoch: 87 \tTraining Loss:  0.078 \tTrain_Accu: 96%  \tValid_Acc:14%  \tVal_kappa : 0.018  \n",
            "Epoch: 88 \tTraining Loss:  0.076 \tTrain_Accu: 98%  \tValid_Acc:11%  \tVal_kappa : -0.309  \n",
            "Epoch: 89 \tTraining Loss:  0.053 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.205  \n",
            "Epoch: 90 \tTraining Loss:  0.134 \tTrain_Accu: 96%  \tValid_Acc:16%  \tVal_kappa : -0.161  \n",
            "Epoch: 91 \tTraining Loss:  0.136 \tTrain_Accu: 95%  \tValid_Acc:17%  \tVal_kappa : -0.104  \n",
            "Epoch: 92 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.112  \n",
            "Epoch: 93 \tTraining Loss:  0.110 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.153  \n",
            "Epoch: 94 \tTraining Loss:  0.070 \tTrain_Accu: 97%  \tValid_Acc:13%  \tVal_kappa : -0.219  \n",
            "Epoch: 95 \tTraining Loss:  0.128 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.302  \n",
            "Epoch: 96 \tTraining Loss:  0.123 \tTrain_Accu: 96%  \tValid_Acc:16%  \tVal_kappa : -0.152  \n",
            "Epoch: 97 \tTraining Loss:  0.108 \tTrain_Accu: 97%  \tValid_Acc:17%  \tVal_kappa : -0.238  \n",
            "Epoch: 98 \tTraining Loss:  0.074 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : -0.135  \n",
            "Epoch: 99 \tTraining Loss:  0.132 \tTrain_Accu: 95%  \tValid_Acc:13%  \tVal_kappa : -0.121  \n",
            "Epoch: 100 \tTraining Loss:  0.092 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.085  \n",
            "Epoch: 101 \tTraining Loss:  0.105 \tTrain_Accu: 96%  \tValid_Acc:14%  \tVal_kappa : -0.064  \n",
            "Epoch: 102 \tTraining Loss:  0.081 \tTrain_Accu: 97%  \tValid_Acc:20%  \tVal_kappa : -0.066  \n",
            "Epoch: 103 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:11%  \tVal_kappa : -0.316  \n",
            "Epoch: 104 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.115  \n",
            "Epoch: 105 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.118  \n",
            "Epoch: 106 \tTraining Loss:  0.100 \tTrain_Accu: 96%  \tValid_Acc:17%  \tVal_kappa : -0.152  \n",
            "Epoch: 107 \tTraining Loss:  0.095 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.203  \n",
            "Epoch: 108 \tTraining Loss:  0.088 \tTrain_Accu: 96%  \tValid_Acc:24%  \tVal_kappa : -0.023  \n",
            "Epoch: 109 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.153  \n",
            "Epoch: 110 \tTraining Loss:  0.101 \tTrain_Accu: 96%  \tValid_Acc:24%  \tVal_kappa : -0.035  \n",
            "Epoch: 111 \tTraining Loss:  0.066 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.388  \n",
            "Epoch: 112 \tTraining Loss:  0.066 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.210  \n",
            "Epoch: 113 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.290  \n",
            "Epoch: 114 \tTraining Loss:  0.128 \tTrain_Accu: 95%  \tValid_Acc:14%  \tVal_kappa : -0.149  \n",
            "Epoch: 115 \tTraining Loss:  0.065 \tTrain_Accu: 97%  \tValid_Acc:13%  \tVal_kappa : -0.165  \n",
            "Epoch: 116 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.125  \n",
            "Epoch: 117 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.186  \n",
            "Epoch: 118 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.262  \n",
            "Epoch: 119 \tTraining Loss:  0.098 \tTrain_Accu: 97%  \tValid_Acc:14%  \tVal_kappa : -0.170  \n",
            "Epoch: 120 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.203  \n",
            "Epoch: 121 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : -0.179  \n",
            "Epoch: 122 \tTraining Loss:  0.073 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.145  \n",
            "Epoch: 123 \tTraining Loss:  0.090 \tTrain_Accu: 95%  \tValid_Acc:19%  \tVal_kappa : -0.079  \n",
            "Epoch: 124 \tTraining Loss:  0.131 \tTrain_Accu: 95%  \tValid_Acc:16%  \tVal_kappa : -0.114  \n",
            "Epoch: 125 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.275  \n",
            "Epoch: 126 \tTraining Loss:  0.053 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.232  \n",
            "Epoch: 127 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.161  \n",
            "Epoch: 128 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \tValid_Acc:6%  \tVal_kappa : -0.208  \n",
            "Epoch: 129 \tTraining Loss:  0.051 \tTrain_Accu: 97%  \tValid_Acc:19%  \tVal_kappa : -0.134  \n",
            "Epoch: 130 \tTraining Loss:  0.086 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.293  \n",
            "Epoch: 131 \tTraining Loss:  0.081 \tTrain_Accu: 97%  \tValid_Acc:13%  \tVal_kappa : -0.206  \n",
            "Epoch: 132 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.250  \n",
            "Epoch: 133 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.172  \n",
            "Epoch: 134 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.095  \n",
            "Epoch: 135 \tTraining Loss:  0.024 \tTrain_Accu: 100%  \tValid_Acc:13%  \tVal_kappa : -0.249  \n",
            "Epoch: 136 \tTraining Loss:  0.074 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.073  \n",
            "Epoch: 137 \tTraining Loss:  0.066 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.075  \n",
            "Epoch: 138 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.009  \n",
            "Epoch: 139 \tTraining Loss:  0.081 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.113  \n",
            "Epoch: 140 \tTraining Loss:  0.075 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : 0.018  \n",
            "Epoch: 141 \tTraining Loss:  0.083 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.208  \n",
            "Epoch: 142 \tTraining Loss:  0.077 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : 0.054  \n",
            "Epoch: 143 \tTraining Loss:  0.061 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.160  \n",
            "Epoch: 144 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.147  \n",
            "Epoch: 145 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.204  \n",
            "Epoch: 146 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.142  \n",
            "Epoch: 147 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : 0.052  \n",
            "Epoch: 148 \tTraining Loss:  0.080 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.122  \n",
            "Epoch: 149 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \tValid_Acc:11%  \tVal_kappa : -0.144  \n",
            "Epoch: 150 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.158  \n",
            "Epoch: 151 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.138  \n",
            "Epoch: 152 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \tValid_Acc:10%  \tVal_kappa : -0.272  \n",
            "Epoch: 153 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.041  \n",
            "Epoch: 154 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.121  \n",
            "Epoch: 155 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.280  \n",
            "Epoch: 156 \tTraining Loss:  0.081 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.088  \n",
            "Epoch: 157 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.129  \n",
            "Epoch: 158 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.156  \n",
            "Epoch: 159 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.093  \n",
            "Epoch: 160 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \tValid_Acc:10%  \tVal_kappa : -0.186  \n",
            "Epoch: 161 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.006  \n",
            "Epoch: 162 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.078  \n",
            "Epoch: 163 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.103  \n",
            "Epoch: 164 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.284  \n",
            "Epoch: 165 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : -0.135  \n",
            "Epoch: 166 \tTraining Loss:  0.073 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.100  \n",
            "Epoch: 167 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.107  \n",
            "Epoch: 168 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.143  \n",
            "Epoch: 169 \tTraining Loss:  0.087 \tTrain_Accu: 98%  \tValid_Acc:26%  \tVal_kappa : 0.014  \n",
            "Epoch: 170 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.241  \n",
            "Epoch: 171 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.016  \n",
            "Epoch: 172 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.083  \n",
            "Epoch: 173 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.252  \n",
            "Epoch: 174 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:11%  \tVal_kappa : -0.213  \n",
            "Epoch: 175 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.217  \n",
            "Epoch: 176 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.024  \n",
            "Epoch: 177 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.242  \n",
            "Epoch: 178 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \tValid_Acc:21%  \tVal_kappa : 0.008  \n",
            "Epoch: 179 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : -0.106  \n",
            "Epoch: 180 \tTraining Loss:  0.029 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.217  \n",
            "Epoch: 181 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.242  \n",
            "Epoch: 182 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : 0.020  \n",
            "Epoch: 183 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \tValid_Acc:11%  \tVal_kappa : -0.258  \n",
            "Epoch: 184 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.229  \n",
            "Epoch: 185 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.173  \n",
            "Epoch: 186 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.239  \n",
            "Epoch: 187 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : -0.112  \n",
            "Epoch: 188 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:11%  \tVal_kappa : -0.228  \n",
            "Epoch: 189 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.197  \n",
            "Epoch: 190 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:11%  \tVal_kappa : -0.153  \n",
            "Epoch: 191 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \tValid_Acc:23%  \tVal_kappa : -0.025  \n",
            "Epoch: 192 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.141  \n",
            "Epoch: 193 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.300  \n",
            "Epoch: 194 \tTraining Loss:  0.031 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.041  \n",
            "Epoch: 195 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : -0.112  \n",
            "Epoch: 196 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.062  \n",
            "Epoch: 197 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:26%  \tVal_kappa : -0.006  \n",
            "Epoch: 198 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.187  \n",
            "Epoch: 199 \tTraining Loss:  0.052 \tTrain_Accu: 97%  \tValid_Acc:16%  \tVal_kappa : -0.127  \n",
            "Epoch: 200 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \tValid_Acc:7%  \tVal_kappa : -0.384  \n",
            "Epoch: 201 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.338  \n",
            "Epoch: 202 \tTraining Loss:  0.034 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.242  \n",
            "Epoch: 203 \tTraining Loss:  0.037 \tTrain_Accu: 98%  \tValid_Acc:24%  \tVal_kappa : -0.129  \n",
            "Epoch: 204 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : -0.099  \n",
            "Epoch: 205 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.235  \n",
            "Epoch: 206 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:10%  \tVal_kappa : -0.298  \n",
            "Epoch: 207 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.331  \n",
            "Epoch: 208 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.184  \n",
            "Epoch: 209 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.115  \n",
            "Epoch: 210 \tTraining Loss:  0.028 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.359  \n",
            "Epoch: 211 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.094  \n",
            "Epoch: 212 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.231  \n",
            "Epoch: 213 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.094  \n",
            "Epoch: 214 \tTraining Loss:  0.085 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.102  \n",
            "Epoch: 215 \tTraining Loss:  0.046 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : -0.032  \n",
            "Epoch: 216 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:16%  \tVal_kappa : -0.086  \n",
            "Epoch: 217 \tTraining Loss:  0.018 \tTrain_Accu: 100%  \tValid_Acc:16%  \tVal_kappa : -0.088  \n",
            "Epoch: 218 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.071  \n",
            "Epoch: 219 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.004  \n",
            "Epoch: 220 \tTraining Loss:  0.019 \tTrain_Accu: 100%  \tValid_Acc:13%  \tVal_kappa : -0.115  \n",
            "Epoch: 221 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \tValid_Acc:14%  \tVal_kappa : -0.223  \n",
            "Epoch: 222 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.089  \n",
            "Epoch: 223 \tTraining Loss:  0.115 \tTrain_Accu: 95%  \tValid_Acc:16%  \tVal_kappa : -0.140  \n",
            "Epoch: 224 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : 0.008  \n",
            "Epoch: 225 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \tValid_Acc:10%  \tVal_kappa : -0.267  \n",
            "Epoch: 226 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.214  \n",
            "Epoch: 227 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.091  \n",
            "Epoch: 228 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \tValid_Acc:20%  \tVal_kappa : -0.101  \n",
            "Epoch: 229 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.270  \n",
            "Epoch: 230 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:13%  \tVal_kappa : -0.249  \n",
            "Epoch: 231 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : 0.020  \n",
            "Epoch: 232 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : 0.029  \n",
            "Epoch: 233 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \tValid_Acc:19%  \tVal_kappa : -0.190  \n",
            "Epoch: 234 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.059  \n",
            "Epoch: 235 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:11%  \tVal_kappa : -0.249  \n",
            "Epoch: 236 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.081  \n",
            "Epoch: 237 \tTraining Loss:  0.034 \tTrain_Accu: 98%  \tValid_Acc:17%  \tVal_kappa : -0.078  \n",
            "Epoch: 238 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:24%  \tVal_kappa : -0.026  \n",
            "Epoch: 239 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:20%  \tVal_kappa : -0.154  \n",
            "Epoch: 240 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.208  \n",
            "Epoch: 241 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:23%  \tVal_kappa : -0.046  \n",
            "Epoch: 242 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:16%  \tVal_kappa : -0.063  \n",
            "Epoch: 243 \tTraining Loss:  0.015 \tTrain_Accu: 100%  \tValid_Acc:20%  \tVal_kappa : 0.029  \n",
            "Epoch: 244 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.275  \n",
            "Epoch: 245 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:21%  \tVal_kappa : -0.005  \n",
            "Epoch: 246 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:19%  \tVal_kappa : -0.088  \n",
            "Epoch: 247 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:14%  \tVal_kappa : -0.192  \n",
            "Epoch: 248 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:17%  \tVal_kappa : -0.096  \n",
            "Epoch: 249 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:21%  \tVal_kappa : 0.093  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 01:16:07,964]\u001b[0m Trial 10 finished with value: 12.9 and parameters: {}. Best is trial 9 with value: 99.7.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:13%  \tVal_kappa : -0.190  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/DL_project/optimise_valid_ENI']"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl2yzEUGTLPz"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "s2gdFUvnpIpj",
        "outputId": "a8ce7eb1-3546-4ecd-8512-7267ac42c1a6"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_ENI_rain[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop()\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_ENI_RMSprops_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 0, 3, 1, 1, 1, 3, 3, 3, 2, 4, 1, 2, 1, 3, 3, 1, 2, 2, 0, 1, 1, 1, 1,\n",
            "        0, 2, 0, 1, 1, 4, 1, 4, 1, 4, 2, 2, 2, 2, 4, 4, 1, 4, 2, 1, 0, 3, 4, 3,\n",
            "        4, 2, 2, 1, 1, 1, 4, 1, 3, 4, 1, 2, 2, 2, 1, 1, 1, 0, 1, 1, 1, 2])\n",
            "labels tensor([0, 3, 3, 3, 0, 1, 1, 3, 2, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 3, 3, 0, 1, 0,\n",
            "        1, 0, 0, 1, 1, 2, 3, 3, 4, 1, 0, 1, 3, 4, 4, 4, 1, 1, 2, 1, 0, 0, 0, 2,\n",
            "        4, 3, 3, 3, 1, 2, 1, 2, 3, 4, 4, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2])\n",
            "correct : 25\n",
            "test_Accuracy % : 35.7\n",
            "kappa 0.2568292973875701\n",
            "[[ 3  9  6  1  2]\n",
            " [ 1 11  2  1  3]\n",
            " [ 0  2  4  4  1]\n",
            " [ 2  4  3  3  1]\n",
            " [ 0  2  1  0  4]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVDF4M_6B0G0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQyesQvLF5eh"
      },
      "source": [
        "### Training (no validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Mg_HBPF8MV"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_loaders_ENI(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:395], labelsTensors_ENI_rain[:395])\n",
        "    #validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_NSI_rain[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    #valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "   \n",
        "\n",
        "    return train_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGNhZx-8HGqc"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_ENI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "          'save_model' : True,\n",
        "          'lr'       :  0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "          'dropout'       : 0.5,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader = get_loaders_ENI(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "\n",
        "  train_accuracy = []\n",
        "  #valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  #valid_losses = []\n",
        "  \n",
        "  \n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "      #  valid_loss = 0\n",
        "      #  valid_correct = 0\n",
        "       train_acc = 0\n",
        "       #valid_acc = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "      #  with torch.no_grad(): \n",
        "      #     for batch_i, (data, target) in enumerate(valid_loader): \n",
        "      #         data, target = data.to(device), target.to(device)         \n",
        "      #         output = model(data)\n",
        "      #         output_c = output.cpu()\n",
        "      #         target_c = target.cpu()\n",
        "      #         loss = criterion(output_c, target_c) \n",
        "      #         valid_loss += loss.item()\n",
        "      #         valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "      #         valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "      #  valid_loss = valid_loss/len(valid_loader)\n",
        "      #  valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       #valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       #valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  '.format(epoch, train_loss, train_acc))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              #'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              #'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_ENI_RMSprops_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(train_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39L2JIzDIcYv",
        "outputId": "b9bf5953-bff1-45e5-93de-16446e7e6486"
      },
      "source": [
        "import joblib\n",
        "\n",
        "study.optimize(train_ENI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"./optuna_ENI_drop.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.656 \tTrain_Accu: 23%  \n",
            "Epoch: 2 \tTraining Loss:  1.615 \tTrain_Accu: 24%  \n",
            "Epoch: 3 \tTraining Loss:  1.591 \tTrain_Accu: 28%  \n",
            "Epoch: 4 \tTraining Loss:  1.582 \tTrain_Accu: 27%  \n",
            "Epoch: 5 \tTraining Loss:  1.555 \tTrain_Accu: 31%  \n",
            "Epoch: 6 \tTraining Loss:  1.514 \tTrain_Accu: 34%  \n",
            "Epoch: 7 \tTraining Loss:  1.479 \tTrain_Accu: 35%  \n",
            "Epoch: 8 \tTraining Loss:  1.460 \tTrain_Accu: 39%  \n",
            "Epoch: 9 \tTraining Loss:  1.435 \tTrain_Accu: 39%  \n",
            "Epoch: 10 \tTraining Loss:  1.367 \tTrain_Accu: 44%  \n",
            "Epoch: 11 \tTraining Loss:  1.318 \tTrain_Accu: 45%  \n",
            "Epoch: 12 \tTraining Loss:  1.252 \tTrain_Accu: 50%  \n",
            "Epoch: 13 \tTraining Loss:  1.222 \tTrain_Accu: 51%  \n",
            "Epoch: 14 \tTraining Loss:  1.133 \tTrain_Accu: 56%  \n",
            "Epoch: 15 \tTraining Loss:  1.116 \tTrain_Accu: 56%  \n",
            "Epoch: 16 \tTraining Loss:  1.068 \tTrain_Accu: 59%  \n",
            "Epoch: 17 \tTraining Loss:  1.050 \tTrain_Accu: 60%  \n",
            "Epoch: 18 \tTraining Loss:  0.924 \tTrain_Accu: 64%  \n",
            "Epoch: 19 \tTraining Loss:  0.859 \tTrain_Accu: 70%  \n",
            "Epoch: 20 \tTraining Loss:  0.818 \tTrain_Accu: 69%  \n",
            "Epoch: 21 \tTraining Loss:  0.857 \tTrain_Accu: 69%  \n",
            "Epoch: 22 \tTraining Loss:  0.751 \tTrain_Accu: 72%  \n",
            "Epoch: 23 \tTraining Loss:  0.713 \tTrain_Accu: 73%  \n",
            "Epoch: 24 \tTraining Loss:  0.671 \tTrain_Accu: 76%  \n",
            "Epoch: 25 \tTraining Loss:  0.721 \tTrain_Accu: 75%  \n",
            "Epoch: 26 \tTraining Loss:  0.633 \tTrain_Accu: 74%  \n",
            "Epoch: 27 \tTraining Loss:  0.556 \tTrain_Accu: 81%  \n",
            "Epoch: 28 \tTraining Loss:  0.580 \tTrain_Accu: 79%  \n",
            "Epoch: 29 \tTraining Loss:  0.524 \tTrain_Accu: 83%  \n",
            "Epoch: 30 \tTraining Loss:  0.515 \tTrain_Accu: 83%  \n",
            "Epoch: 31 \tTraining Loss:  0.458 \tTrain_Accu: 85%  \n",
            "Epoch: 32 \tTraining Loss:  0.456 \tTrain_Accu: 85%  \n",
            "Epoch: 33 \tTraining Loss:  0.411 \tTrain_Accu: 86%  \n",
            "Epoch: 34 \tTraining Loss:  0.376 \tTrain_Accu: 88%  \n",
            "Epoch: 35 \tTraining Loss:  0.369 \tTrain_Accu: 88%  \n",
            "Epoch: 36 \tTraining Loss:  0.370 \tTrain_Accu: 87%  \n",
            "Epoch: 37 \tTraining Loss:  0.386 \tTrain_Accu: 88%  \n",
            "Epoch: 38 \tTraining Loss:  0.355 \tTrain_Accu: 87%  \n",
            "Epoch: 39 \tTraining Loss:  0.345 \tTrain_Accu: 87%  \n",
            "Epoch: 40 \tTraining Loss:  0.351 \tTrain_Accu: 89%  \n",
            "Epoch: 41 \tTraining Loss:  0.293 \tTrain_Accu: 89%  \n",
            "Epoch: 42 \tTraining Loss:  0.291 \tTrain_Accu: 90%  \n",
            "Epoch: 43 \tTraining Loss:  0.285 \tTrain_Accu: 89%  \n",
            "Epoch: 44 \tTraining Loss:  0.263 \tTrain_Accu: 91%  \n",
            "Epoch: 45 \tTraining Loss:  0.235 \tTrain_Accu: 92%  \n",
            "Epoch: 46 \tTraining Loss:  0.269 \tTrain_Accu: 91%  \n",
            "Epoch: 47 \tTraining Loss:  0.248 \tTrain_Accu: 92%  \n",
            "Epoch: 48 \tTraining Loss:  0.225 \tTrain_Accu: 92%  \n",
            "Epoch: 49 \tTraining Loss:  0.207 \tTrain_Accu: 93%  \n",
            "Epoch: 50 \tTraining Loss:  0.248 \tTrain_Accu: 92%  \n",
            "Epoch: 51 \tTraining Loss:  0.230 \tTrain_Accu: 93%  \n",
            "Epoch: 52 \tTraining Loss:  0.198 \tTrain_Accu: 92%  \n",
            "Epoch: 53 \tTraining Loss:  0.229 \tTrain_Accu: 92%  \n",
            "Epoch: 54 \tTraining Loss:  0.204 \tTrain_Accu: 93%  \n",
            "Epoch: 55 \tTraining Loss:  0.146 \tTrain_Accu: 95%  \n",
            "Epoch: 56 \tTraining Loss:  0.176 \tTrain_Accu: 94%  \n",
            "Epoch: 57 \tTraining Loss:  0.161 \tTrain_Accu: 94%  \n",
            "Epoch: 58 \tTraining Loss:  0.177 \tTrain_Accu: 96%  \n",
            "Epoch: 59 \tTraining Loss:  0.189 \tTrain_Accu: 93%  \n",
            "Epoch: 60 \tTraining Loss:  0.146 \tTrain_Accu: 96%  \n",
            "Epoch: 61 \tTraining Loss:  0.116 \tTrain_Accu: 97%  \n",
            "Epoch: 62 \tTraining Loss:  0.135 \tTrain_Accu: 95%  \n",
            "Epoch: 63 \tTraining Loss:  0.219 \tTrain_Accu: 93%  \n",
            "Epoch: 64 \tTraining Loss:  0.139 \tTrain_Accu: 96%  \n",
            "Epoch: 65 \tTraining Loss:  0.136 \tTrain_Accu: 95%  \n",
            "Epoch: 66 \tTraining Loss:  0.140 \tTrain_Accu: 95%  \n",
            "Epoch: 67 \tTraining Loss:  0.144 \tTrain_Accu: 96%  \n",
            "Epoch: 68 \tTraining Loss:  0.115 \tTrain_Accu: 96%  \n",
            "Epoch: 69 \tTraining Loss:  0.090 \tTrain_Accu: 97%  \n",
            "Epoch: 70 \tTraining Loss:  0.099 \tTrain_Accu: 96%  \n",
            "Epoch: 71 \tTraining Loss:  0.113 \tTrain_Accu: 96%  \n",
            "Epoch: 72 \tTraining Loss:  0.133 \tTrain_Accu: 97%  \n",
            "Epoch: 73 \tTraining Loss:  0.172 \tTrain_Accu: 94%  \n",
            "Epoch: 74 \tTraining Loss:  0.119 \tTrain_Accu: 96%  \n",
            "Epoch: 75 \tTraining Loss:  0.091 \tTrain_Accu: 97%  \n",
            "Epoch: 76 \tTraining Loss:  0.116 \tTrain_Accu: 96%  \n",
            "Epoch: 77 \tTraining Loss:  0.078 \tTrain_Accu: 97%  \n",
            "Epoch: 78 \tTraining Loss:  0.097 \tTrain_Accu: 97%  \n",
            "Epoch: 79 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \n",
            "Epoch: 80 \tTraining Loss:  0.097 \tTrain_Accu: 97%  \n",
            "Epoch: 81 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \n",
            "Epoch: 82 \tTraining Loss:  0.101 \tTrain_Accu: 96%  \n",
            "Epoch: 83 \tTraining Loss:  0.074 \tTrain_Accu: 98%  \n",
            "Epoch: 84 \tTraining Loss:  0.092 \tTrain_Accu: 96%  \n",
            "Epoch: 85 \tTraining Loss:  0.154 \tTrain_Accu: 95%  \n",
            "Epoch: 86 \tTraining Loss:  0.113 \tTrain_Accu: 96%  \n",
            "Epoch: 87 \tTraining Loss:  0.117 \tTrain_Accu: 96%  \n",
            "Epoch: 88 \tTraining Loss:  0.077 \tTrain_Accu: 98%  \n",
            "Epoch: 89 \tTraining Loss:  0.084 \tTrain_Accu: 97%  \n",
            "Epoch: 90 \tTraining Loss:  0.120 \tTrain_Accu: 95%  \n",
            "Epoch: 91 \tTraining Loss:  0.068 \tTrain_Accu: 98%  \n",
            "Epoch: 92 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \n",
            "Epoch: 93 \tTraining Loss:  0.087 \tTrain_Accu: 97%  \n",
            "Epoch: 94 \tTraining Loss:  0.087 \tTrain_Accu: 97%  \n",
            "Epoch: 95 \tTraining Loss:  0.068 \tTrain_Accu: 97%  \n",
            "Epoch: 96 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \n",
            "Epoch: 97 \tTraining Loss:  0.113 \tTrain_Accu: 96%  \n",
            "Epoch: 98 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \n",
            "Epoch: 99 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 100 \tTraining Loss:  0.063 \tTrain_Accu: 97%  \n",
            "Epoch: 101 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \n",
            "Epoch: 102 \tTraining Loss:  0.077 \tTrain_Accu: 98%  \n",
            "Epoch: 103 \tTraining Loss:  0.056 \tTrain_Accu: 99%  \n",
            "Epoch: 104 \tTraining Loss:  0.092 \tTrain_Accu: 97%  \n",
            "Epoch: 105 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \n",
            "Epoch: 106 \tTraining Loss:  0.091 \tTrain_Accu: 95%  \n",
            "Epoch: 107 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \n",
            "Epoch: 108 \tTraining Loss:  0.092 \tTrain_Accu: 97%  \n",
            "Epoch: 109 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \n",
            "Epoch: 110 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \n",
            "Epoch: 111 \tTraining Loss:  0.105 \tTrain_Accu: 95%  \n",
            "Epoch: 112 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \n",
            "Epoch: 113 \tTraining Loss:  0.047 \tTrain_Accu: 99%  \n",
            "Epoch: 114 \tTraining Loss:  0.078 \tTrain_Accu: 98%  \n",
            "Epoch: 115 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 116 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \n",
            "Epoch: 117 \tTraining Loss:  0.084 \tTrain_Accu: 97%  \n",
            "Epoch: 118 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \n",
            "Epoch: 119 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \n",
            "Epoch: 120 \tTraining Loss:  0.084 \tTrain_Accu: 97%  \n",
            "Epoch: 121 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \n",
            "Epoch: 122 \tTraining Loss:  0.066 \tTrain_Accu: 98%  \n",
            "Epoch: 123 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \n",
            "Epoch: 124 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 125 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \n",
            "Epoch: 126 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \n",
            "Epoch: 127 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \n",
            "Epoch: 128 \tTraining Loss:  0.085 \tTrain_Accu: 98%  \n",
            "Epoch: 129 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 130 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \n",
            "Epoch: 131 \tTraining Loss:  0.071 \tTrain_Accu: 97%  \n",
            "Epoch: 132 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \n",
            "Epoch: 133 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \n",
            "Epoch: 134 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 135 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \n",
            "Epoch: 136 \tTraining Loss:  0.074 \tTrain_Accu: 97%  \n",
            "Epoch: 137 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \n",
            "Epoch: 138 \tTraining Loss:  0.054 \tTrain_Accu: 99%  \n",
            "Epoch: 139 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \n",
            "Epoch: 140 \tTraining Loss:  0.085 \tTrain_Accu: 97%  \n",
            "Epoch: 141 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \n",
            "Epoch: 142 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \n",
            "Epoch: 143 \tTraining Loss:  0.070 \tTrain_Accu: 97%  \n",
            "Epoch: 144 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \n",
            "Epoch: 145 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 146 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 147 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \n",
            "Epoch: 148 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \n",
            "Epoch: 149 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 150 \tTraining Loss:  0.058 \tTrain_Accu: 97%  \n",
            "Epoch: 151 \tTraining Loss:  0.114 \tTrain_Accu: 95%  \n",
            "Epoch: 152 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \n",
            "Epoch: 153 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \n",
            "Epoch: 154 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 155 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \n",
            "Epoch: 156 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \n",
            "Epoch: 157 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 158 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 159 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \n",
            "Epoch: 160 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \n",
            "Epoch: 161 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \n",
            "Epoch: 162 \tTraining Loss:  0.032 \tTrain_Accu: 99%  \n",
            "Epoch: 163 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \n",
            "Epoch: 164 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 165 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \n",
            "Epoch: 166 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \n",
            "Epoch: 167 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \n",
            "Epoch: 168 \tTraining Loss:  0.045 \tTrain_Accu: 99%  \n",
            "Epoch: 169 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \n",
            "Epoch: 170 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \n",
            "Epoch: 171 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 172 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \n",
            "Epoch: 173 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 174 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \n",
            "Epoch: 175 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \n",
            "Epoch: 176 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \n",
            "Epoch: 177 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 178 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \n",
            "Epoch: 179 \tTraining Loss:  0.043 \tTrain_Accu: 99%  \n",
            "Epoch: 180 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \n",
            "Epoch: 181 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 182 \tTraining Loss:  0.053 \tTrain_Accu: 99%  \n",
            "Epoch: 183 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 184 \tTraining Loss:  0.050 \tTrain_Accu: 99%  \n",
            "Epoch: 185 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \n",
            "Epoch: 186 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 187 \tTraining Loss:  0.047 \tTrain_Accu: 97%  \n",
            "Epoch: 188 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 189 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 190 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 191 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \n",
            "Epoch: 192 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 193 \tTraining Loss:  0.016 \tTrain_Accu: 100%  \n",
            "Epoch: 194 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \n",
            "Epoch: 195 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \n",
            "Epoch: 196 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 197 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \n",
            "Epoch: 198 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \n",
            "Epoch: 199 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \n",
            "Epoch: 200 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \n",
            "Epoch: 201 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \n",
            "Epoch: 202 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \n",
            "Epoch: 203 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \n",
            "Epoch: 204 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \n",
            "Epoch: 205 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 206 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \n",
            "Epoch: 207 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \n",
            "Epoch: 208 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \n",
            "Epoch: 209 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \n",
            "Epoch: 210 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 211 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \n",
            "Epoch: 212 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \n",
            "Epoch: 213 \tTraining Loss:  0.014 \tTrain_Accu: 99%  \n",
            "Epoch: 214 \tTraining Loss:  0.045 \tTrain_Accu: 97%  \n",
            "Epoch: 215 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 216 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \n",
            "Epoch: 217 \tTraining Loss:  0.016 \tTrain_Accu: 99%  \n",
            "Epoch: 218 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \n",
            "Epoch: 219 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \n",
            "Epoch: 220 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \n",
            "Epoch: 221 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \n",
            "Epoch: 222 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 223 \tTraining Loss:  0.015 \tTrain_Accu: 100%  \n",
            "Epoch: 224 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \n",
            "Epoch: 225 \tTraining Loss:  0.009 \tTrain_Accu: 100%  \n",
            "Epoch: 226 \tTraining Loss:  0.025 \tTrain_Accu: 99%  \n",
            "Epoch: 227 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \n",
            "Epoch: 228 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \n",
            "Epoch: 229 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 230 \tTraining Loss:  0.012 \tTrain_Accu: 99%  \n",
            "Epoch: 231 \tTraining Loss:  0.015 \tTrain_Accu: 99%  \n",
            "Epoch: 232 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \n",
            "Epoch: 233 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \n",
            "Epoch: 234 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \n",
            "Epoch: 235 \tTraining Loss:  0.020 \tTrain_Accu: 100%  \n",
            "Epoch: 236 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 237 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \n",
            "Epoch: 238 \tTraining Loss:  0.045 \tTrain_Accu: 99%  \n",
            "Epoch: 239 \tTraining Loss:  0.040 \tTrain_Accu: 99%  \n",
            "Epoch: 240 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \n",
            "Epoch: 241 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \n",
            "Epoch: 242 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 243 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \n",
            "Epoch: 244 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \n",
            "Epoch: 245 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \n",
            "Epoch: 246 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \n",
            "Epoch: 247 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n",
            "Epoch: 248 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \n",
            "Epoch: 249 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 01:29:37,987]\u001b[0m Trial 12 finished with value: 99.5 and parameters: {}. Best is trial 9 with value: 99.7.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./optuna_ENI_drop.torch']"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIc4_a_XGATl"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "xK6hKitCErfV",
        "outputId": "0e736345-f2fc-4fe7-e52b-640f8c18df05"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_ENI_rain[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop()\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_ENI_RMSprops_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3, 4, 3, 3, 1, 1, 2, 1, 4, 3, 2, 3, 4, 1, 2, 3, 1, 2, 1, 3, 1, 1, 3, 0,\n",
            "        0, 0, 0, 0, 4, 2, 4, 4, 1, 4, 3, 1, 1, 2, 1, 4, 1, 1, 4, 1, 4, 4, 0, 3,\n",
            "        3, 3, 4, 4, 1, 3, 1, 1, 4, 4, 3, 4, 2, 0, 4, 1, 0, 4, 1, 1, 1, 1])\n",
            "labels tensor([0, 3, 3, 3, 0, 1, 1, 3, 2, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 3, 3, 0, 1, 0,\n",
            "        1, 0, 0, 1, 1, 2, 3, 3, 4, 1, 0, 1, 3, 4, 4, 4, 1, 1, 2, 1, 0, 0, 0, 2,\n",
            "        4, 3, 3, 3, 1, 2, 1, 2, 3, 4, 4, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2])\n",
            "correct : 25\n",
            "test_Accuracy % : 35.7\n",
            "kappa 0.2730272736096284\n",
            "[[ 6  4  2  4  5]\n",
            " [ 2 11  2  1  2]\n",
            " [ 0  3  2  3  3]\n",
            " [ 0  3  0  4  6]\n",
            " [ 0  2  1  2  2]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkqsPcxkyp9S"
      },
      "source": [
        "# Temperature data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G28tnvkyp9W"
      },
      "source": [
        "## NNI_temp hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS4jApzdyp9W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "35743866-d050-4d2e-b69b-28058bbf0f0a"
      },
      "source": [
        "# Reading rainfall file of NNI region \n",
        "Data_temp_NNI = pd.read_csv(\"drive/My Drive/DL_project/Target_TMean_NNI_regional_ave_time_series.csv\")\n",
        "Data_temp_NNI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>Tmean_N</th>\n",
              "      <th>cat_3</th>\n",
              "      <th>cat_5</th>\n",
              "      <th>anomalies</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-04-01</td>\n",
              "      <td>17.561887</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.964548</td>\n",
              "      <td>NNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-05-01</td>\n",
              "      <td>15.096590</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.653660</td>\n",
              "      <td>NNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-06-01</td>\n",
              "      <td>12.515731</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.390654</td>\n",
              "      <td>NNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-07-01</td>\n",
              "      <td>10.417690</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.035998</td>\n",
              "      <td>NNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-08-01</td>\n",
              "      <td>9.586142</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.037651</td>\n",
              "      <td>NNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>2019-08-01</td>\n",
              "      <td>10.106427</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.482634</td>\n",
              "      <td>NNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>10.697352</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.590812</td>\n",
              "      <td>NNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>2019-10-01</td>\n",
              "      <td>11.546830</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.230155</td>\n",
              "      <td>NNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>13.554716</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.620366</td>\n",
              "      <td>NNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>15.547866</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.824600</td>\n",
              "      <td>NNI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>465 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           time    Tmean_N  cat_3  cat_5  anomalies region\n",
              "0    1981-04-01  17.561887      3      5   0.964548    NNI\n",
              "1    1981-05-01  15.096590      3      5   0.653660    NNI\n",
              "2    1981-06-01  12.515731      3      4   0.390654    NNI\n",
              "3    1981-07-01  10.417690      2      3   0.035998    NNI\n",
              "4    1981-08-01   9.586142      2      3  -0.037651    NNI\n",
              "..          ...        ...    ...    ...        ...    ...\n",
              "460  2019-08-01  10.106427      3      5   0.482634    NNI\n",
              "461  2019-09-01  10.697352      3      5   0.590812    NNI\n",
              "462  2019-10-01  11.546830      3      4   0.230155    NNI\n",
              "463  2019-11-01  13.554716      3      5   0.620366    NNI\n",
              "464  2019-12-01  15.547866      3      5   0.824600    NNI\n",
              "\n",
              "[465 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nlzComGyp9X"
      },
      "source": [
        "# Extracting lable column\n",
        "labels_temp_NNI = Data_temp_NNI['cat_5'].astype(int) #cat5 column - so 5 prediction classes "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kno9k2ATyp9X"
      },
      "source": [
        "# Function that will convert labels into Pytorch tensors\n",
        "\n",
        "def labels_Tensors(labels):\n",
        "    return (torch.from_numpy(labels.values).type(torch.LongTensor)-1) #cat5 in form 1, 2, 3, 4, 5;\n",
        "\n",
        "# Converting labels of Temp_NNI region into tensors\n",
        "labelsTensors_temp_NNI = labels_Tensors(labels_temp_NNI) # This represents y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OnUEX10knoV",
        "outputId": "4acc94a2-e00f-4b1e-f748-fae6d722d038"
      },
      "source": [
        "labelsTensors_temp_NNI.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bHQzzrWyp9X",
        "outputId": "40796b42-2f58-4421-e75a-bb91e85b57f8"
      },
      "source": [
        "# Train lables distribution\n",
        "Train_labels = labels_temp_NNI[:325]\n",
        "Train_labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    69\n",
              "2    69\n",
              "1    69\n",
              "3    62\n",
              "4    55\n",
              "Name: cat_5, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBMlj3BIyp9Y"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_valid_loaders_NNI_temp(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_NNI[:325])\n",
        "    validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_NNI[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZR7eSfYnpiD"
      },
      "source": [
        "NNI temperature experiments with different batch sizes, lr, optimisers, dropout rates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGzNl8GQo_tw"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_NNI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "         'Batch_size' : trial.suggest_int('Batch_size', 1, 10),\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "          'save_model' : True,\n",
        "          'lr'       : trial.suggest_categorical('lr', [0.1, 0.01, 0.001, 0.0001]),          \n",
        "          'optimizer': trial.suggest_categorical('optimizer',[optim.SGD, optim.Adam, optim.RMSprop]),\n",
        "          'dropout'       : trial.suggest_categorical('dropout', [0.5, 0.7,0.9 ]),\n",
        "          'activation': F.relu}\n",
        "\n",
        "  # Loss function is defined\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # Defining device to run experiments on GPU if available\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  # Calling dataloader function\n",
        "  train_loader, valid_loader = get_valid_loaders_NNI_temp(cfg['Batch_size'])\n",
        "  # Defining CNN model\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  # Setting optimizer\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "   \n",
        "  # Training steps\n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  \n",
        "  \n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "     \n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "       \n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           # Putting data and target on device to run on GPU \n",
        "           data, target = data.to(device), target.to(device)\n",
        "           # making zero gradient\n",
        "           optimizer.zero_grad()\n",
        "           # predicting new values by inserting input\n",
        "           output = model(data)\n",
        "           # bring model output and target back on CPU\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           # clculating loss\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           # calculate gradient\n",
        "           loss.backward()\n",
        "           # update weights\n",
        "           optimizer.step()\n",
        "           #Storing training loss \n",
        "           train_loss += loss.item()\n",
        "           # Calculating number of correct label predictions\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              # Putting data and target on device to run on GPU \n",
        "              data, target = data.to(device), target.to(device) \n",
        "              # predicting new values by inserting input        \n",
        "              output = model(data)\n",
        "              # bring model output and target back on CPU\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              # clculating loss\n",
        "              loss = criterion(output_c, target_c) \n",
        "              #Storing validation loss \n",
        "              valid_loss += loss.item()\n",
        "              # Calculating number of correct label predictions\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "\n",
        "       #calculating average training loss      \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       # calculating training accuracy \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       #calculating average validation loss \n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       #calculating validation accuracy \n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       # Combining training and validation accuracy for each epoch to plot accuracy curves\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       # Combining training and validation loss for each epoch to plot loss curves\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}% \\t Valid Loss:{: .3f} '.format(epoch, train_loss, train_acc, valid_acc, valid_loss))  \n",
        "\n",
        "\n",
        "       # Save model\n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/My Drive/DL_project/check_valid_NNI_RMSprops_temp.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hqXVuxYw_lz",
        "outputId": "6c367627-5fba-4ab6-aa70-5d2becfc0de2"
      },
      "source": [
        "study = optuna.create_study(sampler=optuna.samplers.TPESampler(), direction='maximize')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 01:31:21,196]\u001b[0m A new study created in memory with name: no-name-27efb145-8500-4a14-96b1-acbcd97b1688\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsaf2nCYyp9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e162231-7946-4c13-d8c4-b64bf0e91f6c"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_NNI, n_trials=10)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"drive/My Drive/DL_project/optimise_valid_NNI_temp.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  39965914.690 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 4.036 \n",
            "Epoch: 2 \tTraining Loss:  2.446 \tTrain_Accu: 18%  \tValid_Acc:27% \t Valid Loss: 2.336 \n",
            "Epoch: 3 \tTraining Loss:  1.655 \tTrain_Accu: 23%  \tValid_Acc:17% \t Valid Loss: 1.648 \n",
            "Epoch: 4 \tTraining Loss:  1.697 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.612 \n",
            "Epoch: 5 \tTraining Loss:  1.645 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.652 \n",
            "Epoch: 6 \tTraining Loss:  3.645 \tTrain_Accu: 20%  \tValid_Acc:33% \t Valid Loss: 2.316 \n",
            "Epoch: 7 \tTraining Loss:  1.729 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.692 \n",
            "Epoch: 8 \tTraining Loss:  1.625 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.560 \n",
            "Epoch: 9 \tTraining Loss:  1.634 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.587 \n",
            "Epoch: 10 \tTraining Loss:  1.640 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.661 \n",
            "Epoch: 11 \tTraining Loss:  1.639 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.598 \n",
            "Epoch: 12 \tTraining Loss:  1.634 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.701 \n",
            "Epoch: 13 \tTraining Loss:  1.638 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 14 \tTraining Loss:  1.636 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.653 \n",
            "Epoch: 15 \tTraining Loss:  1.633 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.585 \n",
            "Epoch: 16 \tTraining Loss:  1.640 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.664 \n",
            "Epoch: 17 \tTraining Loss:  1.640 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.675 \n",
            "Epoch: 18 \tTraining Loss:  1.629 \tTrain_Accu: 21%  \tValid_Acc:33% \t Valid Loss: 1.619 \n",
            "Epoch: 19 \tTraining Loss:  1.631 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.717 \n",
            "Epoch: 20 \tTraining Loss:  1.641 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.598 \n",
            "Epoch: 21 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.673 \n",
            "Epoch: 22 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:33% \t Valid Loss: 1.577 \n",
            "Epoch: 23 \tTraining Loss:  1.635 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.646 \n",
            "Epoch: 24 \tTraining Loss:  1.641 \tTrain_Accu: 15%  \tValid_Acc:7% \t Valid Loss: 1.650 \n",
            "Epoch: 25 \tTraining Loss:  1.637 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.689 \n",
            "Epoch: 26 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.695 \n",
            "Epoch: 27 \tTraining Loss:  1.640 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.659 \n",
            "Epoch: 28 \tTraining Loss:  1.629 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.618 \n",
            "Epoch: 29 \tTraining Loss:  1.638 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.729 \n",
            "Epoch: 30 \tTraining Loss:  1.643 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.600 \n",
            "Epoch: 31 \tTraining Loss:  1.637 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 32 \tTraining Loss:  1.634 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.688 \n",
            "Epoch: 33 \tTraining Loss:  1.643 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 34 \tTraining Loss:  1.637 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.626 \n",
            "Epoch: 35 \tTraining Loss:  1.636 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.638 \n",
            "Epoch: 36 \tTraining Loss:  1.622 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.616 \n",
            "Epoch: 37 \tTraining Loss:  1.630 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.631 \n",
            "Epoch: 38 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.614 \n",
            "Epoch: 39 \tTraining Loss:  1.626 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 40 \tTraining Loss:  1.635 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.601 \n",
            "Epoch: 41 \tTraining Loss:  1.630 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.690 \n",
            "Epoch: 42 \tTraining Loss:  1.634 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.613 \n",
            "Epoch: 43 \tTraining Loss:  1.635 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.592 \n",
            "Epoch: 44 \tTraining Loss:  1.620 \tTrain_Accu: 24%  \tValid_Acc:17% \t Valid Loss: 1.659 \n",
            "Epoch: 45 \tTraining Loss:  1.629 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.680 \n",
            "Epoch: 46 \tTraining Loss:  1.637 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.698 \n",
            "Epoch: 47 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.659 \n",
            "Epoch: 48 \tTraining Loss:  1.644 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.651 \n",
            "Epoch: 49 \tTraining Loss:  1.636 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.662 \n",
            "Epoch: 50 \tTraining Loss:  1.629 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 51 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.600 \n",
            "Epoch: 52 \tTraining Loss:  1.643 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.654 \n",
            "Epoch: 53 \tTraining Loss:  1.628 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.537 \n",
            "Epoch: 54 \tTraining Loss:  1.633 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.687 \n",
            "Epoch: 55 \tTraining Loss:  1.635 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.656 \n",
            "Epoch: 56 \tTraining Loss:  1.638 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.603 \n",
            "Epoch: 57 \tTraining Loss:  1.633 \tTrain_Accu: 20%  \tValid_Acc:33% \t Valid Loss: 1.639 \n",
            "Epoch: 58 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.590 \n",
            "Epoch: 59 \tTraining Loss:  1.638 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.632 \n",
            "Epoch: 60 \tTraining Loss:  1.641 \tTrain_Accu: 14%  \tValid_Acc:26% \t Valid Loss: 1.619 \n",
            "Epoch: 61 \tTraining Loss:  1.641 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.645 \n",
            "Epoch: 62 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.648 \n",
            "Epoch: 63 \tTraining Loss:  1.634 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 64 \tTraining Loss:  1.641 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.651 \n",
            "Epoch: 65 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.707 \n",
            "Epoch: 66 \tTraining Loss:  1.638 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.621 \n",
            "Epoch: 67 \tTraining Loss:  1.634 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.681 \n",
            "Epoch: 68 \tTraining Loss:  1.639 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.612 \n",
            "Epoch: 69 \tTraining Loss:  1.642 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.657 \n",
            "Epoch: 70 \tTraining Loss:  1.630 \tTrain_Accu: 24%  \tValid_Acc:17% \t Valid Loss: 1.598 \n",
            "Epoch: 71 \tTraining Loss:  1.632 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.569 \n",
            "Epoch: 72 \tTraining Loss:  1.635 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 73 \tTraining Loss:  1.640 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.643 \n",
            "Epoch: 74 \tTraining Loss:  1.637 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.683 \n",
            "Epoch: 75 \tTraining Loss:  1.632 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.737 \n",
            "Epoch: 76 \tTraining Loss:  1.638 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.650 \n",
            "Epoch: 77 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.727 \n",
            "Epoch: 78 \tTraining Loss:  1.637 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.667 \n",
            "Epoch: 79 \tTraining Loss:  1.637 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.702 \n",
            "Epoch: 80 \tTraining Loss:  1.630 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.681 \n",
            "Epoch: 81 \tTraining Loss:  1.632 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.746 \n",
            "Epoch: 82 \tTraining Loss:  1.642 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.668 \n",
            "Epoch: 83 \tTraining Loss:  1.616 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.766 \n",
            "Epoch: 84 \tTraining Loss:  1.643 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.605 \n",
            "Epoch: 85 \tTraining Loss:  1.639 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.666 \n",
            "Epoch: 86 \tTraining Loss:  1.624 \tTrain_Accu: 20%  \tValid_Acc:33% \t Valid Loss: 1.609 \n",
            "Epoch: 87 \tTraining Loss:  1.640 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.600 \n",
            "Epoch: 88 \tTraining Loss:  1.643 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.674 \n",
            "Epoch: 89 \tTraining Loss:  1.633 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.615 \n",
            "Epoch: 90 \tTraining Loss:  1.624 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.698 \n",
            "Epoch: 91 \tTraining Loss:  1.636 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.621 \n",
            "Epoch: 92 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 93 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.583 \n",
            "Epoch: 94 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.683 \n",
            "Epoch: 95 \tTraining Loss:  1.630 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 96 \tTraining Loss:  1.632 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.622 \n",
            "Epoch: 97 \tTraining Loss:  1.628 \tTrain_Accu: 23%  \tValid_Acc:33% \t Valid Loss: 1.554 \n",
            "Epoch: 98 \tTraining Loss:  1.639 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.744 \n",
            "Epoch: 99 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.716 \n",
            "Epoch: 100 \tTraining Loss:  1.636 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.696 \n",
            "Epoch: 101 \tTraining Loss:  1.644 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.704 \n",
            "Epoch: 102 \tTraining Loss:  1.637 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.708 \n",
            "Epoch: 103 \tTraining Loss:  1.632 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.649 \n",
            "Epoch: 104 \tTraining Loss:  1.637 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 105 \tTraining Loss:  1.636 \tTrain_Accu: 14%  \tValid_Acc:26% \t Valid Loss: 1.570 \n",
            "Epoch: 106 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.572 \n",
            "Epoch: 107 \tTraining Loss:  1.637 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.642 \n",
            "Epoch: 108 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 109 \tTraining Loss:  1.630 \tTrain_Accu: 22%  \tValid_Acc:33% \t Valid Loss: 1.587 \n",
            "Epoch: 110 \tTraining Loss:  1.624 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.660 \n",
            "Epoch: 111 \tTraining Loss:  1.641 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.585 \n",
            "Epoch: 112 \tTraining Loss:  1.632 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.726 \n",
            "Epoch: 113 \tTraining Loss:  1.628 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.594 \n",
            "Epoch: 114 \tTraining Loss:  1.647 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 115 \tTraining Loss:  1.640 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.627 \n",
            "Epoch: 116 \tTraining Loss:  1.631 \tTrain_Accu: 26%  \tValid_Acc:17% \t Valid Loss: 1.607 \n",
            "Epoch: 117 \tTraining Loss:  1.627 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.566 \n",
            "Epoch: 118 \tTraining Loss:  1.635 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.614 \n",
            "Epoch: 119 \tTraining Loss:  1.631 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.674 \n",
            "Epoch: 120 \tTraining Loss:  1.630 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.651 \n",
            "Epoch: 121 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.644 \n",
            "Epoch: 122 \tTraining Loss:  1.630 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.674 \n",
            "Epoch: 123 \tTraining Loss:  1.638 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.670 \n",
            "Epoch: 124 \tTraining Loss:  1.623 \tTrain_Accu: 24%  \tValid_Acc:33% \t Valid Loss: 1.617 \n",
            "Epoch: 125 \tTraining Loss:  1.639 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.621 \n",
            "Epoch: 126 \tTraining Loss:  1.641 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 127 \tTraining Loss:  1.636 \tTrain_Accu: 15%  \tValid_Acc:7% \t Valid Loss: 1.743 \n",
            "Epoch: 128 \tTraining Loss:  1.636 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.649 \n",
            "Epoch: 129 \tTraining Loss:  1.636 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.667 \n",
            "Epoch: 130 \tTraining Loss:  1.629 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.763 \n",
            "Epoch: 131 \tTraining Loss:  1.632 \tTrain_Accu: 19%  \tValid_Acc:33% \t Valid Loss: 1.582 \n",
            "Epoch: 132 \tTraining Loss:  1.638 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.607 \n",
            "Epoch: 133 \tTraining Loss:  1.640 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.653 \n",
            "Epoch: 134 \tTraining Loss:  1.640 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.690 \n",
            "Epoch: 135 \tTraining Loss:  1.638 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.662 \n",
            "Epoch: 136 \tTraining Loss:  1.626 \tTrain_Accu: 23%  \tValid_Acc:7% \t Valid Loss: 1.721 \n",
            "Epoch: 137 \tTraining Loss:  1.636 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.600 \n",
            "Epoch: 138 \tTraining Loss:  1.636 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.606 \n",
            "Epoch: 139 \tTraining Loss:  1.632 \tTrain_Accu: 19%  \tValid_Acc:33% \t Valid Loss: 1.574 \n",
            "Epoch: 140 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.615 \n",
            "Epoch: 141 \tTraining Loss:  1.631 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.623 \n",
            "Epoch: 142 \tTraining Loss:  1.630 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.806 \n",
            "Epoch: 143 \tTraining Loss:  1.634 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.565 \n",
            "Epoch: 144 \tTraining Loss:  1.640 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.642 \n",
            "Epoch: 145 \tTraining Loss:  1.636 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.686 \n",
            "Epoch: 146 \tTraining Loss:  1.634 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.681 \n",
            "Epoch: 147 \tTraining Loss:  1.642 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.617 \n",
            "Epoch: 148 \tTraining Loss:  1.623 \tTrain_Accu: 23%  \tValid_Acc:17% \t Valid Loss: 1.577 \n",
            "Epoch: 149 \tTraining Loss:  1.640 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.654 \n",
            "Epoch: 150 \tTraining Loss:  1.630 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 151 \tTraining Loss:  1.634 \tTrain_Accu: 19%  \tValid_Acc:33% \t Valid Loss: 1.584 \n",
            "Epoch: 152 \tTraining Loss:  1.618 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.742 \n",
            "Epoch: 153 \tTraining Loss:  1.631 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.759 \n",
            "Epoch: 154 \tTraining Loss:  1.629 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.692 \n",
            "Epoch: 155 \tTraining Loss:  1.633 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.661 \n",
            "Epoch: 156 \tTraining Loss:  1.639 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.625 \n",
            "Epoch: 157 \tTraining Loss:  1.633 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.709 \n",
            "Epoch: 158 \tTraining Loss:  1.641 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.615 \n",
            "Epoch: 159 \tTraining Loss:  1.636 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.650 \n",
            "Epoch: 160 \tTraining Loss:  1.644 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.621 \n",
            "Epoch: 161 \tTraining Loss:  1.636 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 162 \tTraining Loss:  1.636 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.671 \n",
            "Epoch: 163 \tTraining Loss:  1.637 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.683 \n",
            "Epoch: 164 \tTraining Loss:  1.638 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.653 \n",
            "Epoch: 165 \tTraining Loss:  1.632 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.572 \n",
            "Epoch: 166 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.612 \n",
            "Epoch: 167 \tTraining Loss:  1.629 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.629 \n",
            "Epoch: 168 \tTraining Loss:  1.639 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.660 \n",
            "Epoch: 169 \tTraining Loss:  1.629 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.624 \n",
            "Epoch: 170 \tTraining Loss:  1.640 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.643 \n",
            "Epoch: 171 \tTraining Loss:  1.626 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.643 \n",
            "Epoch: 172 \tTraining Loss:  1.640 \tTrain_Accu: 18%  \tValid_Acc:33% \t Valid Loss: 1.586 \n",
            "Epoch: 173 \tTraining Loss:  1.637 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.603 \n",
            "Epoch: 174 \tTraining Loss:  1.630 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.641 \n",
            "Epoch: 175 \tTraining Loss:  1.641 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.691 \n",
            "Epoch: 176 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.684 \n",
            "Epoch: 177 \tTraining Loss:  1.634 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.684 \n",
            "Epoch: 178 \tTraining Loss:  1.636 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.696 \n",
            "Epoch: 179 \tTraining Loss:  1.639 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.647 \n",
            "Epoch: 180 \tTraining Loss:  1.630 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.561 \n",
            "Epoch: 181 \tTraining Loss:  1.633 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.683 \n",
            "Epoch: 182 \tTraining Loss:  1.642 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.609 \n",
            "Epoch: 183 \tTraining Loss:  1.634 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.696 \n",
            "Epoch: 184 \tTraining Loss:  1.631 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.658 \n",
            "Epoch: 185 \tTraining Loss:  1.638 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.669 \n",
            "Epoch: 186 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.691 \n",
            "Epoch: 187 \tTraining Loss:  1.637 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.647 \n",
            "Epoch: 188 \tTraining Loss:  1.640 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.649 \n",
            "Epoch: 189 \tTraining Loss:  1.630 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.681 \n",
            "Epoch: 190 \tTraining Loss:  1.625 \tTrain_Accu: 21%  \tValid_Acc:33% \t Valid Loss: 1.588 \n",
            "Epoch: 191 \tTraining Loss:  1.631 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.622 \n",
            "Epoch: 192 \tTraining Loss:  1.635 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.695 \n",
            "Epoch: 193 \tTraining Loss:  1.635 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.670 \n",
            "Epoch: 194 \tTraining Loss:  1.634 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.674 \n",
            "Epoch: 195 \tTraining Loss:  1.634 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.733 \n",
            "Epoch: 196 \tTraining Loss:  1.641 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.605 \n",
            "Epoch: 197 \tTraining Loss:  1.628 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.711 \n",
            "Epoch: 198 \tTraining Loss:  1.636 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.621 \n",
            "Epoch: 199 \tTraining Loss:  1.626 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.659 \n",
            "Epoch: 200 \tTraining Loss:  1.637 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.596 \n",
            "Epoch: 201 \tTraining Loss:  1.626 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.617 \n",
            "Epoch: 202 \tTraining Loss:  1.630 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.627 \n",
            "Epoch: 203 \tTraining Loss:  1.639 \tTrain_Accu: 17%  \tValid_Acc:33% \t Valid Loss: 1.593 \n",
            "Epoch: 204 \tTraining Loss:  1.636 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.613 \n",
            "Epoch: 205 \tTraining Loss:  1.619 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.777 \n",
            "Epoch: 206 \tTraining Loss:  1.637 \tTrain_Accu: 23%  \tValid_Acc:17% \t Valid Loss: 1.694 \n",
            "Epoch: 207 \tTraining Loss:  1.640 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.624 \n",
            "Epoch: 208 \tTraining Loss:  1.644 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.669 \n",
            "Epoch: 209 \tTraining Loss:  1.629 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 210 \tTraining Loss:  1.634 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.607 \n",
            "Epoch: 211 \tTraining Loss:  1.631 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.705 \n",
            "Epoch: 212 \tTraining Loss:  1.642 \tTrain_Accu: 13%  \tValid_Acc:7% \t Valid Loss: 1.684 \n",
            "Epoch: 213 \tTraining Loss:  1.631 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.679 \n",
            "Epoch: 214 \tTraining Loss:  1.638 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.648 \n",
            "Epoch: 215 \tTraining Loss:  1.630 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.612 \n",
            "Epoch: 216 \tTraining Loss:  1.637 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.624 \n",
            "Epoch: 217 \tTraining Loss:  1.640 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.611 \n",
            "Epoch: 218 \tTraining Loss:  1.636 \tTrain_Accu: 23%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 219 \tTraining Loss:  1.639 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.625 \n",
            "Epoch: 220 \tTraining Loss:  1.634 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.627 \n",
            "Epoch: 221 \tTraining Loss:  1.629 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.589 \n",
            "Epoch: 222 \tTraining Loss:  1.637 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.599 \n",
            "Epoch: 223 \tTraining Loss:  1.637 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.650 \n",
            "Epoch: 224 \tTraining Loss:  1.632 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.613 \n",
            "Epoch: 225 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.724 \n",
            "Epoch: 226 \tTraining Loss:  1.633 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.604 \n",
            "Epoch: 227 \tTraining Loss:  1.636 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.621 \n",
            "Epoch: 228 \tTraining Loss:  1.636 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 229 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.615 \n",
            "Epoch: 230 \tTraining Loss:  1.629 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.705 \n",
            "Epoch: 231 \tTraining Loss:  1.638 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.613 \n",
            "Epoch: 232 \tTraining Loss:  1.636 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.646 \n",
            "Epoch: 233 \tTraining Loss:  1.629 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.692 \n",
            "Epoch: 234 \tTraining Loss:  1.647 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.657 \n",
            "Epoch: 235 \tTraining Loss:  1.630 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 236 \tTraining Loss:  1.630 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.664 \n",
            "Epoch: 237 \tTraining Loss:  1.642 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.622 \n",
            "Epoch: 238 \tTraining Loss:  1.639 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 239 \tTraining Loss:  1.621 \tTrain_Accu: 21%  \tValid_Acc:33% \t Valid Loss: 1.576 \n",
            "Epoch: 240 \tTraining Loss:  1.628 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.571 \n",
            "Epoch: 241 \tTraining Loss:  1.640 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.691 \n",
            "Epoch: 242 \tTraining Loss:  1.623 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.625 \n",
            "Epoch: 243 \tTraining Loss:  1.637 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.574 \n",
            "Epoch: 244 \tTraining Loss:  1.644 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.647 \n",
            "Epoch: 245 \tTraining Loss:  1.623 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.768 \n",
            "Epoch: 246 \tTraining Loss:  1.631 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.718 \n",
            "Epoch: 247 \tTraining Loss:  1.633 \tTrain_Accu: 23%  \tValid_Acc:26% \t Valid Loss: 1.600 \n",
            "Epoch: 248 \tTraining Loss:  1.635 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.651 \n",
            "Epoch: 249 \tTraining Loss:  1.629 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.565 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 20:04:18,869]\u001b[0m Trial 0 finished with value: 17.1 and parameters: {'Batch_size': 5, 'lr': 0.1, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'dropout': 0.7}. Best is trial 0 with value: 17.1.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.649 \n",
            "Epoch: 1 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.620 \n",
            "Epoch: 2 \tTraining Loss:  1.580 \tTrain_Accu: 28%  \tValid_Acc:17% \t Valid Loss: 1.656 \n",
            "Epoch: 3 \tTraining Loss:  1.551 \tTrain_Accu: 33%  \tValid_Acc:20% \t Valid Loss: 1.613 \n",
            "Epoch: 4 \tTraining Loss:  1.534 \tTrain_Accu: 28%  \tValid_Acc:19% \t Valid Loss: 1.596 \n",
            "Epoch: 5 \tTraining Loss:  1.534 \tTrain_Accu: 31%  \tValid_Acc:20% \t Valid Loss: 1.572 \n",
            "Epoch: 6 \tTraining Loss:  1.507 \tTrain_Accu: 31%  \tValid_Acc:14% \t Valid Loss: 1.672 \n",
            "Epoch: 7 \tTraining Loss:  1.472 \tTrain_Accu: 33%  \tValid_Acc:29% \t Valid Loss: 1.602 \n",
            "Epoch: 8 \tTraining Loss:  1.466 \tTrain_Accu: 36%  \tValid_Acc:20% \t Valid Loss: 1.598 \n",
            "Epoch: 9 \tTraining Loss:  1.433 \tTrain_Accu: 36%  \tValid_Acc:23% \t Valid Loss: 1.585 \n",
            "Epoch: 10 \tTraining Loss:  1.449 \tTrain_Accu: 34%  \tValid_Acc:26% \t Valid Loss: 1.605 \n",
            "Epoch: 11 \tTraining Loss:  1.404 \tTrain_Accu: 40%  \tValid_Acc:19% \t Valid Loss: 1.657 \n",
            "Epoch: 12 \tTraining Loss:  1.366 \tTrain_Accu: 38%  \tValid_Acc:26% \t Valid Loss: 1.668 \n",
            "Epoch: 13 \tTraining Loss:  1.355 \tTrain_Accu: 39%  \tValid_Acc:21% \t Valid Loss: 1.677 \n",
            "Epoch: 14 \tTraining Loss:  1.341 \tTrain_Accu: 39%  \tValid_Acc:23% \t Valid Loss: 1.750 \n",
            "Epoch: 15 \tTraining Loss:  1.302 \tTrain_Accu: 42%  \tValid_Acc:23% \t Valid Loss: 1.813 \n",
            "Epoch: 16 \tTraining Loss:  1.287 \tTrain_Accu: 46%  \tValid_Acc:16% \t Valid Loss: 1.931 \n",
            "Epoch: 17 \tTraining Loss:  1.271 \tTrain_Accu: 45%  \tValid_Acc:29% \t Valid Loss: 1.662 \n",
            "Epoch: 18 \tTraining Loss:  1.170 \tTrain_Accu: 50%  \tValid_Acc:19% \t Valid Loss: 1.797 \n",
            "Epoch: 19 \tTraining Loss:  1.161 \tTrain_Accu: 49%  \tValid_Acc:24% \t Valid Loss: 1.830 \n",
            "Epoch: 20 \tTraining Loss:  1.078 \tTrain_Accu: 51%  \tValid_Acc:26% \t Valid Loss: 2.003 \n",
            "Epoch: 21 \tTraining Loss:  1.082 \tTrain_Accu: 52%  \tValid_Acc:21% \t Valid Loss: 2.205 \n",
            "Epoch: 22 \tTraining Loss:  1.133 \tTrain_Accu: 49%  \tValid_Acc:26% \t Valid Loss: 1.985 \n",
            "Epoch: 23 \tTraining Loss:  1.043 \tTrain_Accu: 56%  \tValid_Acc:27% \t Valid Loss: 2.269 \n",
            "Epoch: 24 \tTraining Loss:  1.046 \tTrain_Accu: 59%  \tValid_Acc:16% \t Valid Loss: 3.311 \n",
            "Epoch: 25 \tTraining Loss:  1.065 \tTrain_Accu: 61%  \tValid_Acc:20% \t Valid Loss: 2.113 \n",
            "Epoch: 26 \tTraining Loss:  0.942 \tTrain_Accu: 59%  \tValid_Acc:36% \t Valid Loss: 1.911 \n",
            "Epoch: 27 \tTraining Loss:  0.985 \tTrain_Accu: 59%  \tValid_Acc:29% \t Valid Loss: 1.839 \n",
            "Epoch: 28 \tTraining Loss:  0.958 \tTrain_Accu: 62%  \tValid_Acc:27% \t Valid Loss: 1.800 \n",
            "Epoch: 29 \tTraining Loss:  0.850 \tTrain_Accu: 65%  \tValid_Acc:33% \t Valid Loss: 1.954 \n",
            "Epoch: 30 \tTraining Loss:  0.788 \tTrain_Accu: 67%  \tValid_Acc:36% \t Valid Loss: 1.926 \n",
            "Epoch: 31 \tTraining Loss:  0.760 \tTrain_Accu: 67%  \tValid_Acc:27% \t Valid Loss: 2.120 \n",
            "Epoch: 32 \tTraining Loss:  0.793 \tTrain_Accu: 67%  \tValid_Acc:27% \t Valid Loss: 1.931 \n",
            "Epoch: 33 \tTraining Loss:  0.697 \tTrain_Accu: 76%  \tValid_Acc:21% \t Valid Loss: 2.123 \n",
            "Epoch: 34 \tTraining Loss:  0.666 \tTrain_Accu: 73%  \tValid_Acc:29% \t Valid Loss: 2.323 \n",
            "Epoch: 35 \tTraining Loss:  0.580 \tTrain_Accu: 78%  \tValid_Acc:26% \t Valid Loss: 2.545 \n",
            "Epoch: 36 \tTraining Loss:  0.611 \tTrain_Accu: 75%  \tValid_Acc:29% \t Valid Loss: 2.513 \n",
            "Epoch: 37 \tTraining Loss:  0.563 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 3.744 \n",
            "Epoch: 38 \tTraining Loss:  0.498 \tTrain_Accu: 81%  \tValid_Acc:26% \t Valid Loss: 3.153 \n",
            "Epoch: 39 \tTraining Loss:  0.482 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 3.350 \n",
            "Epoch: 40 \tTraining Loss:  0.424 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 3.102 \n",
            "Epoch: 41 \tTraining Loss:  0.526 \tTrain_Accu: 79%  \tValid_Acc:20% \t Valid Loss: 3.384 \n",
            "Epoch: 42 \tTraining Loss:  0.460 \tTrain_Accu: 82%  \tValid_Acc:23% \t Valid Loss: 3.093 \n",
            "Epoch: 43 \tTraining Loss:  0.462 \tTrain_Accu: 81%  \tValid_Acc:33% \t Valid Loss: 2.512 \n",
            "Epoch: 44 \tTraining Loss:  0.426 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 3.200 \n",
            "Epoch: 45 \tTraining Loss:  0.370 \tTrain_Accu: 87%  \tValid_Acc:29% \t Valid Loss: 3.616 \n",
            "Epoch: 46 \tTraining Loss:  0.407 \tTrain_Accu: 85%  \tValid_Acc:31% \t Valid Loss: 2.659 \n",
            "Epoch: 47 \tTraining Loss:  0.299 \tTrain_Accu: 90%  \tValid_Acc:17% \t Valid Loss: 3.732 \n",
            "Epoch: 48 \tTraining Loss:  0.429 \tTrain_Accu: 86%  \tValid_Acc:40% \t Valid Loss: 2.994 \n",
            "Epoch: 49 \tTraining Loss:  0.353 \tTrain_Accu: 87%  \tValid_Acc:33% \t Valid Loss: 2.753 \n",
            "Epoch: 50 \tTraining Loss:  0.368 \tTrain_Accu: 88%  \tValid_Acc:29% \t Valid Loss: 3.626 \n",
            "Epoch: 51 \tTraining Loss:  0.377 \tTrain_Accu: 87%  \tValid_Acc:27% \t Valid Loss: 3.487 \n",
            "Epoch: 52 \tTraining Loss:  0.379 \tTrain_Accu: 89%  \tValid_Acc:29% \t Valid Loss: 3.332 \n",
            "Epoch: 53 \tTraining Loss:  0.398 \tTrain_Accu: 84%  \tValid_Acc:24% \t Valid Loss: 3.523 \n",
            "Epoch: 54 \tTraining Loss:  0.335 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 3.776 \n",
            "Epoch: 55 \tTraining Loss:  0.310 \tTrain_Accu: 87%  \tValid_Acc:20% \t Valid Loss: 3.697 \n",
            "Epoch: 56 \tTraining Loss:  0.321 \tTrain_Accu: 89%  \tValid_Acc:21% \t Valid Loss: 4.090 \n",
            "Epoch: 57 \tTraining Loss:  0.270 \tTrain_Accu: 91%  \tValid_Acc:33% \t Valid Loss: 4.204 \n",
            "Epoch: 58 \tTraining Loss:  0.379 \tTrain_Accu: 84%  \tValid_Acc:26% \t Valid Loss: 3.593 \n",
            "Epoch: 59 \tTraining Loss:  0.302 \tTrain_Accu: 88%  \tValid_Acc:30% \t Valid Loss: 3.949 \n",
            "Epoch: 60 \tTraining Loss:  0.235 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 4.138 \n",
            "Epoch: 61 \tTraining Loss:  0.200 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 4.571 \n",
            "Epoch: 62 \tTraining Loss:  0.216 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 4.023 \n",
            "Epoch: 63 \tTraining Loss:  0.276 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 3.931 \n",
            "Epoch: 64 \tTraining Loss:  0.199 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 4.530 \n",
            "Epoch: 65 \tTraining Loss:  0.282 \tTrain_Accu: 89%  \tValid_Acc:26% \t Valid Loss: 4.265 \n",
            "Epoch: 66 \tTraining Loss:  0.339 \tTrain_Accu: 89%  \tValid_Acc:24% \t Valid Loss: 4.306 \n",
            "Epoch: 67 \tTraining Loss:  0.210 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 3.686 \n",
            "Epoch: 68 \tTraining Loss:  0.205 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 4.511 \n",
            "Epoch: 69 \tTraining Loss:  0.247 \tTrain_Accu: 89%  \tValid_Acc:36% \t Valid Loss: 3.166 \n",
            "Epoch: 70 \tTraining Loss:  0.202 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 3.683 \n",
            "Epoch: 71 \tTraining Loss:  0.177 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 5.311 \n",
            "Epoch: 72 \tTraining Loss:  0.308 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 4.641 \n",
            "Epoch: 73 \tTraining Loss:  0.435 \tTrain_Accu: 87%  \tValid_Acc:31% \t Valid Loss: 3.531 \n",
            "Epoch: 74 \tTraining Loss:  0.249 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 4.371 \n",
            "Epoch: 75 \tTraining Loss:  0.259 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 3.830 \n",
            "Epoch: 76 \tTraining Loss:  0.199 \tTrain_Accu: 93%  \tValid_Acc:33% \t Valid Loss: 3.505 \n",
            "Epoch: 77 \tTraining Loss:  0.206 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 3.899 \n",
            "Epoch: 78 \tTraining Loss:  0.310 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 3.703 \n",
            "Epoch: 79 \tTraining Loss:  0.158 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 4.102 \n",
            "Epoch: 80 \tTraining Loss:  0.192 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 4.364 \n",
            "Epoch: 81 \tTraining Loss:  0.174 \tTrain_Accu: 93%  \tValid_Acc:30% \t Valid Loss: 3.996 \n",
            "Epoch: 82 \tTraining Loss:  0.103 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 4.422 \n",
            "Epoch: 83 \tTraining Loss:  0.187 \tTrain_Accu: 95%  \tValid_Acc:34% \t Valid Loss: 3.827 \n",
            "Epoch: 84 \tTraining Loss:  0.126 \tTrain_Accu: 96%  \tValid_Acc:31% \t Valid Loss: 4.201 \n",
            "Epoch: 85 \tTraining Loss:  0.143 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 3.678 \n",
            "Epoch: 86 \tTraining Loss:  0.140 \tTrain_Accu: 95%  \tValid_Acc:31% \t Valid Loss: 3.886 \n",
            "Epoch: 87 \tTraining Loss:  0.205 \tTrain_Accu: 93%  \tValid_Acc:26% \t Valid Loss: 4.603 \n",
            "Epoch: 88 \tTraining Loss:  0.087 \tTrain_Accu: 97%  \tValid_Acc:39% \t Valid Loss: 4.305 \n",
            "Epoch: 89 \tTraining Loss:  0.170 \tTrain_Accu: 95%  \tValid_Acc:20% \t Valid Loss: 5.210 \n",
            "Epoch: 90 \tTraining Loss:  0.124 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 4.390 \n",
            "Epoch: 91 \tTraining Loss:  0.172 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 3.628 \n",
            "Epoch: 92 \tTraining Loss:  0.129 \tTrain_Accu: 95%  \tValid_Acc:31% \t Valid Loss: 3.875 \n",
            "Epoch: 93 \tTraining Loss:  0.126 \tTrain_Accu: 94%  \tValid_Acc:31% \t Valid Loss: 4.533 \n",
            "Epoch: 94 \tTraining Loss:  0.139 \tTrain_Accu: 95%  \tValid_Acc:31% \t Valid Loss: 4.640 \n",
            "Epoch: 95 \tTraining Loss:  0.096 \tTrain_Accu: 96%  \tValid_Acc:31% \t Valid Loss: 4.239 \n",
            "Epoch: 96 \tTraining Loss:  0.161 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 4.899 \n",
            "Epoch: 97 \tTraining Loss:  0.101 \tTrain_Accu: 95%  \tValid_Acc:31% \t Valid Loss: 4.746 \n",
            "Epoch: 98 \tTraining Loss:  0.082 \tTrain_Accu: 97%  \tValid_Acc:31% \t Valid Loss: 5.325 \n",
            "Epoch: 99 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 5.801 \n",
            "Epoch: 100 \tTraining Loss:  0.150 \tTrain_Accu: 94%  \tValid_Acc:34% \t Valid Loss: 4.616 \n",
            "Epoch: 101 \tTraining Loss:  0.143 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 5.911 \n",
            "Epoch: 102 \tTraining Loss:  0.297 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 4.647 \n",
            "Epoch: 103 \tTraining Loss:  0.195 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 4.009 \n",
            "Epoch: 104 \tTraining Loss:  0.173 \tTrain_Accu: 93%  \tValid_Acc:33% \t Valid Loss: 3.386 \n",
            "Epoch: 105 \tTraining Loss:  0.185 \tTrain_Accu: 95%  \tValid_Acc:34% \t Valid Loss: 4.105 \n",
            "Epoch: 106 \tTraining Loss:  0.128 \tTrain_Accu: 96%  \tValid_Acc:21% \t Valid Loss: 4.048 \n",
            "Epoch: 107 \tTraining Loss:  0.084 \tTrain_Accu: 98%  \tValid_Acc:33% \t Valid Loss: 4.663 \n",
            "Epoch: 108 \tTraining Loss:  0.126 \tTrain_Accu: 95%  \tValid_Acc:29% \t Valid Loss: 4.617 \n",
            "Epoch: 109 \tTraining Loss:  0.148 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 5.285 \n",
            "Epoch: 110 \tTraining Loss:  0.094 \tTrain_Accu: 96%  \tValid_Acc:37% \t Valid Loss: 4.956 \n",
            "Epoch: 111 \tTraining Loss:  0.096 \tTrain_Accu: 97%  \tValid_Acc:30% \t Valid Loss: 5.727 \n",
            "Epoch: 112 \tTraining Loss:  0.139 \tTrain_Accu: 95%  \tValid_Acc:31% \t Valid Loss: 5.900 \n",
            "Epoch: 113 \tTraining Loss:  0.122 \tTrain_Accu: 95%  \tValid_Acc:30% \t Valid Loss: 5.607 \n",
            "Epoch: 114 \tTraining Loss:  0.166 \tTrain_Accu: 96%  \tValid_Acc:33% \t Valid Loss: 3.611 \n",
            "Epoch: 115 \tTraining Loss:  0.127 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 4.434 \n",
            "Epoch: 116 \tTraining Loss:  0.148 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 4.319 \n",
            "Epoch: 117 \tTraining Loss:  0.312 \tTrain_Accu: 91%  \tValid_Acc:31% \t Valid Loss: 3.277 \n",
            "Epoch: 118 \tTraining Loss:  0.169 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 4.304 \n",
            "Epoch: 119 \tTraining Loss:  0.088 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 4.477 \n",
            "Epoch: 120 \tTraining Loss:  0.112 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 4.335 \n",
            "Epoch: 121 \tTraining Loss:  0.145 \tTrain_Accu: 95%  \tValid_Acc:27% \t Valid Loss: 5.382 \n",
            "Epoch: 122 \tTraining Loss:  0.077 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 6.669 \n",
            "Epoch: 123 \tTraining Loss:  0.139 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 6.132 \n",
            "Epoch: 124 \tTraining Loss:  0.093 \tTrain_Accu: 97%  \tValid_Acc:27% \t Valid Loss: 6.865 \n",
            "Epoch: 125 \tTraining Loss:  0.120 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 5.791 \n",
            "Epoch: 126 \tTraining Loss:  0.107 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 4.477 \n",
            "Epoch: 127 \tTraining Loss:  0.119 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 4.806 \n",
            "Epoch: 128 \tTraining Loss:  0.154 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 5.395 \n",
            "Epoch: 129 \tTraining Loss:  0.074 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 5.553 \n",
            "Epoch: 130 \tTraining Loss:  0.070 \tTrain_Accu: 97%  \tValid_Acc:30% \t Valid Loss: 5.516 \n",
            "Epoch: 131 \tTraining Loss:  0.083 \tTrain_Accu: 97%  \tValid_Acc:33% \t Valid Loss: 4.823 \n",
            "Epoch: 132 \tTraining Loss:  0.117 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 4.369 \n",
            "Epoch: 133 \tTraining Loss:  0.093 \tTrain_Accu: 97%  \tValid_Acc:30% \t Valid Loss: 4.496 \n",
            "Epoch: 134 \tTraining Loss:  0.093 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 4.827 \n",
            "Epoch: 135 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:31% \t Valid Loss: 4.574 \n",
            "Epoch: 136 \tTraining Loss:  0.089 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 4.839 \n",
            "Epoch: 137 \tTraining Loss:  0.086 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 5.582 \n",
            "Epoch: 138 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \tValid_Acc:20% \t Valid Loss: 5.676 \n",
            "Epoch: 139 \tTraining Loss:  0.097 \tTrain_Accu: 97%  \tValid_Acc:19% \t Valid Loss: 4.831 \n",
            "Epoch: 140 \tTraining Loss:  0.131 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 4.703 \n",
            "Epoch: 141 \tTraining Loss:  0.131 \tTrain_Accu: 95%  \tValid_Acc:29% \t Valid Loss: 4.806 \n",
            "Epoch: 142 \tTraining Loss:  0.094 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 4.268 \n",
            "Epoch: 143 \tTraining Loss:  0.100 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 3.819 \n",
            "Epoch: 144 \tTraining Loss:  0.100 \tTrain_Accu: 97%  \tValid_Acc:33% \t Valid Loss: 4.720 \n",
            "Epoch: 145 \tTraining Loss:  0.089 \tTrain_Accu: 95%  \tValid_Acc:33% \t Valid Loss: 5.243 \n",
            "Epoch: 146 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:21% \t Valid Loss: 6.928 \n",
            "Epoch: 147 \tTraining Loss:  0.077 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 6.446 \n",
            "Epoch: 148 \tTraining Loss:  0.082 \tTrain_Accu: 97%  \tValid_Acc:17% \t Valid Loss: 6.783 \n",
            "Epoch: 149 \tTraining Loss:  0.095 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 5.573 \n",
            "Epoch: 150 \tTraining Loss:  0.118 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 5.881 \n",
            "Epoch: 151 \tTraining Loss:  0.095 \tTrain_Accu: 97%  \tValid_Acc:27% \t Valid Loss: 4.367 \n",
            "Epoch: 152 \tTraining Loss:  0.110 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 5.071 \n",
            "Epoch: 153 \tTraining Loss:  0.077 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 5.534 \n",
            "Epoch: 154 \tTraining Loss:  0.143 \tTrain_Accu: 94%  \tValid_Acc:21% \t Valid Loss: 5.248 \n",
            "Epoch: 155 \tTraining Loss:  0.064 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 5.748 \n",
            "Epoch: 156 \tTraining Loss:  0.077 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 5.835 \n",
            "Epoch: 157 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 6.088 \n",
            "Epoch: 158 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \tValid_Acc:19% \t Valid Loss: 7.077 \n",
            "Epoch: 159 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 4.279 \n",
            "Epoch: 160 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:19% \t Valid Loss: 6.096 \n",
            "Epoch: 161 \tTraining Loss:  0.076 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 6.887 \n",
            "Epoch: 162 \tTraining Loss:  0.114 \tTrain_Accu: 95%  \tValid_Acc:17% \t Valid Loss: 5.648 \n",
            "Epoch: 163 \tTraining Loss:  0.068 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 5.575 \n",
            "Epoch: 164 \tTraining Loss:  0.062 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 6.307 \n",
            "Epoch: 165 \tTraining Loss:  0.070 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 4.710 \n",
            "Epoch: 166 \tTraining Loss:  0.086 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 5.499 \n",
            "Epoch: 167 \tTraining Loss:  0.109 \tTrain_Accu: 97%  \tValid_Acc:33% \t Valid Loss: 5.767 \n",
            "Epoch: 168 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \tValid_Acc:31% \t Valid Loss: 5.935 \n",
            "Epoch: 169 \tTraining Loss:  0.067 \tTrain_Accu: 96%  \tValid_Acc:33% \t Valid Loss: 6.310 \n",
            "Epoch: 170 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 6.807 \n",
            "Epoch: 171 \tTraining Loss:  0.116 \tTrain_Accu: 95%  \tValid_Acc:20% \t Valid Loss: 5.955 \n",
            "Epoch: 172 \tTraining Loss:  0.073 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 5.019 \n",
            "Epoch: 173 \tTraining Loss:  0.083 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 5.887 \n",
            "Epoch: 174 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 6.233 \n",
            "Epoch: 175 \tTraining Loss:  0.129 \tTrain_Accu: 97%  \tValid_Acc:19% \t Valid Loss: 4.487 \n",
            "Epoch: 176 \tTraining Loss:  0.149 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 4.531 \n",
            "Epoch: 177 \tTraining Loss:  0.126 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 4.254 \n",
            "Epoch: 178 \tTraining Loss:  0.137 \tTrain_Accu: 96%  \tValid_Acc:33% \t Valid Loss: 5.316 \n",
            "Epoch: 179 \tTraining Loss:  0.068 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 4.502 \n",
            "Epoch: 180 \tTraining Loss:  0.085 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 6.771 \n",
            "Epoch: 181 \tTraining Loss:  0.138 \tTrain_Accu: 95%  \tValid_Acc:20% \t Valid Loss: 5.111 \n",
            "Epoch: 182 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 5.462 \n",
            "Epoch: 183 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 5.928 \n",
            "Epoch: 184 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 5.505 \n",
            "Epoch: 185 \tTraining Loss:  0.134 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 4.322 \n",
            "Epoch: 186 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 4.697 \n",
            "Epoch: 187 \tTraining Loss:  0.074 \tTrain_Accu: 98%  \tValid_Acc:31% \t Valid Loss: 5.216 \n",
            "Epoch: 188 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:20% \t Valid Loss: 6.744 \n",
            "Epoch: 189 \tTraining Loss:  0.101 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 5.418 \n",
            "Epoch: 190 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 5.677 \n",
            "Epoch: 191 \tTraining Loss:  0.093 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 6.209 \n",
            "Epoch: 192 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \tValid_Acc:33% \t Valid Loss: 4.859 \n",
            "Epoch: 193 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 5.897 \n",
            "Epoch: 194 \tTraining Loss:  0.080 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 5.150 \n",
            "Epoch: 195 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 5.662 \n",
            "Epoch: 196 \tTraining Loss:  0.084 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 5.438 \n",
            "Epoch: 197 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 4.737 \n",
            "Epoch: 198 \tTraining Loss:  0.082 \tTrain_Accu: 97%  \tValid_Acc:27% \t Valid Loss: 6.085 \n",
            "Epoch: 199 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 6.884 \n",
            "Epoch: 200 \tTraining Loss:  0.099 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 5.564 \n",
            "Epoch: 201 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 5.416 \n",
            "Epoch: 202 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 7.560 \n",
            "Epoch: 203 \tTraining Loss:  0.071 \tTrain_Accu: 98%  \tValid_Acc:34% \t Valid Loss: 6.547 \n",
            "Epoch: 204 \tTraining Loss:  0.052 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 6.055 \n",
            "Epoch: 205 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 5.858 \n",
            "Epoch: 206 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 7.007 \n",
            "Epoch: 207 \tTraining Loss:  0.080 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 6.572 \n",
            "Epoch: 208 \tTraining Loss:  0.066 \tTrain_Accu: 97%  \tValid_Acc:27% \t Valid Loss: 5.291 \n",
            "Epoch: 209 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 6.265 \n",
            "Epoch: 210 \tTraining Loss:  0.058 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 5.778 \n",
            "Epoch: 211 \tTraining Loss:  0.127 \tTrain_Accu: 97%  \tValid_Acc:31% \t Valid Loss: 4.619 \n",
            "Epoch: 212 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 5.456 \n",
            "Epoch: 213 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 5.230 \n",
            "Epoch: 214 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 4.656 \n",
            "Epoch: 215 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 5.524 \n",
            "Epoch: 216 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 5.791 \n",
            "Epoch: 217 \tTraining Loss:  0.058 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 7.100 \n",
            "Epoch: 218 \tTraining Loss:  0.081 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 5.544 \n",
            "Epoch: 219 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 5.382 \n",
            "Epoch: 220 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 6.777 \n",
            "Epoch: 221 \tTraining Loss:  0.028 \tTrain_Accu: 100%  \tValid_Acc:26% \t Valid Loss: 7.141 \n",
            "Epoch: 222 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 7.227 \n",
            "Epoch: 223 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 6.474 \n",
            "Epoch: 224 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \tValid_Acc:23% \t Valid Loss: 7.581 \n",
            "Epoch: 225 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:34% \t Valid Loss: 6.912 \n",
            "Epoch: 226 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 6.733 \n",
            "Epoch: 227 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 7.436 \n",
            "Epoch: 228 \tTraining Loss:  0.096 \tTrain_Accu: 97%  \tValid_Acc:30% \t Valid Loss: 5.996 \n",
            "Epoch: 229 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:29% \t Valid Loss: 6.157 \n",
            "Epoch: 230 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \tValid_Acc:39% \t Valid Loss: 6.123 \n",
            "Epoch: 231 \tTraining Loss:  0.074 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 5.808 \n",
            "Epoch: 232 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 6.290 \n",
            "Epoch: 233 \tTraining Loss:  0.043 \tTrain_Accu: 99%  \tValid_Acc:34% \t Valid Loss: 5.007 \n",
            "Epoch: 234 \tTraining Loss:  0.051 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 6.459 \n",
            "Epoch: 235 \tTraining Loss:  0.068 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 6.931 \n",
            "Epoch: 236 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 6.941 \n",
            "Epoch: 237 \tTraining Loss:  0.033 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 8.020 \n",
            "Epoch: 238 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:29% \t Valid Loss: 7.721 \n",
            "Epoch: 239 \tTraining Loss:  0.078 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 7.003 \n",
            "Epoch: 240 \tTraining Loss:  0.074 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 6.930 \n",
            "Epoch: 241 \tTraining Loss:  0.074 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 7.187 \n",
            "Epoch: 242 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 5.502 \n",
            "Epoch: 243 \tTraining Loss:  0.030 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 7.050 \n",
            "Epoch: 244 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 6.623 \n",
            "Epoch: 245 \tTraining Loss:  0.074 \tTrain_Accu: 97%  \tValid_Acc:27% \t Valid Loss: 6.656 \n",
            "Epoch: 246 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 6.414 \n",
            "Epoch: 247 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \tValid_Acc:14% \t Valid Loss: 6.312 \n",
            "Epoch: 248 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 5.906 \n",
            "Epoch: 249 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 6.739 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 20:06:26,249]\u001b[0m Trial 1 finished with value: 18.6 and parameters: {'Batch_size': 9, 'lr': 0.01, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'dropout': 0.5}. Best is trial 1 with value: 18.6.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.029 \tTrain_Accu: 98%  \tValid_Acc:19% \t Valid Loss: 6.901 \n",
            "Epoch: 1 \tTraining Loss:  2078.363 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 2 \tTraining Loss:  1.637 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.656 \n",
            "Epoch: 3 \tTraining Loss:  1.623 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 4 \tTraining Loss:  1.628 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.652 \n",
            "Epoch: 5 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:33% \t Valid Loss: 1.617 \n",
            "Epoch: 6 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.687 \n",
            "Epoch: 7 \tTraining Loss:  1.622 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.642 \n",
            "Epoch: 8 \tTraining Loss:  1.627 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.611 \n",
            "Epoch: 9 \tTraining Loss:  1.635 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.699 \n",
            "Epoch: 10 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.650 \n",
            "Epoch: 11 \tTraining Loss:  1.631 \tTrain_Accu: 17%  \tValid_Acc:33% \t Valid Loss: 1.598 \n",
            "Epoch: 12 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.692 \n",
            "Epoch: 13 \tTraining Loss:  1.628 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.642 \n",
            "Epoch: 14 \tTraining Loss:  1.625 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.653 \n",
            "Epoch: 15 \tTraining Loss:  1.625 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.657 \n",
            "Epoch: 16 \tTraining Loss:  1.623 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.668 \n",
            "Epoch: 17 \tTraining Loss:  1.624 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.613 \n",
            "Epoch: 18 \tTraining Loss:  1.636 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.696 \n",
            "Epoch: 19 \tTraining Loss:  1.645 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.664 \n",
            "Epoch: 20 \tTraining Loss:  1.622 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.607 \n",
            "Epoch: 21 \tTraining Loss:  1.624 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.651 \n",
            "Epoch: 22 \tTraining Loss:  1.629 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.588 \n",
            "Epoch: 23 \tTraining Loss:  1.631 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.697 \n",
            "Epoch: 24 \tTraining Loss:  1.622 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 25 \tTraining Loss:  1.622 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.644 \n",
            "Epoch: 26 \tTraining Loss:  1.635 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.676 \n",
            "Epoch: 27 \tTraining Loss:  1.628 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.701 \n",
            "Epoch: 28 \tTraining Loss:  1.625 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.584 \n",
            "Epoch: 29 \tTraining Loss:  1.621 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.646 \n",
            "Epoch: 30 \tTraining Loss:  1.623 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.656 \n",
            "Epoch: 31 \tTraining Loss:  1.618 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 32 \tTraining Loss:  1.620 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.655 \n",
            "Epoch: 33 \tTraining Loss:  1.624 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.638 \n",
            "Epoch: 34 \tTraining Loss:  1.617 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.658 \n",
            "Epoch: 35 \tTraining Loss:  1.626 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.622 \n",
            "Epoch: 36 \tTraining Loss:  1.644 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.660 \n",
            "Epoch: 37 \tTraining Loss:  1.645 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.650 \n",
            "Epoch: 38 \tTraining Loss:  1.630 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.659 \n",
            "Epoch: 39 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.603 \n",
            "Epoch: 40 \tTraining Loss:  1.624 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.686 \n",
            "Epoch: 41 \tTraining Loss:  1.632 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.712 \n",
            "Epoch: 42 \tTraining Loss:  1.622 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.643 \n",
            "Epoch: 43 \tTraining Loss:  1.627 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.616 \n",
            "Epoch: 44 \tTraining Loss:  1.627 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.724 \n",
            "Epoch: 45 \tTraining Loss:  1.628 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.683 \n",
            "Epoch: 46 \tTraining Loss:  1.621 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.644 \n",
            "Epoch: 47 \tTraining Loss:  1.629 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.651 \n",
            "Epoch: 48 \tTraining Loss:  1.626 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.621 \n",
            "Epoch: 49 \tTraining Loss:  1.624 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 50 \tTraining Loss:  1.626 \tTrain_Accu: 23%  \tValid_Acc:26% \t Valid Loss: 1.650 \n",
            "Epoch: 51 \tTraining Loss:  1.636 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.608 \n",
            "Epoch: 52 \tTraining Loss:  1.626 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.621 \n",
            "Epoch: 53 \tTraining Loss:  1.623 \tTrain_Accu: 23%  \tValid_Acc:33% \t Valid Loss: 1.557 \n",
            "Epoch: 54 \tTraining Loss:  1.645 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.686 \n",
            "Epoch: 55 \tTraining Loss:  1.624 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 56 \tTraining Loss:  1.623 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.657 \n",
            "Epoch: 57 \tTraining Loss:  1.618 \tTrain_Accu: 24%  \tValid_Acc:7% \t Valid Loss: 1.664 \n",
            "Epoch: 58 \tTraining Loss:  1.628 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 59 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.621 \n",
            "Epoch: 60 \tTraining Loss:  1.619 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.689 \n",
            "Epoch: 61 \tTraining Loss:  1.635 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.652 \n",
            "Epoch: 62 \tTraining Loss:  1.619 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 63 \tTraining Loss:  1.630 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.618 \n",
            "Epoch: 64 \tTraining Loss:  1.624 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.664 \n",
            "Epoch: 65 \tTraining Loss:  1.621 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.599 \n",
            "Epoch: 66 \tTraining Loss:  1.646 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.645 \n",
            "Epoch: 67 \tTraining Loss:  1.626 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.638 \n",
            "Epoch: 68 \tTraining Loss:  1.622 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.602 \n",
            "Epoch: 69 \tTraining Loss:  1.622 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.652 \n",
            "Epoch: 70 \tTraining Loss:  1.627 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.586 \n",
            "Epoch: 71 \tTraining Loss:  1.636 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.576 \n",
            "Epoch: 72 \tTraining Loss:  1.624 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.671 \n",
            "Epoch: 73 \tTraining Loss:  1.618 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 74 \tTraining Loss:  1.628 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 75 \tTraining Loss:  1.627 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.674 \n",
            "Epoch: 76 \tTraining Loss:  1.622 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.623 \n",
            "Epoch: 77 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.704 \n",
            "Epoch: 78 \tTraining Loss:  1.642 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.651 \n",
            "Epoch: 79 \tTraining Loss:  1.635 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 80 \tTraining Loss:  1.646 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.680 \n",
            "Epoch: 81 \tTraining Loss:  1.628 \tTrain_Accu: 23%  \tValid_Acc:26% \t Valid Loss: 1.665 \n",
            "Epoch: 82 \tTraining Loss:  1.629 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.652 \n",
            "Epoch: 83 \tTraining Loss:  1.635 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.620 \n",
            "Epoch: 84 \tTraining Loss:  1.639 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.668 \n",
            "Epoch: 85 \tTraining Loss:  1.623 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 86 \tTraining Loss:  1.631 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.611 \n",
            "Epoch: 87 \tTraining Loss:  1.628 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.602 \n",
            "Epoch: 88 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.653 \n",
            "Epoch: 89 \tTraining Loss:  1.631 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.607 \n",
            "Epoch: 90 \tTraining Loss:  1.625 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.699 \n",
            "Epoch: 91 \tTraining Loss:  1.624 \tTrain_Accu: 23%  \tValid_Acc:17% \t Valid Loss: 1.649 \n",
            "Epoch: 92 \tTraining Loss:  1.626 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.689 \n",
            "Epoch: 93 \tTraining Loss:  1.631 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.670 \n",
            "Epoch: 94 \tTraining Loss:  1.631 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.630 \n",
            "Epoch: 95 \tTraining Loss:  1.628 \tTrain_Accu: 21%  \tValid_Acc:33% \t Valid Loss: 1.585 \n",
            "Epoch: 96 \tTraining Loss:  1.627 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.621 \n",
            "Epoch: 97 \tTraining Loss:  1.628 \tTrain_Accu: 20%  \tValid_Acc:33% \t Valid Loss: 1.594 \n",
            "Epoch: 98 \tTraining Loss:  1.620 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.709 \n",
            "Epoch: 99 \tTraining Loss:  1.626 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.677 \n",
            "Epoch: 100 \tTraining Loss:  1.627 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.594 \n",
            "Epoch: 101 \tTraining Loss:  1.619 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.680 \n",
            "Epoch: 102 \tTraining Loss:  1.629 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 103 \tTraining Loss:  1.625 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 104 \tTraining Loss:  1.622 \tTrain_Accu: 15%  \tValid_Acc:7% \t Valid Loss: 1.652 \n",
            "Epoch: 105 \tTraining Loss:  1.619 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.615 \n",
            "Epoch: 106 \tTraining Loss:  1.626 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 107 \tTraining Loss:  1.624 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.723 \n",
            "Epoch: 108 \tTraining Loss:  1.621 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.627 \n",
            "Epoch: 109 \tTraining Loss:  1.626 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.665 \n",
            "Epoch: 110 \tTraining Loss:  1.636 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.749 \n",
            "Epoch: 111 \tTraining Loss:  1.622 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.624 \n",
            "Epoch: 112 \tTraining Loss:  1.625 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.672 \n",
            "Epoch: 113 \tTraining Loss:  1.623 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.679 \n",
            "Epoch: 114 \tTraining Loss:  1.634 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.604 \n",
            "Epoch: 115 \tTraining Loss:  1.626 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 116 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.611 \n",
            "Epoch: 117 \tTraining Loss:  1.635 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.573 \n",
            "Epoch: 118 \tTraining Loss:  1.641 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 119 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.677 \n",
            "Epoch: 120 \tTraining Loss:  1.624 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.574 \n",
            "Epoch: 121 \tTraining Loss:  1.638 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.623 \n",
            "Epoch: 122 \tTraining Loss:  1.627 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 123 \tTraining Loss:  1.628 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 124 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.590 \n",
            "Epoch: 125 \tTraining Loss:  1.638 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.617 \n",
            "Epoch: 126 \tTraining Loss:  1.623 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.678 \n",
            "Epoch: 127 \tTraining Loss:  1.629 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.729 \n",
            "Epoch: 128 \tTraining Loss:  1.628 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.648 \n",
            "Epoch: 129 \tTraining Loss:  1.633 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.647 \n",
            "Epoch: 130 \tTraining Loss:  1.622 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.741 \n",
            "Epoch: 131 \tTraining Loss:  1.620 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.581 \n",
            "Epoch: 132 \tTraining Loss:  1.624 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.708 \n",
            "Epoch: 133 \tTraining Loss:  1.630 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.625 \n",
            "Epoch: 134 \tTraining Loss:  1.623 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.645 \n",
            "Epoch: 135 \tTraining Loss:  1.630 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.648 \n",
            "Epoch: 136 \tTraining Loss:  1.634 \tTrain_Accu: 14%  \tValid_Acc:7% \t Valid Loss: 1.695 \n",
            "Epoch: 137 \tTraining Loss:  1.635 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 138 \tTraining Loss:  1.623 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 139 \tTraining Loss:  1.627 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.642 \n",
            "Epoch: 140 \tTraining Loss:  1.634 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 141 \tTraining Loss:  1.622 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 142 \tTraining Loss:  1.630 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.715 \n",
            "Epoch: 143 \tTraining Loss:  1.624 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.561 \n",
            "Epoch: 144 \tTraining Loss:  1.647 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.650 \n",
            "Epoch: 145 \tTraining Loss:  1.627 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 146 \tTraining Loss:  1.627 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.662 \n",
            "Epoch: 147 \tTraining Loss:  1.622 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.700 \n",
            "Epoch: 148 \tTraining Loss:  1.635 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.599 \n",
            "Epoch: 149 \tTraining Loss:  1.627 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.649 \n",
            "Epoch: 150 \tTraining Loss:  1.625 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.696 \n",
            "Epoch: 151 \tTraining Loss:  1.625 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 152 \tTraining Loss:  1.612 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.714 \n",
            "Epoch: 153 \tTraining Loss:  1.642 \tTrain_Accu: 18%  \tValid_Acc:33% \t Valid Loss: 1.606 \n",
            "Epoch: 154 \tTraining Loss:  1.644 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.584 \n",
            "Epoch: 155 \tTraining Loss:  1.631 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 156 \tTraining Loss:  1.626 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 157 \tTraining Loss:  1.626 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.689 \n",
            "Epoch: 158 \tTraining Loss:  1.623 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 159 \tTraining Loss:  1.622 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 160 \tTraining Loss:  1.624 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.631 \n",
            "Epoch: 161 \tTraining Loss:  1.618 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.610 \n",
            "Epoch: 162 \tTraining Loss:  1.638 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.690 \n",
            "Epoch: 163 \tTraining Loss:  1.634 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 164 \tTraining Loss:  1.623 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.646 \n",
            "Epoch: 165 \tTraining Loss:  1.625 \tTrain_Accu: 20%  \tValid_Acc:33% \t Valid Loss: 1.609 \n",
            "Epoch: 166 \tTraining Loss:  1.625 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.620 \n",
            "Epoch: 167 \tTraining Loss:  1.641 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.624 \n",
            "Epoch: 168 \tTraining Loss:  1.626 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.686 \n",
            "Epoch: 169 \tTraining Loss:  1.628 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 170 \tTraining Loss:  1.631 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.687 \n",
            "Epoch: 171 \tTraining Loss:  1.629 \tTrain_Accu: 19%  \tValid_Acc:33% \t Valid Loss: 1.606 \n",
            "Epoch: 172 \tTraining Loss:  1.630 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.697 \n",
            "Epoch: 173 \tTraining Loss:  1.620 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.650 \n",
            "Epoch: 174 \tTraining Loss:  1.633 \tTrain_Accu: 23%  \tValid_Acc:17% \t Valid Loss: 1.656 \n",
            "Epoch: 175 \tTraining Loss:  1.632 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 176 \tTraining Loss:  1.630 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.593 \n",
            "Epoch: 177 \tTraining Loss:  1.633 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.672 \n",
            "Epoch: 178 \tTraining Loss:  1.626 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.675 \n",
            "Epoch: 179 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.668 \n",
            "Epoch: 180 \tTraining Loss:  1.624 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.619 \n",
            "Epoch: 181 \tTraining Loss:  1.633 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.651 \n",
            "Epoch: 182 \tTraining Loss:  1.631 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.678 \n",
            "Epoch: 183 \tTraining Loss:  1.631 \tTrain_Accu: 14%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 184 \tTraining Loss:  1.631 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.647 \n",
            "Epoch: 185 \tTraining Loss:  1.629 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.701 \n",
            "Epoch: 186 \tTraining Loss:  1.618 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 187 \tTraining Loss:  1.631 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.617 \n",
            "Epoch: 188 \tTraining Loss:  1.627 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.712 \n",
            "Epoch: 189 \tTraining Loss:  1.633 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.669 \n",
            "Epoch: 190 \tTraining Loss:  1.629 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.625 \n",
            "Epoch: 191 \tTraining Loss:  1.627 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.595 \n",
            "Epoch: 192 \tTraining Loss:  1.630 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.614 \n",
            "Epoch: 193 \tTraining Loss:  1.628 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.652 \n",
            "Epoch: 194 \tTraining Loss:  1.636 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.663 \n",
            "Epoch: 195 \tTraining Loss:  1.616 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 196 \tTraining Loss:  1.619 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.595 \n",
            "Epoch: 197 \tTraining Loss:  1.630 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.712 \n",
            "Epoch: 198 \tTraining Loss:  1.630 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.625 \n",
            "Epoch: 199 \tTraining Loss:  1.639 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.648 \n",
            "Epoch: 200 \tTraining Loss:  1.639 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.657 \n",
            "Epoch: 201 \tTraining Loss:  1.618 \tTrain_Accu: 23%  \tValid_Acc:33% \t Valid Loss: 1.610 \n",
            "Epoch: 202 \tTraining Loss:  1.637 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.716 \n",
            "Epoch: 203 \tTraining Loss:  1.623 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.631 \n",
            "Epoch: 204 \tTraining Loss:  1.628 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.675 \n",
            "Epoch: 205 \tTraining Loss:  1.628 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.697 \n",
            "Epoch: 206 \tTraining Loss:  1.637 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.616 \n",
            "Epoch: 207 \tTraining Loss:  1.629 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.658 \n",
            "Epoch: 208 \tTraining Loss:  1.632 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.713 \n",
            "Epoch: 209 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.622 \n",
            "Epoch: 210 \tTraining Loss:  1.627 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.629 \n",
            "Epoch: 211 \tTraining Loss:  1.631 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.727 \n",
            "Epoch: 212 \tTraining Loss:  1.623 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.656 \n",
            "Epoch: 213 \tTraining Loss:  1.629 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.622 \n",
            "Epoch: 214 \tTraining Loss:  1.623 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.660 \n",
            "Epoch: 215 \tTraining Loss:  1.629 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.664 \n",
            "Epoch: 216 \tTraining Loss:  1.642 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.648 \n",
            "Epoch: 217 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.647 \n",
            "Epoch: 218 \tTraining Loss:  1.634 \tTrain_Accu: 15%  \tValid_Acc:33% \t Valid Loss: 1.589 \n",
            "Epoch: 219 \tTraining Loss:  1.623 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.659 \n",
            "Epoch: 220 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 221 \tTraining Loss:  1.628 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.583 \n",
            "Epoch: 222 \tTraining Loss:  1.633 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.643 \n",
            "Epoch: 223 \tTraining Loss:  1.636 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.664 \n",
            "Epoch: 224 \tTraining Loss:  1.627 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.598 \n",
            "Epoch: 225 \tTraining Loss:  1.615 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.746 \n",
            "Epoch: 226 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.657 \n",
            "Epoch: 227 \tTraining Loss:  1.629 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.624 \n",
            "Epoch: 228 \tTraining Loss:  1.641 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.612 \n",
            "Epoch: 229 \tTraining Loss:  1.618 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.627 \n",
            "Epoch: 230 \tTraining Loss:  1.634 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.653 \n",
            "Epoch: 231 \tTraining Loss:  1.622 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.579 \n",
            "Epoch: 232 \tTraining Loss:  1.621 \tTrain_Accu: 23%  \tValid_Acc:17% \t Valid Loss: 1.648 \n",
            "Epoch: 233 \tTraining Loss:  1.624 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 234 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.605 \n",
            "Epoch: 235 \tTraining Loss:  1.634 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.608 \n",
            "Epoch: 236 \tTraining Loss:  1.636 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.655 \n",
            "Epoch: 237 \tTraining Loss:  1.621 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.647 \n",
            "Epoch: 238 \tTraining Loss:  1.624 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.630 \n",
            "Epoch: 239 \tTraining Loss:  1.625 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.582 \n",
            "Epoch: 240 \tTraining Loss:  1.646 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 241 \tTraining Loss:  1.626 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.687 \n",
            "Epoch: 242 \tTraining Loss:  1.629 \tTrain_Accu: 24%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 243 \tTraining Loss:  1.633 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.672 \n",
            "Epoch: 244 \tTraining Loss:  1.625 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.617 \n",
            "Epoch: 245 \tTraining Loss:  1.619 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.671 \n",
            "Epoch: 246 \tTraining Loss:  1.640 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.708 \n",
            "Epoch: 247 \tTraining Loss:  1.638 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.571 \n",
            "Epoch: 248 \tTraining Loss:  1.630 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.609 \n",
            "Epoch: 249 \tTraining Loss:  1.629 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.632 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 20:08:54,284]\u001b[0m Trial 2 finished with value: 17.1 and parameters: {'Batch_size': 7, 'lr': 0.1, 'optimizer': <class 'torch.optim.adam.Adam'>, 'dropout': 0.5}. Best is trial 1 with value: 18.6.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  1.637 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.648 \n",
            "Epoch: 1 \tTraining Loss:  1.659 \tTrain_Accu: 22%  \tValid_Acc:31% \t Valid Loss: 1.551 \n",
            "Epoch: 2 \tTraining Loss:  1.575 \tTrain_Accu: 31%  \tValid_Acc:20% \t Valid Loss: 1.729 \n",
            "Epoch: 3 \tTraining Loss:  1.486 \tTrain_Accu: 36%  \tValid_Acc:29% \t Valid Loss: 1.624 \n",
            "Epoch: 4 \tTraining Loss:  1.402 \tTrain_Accu: 41%  \tValid_Acc:23% \t Valid Loss: 1.642 \n",
            "Epoch: 5 \tTraining Loss:  1.241 \tTrain_Accu: 49%  \tValid_Acc:29% \t Valid Loss: 1.648 \n",
            "Epoch: 6 \tTraining Loss:  1.096 \tTrain_Accu: 54%  \tValid_Acc:30% \t Valid Loss: 1.855 \n",
            "Epoch: 7 \tTraining Loss:  0.889 \tTrain_Accu: 61%  \tValid_Acc:29% \t Valid Loss: 2.196 \n",
            "Epoch: 8 \tTraining Loss:  0.678 \tTrain_Accu: 76%  \tValid_Acc:33% \t Valid Loss: 1.924 \n",
            "Epoch: 9 \tTraining Loss:  0.612 \tTrain_Accu: 75%  \tValid_Acc:23% \t Valid Loss: 2.202 \n",
            "Epoch: 10 \tTraining Loss:  0.519 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 2.681 \n",
            "Epoch: 11 \tTraining Loss:  0.353 \tTrain_Accu: 89%  \tValid_Acc:29% \t Valid Loss: 2.849 \n",
            "Epoch: 12 \tTraining Loss:  0.310 \tTrain_Accu: 88%  \tValid_Acc:23% \t Valid Loss: 3.087 \n",
            "Epoch: 13 \tTraining Loss:  0.275 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 3.708 \n",
            "Epoch: 14 \tTraining Loss:  0.261 \tTrain_Accu: 90%  \tValid_Acc:20% \t Valid Loss: 3.751 \n",
            "Epoch: 15 \tTraining Loss:  0.228 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 3.222 \n",
            "Epoch: 16 \tTraining Loss:  0.313 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 2.777 \n",
            "Epoch: 17 \tTraining Loss:  0.192 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 3.766 \n",
            "Epoch: 18 \tTraining Loss:  0.237 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 3.104 \n",
            "Epoch: 19 \tTraining Loss:  0.207 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 3.777 \n",
            "Epoch: 20 \tTraining Loss:  0.206 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 5.444 \n",
            "Epoch: 21 \tTraining Loss:  0.138 \tTrain_Accu: 96%  \tValid_Acc:33% \t Valid Loss: 3.659 \n",
            "Epoch: 22 \tTraining Loss:  0.134 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 4.650 \n",
            "Epoch: 23 \tTraining Loss:  0.136 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 4.930 \n",
            "Epoch: 24 \tTraining Loss:  0.126 \tTrain_Accu: 96%  \tValid_Acc:11% \t Valid Loss: 5.046 \n",
            "Epoch: 25 \tTraining Loss:  0.187 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 3.793 \n",
            "Epoch: 26 \tTraining Loss:  0.204 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 3.675 \n",
            "Epoch: 27 \tTraining Loss:  0.154 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 4.385 \n",
            "Epoch: 28 \tTraining Loss:  0.108 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 4.154 \n",
            "Epoch: 29 \tTraining Loss:  0.189 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 4.029 \n",
            "Epoch: 30 \tTraining Loss:  0.138 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 5.772 \n",
            "Epoch: 31 \tTraining Loss:  0.130 \tTrain_Accu: 97%  \tValid_Acc:21% \t Valid Loss: 4.894 \n",
            "Epoch: 32 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 5.429 \n",
            "Epoch: 33 \tTraining Loss:  0.116 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 5.284 \n",
            "Epoch: 34 \tTraining Loss:  0.096 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 4.939 \n",
            "Epoch: 35 \tTraining Loss:  0.092 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 4.419 \n",
            "Epoch: 36 \tTraining Loss:  0.108 \tTrain_Accu: 97%  \tValid_Acc:33% \t Valid Loss: 5.291 \n",
            "Epoch: 37 \tTraining Loss:  0.180 \tTrain_Accu: 96%  \tValid_Acc:19% \t Valid Loss: 3.945 \n",
            "Epoch: 38 \tTraining Loss:  0.119 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 4.312 \n",
            "Epoch: 39 \tTraining Loss:  0.081 \tTrain_Accu: 97%  \tValid_Acc:21% \t Valid Loss: 5.835 \n",
            "Epoch: 40 \tTraining Loss:  0.078 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 4.550 \n",
            "Epoch: 41 \tTraining Loss:  0.117 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 4.464 \n",
            "Epoch: 42 \tTraining Loss:  0.104 \tTrain_Accu: 97%  \tValid_Acc:19% \t Valid Loss: 5.129 \n",
            "Epoch: 43 \tTraining Loss:  0.068 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 4.218 \n",
            "Epoch: 44 \tTraining Loss:  0.100 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 5.149 \n",
            "Epoch: 45 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \tValid_Acc:21% \t Valid Loss: 8.598 \n",
            "Epoch: 46 \tTraining Loss:  0.073 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 5.376 \n",
            "Epoch: 47 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:23% \t Valid Loss: 5.316 \n",
            "Epoch: 48 \tTraining Loss:  0.034 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 5.601 \n",
            "Epoch: 49 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:21% \t Valid Loss: 5.936 \n",
            "Epoch: 50 \tTraining Loss:  0.065 \tTrain_Accu: 97%  \tValid_Acc:30% \t Valid Loss: 6.953 \n",
            "Epoch: 51 \tTraining Loss:  0.119 \tTrain_Accu: 97%  \tValid_Acc:20% \t Valid Loss: 7.017 \n",
            "Epoch: 52 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 6.251 \n",
            "Epoch: 53 \tTraining Loss:  0.093 \tTrain_Accu: 98%  \tValid_Acc:21% \t Valid Loss: 5.598 \n",
            "Epoch: 54 \tTraining Loss:  0.050 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 7.781 \n",
            "Epoch: 55 \tTraining Loss:  0.082 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 5.210 \n",
            "Epoch: 56 \tTraining Loss:  0.072 \tTrain_Accu: 96%  \tValid_Acc:31% \t Valid Loss: 5.815 \n",
            "Epoch: 57 \tTraining Loss:  0.046 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 4.966 \n",
            "Epoch: 58 \tTraining Loss:  0.053 \tTrain_Accu: 99%  \tValid_Acc:21% \t Valid Loss: 4.733 \n",
            "Epoch: 59 \tTraining Loss:  0.034 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 5.854 \n",
            "Epoch: 60 \tTraining Loss:  0.016 \tTrain_Accu: 99%  \tValid_Acc:21% \t Valid Loss: 5.905 \n",
            "Epoch: 61 \tTraining Loss:  0.013 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 6.116 \n",
            "Epoch: 62 \tTraining Loss:  0.079 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 6.846 \n",
            "Epoch: 63 \tTraining Loss:  0.041 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 6.058 \n",
            "Epoch: 64 \tTraining Loss:  0.102 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 7.378 \n",
            "Epoch: 65 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 7.208 \n",
            "Epoch: 66 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 5.609 \n",
            "Epoch: 67 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 8.251 \n",
            "Epoch: 68 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 10.323 \n",
            "Epoch: 69 \tTraining Loss:  0.066 \tTrain_Accu: 98%  \tValid_Acc:33% \t Valid Loss: 6.118 \n",
            "Epoch: 70 \tTraining Loss:  0.040 \tTrain_Accu: 98%  \tValid_Acc:34% \t Valid Loss: 6.199 \n",
            "Epoch: 71 \tTraining Loss:  0.074 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 6.430 \n",
            "Epoch: 72 \tTraining Loss:  0.087 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 5.800 \n",
            "Epoch: 73 \tTraining Loss:  0.051 \tTrain_Accu: 99%  \tValid_Acc:17% \t Valid Loss: 7.259 \n",
            "Epoch: 74 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 6.541 \n",
            "Epoch: 75 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 8.342 \n",
            "Epoch: 76 \tTraining Loss:  0.009 \tTrain_Accu: 100%  \tValid_Acc:23% \t Valid Loss: 9.195 \n",
            "Epoch: 77 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 13.277 \n",
            "Epoch: 78 \tTraining Loss:  0.122 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 7.452 \n",
            "Epoch: 79 \tTraining Loss:  0.069 \tTrain_Accu: 98%  \tValid_Acc:20% \t Valid Loss: 8.120 \n",
            "Epoch: 80 \tTraining Loss:  0.047 \tTrain_Accu: 98%  \tValid_Acc:20% \t Valid Loss: 7.169 \n",
            "Epoch: 81 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 6.890 \n",
            "Epoch: 82 \tTraining Loss:  0.085 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 5.930 \n",
            "Epoch: 83 \tTraining Loss:  0.012 \tTrain_Accu: 100%  \tValid_Acc:20% \t Valid Loss: 8.667 \n",
            "Epoch: 84 \tTraining Loss:  0.098 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 5.522 \n",
            "Epoch: 85 \tTraining Loss:  0.052 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 7.381 \n",
            "Epoch: 86 \tTraining Loss:  0.012 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 7.998 \n",
            "Epoch: 87 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \tValid_Acc:31% \t Valid Loss: 7.587 \n",
            "Epoch: 88 \tTraining Loss:  0.036 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 7.203 \n",
            "Epoch: 89 \tTraining Loss:  0.039 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 6.851 \n",
            "Epoch: 90 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 7.116 \n",
            "Epoch: 91 \tTraining Loss:  0.014 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 7.861 \n",
            "Epoch: 92 \tTraining Loss:  0.063 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 6.290 \n",
            "Epoch: 93 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:31% \t Valid Loss: 10.504 \n",
            "Epoch: 94 \tTraining Loss:  0.063 \tTrain_Accu: 99%  \tValid_Acc:29% \t Valid Loss: 7.413 \n",
            "Epoch: 95 \tTraining Loss:  0.011 \tTrain_Accu: 100%  \tValid_Acc:30% \t Valid Loss: 9.522 \n",
            "Epoch: 96 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:23% \t Valid Loss: 8.434 \n",
            "Epoch: 97 \tTraining Loss:  0.046 \tTrain_Accu: 99%  \tValid_Acc:31% \t Valid Loss: 6.746 \n",
            "Epoch: 98 \tTraining Loss:  0.065 \tTrain_Accu: 99%  \tValid_Acc:29% \t Valid Loss: 8.333 \n",
            "Epoch: 99 \tTraining Loss:  0.007 \tTrain_Accu: 100%  \tValid_Acc:26% \t Valid Loss: 9.613 \n",
            "Epoch: 100 \tTraining Loss:  0.013 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 7.736 \n",
            "Epoch: 101 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 10.880 \n",
            "Epoch: 102 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 8.901 \n",
            "Epoch: 103 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:20% \t Valid Loss: 9.150 \n",
            "Epoch: 104 \tTraining Loss:  0.009 \tTrain_Accu: 100%  \tValid_Acc:21% \t Valid Loss: 9.915 \n",
            "Epoch: 105 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \tValid_Acc:20% \t Valid Loss: 6.421 \n",
            "Epoch: 106 \tTraining Loss:  0.014 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 8.121 \n",
            "Epoch: 107 \tTraining Loss:  0.045 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 7.008 \n",
            "Epoch: 108 \tTraining Loss:  0.014 \tTrain_Accu: 99%  \tValid_Acc:21% \t Valid Loss: 14.808 \n",
            "Epoch: 109 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 8.269 \n",
            "Epoch: 110 \tTraining Loss:  0.037 \tTrain_Accu: 99%  \tValid_Acc:23% \t Valid Loss: 7.831 \n",
            "Epoch: 111 \tTraining Loss:  0.013 \tTrain_Accu: 99%  \tValid_Acc:20% \t Valid Loss: 9.752 \n",
            "Epoch: 112 \tTraining Loss:  0.019 \tTrain_Accu: 100%  \tValid_Acc:23% \t Valid Loss: 10.016 \n",
            "Epoch: 113 \tTraining Loss:  0.079 \tTrain_Accu: 99%  \tValid_Acc:19% \t Valid Loss: 8.653 \n",
            "Epoch: 114 \tTraining Loss:  0.077 \tTrain_Accu: 98%  \tValid_Acc:19% \t Valid Loss: 8.240 \n",
            "Epoch: 115 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \tValid_Acc:20% \t Valid Loss: 7.740 \n",
            "Epoch: 116 \tTraining Loss:  0.007 \tTrain_Accu: 100%  \tValid_Acc:24% \t Valid Loss: 10.119 \n",
            "Epoch: 117 \tTraining Loss:  0.005 \tTrain_Accu: 100%  \tValid_Acc:29% \t Valid Loss: 7.918 \n",
            "Epoch: 118 \tTraining Loss:  0.009 \tTrain_Accu: 100%  \tValid_Acc:24% \t Valid Loss: 10.374 \n",
            "Epoch: 119 \tTraining Loss:  0.001 \tTrain_Accu: 100%  \tValid_Acc:26% \t Valid Loss: 8.203 \n",
            "Epoch: 120 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 9.885 \n",
            "Epoch: 121 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:20% \t Valid Loss: 10.729 \n",
            "Epoch: 122 \tTraining Loss:  0.045 \tTrain_Accu: 99%  \tValid_Acc:20% \t Valid Loss: 6.962 \n",
            "Epoch: 123 \tTraining Loss:  0.034 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 7.851 \n",
            "Epoch: 124 \tTraining Loss:  0.076 \tTrain_Accu: 99%  \tValid_Acc:14% \t Valid Loss: 4.141 \n",
            "Epoch: 125 \tTraining Loss:  0.007 \tTrain_Accu: 100%  \tValid_Acc:24% \t Valid Loss: 5.400 \n",
            "Epoch: 126 \tTraining Loss:  0.015 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 8.525 \n",
            "Epoch: 127 \tTraining Loss:  0.043 \tTrain_Accu: 99%  \tValid_Acc:23% \t Valid Loss: 5.263 \n",
            "Epoch: 128 \tTraining Loss:  0.046 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 5.918 \n",
            "Epoch: 129 \tTraining Loss:  0.072 \tTrain_Accu: 99%  \tValid_Acc:21% \t Valid Loss: 6.965 \n",
            "Epoch: 130 \tTraining Loss:  0.026 \tTrain_Accu: 99%  \tValid_Acc:31% \t Valid Loss: 6.235 \n",
            "Epoch: 131 \tTraining Loss:  0.005 \tTrain_Accu: 100%  \tValid_Acc:26% \t Valid Loss: 8.849 \n",
            "Epoch: 132 \tTraining Loss:  0.008 \tTrain_Accu: 100%  \tValid_Acc:24% \t Valid Loss: 12.722 \n",
            "Epoch: 133 \tTraining Loss:  0.000 \tTrain_Accu: 100%  \tValid_Acc:24% \t Valid Loss: 14.745 \n",
            "Epoch: 134 \tTraining Loss:  0.008 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 18.158 \n",
            "Epoch: 135 \tTraining Loss:  0.147 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 20.412 \n",
            "Epoch: 136 \tTraining Loss:  0.010 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 25.276 \n",
            "Epoch: 137 \tTraining Loss:  0.081 \tTrain_Accu: 99%  \tValid_Acc:23% \t Valid Loss: 14.684 \n",
            "Epoch: 138 \tTraining Loss:  0.059 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 13.555 \n",
            "Epoch: 139 \tTraining Loss:  0.028 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 12.974 \n",
            "Epoch: 140 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:29% \t Valid Loss: 9.551 \n",
            "Epoch: 141 \tTraining Loss:  0.065 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 10.812 \n",
            "Epoch: 142 \tTraining Loss:  0.022 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 8.399 \n",
            "Epoch: 143 \tTraining Loss:  0.017 \tTrain_Accu: 99%  \tValid_Acc:19% \t Valid Loss: 10.018 \n",
            "Epoch: 144 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 5.020 \n",
            "Epoch: 145 \tTraining Loss:  0.012 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 7.307 \n",
            "Epoch: 146 \tTraining Loss:  0.009 \tTrain_Accu: 100%  \tValid_Acc:29% \t Valid Loss: 7.818 \n",
            "Epoch: 147 \tTraining Loss:  0.033 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 10.453 \n",
            "Epoch: 148 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \tValid_Acc:20% \t Valid Loss: 10.134 \n",
            "Epoch: 149 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \tValid_Acc:23% \t Valid Loss: 13.429 \n",
            "Epoch: 150 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 15.418 \n",
            "Epoch: 151 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 10.099 \n",
            "Epoch: 152 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \tValid_Acc:30% \t Valid Loss: 11.056 \n",
            "Epoch: 153 \tTraining Loss:  0.001 \tTrain_Accu: 100%  \tValid_Acc:27% \t Valid Loss: 11.521 \n",
            "Epoch: 154 \tTraining Loss:  0.011 \tTrain_Accu: 100%  \tValid_Acc:26% \t Valid Loss: 17.152 \n",
            "Epoch: 155 \tTraining Loss:  0.042 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 20.790 \n",
            "Epoch: 156 \tTraining Loss:  0.053 \tTrain_Accu: 99%  \tValid_Acc:30% \t Valid Loss: 16.513 \n",
            "Epoch: 157 \tTraining Loss:  0.003 \tTrain_Accu: 100%  \tValid_Acc:26% \t Valid Loss: 18.302 \n",
            "Epoch: 158 \tTraining Loss:  0.010 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 14.524 \n",
            "Epoch: 159 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 12.337 \n",
            "Epoch: 160 \tTraining Loss:  0.039 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 10.894 \n",
            "Epoch: 161 \tTraining Loss:  0.083 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 4.066 \n",
            "Epoch: 162 \tTraining Loss:  0.035 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 8.460 \n",
            "Epoch: 163 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:19% \t Valid Loss: 9.733 \n",
            "Epoch: 164 \tTraining Loss:  0.035 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 9.741 \n",
            "Epoch: 165 \tTraining Loss:  0.015 \tTrain_Accu: 99%  \tValid_Acc:23% \t Valid Loss: 10.341 \n",
            "Epoch: 166 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 8.085 \n",
            "Epoch: 167 \tTraining Loss:  0.012 \tTrain_Accu: 99%  \tValid_Acc:23% \t Valid Loss: 10.065 \n",
            "Epoch: 168 \tTraining Loss:  0.003 \tTrain_Accu: 100%  \tValid_Acc:19% \t Valid Loss: 10.840 \n",
            "Epoch: 169 \tTraining Loss:  0.169 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 5.698 \n",
            "Epoch: 170 \tTraining Loss:  0.005 \tTrain_Accu: 100%  \tValid_Acc:21% \t Valid Loss: 8.180 \n",
            "Epoch: 171 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \tValid_Acc:30% \t Valid Loss: 8.525 \n",
            "Epoch: 172 \tTraining Loss:  0.019 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 9.522 \n",
            "Epoch: 173 \tTraining Loss:  0.105 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 10.297 \n",
            "Epoch: 174 \tTraining Loss:  0.011 \tTrain_Accu: 100%  \tValid_Acc:29% \t Valid Loss: 13.283 \n",
            "Epoch: 175 \tTraining Loss:  0.051 \tTrain_Accu: 99%  \tValid_Acc:30% \t Valid Loss: 7.646 \n",
            "Epoch: 176 \tTraining Loss:  0.037 \tTrain_Accu: 98%  \tValid_Acc:21% \t Valid Loss: 10.171 \n",
            "Epoch: 177 \tTraining Loss:  0.005 \tTrain_Accu: 100%  \tValid_Acc:23% \t Valid Loss: 10.474 \n",
            "Epoch: 178 \tTraining Loss:  0.000 \tTrain_Accu: 100%  \tValid_Acc:21% \t Valid Loss: 12.347 \n",
            "Epoch: 179 \tTraining Loss:  0.027 \tTrain_Accu: 100%  \tValid_Acc:21% \t Valid Loss: 12.007 \n",
            "Epoch: 180 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 9.225 \n",
            "Epoch: 181 \tTraining Loss:  0.020 \tTrain_Accu: 99%  \tValid_Acc:33% \t Valid Loss: 11.079 \n",
            "Epoch: 182 \tTraining Loss:  0.021 \tTrain_Accu: 99%  \tValid_Acc:21% \t Valid Loss: 12.509 \n",
            "Epoch: 183 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:30% \t Valid Loss: 12.103 \n",
            "Epoch: 184 \tTraining Loss:  0.024 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 12.086 \n",
            "Epoch: 185 \tTraining Loss:  0.037 \tTrain_Accu: 98%  \tValid_Acc:21% \t Valid Loss: 11.523 \n",
            "Epoch: 186 \tTraining Loss:  0.031 \tTrain_Accu: 99%  \tValid_Acc:21% \t Valid Loss: 8.649 \n",
            "Epoch: 187 \tTraining Loss:  0.033 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 13.474 \n",
            "Epoch: 188 \tTraining Loss:  0.044 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 6.627 \n",
            "Epoch: 189 \tTraining Loss:  0.009 \tTrain_Accu: 100%  \tValid_Acc:27% \t Valid Loss: 9.498 \n",
            "Epoch: 190 \tTraining Loss:  0.004 \tTrain_Accu: 100%  \tValid_Acc:19% \t Valid Loss: 8.606 \n",
            "Epoch: 191 \tTraining Loss:  0.009 \tTrain_Accu: 100%  \tValid_Acc:27% \t Valid Loss: 7.868 \n",
            "Epoch: 192 \tTraining Loss:  0.050 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 9.230 \n",
            "Epoch: 193 \tTraining Loss:  0.029 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 13.191 \n",
            "Epoch: 194 \tTraining Loss:  0.004 \tTrain_Accu: 100%  \tValid_Acc:27% \t Valid Loss: 12.431 \n",
            "Epoch: 195 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:20% \t Valid Loss: 10.451 \n",
            "Epoch: 196 \tTraining Loss:  0.004 \tTrain_Accu: 100%  \tValid_Acc:27% \t Valid Loss: 11.036 \n",
            "Epoch: 197 \tTraining Loss:  0.012 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 11.487 \n",
            "Epoch: 198 \tTraining Loss:  0.073 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 13.028 \n",
            "Epoch: 199 \tTraining Loss:  0.052 \tTrain_Accu: 100%  \tValid_Acc:29% \t Valid Loss: 9.086 \n",
            "Epoch: 200 \tTraining Loss:  0.015 \tTrain_Accu: 99%  \tValid_Acc:20% \t Valid Loss: 10.294 \n",
            "Epoch: 201 \tTraining Loss:  0.016 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 7.050 \n",
            "Epoch: 202 \tTraining Loss:  0.003 \tTrain_Accu: 100%  \tValid_Acc:31% \t Valid Loss: 8.806 \n",
            "Epoch: 203 \tTraining Loss:  0.000 \tTrain_Accu: 100%  \tValid_Acc:23% \t Valid Loss: 10.071 \n",
            "Epoch: 204 \tTraining Loss:  0.015 \tTrain_Accu: 100%  \tValid_Acc:24% \t Valid Loss: 9.504 \n",
            "Epoch: 205 \tTraining Loss:  0.002 \tTrain_Accu: 100%  \tValid_Acc:31% \t Valid Loss: 10.051 \n",
            "Epoch: 206 \tTraining Loss:  0.005 \tTrain_Accu: 100%  \tValid_Acc:24% \t Valid Loss: 12.543 \n",
            "Epoch: 207 \tTraining Loss:  0.010 \tTrain_Accu: 100%  \tValid_Acc:26% \t Valid Loss: 8.672 \n",
            "Epoch: 208 \tTraining Loss:  0.013 \tTrain_Accu: 100%  \tValid_Acc:23% \t Valid Loss: 7.110 \n",
            "Epoch: 209 \tTraining Loss:  0.005 \tTrain_Accu: 100%  \tValid_Acc:21% \t Valid Loss: 14.814 \n",
            "Epoch: 210 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:21% \t Valid Loss: 20.737 \n",
            "Epoch: 211 \tTraining Loss:  0.003 \tTrain_Accu: 100%  \tValid_Acc:20% \t Valid Loss: 17.594 \n",
            "Epoch: 212 \tTraining Loss:  0.042 \tTrain_Accu: 99%  \tValid_Acc:21% \t Valid Loss: 7.630 \n",
            "Epoch: 213 \tTraining Loss:  0.048 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 8.210 \n",
            "Epoch: 214 \tTraining Loss:  0.014 \tTrain_Accu: 99%  \tValid_Acc:17% \t Valid Loss: 12.030 \n",
            "Epoch: 215 \tTraining Loss:  0.037 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 23.568 \n",
            "Epoch: 216 \tTraining Loss:  0.064 \tTrain_Accu: 99%  \tValid_Acc:20% \t Valid Loss: 14.097 \n",
            "Epoch: 217 \tTraining Loss:  0.027 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 11.838 \n",
            "Epoch: 218 \tTraining Loss:  0.003 \tTrain_Accu: 100%  \tValid_Acc:21% \t Valid Loss: 11.588 \n",
            "Epoch: 219 \tTraining Loss:  0.006 \tTrain_Accu: 100%  \tValid_Acc:31% \t Valid Loss: 9.888 \n",
            "Epoch: 220 \tTraining Loss:  0.010 \tTrain_Accu: 99%  \tValid_Acc:26% \t Valid Loss: 12.095 \n",
            "Epoch: 221 \tTraining Loss:  0.011 \tTrain_Accu: 100%  \tValid_Acc:30% \t Valid Loss: 10.234 \n",
            "Epoch: 222 \tTraining Loss:  0.084 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 4.987 \n",
            "Epoch: 223 \tTraining Loss:  0.012 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 8.083 \n",
            "Epoch: 224 \tTraining Loss:  0.006 \tTrain_Accu: 100%  \tValid_Acc:27% \t Valid Loss: 7.928 \n",
            "Epoch: 225 \tTraining Loss:  0.008 \tTrain_Accu: 99%  \tValid_Acc:21% \t Valid Loss: 11.542 \n",
            "Epoch: 226 \tTraining Loss:  0.005 \tTrain_Accu: 100%  \tValid_Acc:29% \t Valid Loss: 13.033 \n",
            "Epoch: 227 \tTraining Loss:  0.016 \tTrain_Accu: 99%  \tValid_Acc:30% \t Valid Loss: 14.662 \n",
            "Epoch: 228 \tTraining Loss:  0.014 \tTrain_Accu: 99%  \tValid_Acc:29% \t Valid Loss: 15.460 \n",
            "Epoch: 229 \tTraining Loss:  0.029 \tTrain_Accu: 99%  \tValid_Acc:20% \t Valid Loss: 12.602 \n",
            "Epoch: 230 \tTraining Loss:  0.005 \tTrain_Accu: 100%  \tValid_Acc:21% \t Valid Loss: 16.745 \n",
            "Epoch: 231 \tTraining Loss:  0.194 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 7.671 \n",
            "Epoch: 232 \tTraining Loss:  0.059 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 3.261 \n",
            "Epoch: 233 \tTraining Loss:  0.014 \tTrain_Accu: 100%  \tValid_Acc:26% \t Valid Loss: 8.732 \n",
            "Epoch: 234 \tTraining Loss:  0.013 \tTrain_Accu: 99%  \tValid_Acc:31% \t Valid Loss: 6.734 \n",
            "Epoch: 235 \tTraining Loss:  0.018 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 9.736 \n",
            "Epoch: 236 \tTraining Loss:  0.015 \tTrain_Accu: 100%  \tValid_Acc:24% \t Valid Loss: 8.860 \n",
            "Epoch: 237 \tTraining Loss:  0.005 \tTrain_Accu: 100%  \tValid_Acc:30% \t Valid Loss: 11.831 \n",
            "Epoch: 238 \tTraining Loss:  0.013 \tTrain_Accu: 100%  \tValid_Acc:21% \t Valid Loss: 11.475 \n",
            "Epoch: 239 \tTraining Loss:  0.003 \tTrain_Accu: 100%  \tValid_Acc:27% \t Valid Loss: 8.777 \n",
            "Epoch: 240 \tTraining Loss:  0.014 \tTrain_Accu: 99%  \tValid_Acc:20% \t Valid Loss: 18.437 \n",
            "Epoch: 241 \tTraining Loss:  0.047 \tTrain_Accu: 100%  \tValid_Acc:23% \t Valid Loss: 11.787 \n",
            "Epoch: 242 \tTraining Loss:  0.004 \tTrain_Accu: 100%  \tValid_Acc:23% \t Valid Loss: 11.680 \n",
            "Epoch: 243 \tTraining Loss:  0.010 \tTrain_Accu: 100%  \tValid_Acc:26% \t Valid Loss: 9.549 \n",
            "Epoch: 244 \tTraining Loss:  0.087 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 27.740 \n",
            "Epoch: 245 \tTraining Loss:  0.088 \tTrain_Accu: 99%  \tValid_Acc:20% \t Valid Loss: 17.013 \n",
            "Epoch: 246 \tTraining Loss:  0.090 \tTrain_Accu: 99%  \tValid_Acc:23% \t Valid Loss: 16.790 \n",
            "Epoch: 247 \tTraining Loss:  0.000 \tTrain_Accu: 100%  \tValid_Acc:23% \t Valid Loss: 16.205 \n",
            "Epoch: 248 \tTraining Loss:  0.023 \tTrain_Accu: 99%  \tValid_Acc:27% \t Valid Loss: 15.177 \n",
            "Epoch: 249 \tTraining Loss:  0.011 \tTrain_Accu: 99%  \tValid_Acc:24% \t Valid Loss: 16.676 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 20:15:29,685]\u001b[0m Trial 3 finished with value: 22.9 and parameters: {'Batch_size': 1, 'lr': 0.001, 'optimizer': <class 'torch.optim.adam.Adam'>, 'dropout': 0.5}. Best is trial 3 with value: 22.9.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.018 \tTrain_Accu: 100%  \tValid_Acc:23% \t Valid Loss: 13.048 \n",
            "Epoch: 1 \tTraining Loss:  940.872 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.671 \n",
            "Epoch: 2 \tTraining Loss:  1.640 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.661 \n",
            "Epoch: 3 \tTraining Loss:  1.621 \tTrain_Accu: 24%  \tValid_Acc:26% \t Valid Loss: 1.673 \n",
            "Epoch: 4 \tTraining Loss:  1.624 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 5 \tTraining Loss:  1.641 \tTrain_Accu: 15%  \tValid_Acc:7% \t Valid Loss: 1.633 \n",
            "Epoch: 6 \tTraining Loss:  1.630 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.699 \n",
            "Epoch: 7 \tTraining Loss:  1.629 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.650 \n",
            "Epoch: 8 \tTraining Loss:  1.633 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.601 \n",
            "Epoch: 9 \tTraining Loss:  1.640 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.682 \n",
            "Epoch: 10 \tTraining Loss:  1.636 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.643 \n",
            "Epoch: 11 \tTraining Loss:  1.643 \tTrain_Accu: 18%  \tValid_Acc:33% \t Valid Loss: 1.606 \n",
            "Epoch: 12 \tTraining Loss:  1.644 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.708 \n",
            "Epoch: 13 \tTraining Loss:  1.634 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.669 \n",
            "Epoch: 14 \tTraining Loss:  1.631 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.647 \n",
            "Epoch: 15 \tTraining Loss:  1.632 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 16 \tTraining Loss:  1.631 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.657 \n",
            "Epoch: 17 \tTraining Loss:  1.627 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.595 \n",
            "Epoch: 18 \tTraining Loss:  1.634 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.697 \n",
            "Epoch: 19 \tTraining Loss:  1.642 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.645 \n",
            "Epoch: 20 \tTraining Loss:  1.626 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.608 \n",
            "Epoch: 21 \tTraining Loss:  1.626 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.653 \n",
            "Epoch: 22 \tTraining Loss:  1.634 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.574 \n",
            "Epoch: 23 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.671 \n",
            "Epoch: 24 \tTraining Loss:  1.627 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.667 \n",
            "Epoch: 25 \tTraining Loss:  1.629 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.645 \n",
            "Epoch: 26 \tTraining Loss:  1.641 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.690 \n",
            "Epoch: 27 \tTraining Loss:  1.635 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.691 \n",
            "Epoch: 28 \tTraining Loss:  1.629 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.591 \n",
            "Epoch: 29 \tTraining Loss:  1.632 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 30 \tTraining Loss:  1.626 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.661 \n",
            "Epoch: 31 \tTraining Loss:  1.626 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.645 \n",
            "Epoch: 32 \tTraining Loss:  1.621 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.662 \n",
            "Epoch: 33 \tTraining Loss:  1.626 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.642 \n",
            "Epoch: 34 \tTraining Loss:  1.619 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.688 \n",
            "Epoch: 35 \tTraining Loss:  1.631 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.600 \n",
            "Epoch: 36 \tTraining Loss:  1.644 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.654 \n",
            "Epoch: 37 \tTraining Loss:  1.656 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 38 \tTraining Loss:  1.630 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 39 \tTraining Loss:  1.634 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.591 \n",
            "Epoch: 40 \tTraining Loss:  1.628 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.688 \n",
            "Epoch: 41 \tTraining Loss:  1.638 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.733 \n",
            "Epoch: 42 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.646 \n",
            "Epoch: 43 \tTraining Loss:  1.633 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.615 \n",
            "Epoch: 44 \tTraining Loss:  1.628 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.688 \n",
            "Epoch: 45 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.688 \n",
            "Epoch: 46 \tTraining Loss:  1.628 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.649 \n",
            "Epoch: 47 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.679 \n",
            "Epoch: 48 \tTraining Loss:  1.631 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.619 \n",
            "Epoch: 49 \tTraining Loss:  1.626 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.645 \n",
            "Epoch: 50 \tTraining Loss:  1.630 \tTrain_Accu: 23%  \tValid_Acc:26% \t Valid Loss: 1.656 \n",
            "Epoch: 51 \tTraining Loss:  1.641 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 52 \tTraining Loss:  1.631 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.612 \n",
            "Epoch: 53 \tTraining Loss:  1.617 \tTrain_Accu: 25%  \tValid_Acc:33% \t Valid Loss: 1.540 \n",
            "Epoch: 54 \tTraining Loss:  1.648 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.665 \n",
            "Epoch: 55 \tTraining Loss:  1.632 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.647 \n",
            "Epoch: 56 \tTraining Loss:  1.631 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.641 \n",
            "Epoch: 57 \tTraining Loss:  1.623 \tTrain_Accu: 24%  \tValid_Acc:7% \t Valid Loss: 1.648 \n",
            "Epoch: 58 \tTraining Loss:  1.622 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.605 \n",
            "Epoch: 59 \tTraining Loss:  1.637 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.614 \n",
            "Epoch: 60 \tTraining Loss:  1.622 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.678 \n",
            "Epoch: 61 \tTraining Loss:  1.642 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.646 \n",
            "Epoch: 62 \tTraining Loss:  1.621 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 63 \tTraining Loss:  1.633 \tTrain_Accu: 21%  \tValid_Acc:33% \t Valid Loss: 1.590 \n",
            "Epoch: 64 \tTraining Loss:  1.629 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 65 \tTraining Loss:  1.625 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.619 \n",
            "Epoch: 66 \tTraining Loss:  1.649 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.676 \n",
            "Epoch: 67 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.644 \n",
            "Epoch: 68 \tTraining Loss:  1.625 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.617 \n",
            "Epoch: 69 \tTraining Loss:  1.629 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 70 \tTraining Loss:  1.631 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.579 \n",
            "Epoch: 71 \tTraining Loss:  1.639 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.561 \n",
            "Epoch: 72 \tTraining Loss:  1.628 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 73 \tTraining Loss:  1.626 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.650 \n",
            "Epoch: 74 \tTraining Loss:  1.634 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.661 \n",
            "Epoch: 75 \tTraining Loss:  1.629 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.721 \n",
            "Epoch: 76 \tTraining Loss:  1.630 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.617 \n",
            "Epoch: 77 \tTraining Loss:  1.619 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.712 \n",
            "Epoch: 78 \tTraining Loss:  1.642 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.641 \n",
            "Epoch: 79 \tTraining Loss:  1.638 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 80 \tTraining Loss:  1.649 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.728 \n",
            "Epoch: 81 \tTraining Loss:  1.638 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.656 \n",
            "Epoch: 82 \tTraining Loss:  1.633 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.655 \n",
            "Epoch: 83 \tTraining Loss:  1.632 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 84 \tTraining Loss:  1.642 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.642 \n",
            "Epoch: 85 \tTraining Loss:  1.626 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.620 \n",
            "Epoch: 86 \tTraining Loss:  1.626 \tTrain_Accu: 22%  \tValid_Acc:33% \t Valid Loss: 1.583 \n",
            "Epoch: 87 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.597 \n",
            "Epoch: 88 \tTraining Loss:  1.635 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.670 \n",
            "Epoch: 89 \tTraining Loss:  1.628 \tTrain_Accu: 23%  \tValid_Acc:26% \t Valid Loss: 1.610 \n",
            "Epoch: 90 \tTraining Loss:  1.627 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.703 \n",
            "Epoch: 91 \tTraining Loss:  1.623 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.664 \n",
            "Epoch: 92 \tTraining Loss:  1.625 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.688 \n",
            "Epoch: 93 \tTraining Loss:  1.642 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.681 \n",
            "Epoch: 94 \tTraining Loss:  1.634 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.648 \n",
            "Epoch: 95 \tTraining Loss:  1.627 \tTrain_Accu: 20%  \tValid_Acc:33% \t Valid Loss: 1.573 \n",
            "Epoch: 96 \tTraining Loss:  1.630 \tTrain_Accu: 18%  \tValid_Acc:33% \t Valid Loss: 1.587 \n",
            "Epoch: 97 \tTraining Loss:  1.639 \tTrain_Accu: 15%  \tValid_Acc:33% \t Valid Loss: 1.596 \n",
            "Epoch: 98 \tTraining Loss:  1.618 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.698 \n",
            "Epoch: 99 \tTraining Loss:  1.629 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.704 \n",
            "Epoch: 100 \tTraining Loss:  1.632 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.598 \n",
            "Epoch: 101 \tTraining Loss:  1.627 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.673 \n",
            "Epoch: 102 \tTraining Loss:  1.625 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.664 \n",
            "Epoch: 103 \tTraining Loss:  1.627 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.645 \n",
            "Epoch: 104 \tTraining Loss:  1.629 \tTrain_Accu: 14%  \tValid_Acc:7% \t Valid Loss: 1.655 \n",
            "Epoch: 105 \tTraining Loss:  1.623 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 106 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.616 \n",
            "Epoch: 107 \tTraining Loss:  1.628 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.717 \n",
            "Epoch: 108 \tTraining Loss:  1.630 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.607 \n",
            "Epoch: 109 \tTraining Loss:  1.628 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.685 \n",
            "Epoch: 110 \tTraining Loss:  1.631 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.748 \n",
            "Epoch: 111 \tTraining Loss:  1.624 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.645 \n",
            "Epoch: 112 \tTraining Loss:  1.636 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.691 \n",
            "Epoch: 113 \tTraining Loss:  1.628 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.678 \n",
            "Epoch: 114 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.607 \n",
            "Epoch: 115 \tTraining Loss:  1.633 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.647 \n",
            "Epoch: 116 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.626 \n",
            "Epoch: 117 \tTraining Loss:  1.631 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.569 \n",
            "Epoch: 118 \tTraining Loss:  1.644 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.609 \n",
            "Epoch: 119 \tTraining Loss:  1.642 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.680 \n",
            "Epoch: 120 \tTraining Loss:  1.630 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.572 \n",
            "Epoch: 121 \tTraining Loss:  1.642 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 122 \tTraining Loss:  1.627 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 123 \tTraining Loss:  1.632 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.617 \n",
            "Epoch: 124 \tTraining Loss:  1.642 \tTrain_Accu: 20%  \tValid_Acc:33% \t Valid Loss: 1.592 \n",
            "Epoch: 125 \tTraining Loss:  1.641 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.580 \n",
            "Epoch: 126 \tTraining Loss:  1.630 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.680 \n",
            "Epoch: 127 \tTraining Loss:  1.632 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.706 \n",
            "Epoch: 128 \tTraining Loss:  1.626 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.669 \n",
            "Epoch: 129 \tTraining Loss:  1.642 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.625 \n",
            "Epoch: 130 \tTraining Loss:  1.620 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.750 \n",
            "Epoch: 131 \tTraining Loss:  1.620 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.568 \n",
            "Epoch: 132 \tTraining Loss:  1.628 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.707 \n",
            "Epoch: 133 \tTraining Loss:  1.637 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.619 \n",
            "Epoch: 134 \tTraining Loss:  1.628 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.666 \n",
            "Epoch: 135 \tTraining Loss:  1.632 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.658 \n",
            "Epoch: 136 \tTraining Loss:  1.648 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.702 \n",
            "Epoch: 137 \tTraining Loss:  1.645 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.622 \n",
            "Epoch: 138 \tTraining Loss:  1.626 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.618 \n",
            "Epoch: 139 \tTraining Loss:  1.628 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.610 \n",
            "Epoch: 140 \tTraining Loss:  1.641 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.615 \n",
            "Epoch: 141 \tTraining Loss:  1.629 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.651 \n",
            "Epoch: 142 \tTraining Loss:  1.633 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.730 \n",
            "Epoch: 143 \tTraining Loss:  1.625 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.558 \n",
            "Epoch: 144 \tTraining Loss:  1.641 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 145 \tTraining Loss:  1.635 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 146 \tTraining Loss:  1.629 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.683 \n",
            "Epoch: 147 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.723 \n",
            "Epoch: 148 \tTraining Loss:  1.629 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.580 \n",
            "Epoch: 149 \tTraining Loss:  1.634 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.644 \n",
            "Epoch: 150 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.696 \n",
            "Epoch: 151 \tTraining Loss:  1.627 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 152 \tTraining Loss:  1.617 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.741 \n",
            "Epoch: 153 \tTraining Loss:  1.641 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.624 \n",
            "Epoch: 154 \tTraining Loss:  1.645 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.610 \n",
            "Epoch: 155 \tTraining Loss:  1.637 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 156 \tTraining Loss:  1.633 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 157 \tTraining Loss:  1.630 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.686 \n",
            "Epoch: 158 \tTraining Loss:  1.625 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.660 \n",
            "Epoch: 159 \tTraining Loss:  1.630 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.651 \n",
            "Epoch: 160 \tTraining Loss:  1.627 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.615 \n",
            "Epoch: 161 \tTraining Loss:  1.623 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.606 \n",
            "Epoch: 162 \tTraining Loss:  1.650 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.728 \n",
            "Epoch: 163 \tTraining Loss:  1.647 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.618 \n",
            "Epoch: 164 \tTraining Loss:  1.628 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.658 \n",
            "Epoch: 165 \tTraining Loss:  1.632 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.623 \n",
            "Epoch: 166 \tTraining Loss:  1.627 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 167 \tTraining Loss:  1.639 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.593 \n",
            "Epoch: 168 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.709 \n",
            "Epoch: 169 \tTraining Loss:  1.632 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.652 \n",
            "Epoch: 170 \tTraining Loss:  1.631 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.676 \n",
            "Epoch: 171 \tTraining Loss:  1.637 \tTrain_Accu: 17%  \tValid_Acc:33% \t Valid Loss: 1.629 \n",
            "Epoch: 172 \tTraining Loss:  1.634 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.689 \n",
            "Epoch: 173 \tTraining Loss:  1.625 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 174 \tTraining Loss:  1.634 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.646 \n",
            "Epoch: 175 \tTraining Loss:  1.641 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.646 \n",
            "Epoch: 176 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.594 \n",
            "Epoch: 177 \tTraining Loss:  1.635 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.701 \n",
            "Epoch: 178 \tTraining Loss:  1.631 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.702 \n",
            "Epoch: 179 \tTraining Loss:  1.643 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 180 \tTraining Loss:  1.629 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.595 \n",
            "Epoch: 181 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.652 \n",
            "Epoch: 182 \tTraining Loss:  1.637 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.693 \n",
            "Epoch: 183 \tTraining Loss:  1.644 \tTrain_Accu: 14%  \tValid_Acc:26% \t Valid Loss: 1.648 \n",
            "Epoch: 184 \tTraining Loss:  1.627 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.695 \n",
            "Epoch: 185 \tTraining Loss:  1.634 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.690 \n",
            "Epoch: 186 \tTraining Loss:  1.624 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.629 \n",
            "Epoch: 187 \tTraining Loss:  1.633 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.602 \n",
            "Epoch: 188 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.724 \n",
            "Epoch: 189 \tTraining Loss:  1.642 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.660 \n",
            "Epoch: 190 \tTraining Loss:  1.635 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 191 \tTraining Loss:  1.635 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.599 \n",
            "Epoch: 192 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 193 \tTraining Loss:  1.633 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.661 \n",
            "Epoch: 194 \tTraining Loss:  1.633 \tTrain_Accu: 23%  \tValid_Acc:26% \t Valid Loss: 1.708 \n",
            "Epoch: 195 \tTraining Loss:  1.620 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.649 \n",
            "Epoch: 196 \tTraining Loss:  1.627 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.578 \n",
            "Epoch: 197 \tTraining Loss:  1.632 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.696 \n",
            "Epoch: 198 \tTraining Loss:  1.641 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.654 \n",
            "Epoch: 199 \tTraining Loss:  1.640 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.620 \n",
            "Epoch: 200 \tTraining Loss:  1.638 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.652 \n",
            "Epoch: 201 \tTraining Loss:  1.621 \tTrain_Accu: 22%  \tValid_Acc:33% \t Valid Loss: 1.595 \n",
            "Epoch: 202 \tTraining Loss:  1.631 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.690 \n",
            "Epoch: 203 \tTraining Loss:  1.631 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.647 \n",
            "Epoch: 204 \tTraining Loss:  1.633 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.653 \n",
            "Epoch: 205 \tTraining Loss:  1.624 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.741 \n",
            "Epoch: 206 \tTraining Loss:  1.642 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 207 \tTraining Loss:  1.631 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.660 \n",
            "Epoch: 208 \tTraining Loss:  1.632 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.728 \n",
            "Epoch: 209 \tTraining Loss:  1.639 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 210 \tTraining Loss:  1.633 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.587 \n",
            "Epoch: 211 \tTraining Loss:  1.639 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.748 \n",
            "Epoch: 212 \tTraining Loss:  1.627 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 213 \tTraining Loss:  1.630 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.631 \n",
            "Epoch: 214 \tTraining Loss:  1.627 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.660 \n",
            "Epoch: 215 \tTraining Loss:  1.629 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.665 \n",
            "Epoch: 216 \tTraining Loss:  1.651 \tTrain_Accu: 14%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 217 \tTraining Loss:  1.641 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 218 \tTraining Loss:  1.642 \tTrain_Accu: 16%  \tValid_Acc:33% \t Valid Loss: 1.594 \n",
            "Epoch: 219 \tTraining Loss:  1.625 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.684 \n",
            "Epoch: 220 \tTraining Loss:  1.632 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 221 \tTraining Loss:  1.632 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.572 \n",
            "Epoch: 222 \tTraining Loss:  1.635 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.616 \n",
            "Epoch: 223 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 224 \tTraining Loss:  1.631 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.584 \n",
            "Epoch: 225 \tTraining Loss:  1.621 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.745 \n",
            "Epoch: 226 \tTraining Loss:  1.639 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.672 \n",
            "Epoch: 227 \tTraining Loss:  1.629 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.646 \n",
            "Epoch: 228 \tTraining Loss:  1.642 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.604 \n",
            "Epoch: 229 \tTraining Loss:  1.625 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.627 \n",
            "Epoch: 230 \tTraining Loss:  1.634 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.675 \n",
            "Epoch: 231 \tTraining Loss:  1.624 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.567 \n",
            "Epoch: 232 \tTraining Loss:  1.620 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.629 \n",
            "Epoch: 233 \tTraining Loss:  1.625 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 234 \tTraining Loss:  1.641 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.595 \n",
            "Epoch: 235 \tTraining Loss:  1.637 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.605 \n",
            "Epoch: 236 \tTraining Loss:  1.644 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.668 \n",
            "Epoch: 237 \tTraining Loss:  1.624 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.666 \n",
            "Epoch: 238 \tTraining Loss:  1.632 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.602 \n",
            "Epoch: 239 \tTraining Loss:  1.629 \tTrain_Accu: 17%  \tValid_Acc:33% \t Valid Loss: 1.566 \n",
            "Epoch: 240 \tTraining Loss:  1.650 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.608 \n",
            "Epoch: 241 \tTraining Loss:  1.627 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.674 \n",
            "Epoch: 242 \tTraining Loss:  1.634 \tTrain_Accu: 23%  \tValid_Acc:17% \t Valid Loss: 1.657 \n",
            "Epoch: 243 \tTraining Loss:  1.638 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.693 \n",
            "Epoch: 244 \tTraining Loss:  1.633 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.594 \n",
            "Epoch: 245 \tTraining Loss:  1.619 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.706 \n",
            "Epoch: 246 \tTraining Loss:  1.647 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.748 \n",
            "Epoch: 247 \tTraining Loss:  1.646 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.583 \n",
            "Epoch: 248 \tTraining Loss:  1.638 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.609 \n",
            "Epoch: 249 \tTraining Loss:  1.638 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.632 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 20:18:09,954]\u001b[0m Trial 4 finished with value: 17.1 and parameters: {'Batch_size': 5, 'lr': 0.1, 'optimizer': <class 'torch.optim.adam.Adam'>, 'dropout': 0.7}. Best is trial 3 with value: 22.9.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  1.641 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 1 \tTraining Loss:  2.008 \tTrain_Accu: 18%  \tValid_Acc:9% \t Valid Loss: 1.632 \n",
            "Epoch: 2 \tTraining Loss:  1.606 \tTrain_Accu: 22%  \tValid_Acc:14% \t Valid Loss: 1.625 \n",
            "Epoch: 3 \tTraining Loss:  1.616 \tTrain_Accu: 20%  \tValid_Acc:14% \t Valid Loss: 1.633 \n",
            "Epoch: 4 \tTraining Loss:  1.609 \tTrain_Accu: 18%  \tValid_Acc:16% \t Valid Loss: 1.622 \n",
            "Epoch: 5 \tTraining Loss:  1.607 \tTrain_Accu: 23%  \tValid_Acc:16% \t Valid Loss: 1.630 \n",
            "Epoch: 6 \tTraining Loss:  1.613 \tTrain_Accu: 25%  \tValid_Acc:9% \t Valid Loss: 1.651 \n",
            "Epoch: 7 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:19% \t Valid Loss: 1.633 \n",
            "Epoch: 8 \tTraining Loss:  1.601 \tTrain_Accu: 25%  \tValid_Acc:16% \t Valid Loss: 1.626 \n",
            "Epoch: 9 \tTraining Loss:  1.614 \tTrain_Accu: 23%  \tValid_Acc:17% \t Valid Loss: 1.917 \n",
            "Epoch: 10 \tTraining Loss:  1.616 \tTrain_Accu: 22%  \tValid_Acc:16% \t Valid Loss: 1.637 \n",
            "Epoch: 11 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:21% \t Valid Loss: 1.620 \n",
            "Epoch: 12 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:23% \t Valid Loss: 1.646 \n",
            "Epoch: 13 \tTraining Loss:  1.612 \tTrain_Accu: 20%  \tValid_Acc:20% \t Valid Loss: 1.634 \n",
            "Epoch: 14 \tTraining Loss:  1.610 \tTrain_Accu: 21%  \tValid_Acc:14% \t Valid Loss: 1.634 \n",
            "Epoch: 15 \tTraining Loss:  1.608 \tTrain_Accu: 22%  \tValid_Acc:21% \t Valid Loss: 1.637 \n",
            "Epoch: 16 \tTraining Loss:  1.610 \tTrain_Accu: 23%  \tValid_Acc:23% \t Valid Loss: 1.633 \n",
            "Epoch: 17 \tTraining Loss:  1.609 \tTrain_Accu: 24%  \tValid_Acc:20% \t Valid Loss: 1.628 \n",
            "Epoch: 18 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:23% \t Valid Loss: 1.633 \n",
            "Epoch: 19 \tTraining Loss:  1.613 \tTrain_Accu: 19%  \tValid_Acc:24% \t Valid Loss: 1.621 \n",
            "Epoch: 20 \tTraining Loss:  1.608 \tTrain_Accu: 23%  \tValid_Acc:21% \t Valid Loss: 1.635 \n",
            "Epoch: 21 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:20% \t Valid Loss: 1.633 \n",
            "Epoch: 22 \tTraining Loss:  1.608 \tTrain_Accu: 22%  \tValid_Acc:23% \t Valid Loss: 1.635 \n",
            "Epoch: 23 \tTraining Loss:  1.613 \tTrain_Accu: 19%  \tValid_Acc:20% \t Valid Loss: 1.624 \n",
            "Epoch: 24 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:24% \t Valid Loss: 1.635 \n",
            "Epoch: 25 \tTraining Loss:  1.617 \tTrain_Accu: 22%  \tValid_Acc:19% \t Valid Loss: 1.642 \n",
            "Epoch: 26 \tTraining Loss:  1.610 \tTrain_Accu: 20%  \tValid_Acc:19% \t Valid Loss: 1.630 \n",
            "Epoch: 27 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.625 \n",
            "Epoch: 28 \tTraining Loss:  1.593 \tTrain_Accu: 25%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 29 \tTraining Loss:  1.624 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.650 \n",
            "Epoch: 30 \tTraining Loss:  1.604 \tTrain_Accu: 21%  \tValid_Acc:20% \t Valid Loss: 1.632 \n",
            "Epoch: 31 \tTraining Loss:  1.611 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 32 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:14% \t Valid Loss: 1.648 \n",
            "Epoch: 33 \tTraining Loss:  1.619 \tTrain_Accu: 23%  \tValid_Acc:20% \t Valid Loss: 1.642 \n",
            "Epoch: 34 \tTraining Loss:  1.606 \tTrain_Accu: 22%  \tValid_Acc:19% \t Valid Loss: 1.637 \n",
            "Epoch: 35 \tTraining Loss:  1.593 \tTrain_Accu: 26%  \tValid_Acc:20% \t Valid Loss: 1.659 \n",
            "Epoch: 36 \tTraining Loss:  1.607 \tTrain_Accu: 23%  \tValid_Acc:13% \t Valid Loss: 1.636 \n",
            "Epoch: 37 \tTraining Loss:  1.604 \tTrain_Accu: 23%  \tValid_Acc:14% \t Valid Loss: 1.654 \n",
            "Epoch: 38 \tTraining Loss:  1.604 \tTrain_Accu: 20%  \tValid_Acc:11% \t Valid Loss: 1.642 \n",
            "Epoch: 39 \tTraining Loss:  1.574 \tTrain_Accu: 25%  \tValid_Acc:20% \t Valid Loss: 1.680 \n",
            "Epoch: 40 \tTraining Loss:  1.595 \tTrain_Accu: 22%  \tValid_Acc:20% \t Valid Loss: 1.636 \n",
            "Epoch: 41 \tTraining Loss:  1.595 \tTrain_Accu: 24%  \tValid_Acc:19% \t Valid Loss: 1.605 \n",
            "Epoch: 42 \tTraining Loss:  1.597 \tTrain_Accu: 25%  \tValid_Acc:24% \t Valid Loss: 1.626 \n",
            "Epoch: 43 \tTraining Loss:  1.574 \tTrain_Accu: 26%  \tValid_Acc:20% \t Valid Loss: 1.613 \n",
            "Epoch: 44 \tTraining Loss:  1.590 \tTrain_Accu: 24%  \tValid_Acc:24% \t Valid Loss: 1.647 \n",
            "Epoch: 45 \tTraining Loss:  1.547 \tTrain_Accu: 27%  \tValid_Acc:20% \t Valid Loss: 1.634 \n",
            "Epoch: 46 \tTraining Loss:  1.566 \tTrain_Accu: 23%  \tValid_Acc:29% \t Valid Loss: 1.573 \n",
            "Epoch: 47 \tTraining Loss:  1.581 \tTrain_Accu: 24%  \tValid_Acc:19% \t Valid Loss: 1.678 \n",
            "Epoch: 48 \tTraining Loss:  1.579 \tTrain_Accu: 27%  \tValid_Acc:21% \t Valid Loss: 1.642 \n",
            "Epoch: 49 \tTraining Loss:  1.574 \tTrain_Accu: 27%  \tValid_Acc:24% \t Valid Loss: 1.593 \n",
            "Epoch: 50 \tTraining Loss:  1.537 \tTrain_Accu: 29%  \tValid_Acc:23% \t Valid Loss: 1.646 \n",
            "Epoch: 51 \tTraining Loss:  1.590 \tTrain_Accu: 27%  \tValid_Acc:31% \t Valid Loss: 1.616 \n",
            "Epoch: 52 \tTraining Loss:  1.579 \tTrain_Accu: 27%  \tValid_Acc:14% \t Valid Loss: 1.594 \n",
            "Epoch: 53 \tTraining Loss:  1.578 \tTrain_Accu: 26%  \tValid_Acc:16% \t Valid Loss: 1.677 \n",
            "Epoch: 54 \tTraining Loss:  1.586 \tTrain_Accu: 27%  \tValid_Acc:26% \t Valid Loss: 1.594 \n",
            "Epoch: 55 \tTraining Loss:  1.536 \tTrain_Accu: 28%  \tValid_Acc:26% \t Valid Loss: 1.659 \n",
            "Epoch: 56 \tTraining Loss:  1.567 \tTrain_Accu: 27%  \tValid_Acc:36% \t Valid Loss: 1.603 \n",
            "Epoch: 57 \tTraining Loss:  1.554 \tTrain_Accu: 26%  \tValid_Acc:24% \t Valid Loss: 1.586 \n",
            "Epoch: 58 \tTraining Loss:  1.507 \tTrain_Accu: 27%  \tValid_Acc:24% \t Valid Loss: 1.610 \n",
            "Epoch: 59 \tTraining Loss:  1.546 \tTrain_Accu: 32%  \tValid_Acc:14% \t Valid Loss: 1.627 \n",
            "Epoch: 60 \tTraining Loss:  1.518 \tTrain_Accu: 30%  \tValid_Acc:27% \t Valid Loss: 1.573 \n",
            "Epoch: 61 \tTraining Loss:  1.506 \tTrain_Accu: 31%  \tValid_Acc:26% \t Valid Loss: 1.607 \n",
            "Epoch: 62 \tTraining Loss:  1.506 \tTrain_Accu: 30%  \tValid_Acc:23% \t Valid Loss: 1.610 \n",
            "Epoch: 63 \tTraining Loss:  1.505 \tTrain_Accu: 33%  \tValid_Acc:16% \t Valid Loss: 1.671 \n",
            "Epoch: 64 \tTraining Loss:  1.470 \tTrain_Accu: 34%  \tValid_Acc:14% \t Valid Loss: 1.617 \n",
            "Epoch: 65 \tTraining Loss:  1.508 \tTrain_Accu: 34%  \tValid_Acc:19% \t Valid Loss: 1.669 \n",
            "Epoch: 66 \tTraining Loss:  1.499 \tTrain_Accu: 31%  \tValid_Acc:26% \t Valid Loss: 1.594 \n",
            "Epoch: 67 \tTraining Loss:  1.471 \tTrain_Accu: 34%  \tValid_Acc:24% \t Valid Loss: 1.699 \n",
            "Epoch: 68 \tTraining Loss:  1.503 \tTrain_Accu: 31%  \tValid_Acc:21% \t Valid Loss: 1.578 \n",
            "Epoch: 69 \tTraining Loss:  1.515 \tTrain_Accu: 31%  \tValid_Acc:19% \t Valid Loss: 1.596 \n",
            "Epoch: 70 \tTraining Loss:  1.494 \tTrain_Accu: 28%  \tValid_Acc:16% \t Valid Loss: 1.704 \n",
            "Epoch: 71 \tTraining Loss:  1.497 \tTrain_Accu: 30%  \tValid_Acc:29% \t Valid Loss: 1.576 \n",
            "Epoch: 72 \tTraining Loss:  1.460 \tTrain_Accu: 38%  \tValid_Acc:19% \t Valid Loss: 1.618 \n",
            "Epoch: 73 \tTraining Loss:  1.448 \tTrain_Accu: 32%  \tValid_Acc:13% \t Valid Loss: 1.752 \n",
            "Epoch: 74 \tTraining Loss:  1.396 \tTrain_Accu: 37%  \tValid_Acc:17% \t Valid Loss: 1.711 \n",
            "Epoch: 75 \tTraining Loss:  1.471 \tTrain_Accu: 29%  \tValid_Acc:23% \t Valid Loss: 1.591 \n",
            "Epoch: 76 \tTraining Loss:  1.469 \tTrain_Accu: 32%  \tValid_Acc:30% \t Valid Loss: 1.553 \n",
            "Epoch: 77 \tTraining Loss:  1.457 \tTrain_Accu: 34%  \tValid_Acc:20% \t Valid Loss: 1.621 \n",
            "Epoch: 78 \tTraining Loss:  1.410 \tTrain_Accu: 35%  \tValid_Acc:20% \t Valid Loss: 1.617 \n",
            "Epoch: 79 \tTraining Loss:  1.486 \tTrain_Accu: 30%  \tValid_Acc:23% \t Valid Loss: 1.505 \n",
            "Epoch: 80 \tTraining Loss:  1.441 \tTrain_Accu: 35%  \tValid_Acc:16% \t Valid Loss: 2.036 \n",
            "Epoch: 81 \tTraining Loss:  1.410 \tTrain_Accu: 36%  \tValid_Acc:16% \t Valid Loss: 1.654 \n",
            "Epoch: 82 \tTraining Loss:  1.406 \tTrain_Accu: 38%  \tValid_Acc:21% \t Valid Loss: 1.564 \n",
            "Epoch: 83 \tTraining Loss:  1.366 \tTrain_Accu: 34%  \tValid_Acc:17% \t Valid Loss: 1.572 \n",
            "Epoch: 84 \tTraining Loss:  1.422 \tTrain_Accu: 36%  \tValid_Acc:21% \t Valid Loss: 1.638 \n",
            "Epoch: 85 \tTraining Loss:  1.424 \tTrain_Accu: 35%  \tValid_Acc:24% \t Valid Loss: 1.557 \n",
            "Epoch: 86 \tTraining Loss:  1.412 \tTrain_Accu: 34%  \tValid_Acc:20% \t Valid Loss: 1.531 \n",
            "Epoch: 87 \tTraining Loss:  1.383 \tTrain_Accu: 38%  \tValid_Acc:19% \t Valid Loss: 1.580 \n",
            "Epoch: 88 \tTraining Loss:  1.381 \tTrain_Accu: 38%  \tValid_Acc:23% \t Valid Loss: 1.753 \n",
            "Epoch: 89 \tTraining Loss:  1.358 \tTrain_Accu: 38%  \tValid_Acc:24% \t Valid Loss: 1.566 \n",
            "Epoch: 90 \tTraining Loss:  1.324 \tTrain_Accu: 41%  \tValid_Acc:24% \t Valid Loss: 1.674 \n",
            "Epoch: 91 \tTraining Loss:  1.376 \tTrain_Accu: 38%  \tValid_Acc:20% \t Valid Loss: 1.786 \n",
            "Epoch: 92 \tTraining Loss:  1.389 \tTrain_Accu: 39%  \tValid_Acc:24% \t Valid Loss: 1.560 \n",
            "Epoch: 93 \tTraining Loss:  1.333 \tTrain_Accu: 41%  \tValid_Acc:13% \t Valid Loss: 1.638 \n",
            "Epoch: 94 \tTraining Loss:  1.346 \tTrain_Accu: 43%  \tValid_Acc:23% \t Valid Loss: 1.569 \n",
            "Epoch: 95 \tTraining Loss:  1.361 \tTrain_Accu: 41%  \tValid_Acc:27% \t Valid Loss: 1.681 \n",
            "Epoch: 96 \tTraining Loss:  1.309 \tTrain_Accu: 42%  \tValid_Acc:21% \t Valid Loss: 1.687 \n",
            "Epoch: 97 \tTraining Loss:  1.356 \tTrain_Accu: 38%  \tValid_Acc:20% \t Valid Loss: 1.546 \n",
            "Epoch: 98 \tTraining Loss:  1.314 \tTrain_Accu: 42%  \tValid_Acc:20% \t Valid Loss: 1.700 \n",
            "Epoch: 99 \tTraining Loss:  1.351 \tTrain_Accu: 42%  \tValid_Acc:30% \t Valid Loss: 1.630 \n",
            "Epoch: 100 \tTraining Loss:  1.251 \tTrain_Accu: 41%  \tValid_Acc:19% \t Valid Loss: 1.836 \n",
            "Epoch: 101 \tTraining Loss:  1.284 \tTrain_Accu: 43%  \tValid_Acc:30% \t Valid Loss: 2.142 \n",
            "Epoch: 102 \tTraining Loss:  1.302 \tTrain_Accu: 42%  \tValid_Acc:29% \t Valid Loss: 1.657 \n",
            "Epoch: 103 \tTraining Loss:  1.320 \tTrain_Accu: 41%  \tValid_Acc:26% \t Valid Loss: 1.840 \n",
            "Epoch: 104 \tTraining Loss:  1.245 \tTrain_Accu: 47%  \tValid_Acc:30% \t Valid Loss: 1.532 \n",
            "Epoch: 105 \tTraining Loss:  1.318 \tTrain_Accu: 39%  \tValid_Acc:30% \t Valid Loss: 1.882 \n",
            "Epoch: 106 \tTraining Loss:  1.313 \tTrain_Accu: 46%  \tValid_Acc:27% \t Valid Loss: 1.579 \n",
            "Epoch: 107 \tTraining Loss:  1.239 \tTrain_Accu: 44%  \tValid_Acc:17% \t Valid Loss: 2.242 \n",
            "Epoch: 108 \tTraining Loss:  1.250 \tTrain_Accu: 49%  \tValid_Acc:20% \t Valid Loss: 2.113 \n",
            "Epoch: 109 \tTraining Loss:  1.256 \tTrain_Accu: 48%  \tValid_Acc:24% \t Valid Loss: 1.685 \n",
            "Epoch: 110 \tTraining Loss:  1.219 \tTrain_Accu: 48%  \tValid_Acc:27% \t Valid Loss: 1.656 \n",
            "Epoch: 111 \tTraining Loss:  1.243 \tTrain_Accu: 44%  \tValid_Acc:23% \t Valid Loss: 1.715 \n",
            "Epoch: 112 \tTraining Loss:  1.223 \tTrain_Accu: 50%  \tValid_Acc:21% \t Valid Loss: 1.639 \n",
            "Epoch: 113 \tTraining Loss:  1.277 \tTrain_Accu: 43%  \tValid_Acc:23% \t Valid Loss: 1.850 \n",
            "Epoch: 114 \tTraining Loss:  1.230 \tTrain_Accu: 42%  \tValid_Acc:27% \t Valid Loss: 2.228 \n",
            "Epoch: 115 \tTraining Loss:  1.238 \tTrain_Accu: 47%  \tValid_Acc:19% \t Valid Loss: 2.172 \n",
            "Epoch: 116 \tTraining Loss:  1.256 \tTrain_Accu: 46%  \tValid_Acc:20% \t Valid Loss: 1.624 \n",
            "Epoch: 117 \tTraining Loss:  1.274 \tTrain_Accu: 42%  \tValid_Acc:30% \t Valid Loss: 1.634 \n",
            "Epoch: 118 \tTraining Loss:  1.194 \tTrain_Accu: 47%  \tValid_Acc:14% \t Valid Loss: 1.915 \n",
            "Epoch: 119 \tTraining Loss:  1.224 \tTrain_Accu: 45%  \tValid_Acc:33% \t Valid Loss: 1.709 \n",
            "Epoch: 120 \tTraining Loss:  1.160 \tTrain_Accu: 49%  \tValid_Acc:21% \t Valid Loss: 2.133 \n",
            "Epoch: 121 \tTraining Loss:  1.188 \tTrain_Accu: 49%  \tValid_Acc:24% \t Valid Loss: 1.887 \n",
            "Epoch: 122 \tTraining Loss:  1.113 \tTrain_Accu: 49%  \tValid_Acc:26% \t Valid Loss: 2.117 \n",
            "Epoch: 123 \tTraining Loss:  1.186 \tTrain_Accu: 47%  \tValid_Acc:26% \t Valid Loss: 2.740 \n",
            "Epoch: 124 \tTraining Loss:  1.224 \tTrain_Accu: 46%  \tValid_Acc:20% \t Valid Loss: 2.010 \n",
            "Epoch: 125 \tTraining Loss:  1.208 \tTrain_Accu: 47%  \tValid_Acc:24% \t Valid Loss: 2.099 \n",
            "Epoch: 126 \tTraining Loss:  1.184 \tTrain_Accu: 47%  \tValid_Acc:27% \t Valid Loss: 1.906 \n",
            "Epoch: 127 \tTraining Loss:  1.193 \tTrain_Accu: 47%  \tValid_Acc:27% \t Valid Loss: 1.973 \n",
            "Epoch: 128 \tTraining Loss:  1.160 \tTrain_Accu: 51%  \tValid_Acc:21% \t Valid Loss: 1.900 \n",
            "Epoch: 129 \tTraining Loss:  1.095 \tTrain_Accu: 50%  \tValid_Acc:21% \t Valid Loss: 1.817 \n",
            "Epoch: 130 \tTraining Loss:  1.177 \tTrain_Accu: 50%  \tValid_Acc:24% \t Valid Loss: 1.710 \n",
            "Epoch: 131 \tTraining Loss:  1.195 \tTrain_Accu: 46%  \tValid_Acc:30% \t Valid Loss: 1.765 \n",
            "Epoch: 132 \tTraining Loss:  1.146 \tTrain_Accu: 51%  \tValid_Acc:27% \t Valid Loss: 1.717 \n",
            "Epoch: 133 \tTraining Loss:  1.137 \tTrain_Accu: 51%  \tValid_Acc:27% \t Valid Loss: 2.379 \n",
            "Epoch: 134 \tTraining Loss:  1.158 \tTrain_Accu: 49%  \tValid_Acc:27% \t Valid Loss: 2.140 \n",
            "Epoch: 135 \tTraining Loss:  1.089 \tTrain_Accu: 55%  \tValid_Acc:26% \t Valid Loss: 2.300 \n",
            "Epoch: 136 \tTraining Loss:  1.143 \tTrain_Accu: 51%  \tValid_Acc:26% \t Valid Loss: 1.849 \n",
            "Epoch: 137 \tTraining Loss:  1.156 \tTrain_Accu: 47%  \tValid_Acc:26% \t Valid Loss: 1.671 \n",
            "Epoch: 138 \tTraining Loss:  1.101 \tTrain_Accu: 55%  \tValid_Acc:21% \t Valid Loss: 2.149 \n",
            "Epoch: 139 \tTraining Loss:  1.134 \tTrain_Accu: 53%  \tValid_Acc:31% \t Valid Loss: 2.270 \n",
            "Epoch: 140 \tTraining Loss:  1.143 \tTrain_Accu: 51%  \tValid_Acc:23% \t Valid Loss: 1.824 \n",
            "Epoch: 141 \tTraining Loss:  1.144 \tTrain_Accu: 53%  \tValid_Acc:20% \t Valid Loss: 1.729 \n",
            "Epoch: 142 \tTraining Loss:  1.096 \tTrain_Accu: 54%  \tValid_Acc:23% \t Valid Loss: 2.113 \n",
            "Epoch: 143 \tTraining Loss:  1.116 \tTrain_Accu: 56%  \tValid_Acc:27% \t Valid Loss: 2.483 \n",
            "Epoch: 144 \tTraining Loss:  1.135 \tTrain_Accu: 50%  \tValid_Acc:29% \t Valid Loss: 2.747 \n",
            "Epoch: 145 \tTraining Loss:  1.111 \tTrain_Accu: 56%  \tValid_Acc:26% \t Valid Loss: 1.989 \n",
            "Epoch: 146 \tTraining Loss:  1.044 \tTrain_Accu: 56%  \tValid_Acc:23% \t Valid Loss: 2.454 \n",
            "Epoch: 147 \tTraining Loss:  1.053 \tTrain_Accu: 56%  \tValid_Acc:26% \t Valid Loss: 2.145 \n",
            "Epoch: 148 \tTraining Loss:  1.116 \tTrain_Accu: 50%  \tValid_Acc:31% \t Valid Loss: 1.796 \n",
            "Epoch: 149 \tTraining Loss:  1.095 \tTrain_Accu: 53%  \tValid_Acc:24% \t Valid Loss: 1.819 \n",
            "Epoch: 150 \tTraining Loss:  1.080 \tTrain_Accu: 52%  \tValid_Acc:24% \t Valid Loss: 1.978 \n",
            "Epoch: 151 \tTraining Loss:  1.135 \tTrain_Accu: 55%  \tValid_Acc:20% \t Valid Loss: 2.418 \n",
            "Epoch: 152 \tTraining Loss:  1.138 \tTrain_Accu: 55%  \tValid_Acc:26% \t Valid Loss: 1.959 \n",
            "Epoch: 153 \tTraining Loss:  1.096 \tTrain_Accu: 55%  \tValid_Acc:29% \t Valid Loss: 1.770 \n",
            "Epoch: 154 \tTraining Loss:  1.082 \tTrain_Accu: 57%  \tValid_Acc:21% \t Valid Loss: 2.713 \n",
            "Epoch: 155 \tTraining Loss:  1.096 \tTrain_Accu: 57%  \tValid_Acc:23% \t Valid Loss: 2.575 \n",
            "Epoch: 156 \tTraining Loss:  1.093 \tTrain_Accu: 57%  \tValid_Acc:26% \t Valid Loss: 2.196 \n",
            "Epoch: 157 \tTraining Loss:  1.001 \tTrain_Accu: 57%  \tValid_Acc:27% \t Valid Loss: 2.301 \n",
            "Epoch: 158 \tTraining Loss:  1.067 \tTrain_Accu: 61%  \tValid_Acc:24% \t Valid Loss: 2.182 \n",
            "Epoch: 159 \tTraining Loss:  1.055 \tTrain_Accu: 54%  \tValid_Acc:29% \t Valid Loss: 1.580 \n",
            "Epoch: 160 \tTraining Loss:  1.054 \tTrain_Accu: 57%  \tValid_Acc:33% \t Valid Loss: 1.825 \n",
            "Epoch: 161 \tTraining Loss:  1.050 \tTrain_Accu: 58%  \tValid_Acc:19% \t Valid Loss: 1.929 \n",
            "Epoch: 162 \tTraining Loss:  1.100 \tTrain_Accu: 55%  \tValid_Acc:31% \t Valid Loss: 2.529 \n",
            "Epoch: 163 \tTraining Loss:  1.057 \tTrain_Accu: 56%  \tValid_Acc:21% \t Valid Loss: 2.304 \n",
            "Epoch: 164 \tTraining Loss:  1.035 \tTrain_Accu: 57%  \tValid_Acc:31% \t Valid Loss: 2.218 \n",
            "Epoch: 165 \tTraining Loss:  1.004 \tTrain_Accu: 59%  \tValid_Acc:19% \t Valid Loss: 2.509 \n",
            "Epoch: 166 \tTraining Loss:  1.059 \tTrain_Accu: 58%  \tValid_Acc:24% \t Valid Loss: 2.641 \n",
            "Epoch: 167 \tTraining Loss:  1.052 \tTrain_Accu: 58%  \tValid_Acc:27% \t Valid Loss: 2.407 \n",
            "Epoch: 168 \tTraining Loss:  1.023 \tTrain_Accu: 59%  \tValid_Acc:29% \t Valid Loss: 2.191 \n",
            "Epoch: 169 \tTraining Loss:  1.054 \tTrain_Accu: 62%  \tValid_Acc:36% \t Valid Loss: 2.284 \n",
            "Epoch: 170 \tTraining Loss:  0.982 \tTrain_Accu: 59%  \tValid_Acc:30% \t Valid Loss: 3.182 \n",
            "Epoch: 171 \tTraining Loss:  1.050 \tTrain_Accu: 59%  \tValid_Acc:24% \t Valid Loss: 2.453 \n",
            "Epoch: 172 \tTraining Loss:  1.038 \tTrain_Accu: 55%  \tValid_Acc:19% \t Valid Loss: 2.384 \n",
            "Epoch: 173 \tTraining Loss:  1.130 \tTrain_Accu: 57%  \tValid_Acc:23% \t Valid Loss: 1.911 \n",
            "Epoch: 174 \tTraining Loss:  1.038 \tTrain_Accu: 56%  \tValid_Acc:29% \t Valid Loss: 3.007 \n",
            "Epoch: 175 \tTraining Loss:  1.020 \tTrain_Accu: 56%  \tValid_Acc:31% \t Valid Loss: 3.225 \n",
            "Epoch: 176 \tTraining Loss:  0.967 \tTrain_Accu: 60%  \tValid_Acc:29% \t Valid Loss: 3.401 \n",
            "Epoch: 177 \tTraining Loss:  0.983 \tTrain_Accu: 60%  \tValid_Acc:36% \t Valid Loss: 3.291 \n",
            "Epoch: 178 \tTraining Loss:  0.936 \tTrain_Accu: 60%  \tValid_Acc:21% \t Valid Loss: 3.216 \n",
            "Epoch: 179 \tTraining Loss:  0.901 \tTrain_Accu: 64%  \tValid_Acc:26% \t Valid Loss: 2.033 \n",
            "Epoch: 180 \tTraining Loss:  1.029 \tTrain_Accu: 59%  \tValid_Acc:30% \t Valid Loss: 2.633 \n",
            "Epoch: 181 \tTraining Loss:  0.957 \tTrain_Accu: 62%  \tValid_Acc:31% \t Valid Loss: 2.663 \n",
            "Epoch: 182 \tTraining Loss:  1.011 \tTrain_Accu: 58%  \tValid_Acc:33% \t Valid Loss: 2.819 \n",
            "Epoch: 183 \tTraining Loss:  0.962 \tTrain_Accu: 59%  \tValid_Acc:29% \t Valid Loss: 2.913 \n",
            "Epoch: 184 \tTraining Loss:  0.932 \tTrain_Accu: 63%  \tValid_Acc:21% \t Valid Loss: 3.084 \n",
            "Epoch: 185 \tTraining Loss:  1.009 \tTrain_Accu: 61%  \tValid_Acc:17% \t Valid Loss: 2.019 \n",
            "Epoch: 186 \tTraining Loss:  1.035 \tTrain_Accu: 57%  \tValid_Acc:30% \t Valid Loss: 3.469 \n",
            "Epoch: 187 \tTraining Loss:  0.981 \tTrain_Accu: 58%  \tValid_Acc:26% \t Valid Loss: 2.315 \n",
            "Epoch: 188 \tTraining Loss:  1.008 \tTrain_Accu: 61%  \tValid_Acc:33% \t Valid Loss: 3.515 \n",
            "Epoch: 189 \tTraining Loss:  0.961 \tTrain_Accu: 61%  \tValid_Acc:36% \t Valid Loss: 3.246 \n",
            "Epoch: 190 \tTraining Loss:  0.967 \tTrain_Accu: 62%  \tValid_Acc:27% \t Valid Loss: 2.555 \n",
            "Epoch: 191 \tTraining Loss:  1.054 \tTrain_Accu: 57%  \tValid_Acc:24% \t Valid Loss: 3.039 \n",
            "Epoch: 192 \tTraining Loss:  0.938 \tTrain_Accu: 64%  \tValid_Acc:29% \t Valid Loss: 2.849 \n",
            "Epoch: 193 \tTraining Loss:  1.034 \tTrain_Accu: 60%  \tValid_Acc:37% \t Valid Loss: 2.721 \n",
            "Epoch: 194 \tTraining Loss:  0.987 \tTrain_Accu: 62%  \tValid_Acc:19% \t Valid Loss: 3.285 \n",
            "Epoch: 195 \tTraining Loss:  1.046 \tTrain_Accu: 62%  \tValid_Acc:31% \t Valid Loss: 3.246 \n",
            "Epoch: 196 \tTraining Loss:  0.987 \tTrain_Accu: 62%  \tValid_Acc:26% \t Valid Loss: 3.512 \n",
            "Epoch: 197 \tTraining Loss:  0.860 \tTrain_Accu: 66%  \tValid_Acc:19% \t Valid Loss: 3.910 \n",
            "Epoch: 198 \tTraining Loss:  0.899 \tTrain_Accu: 65%  \tValid_Acc:23% \t Valid Loss: 2.936 \n",
            "Epoch: 199 \tTraining Loss:  0.907 \tTrain_Accu: 66%  \tValid_Acc:26% \t Valid Loss: 4.188 \n",
            "Epoch: 200 \tTraining Loss:  1.003 \tTrain_Accu: 61%  \tValid_Acc:26% \t Valid Loss: 3.204 \n",
            "Epoch: 201 \tTraining Loss:  0.934 \tTrain_Accu: 59%  \tValid_Acc:24% \t Valid Loss: 3.865 \n",
            "Epoch: 202 \tTraining Loss:  0.904 \tTrain_Accu: 66%  \tValid_Acc:33% \t Valid Loss: 2.467 \n",
            "Epoch: 203 \tTraining Loss:  0.944 \tTrain_Accu: 60%  \tValid_Acc:30% \t Valid Loss: 4.877 \n",
            "Epoch: 204 \tTraining Loss:  0.926 \tTrain_Accu: 62%  \tValid_Acc:26% \t Valid Loss: 3.676 \n",
            "Epoch: 205 \tTraining Loss:  1.045 \tTrain_Accu: 56%  \tValid_Acc:26% \t Valid Loss: 1.954 \n",
            "Epoch: 206 \tTraining Loss:  0.935 \tTrain_Accu: 62%  \tValid_Acc:31% \t Valid Loss: 4.540 \n",
            "Epoch: 207 \tTraining Loss:  0.875 \tTrain_Accu: 65%  \tValid_Acc:24% \t Valid Loss: 2.622 \n",
            "Epoch: 208 \tTraining Loss:  0.949 \tTrain_Accu: 61%  \tValid_Acc:21% \t Valid Loss: 3.346 \n",
            "Epoch: 209 \tTraining Loss:  0.890 \tTrain_Accu: 63%  \tValid_Acc:29% \t Valid Loss: 4.301 \n",
            "Epoch: 210 \tTraining Loss:  0.824 \tTrain_Accu: 69%  \tValid_Acc:30% \t Valid Loss: 3.704 \n",
            "Epoch: 211 \tTraining Loss:  0.910 \tTrain_Accu: 65%  \tValid_Acc:23% \t Valid Loss: 2.447 \n",
            "Epoch: 212 \tTraining Loss:  0.949 \tTrain_Accu: 65%  \tValid_Acc:29% \t Valid Loss: 3.020 \n",
            "Epoch: 213 \tTraining Loss:  0.856 \tTrain_Accu: 64%  \tValid_Acc:26% \t Valid Loss: 4.321 \n",
            "Epoch: 214 \tTraining Loss:  0.918 \tTrain_Accu: 63%  \tValid_Acc:21% \t Valid Loss: 3.455 \n",
            "Epoch: 215 \tTraining Loss:  0.995 \tTrain_Accu: 65%  \tValid_Acc:29% \t Valid Loss: 2.536 \n",
            "Epoch: 216 \tTraining Loss:  0.888 \tTrain_Accu: 64%  \tValid_Acc:20% \t Valid Loss: 4.241 \n",
            "Epoch: 217 \tTraining Loss:  0.873 \tTrain_Accu: 69%  \tValid_Acc:26% \t Valid Loss: 2.850 \n",
            "Epoch: 218 \tTraining Loss:  0.929 \tTrain_Accu: 65%  \tValid_Acc:27% \t Valid Loss: 3.767 \n",
            "Epoch: 219 \tTraining Loss:  0.902 \tTrain_Accu: 68%  \tValid_Acc:21% \t Valid Loss: 4.116 \n",
            "Epoch: 220 \tTraining Loss:  0.889 \tTrain_Accu: 64%  \tValid_Acc:29% \t Valid Loss: 2.909 \n",
            "Epoch: 221 \tTraining Loss:  0.928 \tTrain_Accu: 67%  \tValid_Acc:27% \t Valid Loss: 6.146 \n",
            "Epoch: 222 \tTraining Loss:  1.025 \tTrain_Accu: 62%  \tValid_Acc:24% \t Valid Loss: 2.902 \n",
            "Epoch: 223 \tTraining Loss:  0.950 \tTrain_Accu: 63%  \tValid_Acc:37% \t Valid Loss: 3.390 \n",
            "Epoch: 224 \tTraining Loss:  1.017 \tTrain_Accu: 64%  \tValid_Acc:23% \t Valid Loss: 4.337 \n",
            "Epoch: 225 \tTraining Loss:  0.869 \tTrain_Accu: 66%  \tValid_Acc:27% \t Valid Loss: 5.389 \n",
            "Epoch: 226 \tTraining Loss:  0.895 \tTrain_Accu: 64%  \tValid_Acc:24% \t Valid Loss: 2.269 \n",
            "Epoch: 227 \tTraining Loss:  0.874 \tTrain_Accu: 66%  \tValid_Acc:29% \t Valid Loss: 4.418 \n",
            "Epoch: 228 \tTraining Loss:  0.942 \tTrain_Accu: 64%  \tValid_Acc:30% \t Valid Loss: 4.645 \n",
            "Epoch: 229 \tTraining Loss:  0.921 \tTrain_Accu: 64%  \tValid_Acc:29% \t Valid Loss: 2.336 \n",
            "Epoch: 230 \tTraining Loss:  0.917 \tTrain_Accu: 62%  \tValid_Acc:30% \t Valid Loss: 2.582 \n",
            "Epoch: 231 \tTraining Loss:  0.820 \tTrain_Accu: 66%  \tValid_Acc:31% \t Valid Loss: 4.269 \n",
            "Epoch: 232 \tTraining Loss:  0.897 \tTrain_Accu: 65%  \tValid_Acc:24% \t Valid Loss: 4.207 \n",
            "Epoch: 233 \tTraining Loss:  0.907 \tTrain_Accu: 64%  \tValid_Acc:17% \t Valid Loss: 2.575 \n",
            "Epoch: 234 \tTraining Loss:  1.006 \tTrain_Accu: 59%  \tValid_Acc:23% \t Valid Loss: 2.774 \n",
            "Epoch: 235 \tTraining Loss:  0.846 \tTrain_Accu: 66%  \tValid_Acc:27% \t Valid Loss: 3.125 \n",
            "Epoch: 236 \tTraining Loss:  1.051 \tTrain_Accu: 65%  \tValid_Acc:31% \t Valid Loss: 2.393 \n",
            "Epoch: 237 \tTraining Loss:  0.856 \tTrain_Accu: 68%  \tValid_Acc:21% \t Valid Loss: 4.117 \n",
            "Epoch: 238 \tTraining Loss:  1.107 \tTrain_Accu: 59%  \tValid_Acc:27% \t Valid Loss: 2.595 \n",
            "Epoch: 239 \tTraining Loss:  0.937 \tTrain_Accu: 62%  \tValid_Acc:27% \t Valid Loss: 4.979 \n",
            "Epoch: 240 \tTraining Loss:  0.883 \tTrain_Accu: 64%  \tValid_Acc:26% \t Valid Loss: 3.511 \n",
            "Epoch: 241 \tTraining Loss:  0.898 \tTrain_Accu: 64%  \tValid_Acc:16% \t Valid Loss: 3.640 \n",
            "Epoch: 242 \tTraining Loss:  0.851 \tTrain_Accu: 66%  \tValid_Acc:20% \t Valid Loss: 3.349 \n",
            "Epoch: 243 \tTraining Loss:  0.993 \tTrain_Accu: 62%  \tValid_Acc:20% \t Valid Loss: 3.268 \n",
            "Epoch: 244 \tTraining Loss:  0.952 \tTrain_Accu: 63%  \tValid_Acc:23% \t Valid Loss: 6.151 \n",
            "Epoch: 245 \tTraining Loss:  1.212 \tTrain_Accu: 55%  \tValid_Acc:33% \t Valid Loss: 3.090 \n",
            "Epoch: 246 \tTraining Loss:  0.917 \tTrain_Accu: 63%  \tValid_Acc:27% \t Valid Loss: 3.803 \n",
            "Epoch: 247 \tTraining Loss:  0.799 \tTrain_Accu: 69%  \tValid_Acc:33% \t Valid Loss: 3.545 \n",
            "Epoch: 248 \tTraining Loss:  0.808 \tTrain_Accu: 71%  \tValid_Acc:34% \t Valid Loss: 2.573 \n",
            "Epoch: 249 \tTraining Loss:  0.887 \tTrain_Accu: 69%  \tValid_Acc:29% \t Valid Loss: 3.982 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 20:20:54,405]\u001b[0m Trial 5 finished with value: 30.0 and parameters: {'Batch_size': 4, 'lr': 0.001, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'dropout': 0.9}. Best is trial 5 with value: 30.0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.951 \tTrain_Accu: 62%  \tValid_Acc:30% \t Valid Loss: 4.053 \n",
            "Epoch: 1 \tTraining Loss:  1.867 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.648 \n",
            "Epoch: 2 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:20% \t Valid Loss: 1.642 \n",
            "Epoch: 3 \tTraining Loss:  1.613 \tTrain_Accu: 22%  \tValid_Acc:23% \t Valid Loss: 1.618 \n",
            "Epoch: 4 \tTraining Loss:  1.619 \tTrain_Accu: 16%  \tValid_Acc:19% \t Valid Loss: 1.639 \n",
            "Epoch: 5 \tTraining Loss:  1.618 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 6 \tTraining Loss:  1.620 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 7 \tTraining Loss:  1.619 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.638 \n",
            "Epoch: 8 \tTraining Loss:  1.612 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.617 \n",
            "Epoch: 9 \tTraining Loss:  1.617 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.618 \n",
            "Epoch: 10 \tTraining Loss:  1.616 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.625 \n",
            "Epoch: 11 \tTraining Loss:  1.616 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.619 \n",
            "Epoch: 12 \tTraining Loss:  1.614 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.664 \n",
            "Epoch: 13 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 14 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.649 \n",
            "Epoch: 15 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 16 \tTraining Loss:  1.618 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.643 \n",
            "Epoch: 17 \tTraining Loss:  1.616 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.626 \n",
            "Epoch: 18 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.647 \n",
            "Epoch: 19 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.661 \n",
            "Epoch: 20 \tTraining Loss:  1.617 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.618 \n",
            "Epoch: 21 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 22 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.609 \n",
            "Epoch: 23 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 24 \tTraining Loss:  1.616 \tTrain_Accu: 15%  \tValid_Acc:7% \t Valid Loss: 1.649 \n",
            "Epoch: 25 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.649 \n",
            "Epoch: 26 \tTraining Loss:  1.617 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 27 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.653 \n",
            "Epoch: 28 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.627 \n",
            "Epoch: 29 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.656 \n",
            "Epoch: 30 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 31 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.643 \n",
            "Epoch: 32 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.645 \n",
            "Epoch: 33 \tTraining Loss:  1.616 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 34 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 35 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 36 \tTraining Loss:  1.612 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.644 \n",
            "Epoch: 37 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.625 \n",
            "Epoch: 38 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 39 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 40 \tTraining Loss:  1.616 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.624 \n",
            "Epoch: 41 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.645 \n",
            "Epoch: 42 \tTraining Loss:  1.612 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 43 \tTraining Loss:  1.614 \tTrain_Accu: 14%  \tValid_Acc:26% \t Valid Loss: 1.625 \n",
            "Epoch: 44 \tTraining Loss:  1.611 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.652 \n",
            "Epoch: 45 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.650 \n",
            "Epoch: 46 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 47 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.644 \n",
            "Epoch: 48 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 49 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 50 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 51 \tTraining Loss:  1.617 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.624 \n",
            "Epoch: 52 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 53 \tTraining Loss:  1.613 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.605 \n",
            "Epoch: 54 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.626 \n",
            "Epoch: 55 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 56 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 57 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.626 \n",
            "Epoch: 58 \tTraining Loss:  1.614 \tTrain_Accu: 23%  \tValid_Acc:26% \t Valid Loss: 1.618 \n",
            "Epoch: 59 \tTraining Loss:  1.617 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.618 \n",
            "Epoch: 60 \tTraining Loss:  1.612 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 61 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.650 \n",
            "Epoch: 62 \tTraining Loss:  1.616 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 63 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 64 \tTraining Loss:  1.616 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.638 \n",
            "Epoch: 65 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 66 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.645 \n",
            "Epoch: 67 \tTraining Loss:  1.615 \tTrain_Accu: 14%  \tValid_Acc:26% \t Valid Loss: 1.641 \n",
            "Epoch: 68 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.614 \n",
            "Epoch: 69 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 70 \tTraining Loss:  1.612 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.618 \n",
            "Epoch: 71 \tTraining Loss:  1.615 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.621 \n",
            "Epoch: 72 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 73 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.644 \n",
            "Epoch: 74 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.651 \n",
            "Epoch: 75 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.658 \n",
            "Epoch: 76 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.640 \n",
            "Epoch: 77 \tTraining Loss:  1.612 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.654 \n",
            "Epoch: 78 \tTraining Loss:  1.616 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.648 \n",
            "Epoch: 79 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.646 \n",
            "Epoch: 80 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.648 \n",
            "Epoch: 81 \tTraining Loss:  1.613 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.667 \n",
            "Epoch: 82 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.650 \n",
            "Epoch: 83 \tTraining Loss:  1.609 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.654 \n",
            "Epoch: 84 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.648 \n",
            "Epoch: 85 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.638 \n",
            "Epoch: 86 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 87 \tTraining Loss:  1.616 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.624 \n",
            "Epoch: 88 \tTraining Loss:  1.617 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.641 \n",
            "Epoch: 89 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 90 \tTraining Loss:  1.612 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.657 \n",
            "Epoch: 91 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 92 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.643 \n",
            "Epoch: 93 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.629 \n",
            "Epoch: 94 \tTraining Loss:  1.616 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.641 \n",
            "Epoch: 95 \tTraining Loss:  1.613 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 96 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 97 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.602 \n",
            "Epoch: 98 \tTraining Loss:  1.613 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.650 \n",
            "Epoch: 99 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.666 \n",
            "Epoch: 100 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 101 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.664 \n",
            "Epoch: 102 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.661 \n",
            "Epoch: 103 \tTraining Loss:  1.613 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 104 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 105 \tTraining Loss:  1.615 \tTrain_Accu: 14%  \tValid_Acc:26% \t Valid Loss: 1.609 \n",
            "Epoch: 106 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.621 \n",
            "Epoch: 107 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.654 \n",
            "Epoch: 108 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 109 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.617 \n",
            "Epoch: 110 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 111 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.629 \n",
            "Epoch: 112 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 113 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.621 \n",
            "Epoch: 114 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 115 \tTraining Loss:  1.617 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.622 \n",
            "Epoch: 116 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.631 \n",
            "Epoch: 117 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.622 \n",
            "Epoch: 118 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 119 \tTraining Loss:  1.616 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.646 \n",
            "Epoch: 120 \tTraining Loss:  1.613 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 121 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 122 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 123 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.643 \n",
            "Epoch: 124 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.613 \n",
            "Epoch: 125 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 126 \tTraining Loss:  1.616 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 127 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.665 \n",
            "Epoch: 128 \tTraining Loss:  1.615 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.648 \n",
            "Epoch: 129 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.645 \n",
            "Epoch: 130 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.666 \n",
            "Epoch: 131 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.615 \n",
            "Epoch: 132 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.620 \n",
            "Epoch: 133 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.642 \n",
            "Epoch: 134 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.654 \n",
            "Epoch: 135 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 136 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.660 \n",
            "Epoch: 137 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 138 \tTraining Loss:  1.617 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.616 \n",
            "Epoch: 139 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.618 \n",
            "Epoch: 140 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 141 \tTraining Loss:  1.613 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 142 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.664 \n",
            "Epoch: 143 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.617 \n",
            "Epoch: 144 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 145 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.643 \n",
            "Epoch: 146 \tTraining Loss:  1.615 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 147 \tTraining Loss:  1.617 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.630 \n",
            "Epoch: 148 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.612 \n",
            "Epoch: 149 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 150 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 151 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.627 \n",
            "Epoch: 152 \tTraining Loss:  1.611 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.643 \n",
            "Epoch: 153 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.649 \n",
            "Epoch: 154 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.644 \n",
            "Epoch: 155 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.644 \n",
            "Epoch: 156 \tTraining Loss:  1.613 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 157 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.659 \n",
            "Epoch: 158 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 159 \tTraining Loss:  1.616 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.625 \n",
            "Epoch: 160 \tTraining Loss:  1.618 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.620 \n",
            "Epoch: 161 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.624 \n",
            "Epoch: 162 \tTraining Loss:  1.618 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 163 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.646 \n",
            "Epoch: 164 \tTraining Loss:  1.617 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.626 \n",
            "Epoch: 165 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.620 \n",
            "Epoch: 166 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.613 \n",
            "Epoch: 167 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 168 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.640 \n",
            "Epoch: 169 \tTraining Loss:  1.612 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.631 \n",
            "Epoch: 170 \tTraining Loss:  1.617 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.628 \n",
            "Epoch: 171 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.631 \n",
            "Epoch: 172 \tTraining Loss:  1.617 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.624 \n",
            "Epoch: 173 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 174 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 175 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.651 \n",
            "Epoch: 176 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 177 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.646 \n",
            "Epoch: 178 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.649 \n",
            "Epoch: 179 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.649 \n",
            "Epoch: 180 \tTraining Loss:  1.613 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.623 \n",
            "Epoch: 181 \tTraining Loss:  1.616 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.622 \n",
            "Epoch: 182 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 183 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.652 \n",
            "Epoch: 184 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 185 \tTraining Loss:  1.617 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 186 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.631 \n",
            "Epoch: 187 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.642 \n",
            "Epoch: 188 \tTraining Loss:  1.617 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.635 \n",
            "Epoch: 189 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.647 \n",
            "Epoch: 190 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.622 \n",
            "Epoch: 191 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.627 \n",
            "Epoch: 192 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 193 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 194 \tTraining Loss:  1.617 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 195 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 196 \tTraining Loss:  1.616 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.615 \n",
            "Epoch: 197 \tTraining Loss:  1.613 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.650 \n",
            "Epoch: 198 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 199 \tTraining Loss:  1.613 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.643 \n",
            "Epoch: 200 \tTraining Loss:  1.617 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.622 \n",
            "Epoch: 201 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.616 \n",
            "Epoch: 202 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 203 \tTraining Loss:  1.616 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.617 \n",
            "Epoch: 204 \tTraining Loss:  1.617 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 205 \tTraining Loss:  1.612 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.662 \n",
            "Epoch: 206 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.653 \n",
            "Epoch: 207 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.642 \n",
            "Epoch: 208 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.652 \n",
            "Epoch: 209 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.633 \n",
            "Epoch: 210 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.629 \n",
            "Epoch: 211 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.662 \n",
            "Epoch: 212 \tTraining Loss:  1.615 \tTrain_Accu: 15%  \tValid_Acc:7% \t Valid Loss: 1.663 \n",
            "Epoch: 213 \tTraining Loss:  1.613 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.654 \n",
            "Epoch: 214 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.643 \n",
            "Epoch: 215 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.622 \n",
            "Epoch: 216 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 217 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.631 \n",
            "Epoch: 218 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 219 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 220 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.623 \n",
            "Epoch: 221 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.619 \n",
            "Epoch: 222 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.627 \n",
            "Epoch: 223 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 224 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 225 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.668 \n",
            "Epoch: 226 \tTraining Loss:  1.617 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 227 \tTraining Loss:  1.616 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.616 \n",
            "Epoch: 228 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 229 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 230 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.649 \n",
            "Epoch: 231 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 232 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 233 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 234 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 235 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 236 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 237 \tTraining Loss:  1.615 \tTrain_Accu: 15%  \tValid_Acc:7% \t Valid Loss: 1.645 \n",
            "Epoch: 238 \tTraining Loss:  1.617 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.626 \n",
            "Epoch: 239 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.613 \n",
            "Epoch: 240 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.617 \n",
            "Epoch: 241 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.641 \n",
            "Epoch: 242 \tTraining Loss:  1.612 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 243 \tTraining Loss:  1.617 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 244 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.645 \n",
            "Epoch: 245 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.655 \n",
            "Epoch: 246 \tTraining Loss:  1.613 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.660 \n",
            "Epoch: 247 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.629 \n",
            "Epoch: 248 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 249 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.626 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 20:23:15,763]\u001b[0m Trial 6 finished with value: 25.7 and parameters: {'Batch_size': 4, 'lr': 0.1, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'dropout': 0.5}. Best is trial 5 with value: 30.0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  1.616 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.621 \n",
            "Epoch: 1 \tTraining Loss:  2.856 \tTrain_Accu: 20%  \tValid_Acc:13% \t Valid Loss: 1.633 \n",
            "Epoch: 2 \tTraining Loss:  1.604 \tTrain_Accu: 23%  \tValid_Acc:10% \t Valid Loss: 1.658 \n",
            "Epoch: 3 \tTraining Loss:  1.620 \tTrain_Accu: 23%  \tValid_Acc:13% \t Valid Loss: 1.607 \n",
            "Epoch: 4 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:11% \t Valid Loss: 1.641 \n",
            "Epoch: 5 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:19% \t Valid Loss: 1.629 \n",
            "Epoch: 6 \tTraining Loss:  1.611 \tTrain_Accu: 22%  \tValid_Acc:19% \t Valid Loss: 1.643 \n",
            "Epoch: 7 \tTraining Loss:  1.616 \tTrain_Accu: 19%  \tValid_Acc:14% \t Valid Loss: 1.645 \n",
            "Epoch: 8 \tTraining Loss:  1.610 \tTrain_Accu: 21%  \tValid_Acc:10% \t Valid Loss: 1.643 \n",
            "Epoch: 9 \tTraining Loss:  1.612 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.643 \n",
            "Epoch: 10 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:13% \t Valid Loss: 1.627 \n",
            "Epoch: 11 \tTraining Loss:  1.611 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 12 \tTraining Loss:  1.609 \tTrain_Accu: 16%  \tValid_Acc:6% \t Valid Loss: 1.627 \n",
            "Epoch: 13 \tTraining Loss:  1.606 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 14 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 15 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.648 \n",
            "Epoch: 16 \tTraining Loss:  1.610 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 17 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 18 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:13% \t Valid Loss: 1.630 \n",
            "Epoch: 19 \tTraining Loss:  1.605 \tTrain_Accu: 22%  \tValid_Acc:6% \t Valid Loss: 1.636 \n",
            "Epoch: 20 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.647 \n",
            "Epoch: 21 \tTraining Loss:  1.609 \tTrain_Accu: 19%  \tValid_Acc:10% \t Valid Loss: 1.631 \n",
            "Epoch: 22 \tTraining Loss:  1.613 \tTrain_Accu: 22%  \tValid_Acc:14% \t Valid Loss: 1.640 \n",
            "Epoch: 23 \tTraining Loss:  1.608 \tTrain_Accu: 22%  \tValid_Acc:14% \t Valid Loss: 1.632 \n",
            "Epoch: 24 \tTraining Loss:  1.607 \tTrain_Accu: 23%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 25 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.634 \n",
            "Epoch: 26 \tTraining Loss:  1.611 \tTrain_Accu: 22%  \tValid_Acc:19% \t Valid Loss: 1.635 \n",
            "Epoch: 27 \tTraining Loss:  1.606 \tTrain_Accu: 22%  \tValid_Acc:16% \t Valid Loss: 1.632 \n",
            "Epoch: 28 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:14% \t Valid Loss: 1.638 \n",
            "Epoch: 29 \tTraining Loss:  1.612 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 30 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 31 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:23% \t Valid Loss: 1.640 \n",
            "Epoch: 32 \tTraining Loss:  1.606 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.635 \n",
            "Epoch: 33 \tTraining Loss:  1.610 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 34 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 35 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 36 \tTraining Loss:  1.609 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.644 \n",
            "Epoch: 37 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.645 \n",
            "Epoch: 38 \tTraining Loss:  1.610 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.635 \n",
            "Epoch: 39 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.635 \n",
            "Epoch: 40 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 41 \tTraining Loss:  1.610 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.626 \n",
            "Epoch: 42 \tTraining Loss:  1.608 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 43 \tTraining Loss:  1.605 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 44 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.631 \n",
            "Epoch: 45 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 46 \tTraining Loss:  1.606 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 47 \tTraining Loss:  1.606 \tTrain_Accu: 23%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 48 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 49 \tTraining Loss:  1.606 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.642 \n",
            "Epoch: 50 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 51 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 52 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 53 \tTraining Loss:  1.612 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.644 \n",
            "Epoch: 54 \tTraining Loss:  1.612 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 55 \tTraining Loss:  1.606 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.627 \n",
            "Epoch: 56 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 57 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 58 \tTraining Loss:  1.608 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.631 \n",
            "Epoch: 59 \tTraining Loss:  1.611 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 60 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.624 \n",
            "Epoch: 61 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.627 \n",
            "Epoch: 62 \tTraining Loss:  1.609 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 63 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 64 \tTraining Loss:  1.605 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 65 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.631 \n",
            "Epoch: 66 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 67 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 68 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 69 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 70 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 71 \tTraining Loss:  1.607 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 72 \tTraining Loss:  1.606 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.635 \n",
            "Epoch: 73 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 74 \tTraining Loss:  1.606 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 75 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 76 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.644 \n",
            "Epoch: 77 \tTraining Loss:  1.606 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 78 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 79 \tTraining Loss:  1.606 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 80 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 81 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 82 \tTraining Loss:  1.610 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.644 \n",
            "Epoch: 83 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 84 \tTraining Loss:  1.605 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.649 \n",
            "Epoch: 85 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 86 \tTraining Loss:  1.608 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 87 \tTraining Loss:  1.610 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 88 \tTraining Loss:  1.608 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 89 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 90 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 91 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.643 \n",
            "Epoch: 92 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.638 \n",
            "Epoch: 93 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 94 \tTraining Loss:  1.610 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 95 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 96 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 97 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 98 \tTraining Loss:  1.608 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.623 \n",
            "Epoch: 99 \tTraining Loss:  1.607 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 100 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 101 \tTraining Loss:  1.606 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 102 \tTraining Loss:  1.606 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 103 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 104 \tTraining Loss:  1.605 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 105 \tTraining Loss:  1.612 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 106 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 107 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 108 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 109 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 110 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.629 \n",
            "Epoch: 111 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 112 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 113 \tTraining Loss:  1.613 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 114 \tTraining Loss:  1.606 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 115 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.634 \n",
            "Epoch: 116 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.630 \n",
            "Epoch: 117 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 118 \tTraining Loss:  1.605 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 119 \tTraining Loss:  1.610 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 120 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 121 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 122 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 123 \tTraining Loss:  1.605 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 124 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 125 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 126 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 127 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 128 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 129 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 130 \tTraining Loss:  1.606 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 131 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.646 \n",
            "Epoch: 132 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 133 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.626 \n",
            "Epoch: 134 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.633 \n",
            "Epoch: 135 \tTraining Loss:  1.610 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 136 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 137 \tTraining Loss:  1.607 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.644 \n",
            "Epoch: 138 \tTraining Loss:  1.611 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 139 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 140 \tTraining Loss:  1.607 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.629 \n",
            "Epoch: 141 \tTraining Loss:  1.606 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 142 \tTraining Loss:  1.610 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 143 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.644 \n",
            "Epoch: 144 \tTraining Loss:  1.609 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 145 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 146 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 147 \tTraining Loss:  1.611 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 148 \tTraining Loss:  1.608 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.631 \n",
            "Epoch: 149 \tTraining Loss:  1.607 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.625 \n",
            "Epoch: 150 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 151 \tTraining Loss:  1.605 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 152 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 153 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 154 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 155 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 156 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 157 \tTraining Loss:  1.606 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 158 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 159 \tTraining Loss:  1.612 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 160 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 161 \tTraining Loss:  1.606 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 162 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.627 \n",
            "Epoch: 163 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.625 \n",
            "Epoch: 164 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 165 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 166 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.629 \n",
            "Epoch: 167 \tTraining Loss:  1.608 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.626 \n",
            "Epoch: 168 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.632 \n",
            "Epoch: 169 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 170 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 171 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 172 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.631 \n",
            "Epoch: 173 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.628 \n",
            "Epoch: 174 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 175 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 176 \tTraining Loss:  1.606 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 177 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 178 \tTraining Loss:  1.606 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 179 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 180 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.645 \n",
            "Epoch: 181 \tTraining Loss:  1.612 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 182 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.629 \n",
            "Epoch: 183 \tTraining Loss:  1.608 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 184 \tTraining Loss:  1.606 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 185 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 186 \tTraining Loss:  1.610 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 187 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 188 \tTraining Loss:  1.610 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.634 \n",
            "Epoch: 189 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.629 \n",
            "Epoch: 190 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.635 \n",
            "Epoch: 191 \tTraining Loss:  1.608 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.631 \n",
            "Epoch: 192 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.629 \n",
            "Epoch: 193 \tTraining Loss:  1.610 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 194 \tTraining Loss:  1.612 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 195 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 196 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.631 \n",
            "Epoch: 197 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.621 \n",
            "Epoch: 198 \tTraining Loss:  1.609 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 199 \tTraining Loss:  1.610 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 200 \tTraining Loss:  1.613 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 201 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 202 \tTraining Loss:  1.610 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.629 \n",
            "Epoch: 203 \tTraining Loss:  1.612 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 204 \tTraining Loss:  1.609 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.627 \n",
            "Epoch: 205 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.627 \n",
            "Epoch: 206 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 207 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.644 \n",
            "Epoch: 208 \tTraining Loss:  1.610 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 209 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 210 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.640 \n",
            "Epoch: 211 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 212 \tTraining Loss:  1.605 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.644 \n",
            "Epoch: 213 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.647 \n",
            "Epoch: 214 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.647 \n",
            "Epoch: 215 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.642 \n",
            "Epoch: 216 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.633 \n",
            "Epoch: 217 \tTraining Loss:  1.606 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 218 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 219 \tTraining Loss:  1.610 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 220 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 221 \tTraining Loss:  1.610 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 222 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 223 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 224 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 225 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 226 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.647 \n",
            "Epoch: 227 \tTraining Loss:  1.611 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.634 \n",
            "Epoch: 228 \tTraining Loss:  1.606 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.627 \n",
            "Epoch: 229 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 230 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 231 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 232 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 233 \tTraining Loss:  1.611 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 234 \tTraining Loss:  1.606 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 235 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 236 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 237 \tTraining Loss:  1.605 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.638 \n",
            "Epoch: 238 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 239 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 240 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 241 \tTraining Loss:  1.606 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.627 \n",
            "Epoch: 242 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.631 \n",
            "Epoch: 243 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 244 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 245 \tTraining Loss:  1.608 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.638 \n",
            "Epoch: 246 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 247 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.646 \n",
            "Epoch: 248 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 249 \tTraining Loss:  1.606 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.648 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 20:25:33,644]\u001b[0m Trial 7 finished with value: 17.1 and parameters: {'Batch_size': 9, 'lr': 0.01, 'optimizer': <class 'torch.optim.adam.Adam'>, 'dropout': 0.7}. Best is trial 5 with value: 30.0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 1 \tTraining Loss:  1.613 \tTrain_Accu: 23%  \tValid_Acc:11% \t Valid Loss: 1.652 \n",
            "Epoch: 2 \tTraining Loss:  1.567 \tTrain_Accu: 27%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 3 \tTraining Loss:  1.541 \tTrain_Accu: 28%  \tValid_Acc:19% \t Valid Loss: 1.668 \n",
            "Epoch: 4 \tTraining Loss:  1.520 \tTrain_Accu: 29%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 5 \tTraining Loss:  1.475 \tTrain_Accu: 34%  \tValid_Acc:26% \t Valid Loss: 1.640 \n",
            "Epoch: 6 \tTraining Loss:  1.457 \tTrain_Accu: 35%  \tValid_Acc:29% \t Valid Loss: 1.646 \n",
            "Epoch: 7 \tTraining Loss:  1.415 \tTrain_Accu: 37%  \tValid_Acc:26% \t Valid Loss: 1.694 \n",
            "Epoch: 8 \tTraining Loss:  1.338 \tTrain_Accu: 45%  \tValid_Acc:19% \t Valid Loss: 1.743 \n",
            "Epoch: 9 \tTraining Loss:  1.310 \tTrain_Accu: 42%  \tValid_Acc:23% \t Valid Loss: 1.802 \n",
            "Epoch: 10 \tTraining Loss:  1.239 \tTrain_Accu: 47%  \tValid_Acc:24% \t Valid Loss: 1.838 \n",
            "Epoch: 11 \tTraining Loss:  1.223 \tTrain_Accu: 50%  \tValid_Acc:29% \t Valid Loss: 1.641 \n",
            "Epoch: 12 \tTraining Loss:  1.175 \tTrain_Accu: 49%  \tValid_Acc:31% \t Valid Loss: 1.713 \n",
            "Epoch: 13 \tTraining Loss:  1.125 \tTrain_Accu: 52%  \tValid_Acc:29% \t Valid Loss: 1.665 \n",
            "Epoch: 14 \tTraining Loss:  1.120 \tTrain_Accu: 56%  \tValid_Acc:31% \t Valid Loss: 1.763 \n",
            "Epoch: 15 \tTraining Loss:  1.007 \tTrain_Accu: 59%  \tValid_Acc:30% \t Valid Loss: 1.921 \n",
            "Epoch: 16 \tTraining Loss:  1.010 \tTrain_Accu: 57%  \tValid_Acc:24% \t Valid Loss: 1.872 \n",
            "Epoch: 17 \tTraining Loss:  0.944 \tTrain_Accu: 64%  \tValid_Acc:33% \t Valid Loss: 1.837 \n",
            "Epoch: 18 \tTraining Loss:  0.904 \tTrain_Accu: 65%  \tValid_Acc:20% \t Valid Loss: 1.768 \n",
            "Epoch: 19 \tTraining Loss:  0.893 \tTrain_Accu: 65%  \tValid_Acc:21% \t Valid Loss: 1.975 \n",
            "Epoch: 20 \tTraining Loss:  0.787 \tTrain_Accu: 69%  \tValid_Acc:23% \t Valid Loss: 2.008 \n",
            "Epoch: 21 \tTraining Loss:  0.807 \tTrain_Accu: 70%  \tValid_Acc:33% \t Valid Loss: 1.991 \n",
            "Epoch: 22 \tTraining Loss:  0.664 \tTrain_Accu: 73%  \tValid_Acc:33% \t Valid Loss: 2.152 \n",
            "Epoch: 23 \tTraining Loss:  0.738 \tTrain_Accu: 72%  \tValid_Acc:20% \t Valid Loss: 2.195 \n",
            "Epoch: 24 \tTraining Loss:  0.605 \tTrain_Accu: 76%  \tValid_Acc:27% \t Valid Loss: 2.259 \n",
            "Epoch: 25 \tTraining Loss:  0.669 \tTrain_Accu: 74%  \tValid_Acc:29% \t Valid Loss: 1.949 \n",
            "Epoch: 26 \tTraining Loss:  0.636 \tTrain_Accu: 74%  \tValid_Acc:31% \t Valid Loss: 2.020 \n",
            "Epoch: 27 \tTraining Loss:  0.611 \tTrain_Accu: 78%  \tValid_Acc:26% \t Valid Loss: 2.092 \n",
            "Epoch: 28 \tTraining Loss:  0.522 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 2.400 \n",
            "Epoch: 29 \tTraining Loss:  0.598 \tTrain_Accu: 77%  \tValid_Acc:27% \t Valid Loss: 1.876 \n",
            "Epoch: 30 \tTraining Loss:  0.572 \tTrain_Accu: 77%  \tValid_Acc:36% \t Valid Loss: 2.262 \n",
            "Epoch: 31 \tTraining Loss:  0.538 \tTrain_Accu: 78%  \tValid_Acc:30% \t Valid Loss: 2.594 \n",
            "Epoch: 32 \tTraining Loss:  0.489 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 2.504 \n",
            "Epoch: 33 \tTraining Loss:  0.441 \tTrain_Accu: 83%  \tValid_Acc:26% \t Valid Loss: 2.396 \n",
            "Epoch: 34 \tTraining Loss:  0.452 \tTrain_Accu: 81%  \tValid_Acc:27% \t Valid Loss: 2.286 \n",
            "Epoch: 35 \tTraining Loss:  0.412 \tTrain_Accu: 86%  \tValid_Acc:21% \t Valid Loss: 2.824 \n",
            "Epoch: 36 \tTraining Loss:  0.444 \tTrain_Accu: 84%  \tValid_Acc:21% \t Valid Loss: 2.826 \n",
            "Epoch: 37 \tTraining Loss:  0.408 \tTrain_Accu: 84%  \tValid_Acc:24% \t Valid Loss: 2.879 \n",
            "Epoch: 38 \tTraining Loss:  0.364 \tTrain_Accu: 86%  \tValid_Acc:24% \t Valid Loss: 3.148 \n",
            "Epoch: 39 \tTraining Loss:  0.356 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 2.643 \n",
            "Epoch: 40 \tTraining Loss:  0.359 \tTrain_Accu: 86%  \tValid_Acc:27% \t Valid Loss: 2.695 \n",
            "Epoch: 41 \tTraining Loss:  0.316 \tTrain_Accu: 89%  \tValid_Acc:26% \t Valid Loss: 3.297 \n",
            "Epoch: 42 \tTraining Loss:  0.348 \tTrain_Accu: 88%  \tValid_Acc:19% \t Valid Loss: 3.279 \n",
            "Epoch: 43 \tTraining Loss:  0.307 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 2.737 \n",
            "Epoch: 44 \tTraining Loss:  0.284 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 3.377 \n",
            "Epoch: 45 \tTraining Loss:  0.246 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 3.650 \n",
            "Epoch: 46 \tTraining Loss:  0.274 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 3.360 \n",
            "Epoch: 47 \tTraining Loss:  0.275 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 3.935 \n",
            "Epoch: 48 \tTraining Loss:  0.244 \tTrain_Accu: 91%  \tValid_Acc:21% \t Valid Loss: 4.044 \n",
            "Epoch: 49 \tTraining Loss:  0.237 \tTrain_Accu: 91%  \tValid_Acc:39% \t Valid Loss: 3.248 \n",
            "Epoch: 50 \tTraining Loss:  0.265 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 3.365 \n",
            "Epoch: 51 \tTraining Loss:  0.225 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 3.763 \n",
            "Epoch: 52 \tTraining Loss:  0.277 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 3.075 \n",
            "Epoch: 53 \tTraining Loss:  0.224 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 3.509 \n",
            "Epoch: 54 \tTraining Loss:  0.261 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 3.376 \n",
            "Epoch: 55 \tTraining Loss:  0.218 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 3.641 \n",
            "Epoch: 56 \tTraining Loss:  0.218 \tTrain_Accu: 92%  \tValid_Acc:33% \t Valid Loss: 3.527 \n",
            "Epoch: 57 \tTraining Loss:  0.230 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 3.709 \n",
            "Epoch: 58 \tTraining Loss:  0.244 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 4.138 \n",
            "Epoch: 59 \tTraining Loss:  0.189 \tTrain_Accu: 93%  \tValid_Acc:20% \t Valid Loss: 4.071 \n",
            "Epoch: 60 \tTraining Loss:  0.176 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 4.019 \n",
            "Epoch: 61 \tTraining Loss:  0.194 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 3.779 \n",
            "Epoch: 62 \tTraining Loss:  0.241 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 4.154 \n",
            "Epoch: 63 \tTraining Loss:  0.211 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 3.904 \n",
            "Epoch: 64 \tTraining Loss:  0.153 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 4.295 \n",
            "Epoch: 65 \tTraining Loss:  0.142 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 4.332 \n",
            "Epoch: 66 \tTraining Loss:  0.192 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 4.068 \n",
            "Epoch: 67 \tTraining Loss:  0.259 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 4.158 \n",
            "Epoch: 68 \tTraining Loss:  0.186 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 4.481 \n",
            "Epoch: 69 \tTraining Loss:  0.173 \tTrain_Accu: 93%  \tValid_Acc:30% \t Valid Loss: 3.521 \n",
            "Epoch: 70 \tTraining Loss:  0.189 \tTrain_Accu: 93%  \tValid_Acc:30% \t Valid Loss: 3.775 \n",
            "Epoch: 71 \tTraining Loss:  0.185 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 3.766 \n",
            "Epoch: 72 \tTraining Loss:  0.157 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 4.074 \n",
            "Epoch: 73 \tTraining Loss:  0.171 \tTrain_Accu: 93%  \tValid_Acc:31% \t Valid Loss: 3.664 \n",
            "Epoch: 74 \tTraining Loss:  0.171 \tTrain_Accu: 94%  \tValid_Acc:33% \t Valid Loss: 3.647 \n",
            "Epoch: 75 \tTraining Loss:  0.155 \tTrain_Accu: 93%  \tValid_Acc:30% \t Valid Loss: 4.288 \n",
            "Epoch: 76 \tTraining Loss:  0.158 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 3.888 \n",
            "Epoch: 77 \tTraining Loss:  0.174 \tTrain_Accu: 94%  \tValid_Acc:34% \t Valid Loss: 3.793 \n",
            "Epoch: 78 \tTraining Loss:  0.131 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 4.123 \n",
            "Epoch: 79 \tTraining Loss:  0.148 \tTrain_Accu: 95%  \tValid_Acc:19% \t Valid Loss: 4.718 \n",
            "Epoch: 80 \tTraining Loss:  0.155 \tTrain_Accu: 94%  \tValid_Acc:33% \t Valid Loss: 3.918 \n",
            "Epoch: 81 \tTraining Loss:  0.216 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 3.561 \n",
            "Epoch: 82 \tTraining Loss:  0.144 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 4.658 \n",
            "Epoch: 83 \tTraining Loss:  0.163 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 4.348 \n",
            "Epoch: 84 \tTraining Loss:  0.166 \tTrain_Accu: 94%  \tValid_Acc:31% \t Valid Loss: 4.253 \n",
            "Epoch: 85 \tTraining Loss:  0.181 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 3.944 \n",
            "Epoch: 86 \tTraining Loss:  0.140 \tTrain_Accu: 94%  \tValid_Acc:31% \t Valid Loss: 4.634 \n",
            "Epoch: 87 \tTraining Loss:  0.124 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 5.438 \n",
            "Epoch: 88 \tTraining Loss:  0.159 \tTrain_Accu: 94%  \tValid_Acc:23% \t Valid Loss: 4.693 \n",
            "Epoch: 89 \tTraining Loss:  0.102 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 5.265 \n",
            "Epoch: 90 \tTraining Loss:  0.152 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 4.349 \n",
            "Epoch: 91 \tTraining Loss:  0.219 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 3.897 \n",
            "Epoch: 92 \tTraining Loss:  0.141 \tTrain_Accu: 95%  \tValid_Acc:27% \t Valid Loss: 4.313 \n",
            "Epoch: 93 \tTraining Loss:  0.182 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 3.731 \n",
            "Epoch: 94 \tTraining Loss:  0.119 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 4.921 \n",
            "Epoch: 95 \tTraining Loss:  0.139 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 4.297 \n",
            "Epoch: 96 \tTraining Loss:  0.139 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 4.802 \n",
            "Epoch: 97 \tTraining Loss:  0.127 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 5.210 \n",
            "Epoch: 98 \tTraining Loss:  0.085 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 5.431 \n",
            "Epoch: 99 \tTraining Loss:  0.118 \tTrain_Accu: 95%  \tValid_Acc:27% \t Valid Loss: 5.564 \n",
            "Epoch: 100 \tTraining Loss:  0.262 \tTrain_Accu: 91%  \tValid_Acc:34% \t Valid Loss: 3.948 \n",
            "Epoch: 101 \tTraining Loss:  0.135 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 4.430 \n",
            "Epoch: 102 \tTraining Loss:  0.106 \tTrain_Accu: 95%  \tValid_Acc:31% \t Valid Loss: 4.426 \n",
            "Epoch: 103 \tTraining Loss:  0.146 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 5.177 \n",
            "Epoch: 104 \tTraining Loss:  0.166 \tTrain_Accu: 95%  \tValid_Acc:30% \t Valid Loss: 5.176 \n",
            "Epoch: 105 \tTraining Loss:  0.124 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 4.811 \n",
            "Epoch: 106 \tTraining Loss:  0.096 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 4.481 \n",
            "Epoch: 107 \tTraining Loss:  0.136 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 4.360 \n",
            "Epoch: 108 \tTraining Loss:  0.108 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 4.291 \n",
            "Epoch: 109 \tTraining Loss:  0.147 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 5.011 \n",
            "Epoch: 110 \tTraining Loss:  0.099 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 4.215 \n",
            "Epoch: 111 \tTraining Loss:  0.151 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 5.298 \n",
            "Epoch: 112 \tTraining Loss:  0.137 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 4.184 \n",
            "Epoch: 113 \tTraining Loss:  0.102 \tTrain_Accu: 96%  \tValid_Acc:21% \t Valid Loss: 5.397 \n",
            "Epoch: 114 \tTraining Loss:  0.169 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 4.902 \n",
            "Epoch: 115 \tTraining Loss:  0.172 \tTrain_Accu: 93%  \tValid_Acc:31% \t Valid Loss: 3.833 \n",
            "Epoch: 116 \tTraining Loss:  0.093 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 4.395 \n",
            "Epoch: 117 \tTraining Loss:  0.144 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 4.757 \n",
            "Epoch: 118 \tTraining Loss:  0.091 \tTrain_Accu: 96%  \tValid_Acc:20% \t Valid Loss: 5.043 \n",
            "Epoch: 119 \tTraining Loss:  0.080 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 5.590 \n",
            "Epoch: 120 \tTraining Loss:  0.138 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 5.145 \n",
            "Epoch: 121 \tTraining Loss:  0.123 \tTrain_Accu: 95%  \tValid_Acc:30% \t Valid Loss: 4.834 \n",
            "Epoch: 122 \tTraining Loss:  0.192 \tTrain_Accu: 91%  \tValid_Acc:33% \t Valid Loss: 3.962 \n",
            "Epoch: 123 \tTraining Loss:  0.120 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 4.567 \n",
            "Epoch: 124 \tTraining Loss:  0.130 \tTrain_Accu: 95%  \tValid_Acc:30% \t Valid Loss: 5.010 \n",
            "Epoch: 125 \tTraining Loss:  0.129 \tTrain_Accu: 95%  \tValid_Acc:31% \t Valid Loss: 4.443 \n",
            "Epoch: 126 \tTraining Loss:  0.089 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 5.523 \n",
            "Epoch: 127 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 4.767 \n",
            "Epoch: 128 \tTraining Loss:  0.127 \tTrain_Accu: 95%  \tValid_Acc:31% \t Valid Loss: 5.128 \n",
            "Epoch: 129 \tTraining Loss:  0.066 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 6.188 \n",
            "Epoch: 130 \tTraining Loss:  0.104 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 4.932 \n",
            "Epoch: 131 \tTraining Loss:  0.091 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 4.966 \n",
            "Epoch: 132 \tTraining Loss:  0.141 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 5.563 \n",
            "Epoch: 133 \tTraining Loss:  0.084 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 4.901 \n",
            "Epoch: 134 \tTraining Loss:  0.102 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 5.929 \n",
            "Epoch: 135 \tTraining Loss:  0.115 \tTrain_Accu: 95%  \tValid_Acc:31% \t Valid Loss: 5.277 \n",
            "Epoch: 136 \tTraining Loss:  0.072 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 6.728 \n",
            "Epoch: 137 \tTraining Loss:  0.138 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 5.216 \n",
            "Epoch: 138 \tTraining Loss:  0.085 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 5.194 \n",
            "Epoch: 139 \tTraining Loss:  0.094 \tTrain_Accu: 95%  \tValid_Acc:27% \t Valid Loss: 5.979 \n",
            "Epoch: 140 \tTraining Loss:  0.089 \tTrain_Accu: 96%  \tValid_Acc:21% \t Valid Loss: 6.587 \n",
            "Epoch: 141 \tTraining Loss:  0.155 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 7.119 \n",
            "Epoch: 142 \tTraining Loss:  0.107 \tTrain_Accu: 97%  \tValid_Acc:31% \t Valid Loss: 5.702 \n",
            "Epoch: 143 \tTraining Loss:  0.103 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 6.350 \n",
            "Epoch: 144 \tTraining Loss:  0.107 \tTrain_Accu: 95%  \tValid_Acc:31% \t Valid Loss: 5.320 \n",
            "Epoch: 145 \tTraining Loss:  0.091 \tTrain_Accu: 97%  \tValid_Acc:19% \t Valid Loss: 5.629 \n",
            "Epoch: 146 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \tValid_Acc:21% \t Valid Loss: 5.381 \n",
            "Epoch: 147 \tTraining Loss:  0.112 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 5.194 \n",
            "Epoch: 148 \tTraining Loss:  0.087 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 5.252 \n",
            "Epoch: 149 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 5.428 \n",
            "Epoch: 150 \tTraining Loss:  0.122 \tTrain_Accu: 95%  \tValid_Acc:34% \t Valid Loss: 5.739 \n",
            "Epoch: 151 \tTraining Loss:  0.090 \tTrain_Accu: 95%  \tValid_Acc:34% \t Valid Loss: 5.878 \n",
            "Epoch: 152 \tTraining Loss:  0.108 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 6.641 \n",
            "Epoch: 153 \tTraining Loss:  0.096 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 4.915 \n",
            "Epoch: 154 \tTraining Loss:  0.074 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 5.732 \n",
            "Epoch: 155 \tTraining Loss:  0.080 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 5.663 \n",
            "Epoch: 156 \tTraining Loss:  0.038 \tTrain_Accu: 98%  \tValid_Acc:36% \t Valid Loss: 6.050 \n",
            "Epoch: 157 \tTraining Loss:  0.067 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 5.964 \n",
            "Epoch: 158 \tTraining Loss:  0.121 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 6.502 \n",
            "Epoch: 159 \tTraining Loss:  0.086 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 5.771 \n",
            "Epoch: 160 \tTraining Loss:  0.098 \tTrain_Accu: 95%  \tValid_Acc:31% \t Valid Loss: 6.412 \n",
            "Epoch: 161 \tTraining Loss:  0.079 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 5.476 \n",
            "Epoch: 162 \tTraining Loss:  0.065 \tTrain_Accu: 97%  \tValid_Acc:20% \t Valid Loss: 6.730 \n",
            "Epoch: 163 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 6.042 \n",
            "Epoch: 164 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \tValid_Acc:34% \t Valid Loss: 7.029 \n",
            "Epoch: 165 \tTraining Loss:  0.114 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 6.015 \n",
            "Epoch: 166 \tTraining Loss:  0.125 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 4.921 \n",
            "Epoch: 167 \tTraining Loss:  0.112 \tTrain_Accu: 95%  \tValid_Acc:30% \t Valid Loss: 5.735 \n",
            "Epoch: 168 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 5.802 \n",
            "Epoch: 169 \tTraining Loss:  0.070 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 5.056 \n",
            "Epoch: 170 \tTraining Loss:  0.087 \tTrain_Accu: 97%  \tValid_Acc:21% \t Valid Loss: 7.592 \n",
            "Epoch: 171 \tTraining Loss:  0.089 \tTrain_Accu: 96%  \tValid_Acc:21% \t Valid Loss: 6.784 \n",
            "Epoch: 172 \tTraining Loss:  0.075 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 5.323 \n",
            "Epoch: 173 \tTraining Loss:  0.113 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 5.912 \n",
            "Epoch: 174 \tTraining Loss:  0.075 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 6.238 \n",
            "Epoch: 175 \tTraining Loss:  0.090 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 7.115 \n",
            "Epoch: 176 \tTraining Loss:  0.083 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 5.839 \n",
            "Epoch: 177 \tTraining Loss:  0.061 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 6.239 \n",
            "Epoch: 178 \tTraining Loss:  0.094 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 6.008 \n",
            "Epoch: 179 \tTraining Loss:  0.109 \tTrain_Accu: 95%  \tValid_Acc:27% \t Valid Loss: 6.364 \n",
            "Epoch: 180 \tTraining Loss:  0.076 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 6.427 \n",
            "Epoch: 181 \tTraining Loss:  0.089 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 5.771 \n",
            "Epoch: 182 \tTraining Loss:  0.100 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 6.716 \n",
            "Epoch: 183 \tTraining Loss:  0.077 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 6.051 \n",
            "Epoch: 184 \tTraining Loss:  0.070 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 6.389 \n",
            "Epoch: 185 \tTraining Loss:  0.078 \tTrain_Accu: 97%  \tValid_Acc:30% \t Valid Loss: 6.262 \n",
            "Epoch: 186 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 5.824 \n",
            "Epoch: 187 \tTraining Loss:  0.098 \tTrain_Accu: 95%  \tValid_Acc:27% \t Valid Loss: 6.343 \n",
            "Epoch: 188 \tTraining Loss:  0.060 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 6.337 \n",
            "Epoch: 189 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:21% \t Valid Loss: 7.108 \n",
            "Epoch: 190 \tTraining Loss:  0.084 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 7.210 \n",
            "Epoch: 191 \tTraining Loss:  0.095 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 7.638 \n",
            "Epoch: 192 \tTraining Loss:  0.078 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 6.315 \n",
            "Epoch: 193 \tTraining Loss:  0.076 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 7.538 \n",
            "Epoch: 194 \tTraining Loss:  0.089 \tTrain_Accu: 97%  \tValid_Acc:20% \t Valid Loss: 6.461 \n",
            "Epoch: 195 \tTraining Loss:  0.088 \tTrain_Accu: 96%  \tValid_Acc:31% \t Valid Loss: 6.872 \n",
            "Epoch: 196 \tTraining Loss:  0.064 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 5.940 \n",
            "Epoch: 197 \tTraining Loss:  0.086 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 5.849 \n",
            "Epoch: 198 \tTraining Loss:  0.053 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 6.530 \n",
            "Epoch: 199 \tTraining Loss:  0.089 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 6.803 \n",
            "Epoch: 200 \tTraining Loss:  0.111 \tTrain_Accu: 96%  \tValid_Acc:31% \t Valid Loss: 6.208 \n",
            "Epoch: 201 \tTraining Loss:  0.121 \tTrain_Accu: 96%  \tValid_Acc:31% \t Valid Loss: 5.199 \n",
            "Epoch: 202 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:31% \t Valid Loss: 5.401 \n",
            "Epoch: 203 \tTraining Loss:  0.091 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 6.502 \n",
            "Epoch: 204 \tTraining Loss:  0.071 \tTrain_Accu: 97%  \tValid_Acc:27% \t Valid Loss: 5.980 \n",
            "Epoch: 205 \tTraining Loss:  0.097 \tTrain_Accu: 95%  \tValid_Acc:29% \t Valid Loss: 6.743 \n",
            "Epoch: 206 \tTraining Loss:  0.065 \tTrain_Accu: 96%  \tValid_Acc:34% \t Valid Loss: 6.614 \n",
            "Epoch: 207 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 6.302 \n",
            "Epoch: 208 \tTraining Loss:  0.061 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 7.447 \n",
            "Epoch: 209 \tTraining Loss:  0.066 \tTrain_Accu: 97%  \tValid_Acc:34% \t Valid Loss: 8.510 \n",
            "Epoch: 210 \tTraining Loss:  0.064 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 8.305 \n",
            "Epoch: 211 \tTraining Loss:  0.073 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 8.596 \n",
            "Epoch: 212 \tTraining Loss:  0.064 \tTrain_Accu: 97%  \tValid_Acc:27% \t Valid Loss: 8.148 \n",
            "Epoch: 213 \tTraining Loss:  0.068 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 6.590 \n",
            "Epoch: 214 \tTraining Loss:  0.052 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 8.639 \n",
            "Epoch: 215 \tTraining Loss:  0.072 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 5.862 \n",
            "Epoch: 216 \tTraining Loss:  0.076 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 6.686 \n",
            "Epoch: 217 \tTraining Loss:  0.058 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 6.047 \n",
            "Epoch: 218 \tTraining Loss:  0.061 \tTrain_Accu: 98%  \tValid_Acc:21% \t Valid Loss: 6.794 \n",
            "Epoch: 219 \tTraining Loss:  0.063 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 8.283 \n",
            "Epoch: 220 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 7.856 \n",
            "Epoch: 221 \tTraining Loss:  0.065 \tTrain_Accu: 97%  \tValid_Acc:19% \t Valid Loss: 8.374 \n",
            "Epoch: 222 \tTraining Loss:  0.113 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 7.770 \n",
            "Epoch: 223 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 6.584 \n",
            "Epoch: 224 \tTraining Loss:  0.084 \tTrain_Accu: 96%  \tValid_Acc:31% \t Valid Loss: 6.970 \n",
            "Epoch: 225 \tTraining Loss:  0.036 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 7.690 \n",
            "Epoch: 226 \tTraining Loss:  0.105 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 7.168 \n",
            "Epoch: 227 \tTraining Loss:  0.099 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 6.361 \n",
            "Epoch: 228 \tTraining Loss:  0.041 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 7.074 \n",
            "Epoch: 229 \tTraining Loss:  0.075 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 7.689 \n",
            "Epoch: 230 \tTraining Loss:  0.062 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 7.823 \n",
            "Epoch: 231 \tTraining Loss:  0.049 \tTrain_Accu: 98%  \tValid_Acc:33% \t Valid Loss: 6.801 \n",
            "Epoch: 232 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 7.241 \n",
            "Epoch: 233 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:27% \t Valid Loss: 5.796 \n",
            "Epoch: 234 \tTraining Loss:  0.097 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 7.042 \n",
            "Epoch: 235 \tTraining Loss:  0.065 \tTrain_Accu: 97%  \tValid_Acc:34% \t Valid Loss: 5.896 \n",
            "Epoch: 236 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 6.589 \n",
            "Epoch: 237 \tTraining Loss:  0.067 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 6.612 \n",
            "Epoch: 238 \tTraining Loss:  0.107 \tTrain_Accu: 95%  \tValid_Acc:33% \t Valid Loss: 6.301 \n",
            "Epoch: 239 \tTraining Loss:  0.075 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 6.563 \n",
            "Epoch: 240 \tTraining Loss:  0.068 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 7.591 \n",
            "Epoch: 241 \tTraining Loss:  0.048 \tTrain_Accu: 98%  \tValid_Acc:34% \t Valid Loss: 6.903 \n",
            "Epoch: 242 \tTraining Loss:  0.065 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 7.836 \n",
            "Epoch: 243 \tTraining Loss:  0.086 \tTrain_Accu: 97%  \tValid_Acc:31% \t Valid Loss: 6.669 \n",
            "Epoch: 244 \tTraining Loss:  0.062 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 6.313 \n",
            "Epoch: 245 \tTraining Loss:  0.043 \tTrain_Accu: 98%  \tValid_Acc:30% \t Valid Loss: 7.286 \n",
            "Epoch: 246 \tTraining Loss:  0.045 \tTrain_Accu: 98%  \tValid_Acc:29% \t Valid Loss: 6.554 \n",
            "Epoch: 247 \tTraining Loss:  0.101 \tTrain_Accu: 95%  \tValid_Acc:33% \t Valid Loss: 6.842 \n",
            "Epoch: 248 \tTraining Loss:  0.056 \tTrain_Accu: 98%  \tValid_Acc:31% \t Valid Loss: 7.302 \n",
            "Epoch: 249 \tTraining Loss:  0.055 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 7.108 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 20:28:15,256]\u001b[0m Trial 8 finished with value: 25.7 and parameters: {'Batch_size': 5, 'lr': 0.0001, 'optimizer': <class 'torch.optim.adam.Adam'>, 'dropout': 0.5}. Best is trial 5 with value: 30.0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.060 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 6.444 \n",
            "Epoch: 1 \tTraining Loss:  1.781 \tTrain_Accu: 18%  \tValid_Acc:20% \t Valid Loss: 1.654 \n",
            "Epoch: 2 \tTraining Loss:  1.618 \tTrain_Accu: 19%  \tValid_Acc:4% \t Valid Loss: 1.634 \n",
            "Epoch: 3 \tTraining Loss:  1.622 \tTrain_Accu: 19%  \tValid_Acc:9% \t Valid Loss: 1.630 \n",
            "Epoch: 4 \tTraining Loss:  1.606 \tTrain_Accu: 23%  \tValid_Acc:10% \t Valid Loss: 1.632 \n",
            "Epoch: 5 \tTraining Loss:  1.610 \tTrain_Accu: 22%  \tValid_Acc:11% \t Valid Loss: 1.624 \n",
            "Epoch: 6 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:10% \t Valid Loss: 1.635 \n",
            "Epoch: 7 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:13% \t Valid Loss: 1.631 \n",
            "Epoch: 8 \tTraining Loss:  1.596 \tTrain_Accu: 27%  \tValid_Acc:10% \t Valid Loss: 1.640 \n",
            "Epoch: 9 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:9% \t Valid Loss: 1.627 \n",
            "Epoch: 10 \tTraining Loss:  1.611 \tTrain_Accu: 19%  \tValid_Acc:13% \t Valid Loss: 1.610 \n",
            "Epoch: 11 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:4% \t Valid Loss: 1.681 \n",
            "Epoch: 12 \tTraining Loss:  1.608 \tTrain_Accu: 22%  \tValid_Acc:10% \t Valid Loss: 1.633 \n",
            "Epoch: 13 \tTraining Loss:  1.599 \tTrain_Accu: 22%  \tValid_Acc:11% \t Valid Loss: 1.644 \n",
            "Epoch: 14 \tTraining Loss:  1.607 \tTrain_Accu: 23%  \tValid_Acc:10% \t Valid Loss: 1.629 \n",
            "Epoch: 15 \tTraining Loss:  1.598 \tTrain_Accu: 22%  \tValid_Acc:11% \t Valid Loss: 1.619 \n",
            "Epoch: 16 \tTraining Loss:  1.611 \tTrain_Accu: 18%  \tValid_Acc:13% \t Valid Loss: 1.616 \n",
            "Epoch: 17 \tTraining Loss:  1.599 \tTrain_Accu: 21%  \tValid_Acc:11% \t Valid Loss: 1.647 \n",
            "Epoch: 18 \tTraining Loss:  1.603 \tTrain_Accu: 21%  \tValid_Acc:10% \t Valid Loss: 1.640 \n",
            "Epoch: 19 \tTraining Loss:  1.599 \tTrain_Accu: 22%  \tValid_Acc:16% \t Valid Loss: 1.635 \n",
            "Epoch: 20 \tTraining Loss:  1.588 \tTrain_Accu: 23%  \tValid_Acc:14% \t Valid Loss: 1.620 \n",
            "Epoch: 21 \tTraining Loss:  1.581 \tTrain_Accu: 24%  \tValid_Acc:20% \t Valid Loss: 1.661 \n",
            "Epoch: 22 \tTraining Loss:  1.587 \tTrain_Accu: 22%  \tValid_Acc:19% \t Valid Loss: 1.650 \n",
            "Epoch: 23 \tTraining Loss:  1.586 \tTrain_Accu: 24%  \tValid_Acc:20% \t Valid Loss: 1.619 \n",
            "Epoch: 24 \tTraining Loss:  1.591 \tTrain_Accu: 25%  \tValid_Acc:3% \t Valid Loss: 1.657 \n",
            "Epoch: 25 \tTraining Loss:  1.604 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.627 \n",
            "Epoch: 26 \tTraining Loss:  1.590 \tTrain_Accu: 24%  \tValid_Acc:13% \t Valid Loss: 1.654 \n",
            "Epoch: 27 \tTraining Loss:  1.578 \tTrain_Accu: 25%  \tValid_Acc:11% \t Valid Loss: 1.666 \n",
            "Epoch: 28 \tTraining Loss:  1.559 \tTrain_Accu: 29%  \tValid_Acc:21% \t Valid Loss: 1.648 \n",
            "Epoch: 29 \tTraining Loss:  1.577 \tTrain_Accu: 24%  \tValid_Acc:21% \t Valid Loss: 1.654 \n",
            "Epoch: 30 \tTraining Loss:  1.582 \tTrain_Accu: 24%  \tValid_Acc:14% \t Valid Loss: 1.647 \n",
            "Epoch: 31 \tTraining Loss:  1.583 \tTrain_Accu: 25%  \tValid_Acc:16% \t Valid Loss: 1.649 \n",
            "Epoch: 32 \tTraining Loss:  1.557 \tTrain_Accu: 28%  \tValid_Acc:19% \t Valid Loss: 1.651 \n",
            "Epoch: 33 \tTraining Loss:  1.581 \tTrain_Accu: 27%  \tValid_Acc:19% \t Valid Loss: 1.637 \n",
            "Epoch: 34 \tTraining Loss:  1.592 \tTrain_Accu: 25%  \tValid_Acc:14% \t Valid Loss: 1.647 \n",
            "Epoch: 35 \tTraining Loss:  1.574 \tTrain_Accu: 24%  \tValid_Acc:21% \t Valid Loss: 1.656 \n",
            "Epoch: 36 \tTraining Loss:  1.579 \tTrain_Accu: 26%  \tValid_Acc:19% \t Valid Loss: 1.626 \n",
            "Epoch: 37 \tTraining Loss:  1.573 \tTrain_Accu: 23%  \tValid_Acc:16% \t Valid Loss: 1.625 \n",
            "Epoch: 38 \tTraining Loss:  1.583 \tTrain_Accu: 27%  \tValid_Acc:23% \t Valid Loss: 1.620 \n",
            "Epoch: 39 \tTraining Loss:  1.559 \tTrain_Accu: 26%  \tValid_Acc:14% \t Valid Loss: 1.647 \n",
            "Epoch: 40 \tTraining Loss:  1.561 \tTrain_Accu: 27%  \tValid_Acc:23% \t Valid Loss: 1.641 \n",
            "Epoch: 41 \tTraining Loss:  1.558 \tTrain_Accu: 28%  \tValid_Acc:27% \t Valid Loss: 1.614 \n",
            "Epoch: 42 \tTraining Loss:  1.533 \tTrain_Accu: 31%  \tValid_Acc:30% \t Valid Loss: 1.623 \n",
            "Epoch: 43 \tTraining Loss:  1.544 \tTrain_Accu: 30%  \tValid_Acc:27% \t Valid Loss: 1.616 \n",
            "Epoch: 44 \tTraining Loss:  1.536 \tTrain_Accu: 30%  \tValid_Acc:16% \t Valid Loss: 1.625 \n",
            "Epoch: 45 \tTraining Loss:  1.547 \tTrain_Accu: 28%  \tValid_Acc:23% \t Valid Loss: 1.620 \n",
            "Epoch: 46 \tTraining Loss:  1.524 \tTrain_Accu: 31%  \tValid_Acc:23% \t Valid Loss: 1.605 \n",
            "Epoch: 47 \tTraining Loss:  1.561 \tTrain_Accu: 31%  \tValid_Acc:31% \t Valid Loss: 1.620 \n",
            "Epoch: 48 \tTraining Loss:  1.533 \tTrain_Accu: 31%  \tValid_Acc:14% \t Valid Loss: 1.640 \n",
            "Epoch: 49 \tTraining Loss:  1.547 \tTrain_Accu: 30%  \tValid_Acc:19% \t Valid Loss: 1.663 \n",
            "Epoch: 50 \tTraining Loss:  1.509 \tTrain_Accu: 33%  \tValid_Acc:24% \t Valid Loss: 1.639 \n",
            "Epoch: 51 \tTraining Loss:  1.523 \tTrain_Accu: 33%  \tValid_Acc:21% \t Valid Loss: 1.681 \n",
            "Epoch: 52 \tTraining Loss:  1.518 \tTrain_Accu: 30%  \tValid_Acc:24% \t Valid Loss: 1.637 \n",
            "Epoch: 53 \tTraining Loss:  1.533 \tTrain_Accu: 32%  \tValid_Acc:21% \t Valid Loss: 1.625 \n",
            "Epoch: 54 \tTraining Loss:  1.522 \tTrain_Accu: 30%  \tValid_Acc:21% \t Valid Loss: 1.615 \n",
            "Epoch: 55 \tTraining Loss:  1.511 \tTrain_Accu: 32%  \tValid_Acc:27% \t Valid Loss: 1.623 \n",
            "Epoch: 56 \tTraining Loss:  1.552 \tTrain_Accu: 31%  \tValid_Acc:21% \t Valid Loss: 1.642 \n",
            "Epoch: 57 \tTraining Loss:  1.521 \tTrain_Accu: 33%  \tValid_Acc:19% \t Valid Loss: 1.621 \n",
            "Epoch: 58 \tTraining Loss:  1.521 \tTrain_Accu: 34%  \tValid_Acc:21% \t Valid Loss: 1.616 \n",
            "Epoch: 59 \tTraining Loss:  1.519 \tTrain_Accu: 35%  \tValid_Acc:26% \t Valid Loss: 1.620 \n",
            "Epoch: 60 \tTraining Loss:  1.485 \tTrain_Accu: 32%  \tValid_Acc:29% \t Valid Loss: 1.598 \n",
            "Epoch: 61 \tTraining Loss:  1.487 \tTrain_Accu: 34%  \tValid_Acc:24% \t Valid Loss: 1.623 \n",
            "Epoch: 62 \tTraining Loss:  1.491 \tTrain_Accu: 34%  \tValid_Acc:24% \t Valid Loss: 1.616 \n",
            "Epoch: 63 \tTraining Loss:  1.487 \tTrain_Accu: 37%  \tValid_Acc:23% \t Valid Loss: 1.639 \n",
            "Epoch: 64 \tTraining Loss:  1.483 \tTrain_Accu: 34%  \tValid_Acc:23% \t Valid Loss: 1.616 \n",
            "Epoch: 65 \tTraining Loss:  1.519 \tTrain_Accu: 32%  \tValid_Acc:29% \t Valid Loss: 1.606 \n",
            "Epoch: 66 \tTraining Loss:  1.493 \tTrain_Accu: 35%  \tValid_Acc:26% \t Valid Loss: 1.608 \n",
            "Epoch: 67 \tTraining Loss:  1.525 \tTrain_Accu: 34%  \tValid_Acc:27% \t Valid Loss: 1.588 \n",
            "Epoch: 68 \tTraining Loss:  1.461 \tTrain_Accu: 36%  \tValid_Acc:20% \t Valid Loss: 1.629 \n",
            "Epoch: 69 \tTraining Loss:  1.475 \tTrain_Accu: 32%  \tValid_Acc:21% \t Valid Loss: 1.620 \n",
            "Epoch: 70 \tTraining Loss:  1.493 \tTrain_Accu: 34%  \tValid_Acc:23% \t Valid Loss: 1.616 \n",
            "Epoch: 71 \tTraining Loss:  1.467 \tTrain_Accu: 36%  \tValid_Acc:23% \t Valid Loss: 1.650 \n",
            "Epoch: 72 \tTraining Loss:  1.462 \tTrain_Accu: 35%  \tValid_Acc:26% \t Valid Loss: 1.619 \n",
            "Epoch: 73 \tTraining Loss:  1.436 \tTrain_Accu: 38%  \tValid_Acc:24% \t Valid Loss: 1.614 \n",
            "Epoch: 74 \tTraining Loss:  1.478 \tTrain_Accu: 38%  \tValid_Acc:30% \t Valid Loss: 1.612 \n",
            "Epoch: 75 \tTraining Loss:  1.441 \tTrain_Accu: 36%  \tValid_Acc:29% \t Valid Loss: 1.612 \n",
            "Epoch: 76 \tTraining Loss:  1.435 \tTrain_Accu: 37%  \tValid_Acc:26% \t Valid Loss: 1.608 \n",
            "Epoch: 77 \tTraining Loss:  1.440 \tTrain_Accu: 36%  \tValid_Acc:29% \t Valid Loss: 1.593 \n",
            "Epoch: 78 \tTraining Loss:  1.411 \tTrain_Accu: 37%  \tValid_Acc:21% \t Valid Loss: 1.614 \n",
            "Epoch: 79 \tTraining Loss:  1.428 \tTrain_Accu: 39%  \tValid_Acc:23% \t Valid Loss: 1.650 \n",
            "Epoch: 80 \tTraining Loss:  1.462 \tTrain_Accu: 37%  \tValid_Acc:26% \t Valid Loss: 1.609 \n",
            "Epoch: 81 \tTraining Loss:  1.454 \tTrain_Accu: 36%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 82 \tTraining Loss:  1.425 \tTrain_Accu: 38%  \tValid_Acc:27% \t Valid Loss: 1.613 \n",
            "Epoch: 83 \tTraining Loss:  1.425 \tTrain_Accu: 38%  \tValid_Acc:26% \t Valid Loss: 1.580 \n",
            "Epoch: 84 \tTraining Loss:  1.437 \tTrain_Accu: 36%  \tValid_Acc:27% \t Valid Loss: 1.609 \n",
            "Epoch: 85 \tTraining Loss:  1.444 \tTrain_Accu: 35%  \tValid_Acc:26% \t Valid Loss: 1.583 \n",
            "Epoch: 86 \tTraining Loss:  1.417 \tTrain_Accu: 36%  \tValid_Acc:24% \t Valid Loss: 1.622 \n",
            "Epoch: 87 \tTraining Loss:  1.421 \tTrain_Accu: 38%  \tValid_Acc:21% \t Valid Loss: 1.683 \n",
            "Epoch: 88 \tTraining Loss:  1.391 \tTrain_Accu: 40%  \tValid_Acc:16% \t Valid Loss: 1.720 \n",
            "Epoch: 89 \tTraining Loss:  1.389 \tTrain_Accu: 40%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 90 \tTraining Loss:  1.377 \tTrain_Accu: 38%  \tValid_Acc:23% \t Valid Loss: 1.877 \n",
            "Epoch: 91 \tTraining Loss:  1.418 \tTrain_Accu: 39%  \tValid_Acc:23% \t Valid Loss: 1.625 \n",
            "Epoch: 92 \tTraining Loss:  1.346 \tTrain_Accu: 40%  \tValid_Acc:24% \t Valid Loss: 1.609 \n",
            "Epoch: 93 \tTraining Loss:  1.299 \tTrain_Accu: 44%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 94 \tTraining Loss:  1.373 \tTrain_Accu: 39%  \tValid_Acc:23% \t Valid Loss: 1.617 \n",
            "Epoch: 95 \tTraining Loss:  1.353 \tTrain_Accu: 38%  \tValid_Acc:27% \t Valid Loss: 1.688 \n",
            "Epoch: 96 \tTraining Loss:  1.400 \tTrain_Accu: 40%  \tValid_Acc:24% \t Valid Loss: 1.639 \n",
            "Epoch: 97 \tTraining Loss:  1.396 \tTrain_Accu: 36%  \tValid_Acc:21% \t Valid Loss: 1.603 \n",
            "Epoch: 98 \tTraining Loss:  1.373 \tTrain_Accu: 39%  \tValid_Acc:23% \t Valid Loss: 1.618 \n",
            "Epoch: 99 \tTraining Loss:  1.347 \tTrain_Accu: 40%  \tValid_Acc:23% \t Valid Loss: 1.639 \n",
            "Epoch: 100 \tTraining Loss:  1.359 \tTrain_Accu: 38%  \tValid_Acc:23% \t Valid Loss: 1.676 \n",
            "Epoch: 101 \tTraining Loss:  1.340 \tTrain_Accu: 38%  \tValid_Acc:23% \t Valid Loss: 1.771 \n",
            "Epoch: 102 \tTraining Loss:  1.332 \tTrain_Accu: 42%  \tValid_Acc:23% \t Valid Loss: 1.759 \n",
            "Epoch: 103 \tTraining Loss:  1.392 \tTrain_Accu: 40%  \tValid_Acc:26% \t Valid Loss: 1.648 \n",
            "Epoch: 104 \tTraining Loss:  1.348 \tTrain_Accu: 38%  \tValid_Acc:23% \t Valid Loss: 1.831 \n",
            "Epoch: 105 \tTraining Loss:  1.344 \tTrain_Accu: 42%  \tValid_Acc:26% \t Valid Loss: 1.590 \n",
            "Epoch: 106 \tTraining Loss:  1.385 \tTrain_Accu: 41%  \tValid_Acc:24% \t Valid Loss: 1.591 \n",
            "Epoch: 107 \tTraining Loss:  1.298 \tTrain_Accu: 43%  \tValid_Acc:21% \t Valid Loss: 1.722 \n",
            "Epoch: 108 \tTraining Loss:  1.367 \tTrain_Accu: 42%  \tValid_Acc:23% \t Valid Loss: 1.622 \n",
            "Epoch: 109 \tTraining Loss:  1.306 \tTrain_Accu: 41%  \tValid_Acc:27% \t Valid Loss: 1.591 \n",
            "Epoch: 110 \tTraining Loss:  1.273 \tTrain_Accu: 44%  \tValid_Acc:23% \t Valid Loss: 1.576 \n",
            "Epoch: 111 \tTraining Loss:  1.313 \tTrain_Accu: 39%  \tValid_Acc:23% \t Valid Loss: 1.660 \n",
            "Epoch: 112 \tTraining Loss:  1.300 \tTrain_Accu: 41%  \tValid_Acc:20% \t Valid Loss: 1.655 \n",
            "Epoch: 113 \tTraining Loss:  1.306 \tTrain_Accu: 44%  \tValid_Acc:24% \t Valid Loss: 1.600 \n",
            "Epoch: 114 \tTraining Loss:  1.370 \tTrain_Accu: 38%  \tValid_Acc:24% \t Valid Loss: 1.651 \n",
            "Epoch: 115 \tTraining Loss:  1.323 \tTrain_Accu: 42%  \tValid_Acc:23% \t Valid Loss: 1.647 \n",
            "Epoch: 116 \tTraining Loss:  1.367 \tTrain_Accu: 38%  \tValid_Acc:21% \t Valid Loss: 1.589 \n",
            "Epoch: 117 \tTraining Loss:  1.347 \tTrain_Accu: 42%  \tValid_Acc:31% \t Valid Loss: 1.570 \n",
            "Epoch: 118 \tTraining Loss:  1.314 \tTrain_Accu: 39%  \tValid_Acc:26% \t Valid Loss: 1.603 \n",
            "Epoch: 119 \tTraining Loss:  1.286 \tTrain_Accu: 45%  \tValid_Acc:26% \t Valid Loss: 1.611 \n",
            "Epoch: 120 \tTraining Loss:  1.281 \tTrain_Accu: 44%  \tValid_Acc:27% \t Valid Loss: 1.701 \n",
            "Epoch: 121 \tTraining Loss:  1.304 \tTrain_Accu: 42%  \tValid_Acc:27% \t Valid Loss: 1.687 \n",
            "Epoch: 122 \tTraining Loss:  1.350 \tTrain_Accu: 41%  \tValid_Acc:24% \t Valid Loss: 1.852 \n",
            "Epoch: 123 \tTraining Loss:  1.288 \tTrain_Accu: 44%  \tValid_Acc:19% \t Valid Loss: 1.776 \n",
            "Epoch: 124 \tTraining Loss:  1.310 \tTrain_Accu: 42%  \tValid_Acc:29% \t Valid Loss: 1.625 \n",
            "Epoch: 125 \tTraining Loss:  1.294 \tTrain_Accu: 44%  \tValid_Acc:27% \t Valid Loss: 1.583 \n",
            "Epoch: 126 \tTraining Loss:  1.302 \tTrain_Accu: 42%  \tValid_Acc:27% \t Valid Loss: 1.566 \n",
            "Epoch: 127 \tTraining Loss:  1.281 \tTrain_Accu: 42%  \tValid_Acc:26% \t Valid Loss: 1.592 \n",
            "Epoch: 128 \tTraining Loss:  1.321 \tTrain_Accu: 41%  \tValid_Acc:27% \t Valid Loss: 1.664 \n",
            "Epoch: 129 \tTraining Loss:  1.300 \tTrain_Accu: 42%  \tValid_Acc:26% \t Valid Loss: 1.548 \n",
            "Epoch: 130 \tTraining Loss:  1.309 \tTrain_Accu: 41%  \tValid_Acc:29% \t Valid Loss: 1.563 \n",
            "Epoch: 131 \tTraining Loss:  1.281 \tTrain_Accu: 42%  \tValid_Acc:26% \t Valid Loss: 1.590 \n",
            "Epoch: 132 \tTraining Loss:  1.239 \tTrain_Accu: 48%  \tValid_Acc:24% \t Valid Loss: 1.686 \n",
            "Epoch: 133 \tTraining Loss:  1.240 \tTrain_Accu: 44%  \tValid_Acc:21% \t Valid Loss: 1.890 \n",
            "Epoch: 134 \tTraining Loss:  1.268 \tTrain_Accu: 42%  \tValid_Acc:21% \t Valid Loss: 1.660 \n",
            "Epoch: 135 \tTraining Loss:  1.263 \tTrain_Accu: 42%  \tValid_Acc:20% \t Valid Loss: 1.709 \n",
            "Epoch: 136 \tTraining Loss:  1.222 \tTrain_Accu: 47%  \tValid_Acc:23% \t Valid Loss: 1.875 \n",
            "Epoch: 137 \tTraining Loss:  1.234 \tTrain_Accu: 47%  \tValid_Acc:23% \t Valid Loss: 1.739 \n",
            "Epoch: 138 \tTraining Loss:  1.187 \tTrain_Accu: 46%  \tValid_Acc:29% \t Valid Loss: 1.592 \n",
            "Epoch: 139 \tTraining Loss:  1.232 \tTrain_Accu: 45%  \tValid_Acc:23% \t Valid Loss: 1.748 \n",
            "Epoch: 140 \tTraining Loss:  1.233 \tTrain_Accu: 47%  \tValid_Acc:29% \t Valid Loss: 1.692 \n",
            "Epoch: 141 \tTraining Loss:  1.272 \tTrain_Accu: 46%  \tValid_Acc:24% \t Valid Loss: 1.744 \n",
            "Epoch: 142 \tTraining Loss:  1.265 \tTrain_Accu: 44%  \tValid_Acc:30% \t Valid Loss: 1.742 \n",
            "Epoch: 143 \tTraining Loss:  1.262 \tTrain_Accu: 44%  \tValid_Acc:21% \t Valid Loss: 1.628 \n",
            "Epoch: 144 \tTraining Loss:  1.231 \tTrain_Accu: 45%  \tValid_Acc:23% \t Valid Loss: 1.704 \n",
            "Epoch: 145 \tTraining Loss:  1.205 \tTrain_Accu: 48%  \tValid_Acc:29% \t Valid Loss: 2.257 \n",
            "Epoch: 146 \tTraining Loss:  1.238 \tTrain_Accu: 44%  \tValid_Acc:24% \t Valid Loss: 1.851 \n",
            "Epoch: 147 \tTraining Loss:  1.262 \tTrain_Accu: 44%  \tValid_Acc:27% \t Valid Loss: 1.657 \n",
            "Epoch: 148 \tTraining Loss:  1.217 \tTrain_Accu: 45%  \tValid_Acc:26% \t Valid Loss: 1.629 \n",
            "Epoch: 149 \tTraining Loss:  1.240 \tTrain_Accu: 46%  \tValid_Acc:20% \t Valid Loss: 1.814 \n",
            "Epoch: 150 \tTraining Loss:  1.206 \tTrain_Accu: 45%  \tValid_Acc:26% \t Valid Loss: 1.700 \n",
            "Epoch: 151 \tTraining Loss:  1.259 \tTrain_Accu: 44%  \tValid_Acc:27% \t Valid Loss: 1.672 \n",
            "Epoch: 152 \tTraining Loss:  1.240 \tTrain_Accu: 44%  \tValid_Acc:30% \t Valid Loss: 1.742 \n",
            "Epoch: 153 \tTraining Loss:  1.224 \tTrain_Accu: 45%  \tValid_Acc:24% \t Valid Loss: 1.697 \n",
            "Epoch: 154 \tTraining Loss:  1.203 \tTrain_Accu: 44%  \tValid_Acc:29% \t Valid Loss: 1.611 \n",
            "Epoch: 155 \tTraining Loss:  1.214 \tTrain_Accu: 46%  \tValid_Acc:20% \t Valid Loss: 1.745 \n",
            "Epoch: 156 \tTraining Loss:  1.246 \tTrain_Accu: 44%  \tValid_Acc:29% \t Valid Loss: 1.569 \n",
            "Epoch: 157 \tTraining Loss:  1.221 \tTrain_Accu: 49%  \tValid_Acc:23% \t Valid Loss: 1.880 \n",
            "Epoch: 158 \tTraining Loss:  1.206 \tTrain_Accu: 47%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 159 \tTraining Loss:  1.260 \tTrain_Accu: 47%  \tValid_Acc:21% \t Valid Loss: 2.079 \n",
            "Epoch: 160 \tTraining Loss:  1.212 \tTrain_Accu: 45%  \tValid_Acc:26% \t Valid Loss: 1.711 \n",
            "Epoch: 161 \tTraining Loss:  1.194 \tTrain_Accu: 47%  \tValid_Acc:24% \t Valid Loss: 1.736 \n",
            "Epoch: 162 \tTraining Loss:  1.199 \tTrain_Accu: 47%  \tValid_Acc:27% \t Valid Loss: 1.671 \n",
            "Epoch: 163 \tTraining Loss:  1.180 \tTrain_Accu: 50%  \tValid_Acc:21% \t Valid Loss: 2.221 \n",
            "Epoch: 164 \tTraining Loss:  1.151 \tTrain_Accu: 47%  \tValid_Acc:26% \t Valid Loss: 1.643 \n",
            "Epoch: 165 \tTraining Loss:  1.217 \tTrain_Accu: 46%  \tValid_Acc:24% \t Valid Loss: 1.686 \n",
            "Epoch: 166 \tTraining Loss:  1.187 \tTrain_Accu: 47%  \tValid_Acc:30% \t Valid Loss: 1.646 \n",
            "Epoch: 167 \tTraining Loss:  1.183 \tTrain_Accu: 45%  \tValid_Acc:21% \t Valid Loss: 1.684 \n",
            "Epoch: 168 \tTraining Loss:  1.182 \tTrain_Accu: 49%  \tValid_Acc:21% \t Valid Loss: 2.149 \n",
            "Epoch: 169 \tTraining Loss:  1.186 \tTrain_Accu: 48%  \tValid_Acc:23% \t Valid Loss: 2.002 \n",
            "Epoch: 170 \tTraining Loss:  1.198 \tTrain_Accu: 44%  \tValid_Acc:21% \t Valid Loss: 1.713 \n",
            "Epoch: 171 \tTraining Loss:  1.207 \tTrain_Accu: 46%  \tValid_Acc:23% \t Valid Loss: 1.572 \n",
            "Epoch: 172 \tTraining Loss:  1.168 \tTrain_Accu: 50%  \tValid_Acc:21% \t Valid Loss: 1.615 \n",
            "Epoch: 173 \tTraining Loss:  1.181 \tTrain_Accu: 47%  \tValid_Acc:24% \t Valid Loss: 1.631 \n",
            "Epoch: 174 \tTraining Loss:  1.198 \tTrain_Accu: 47%  \tValid_Acc:23% \t Valid Loss: 1.841 \n",
            "Epoch: 175 \tTraining Loss:  1.151 \tTrain_Accu: 47%  \tValid_Acc:23% \t Valid Loss: 1.749 \n",
            "Epoch: 176 \tTraining Loss:  1.171 \tTrain_Accu: 46%  \tValid_Acc:34% \t Valid Loss: 1.690 \n",
            "Epoch: 177 \tTraining Loss:  1.189 \tTrain_Accu: 45%  \tValid_Acc:23% \t Valid Loss: 1.758 \n",
            "Epoch: 178 \tTraining Loss:  1.129 \tTrain_Accu: 52%  \tValid_Acc:30% \t Valid Loss: 1.972 \n",
            "Epoch: 179 \tTraining Loss:  1.149 \tTrain_Accu: 50%  \tValid_Acc:19% \t Valid Loss: 1.986 \n",
            "Epoch: 180 \tTraining Loss:  1.173 \tTrain_Accu: 47%  \tValid_Acc:30% \t Valid Loss: 1.922 \n",
            "Epoch: 181 \tTraining Loss:  1.175 \tTrain_Accu: 49%  \tValid_Acc:24% \t Valid Loss: 2.097 \n",
            "Epoch: 182 \tTraining Loss:  1.161 \tTrain_Accu: 47%  \tValid_Acc:21% \t Valid Loss: 2.288 \n",
            "Epoch: 183 \tTraining Loss:  1.165 \tTrain_Accu: 46%  \tValid_Acc:27% \t Valid Loss: 1.623 \n",
            "Epoch: 184 \tTraining Loss:  1.147 \tTrain_Accu: 51%  \tValid_Acc:23% \t Valid Loss: 1.973 \n",
            "Epoch: 185 \tTraining Loss:  1.188 \tTrain_Accu: 50%  \tValid_Acc:17% \t Valid Loss: 1.937 \n",
            "Epoch: 186 \tTraining Loss:  1.169 \tTrain_Accu: 46%  \tValid_Acc:24% \t Valid Loss: 2.195 \n",
            "Epoch: 187 \tTraining Loss:  1.210 \tTrain_Accu: 46%  \tValid_Acc:27% \t Valid Loss: 1.548 \n",
            "Epoch: 188 \tTraining Loss:  1.184 \tTrain_Accu: 46%  \tValid_Acc:23% \t Valid Loss: 2.077 \n",
            "Epoch: 189 \tTraining Loss:  1.127 \tTrain_Accu: 49%  \tValid_Acc:27% \t Valid Loss: 1.786 \n",
            "Epoch: 190 \tTraining Loss:  1.155 \tTrain_Accu: 47%  \tValid_Acc:24% \t Valid Loss: 1.880 \n",
            "Epoch: 191 \tTraining Loss:  1.120 \tTrain_Accu: 51%  \tValid_Acc:21% \t Valid Loss: 1.947 \n",
            "Epoch: 192 \tTraining Loss:  1.170 \tTrain_Accu: 49%  \tValid_Acc:16% \t Valid Loss: 1.946 \n",
            "Epoch: 193 \tTraining Loss:  1.144 \tTrain_Accu: 49%  \tValid_Acc:26% \t Valid Loss: 1.869 \n",
            "Epoch: 194 \tTraining Loss:  1.196 \tTrain_Accu: 45%  \tValid_Acc:21% \t Valid Loss: 1.866 \n",
            "Epoch: 195 \tTraining Loss:  1.202 \tTrain_Accu: 48%  \tValid_Acc:26% \t Valid Loss: 1.764 \n",
            "Epoch: 196 \tTraining Loss:  1.138 \tTrain_Accu: 47%  \tValid_Acc:26% \t Valid Loss: 2.042 \n",
            "Epoch: 197 \tTraining Loss:  1.164 \tTrain_Accu: 47%  \tValid_Acc:26% \t Valid Loss: 1.829 \n",
            "Epoch: 198 \tTraining Loss:  1.140 \tTrain_Accu: 48%  \tValid_Acc:23% \t Valid Loss: 1.779 \n",
            "Epoch: 199 \tTraining Loss:  1.128 \tTrain_Accu: 49%  \tValid_Acc:21% \t Valid Loss: 1.661 \n",
            "Epoch: 200 \tTraining Loss:  1.132 \tTrain_Accu: 49%  \tValid_Acc:24% \t Valid Loss: 1.727 \n",
            "Epoch: 201 \tTraining Loss:  1.141 \tTrain_Accu: 52%  \tValid_Acc:27% \t Valid Loss: 1.904 \n",
            "Epoch: 202 \tTraining Loss:  1.170 \tTrain_Accu: 46%  \tValid_Acc:27% \t Valid Loss: 1.870 \n",
            "Epoch: 203 \tTraining Loss:  1.118 \tTrain_Accu: 50%  \tValid_Acc:17% \t Valid Loss: 2.355 \n",
            "Epoch: 204 \tTraining Loss:  1.113 \tTrain_Accu: 51%  \tValid_Acc:21% \t Valid Loss: 2.205 \n",
            "Epoch: 205 \tTraining Loss:  1.119 \tTrain_Accu: 48%  \tValid_Acc:20% \t Valid Loss: 2.053 \n",
            "Epoch: 206 \tTraining Loss:  1.212 \tTrain_Accu: 46%  \tValid_Acc:29% \t Valid Loss: 1.653 \n",
            "Epoch: 207 \tTraining Loss:  1.183 \tTrain_Accu: 46%  \tValid_Acc:21% \t Valid Loss: 2.265 \n",
            "Epoch: 208 \tTraining Loss:  1.125 \tTrain_Accu: 50%  \tValid_Acc:23% \t Valid Loss: 1.804 \n",
            "Epoch: 209 \tTraining Loss:  1.133 \tTrain_Accu: 47%  \tValid_Acc:23% \t Valid Loss: 2.624 \n",
            "Epoch: 210 \tTraining Loss:  1.098 \tTrain_Accu: 51%  \tValid_Acc:19% \t Valid Loss: 2.971 \n",
            "Epoch: 211 \tTraining Loss:  1.108 \tTrain_Accu: 49%  \tValid_Acc:23% \t Valid Loss: 2.017 \n",
            "Epoch: 212 \tTraining Loss:  1.140 \tTrain_Accu: 50%  \tValid_Acc:23% \t Valid Loss: 2.025 \n",
            "Epoch: 213 \tTraining Loss:  1.123 \tTrain_Accu: 54%  \tValid_Acc:21% \t Valid Loss: 2.227 \n",
            "Epoch: 214 \tTraining Loss:  1.068 \tTrain_Accu: 53%  \tValid_Acc:20% \t Valid Loss: 1.931 \n",
            "Epoch: 215 \tTraining Loss:  1.101 \tTrain_Accu: 51%  \tValid_Acc:21% \t Valid Loss: 2.036 \n",
            "Epoch: 216 \tTraining Loss:  1.135 \tTrain_Accu: 46%  \tValid_Acc:24% \t Valid Loss: 1.831 \n",
            "Epoch: 217 \tTraining Loss:  1.114 \tTrain_Accu: 54%  \tValid_Acc:21% \t Valid Loss: 2.551 \n",
            "Epoch: 218 \tTraining Loss:  1.071 \tTrain_Accu: 50%  \tValid_Acc:23% \t Valid Loss: 2.307 \n",
            "Epoch: 219 \tTraining Loss:  1.103 \tTrain_Accu: 52%  \tValid_Acc:20% \t Valid Loss: 2.045 \n",
            "Epoch: 220 \tTraining Loss:  1.042 \tTrain_Accu: 53%  \tValid_Acc:23% \t Valid Loss: 2.117 \n",
            "Epoch: 221 \tTraining Loss:  1.075 \tTrain_Accu: 52%  \tValid_Acc:24% \t Valid Loss: 2.223 \n",
            "Epoch: 222 \tTraining Loss:  1.065 \tTrain_Accu: 51%  \tValid_Acc:24% \t Valid Loss: 2.152 \n",
            "Epoch: 223 \tTraining Loss:  1.086 \tTrain_Accu: 51%  \tValid_Acc:21% \t Valid Loss: 2.456 \n",
            "Epoch: 224 \tTraining Loss:  1.104 \tTrain_Accu: 52%  \tValid_Acc:24% \t Valid Loss: 1.920 \n",
            "Epoch: 225 \tTraining Loss:  1.133 \tTrain_Accu: 52%  \tValid_Acc:27% \t Valid Loss: 1.897 \n",
            "Epoch: 226 \tTraining Loss:  1.076 \tTrain_Accu: 52%  \tValid_Acc:26% \t Valid Loss: 1.736 \n",
            "Epoch: 227 \tTraining Loss:  1.197 \tTrain_Accu: 45%  \tValid_Acc:20% \t Valid Loss: 2.020 \n",
            "Epoch: 228 \tTraining Loss:  1.065 \tTrain_Accu: 50%  \tValid_Acc:19% \t Valid Loss: 2.480 \n",
            "Epoch: 229 \tTraining Loss:  1.090 \tTrain_Accu: 51%  \tValid_Acc:24% \t Valid Loss: 2.031 \n",
            "Epoch: 230 \tTraining Loss:  1.135 \tTrain_Accu: 49%  \tValid_Acc:21% \t Valid Loss: 2.385 \n",
            "Epoch: 231 \tTraining Loss:  1.143 \tTrain_Accu: 49%  \tValid_Acc:24% \t Valid Loss: 1.879 \n",
            "Epoch: 232 \tTraining Loss:  1.075 \tTrain_Accu: 56%  \tValid_Acc:21% \t Valid Loss: 2.570 \n",
            "Epoch: 233 \tTraining Loss:  1.045 \tTrain_Accu: 53%  \tValid_Acc:27% \t Valid Loss: 1.939 \n",
            "Epoch: 234 \tTraining Loss:  1.115 \tTrain_Accu: 50%  \tValid_Acc:29% \t Valid Loss: 2.294 \n",
            "Epoch: 235 \tTraining Loss:  1.094 \tTrain_Accu: 53%  \tValid_Acc:23% \t Valid Loss: 2.356 \n",
            "Epoch: 236 \tTraining Loss:  1.068 \tTrain_Accu: 50%  \tValid_Acc:21% \t Valid Loss: 2.324 \n",
            "Epoch: 237 \tTraining Loss:  1.139 \tTrain_Accu: 49%  \tValid_Acc:19% \t Valid Loss: 1.940 \n",
            "Epoch: 238 \tTraining Loss:  1.097 \tTrain_Accu: 54%  \tValid_Acc:23% \t Valid Loss: 2.159 \n",
            "Epoch: 239 \tTraining Loss:  1.110 \tTrain_Accu: 51%  \tValid_Acc:24% \t Valid Loss: 2.066 \n",
            "Epoch: 240 \tTraining Loss:  1.056 \tTrain_Accu: 52%  \tValid_Acc:24% \t Valid Loss: 1.968 \n",
            "Epoch: 241 \tTraining Loss:  1.095 \tTrain_Accu: 51%  \tValid_Acc:23% \t Valid Loss: 2.791 \n",
            "Epoch: 242 \tTraining Loss:  1.112 \tTrain_Accu: 52%  \tValid_Acc:20% \t Valid Loss: 2.085 \n",
            "Epoch: 243 \tTraining Loss:  1.110 \tTrain_Accu: 50%  \tValid_Acc:23% \t Valid Loss: 2.110 \n",
            "Epoch: 244 \tTraining Loss:  1.020 \tTrain_Accu: 58%  \tValid_Acc:23% \t Valid Loss: 2.157 \n",
            "Epoch: 245 \tTraining Loss:  1.114 \tTrain_Accu: 47%  \tValid_Acc:27% \t Valid Loss: 1.847 \n",
            "Epoch: 246 \tTraining Loss:  1.149 \tTrain_Accu: 48%  \tValid_Acc:23% \t Valid Loss: 1.871 \n",
            "Epoch: 247 \tTraining Loss:  1.036 \tTrain_Accu: 53%  \tValid_Acc:23% \t Valid Loss: 2.009 \n",
            "Epoch: 248 \tTraining Loss:  1.081 \tTrain_Accu: 49%  \tValid_Acc:26% \t Valid Loss: 1.861 \n",
            "Epoch: 249 \tTraining Loss:  1.112 \tTrain_Accu: 50%  \tValid_Acc:27% \t Valid Loss: 2.083 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-26 20:34:49,970]\u001b[0m Trial 9 finished with value: 22.9 and parameters: {'Batch_size': 1, 'lr': 0.0001, 'optimizer': <class 'torch.optim.adam.Adam'>, 'dropout': 0.9}. Best is trial 5 with value: 30.0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  1.066 \tTrain_Accu: 55%  \tValid_Acc:23% \t Valid Loss: 2.003 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/My Drive/DL_project/optimise_valid_NNI_temp.torch']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j5KFNEUo_tz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "outputId": "9076784c-5436-4b2f-b4b8-b3c102b27336"
      },
      "source": [
        "# Data Frame which display the number of trials excluding below variables columns\n",
        "df_NNI = study.trials_dataframe().drop(['duration','state','datetime_start','datetime_complete'], axis=1)\n",
        "df_NNI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>params_Batch_size</th>\n",
              "      <th>params_dropout</th>\n",
              "      <th>params_lr</th>\n",
              "      <th>params_optimizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>17.1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>18.6</td>\n",
              "      <td>9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>17.1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>22.9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>17.1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>30.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>25.7</td>\n",
              "      <td>4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>17.1</td>\n",
              "      <td>9</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>25.7</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>22.9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   number  value  params_Batch_size  params_dropout  params_lr  \\\n",
              "0       0   17.1                  5             0.7     0.1000   \n",
              "1       1   18.6                  9             0.5     0.0100   \n",
              "2       2   17.1                  7             0.5     0.1000   \n",
              "3       3   22.9                  1             0.5     0.0010   \n",
              "4       4   17.1                  5             0.7     0.1000   \n",
              "5       5   30.0                  4             0.9     0.0010   \n",
              "6       6   25.7                  4             0.5     0.1000   \n",
              "7       7   17.1                  9             0.7     0.0100   \n",
              "8       8   25.7                  5             0.5     0.0001   \n",
              "9       9   22.9                  1             0.9     0.0001   \n",
              "\n",
              "                        params_optimizer  \n",
              "0  <class 'torch.optim.rmsprop.RMSprop'>  \n",
              "1          <class 'torch.optim.sgd.SGD'>  \n",
              "2        <class 'torch.optim.adam.Adam'>  \n",
              "3        <class 'torch.optim.adam.Adam'>  \n",
              "4        <class 'torch.optim.adam.Adam'>  \n",
              "5  <class 'torch.optim.rmsprop.RMSprop'>  \n",
              "6          <class 'torch.optim.sgd.SGD'>  \n",
              "7        <class 'torch.optim.adam.Adam'>  \n",
              "8        <class 'torch.optim.adam.Adam'>  \n",
              "9        <class 'torch.optim.adam.Adam'>  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlvLdhnvyMmG"
      },
      "source": [
        "We are interested in knowing the training accuracy along with the validation accuracy on each trial. So, the below table is created by looking at the output of the objective function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "CsXYdCgmo_t1",
        "outputId": "8a0468ff-5a6b-417d-fd5a-489f2331f034"
      },
      "source": [
        "data = {'Batch-size':[ 5, 9, 7, 1, 5, 4, 4, 9, 5, 1], 'Learning_rate':[0.1, 0.01, 0.1, 0.001, 0.1, 0.001, 0.1, 0.01, 0.0001, 0.0001], 'Optimization':['RMSprop', 'SGD', 'Adam', 'Adam', 'Adam', 'RMSprop', 'SGD', 'Adam', 'Adam', 'Adam'], 'Dropout_rate':[0.7, 0.5, 0.5, 0.5, 0.7, 0.9, 0.5, 0.7, 0.5, 0.9], 'Training_Acc':['18%', '98%', '20%', '100%', '21%', '62%', '19%', '21%', '98%', '55%'], 'Validation_Acc':['17%', '19%', '17%', '23%', '17%', '30%', '26%', '17%', '26%', '23%']  }\n",
        "Table = pd.DataFrame(data)\n",
        "Table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Batch-size</th>\n",
              "      <th>Learning_rate</th>\n",
              "      <th>Optimization</th>\n",
              "      <th>Dropout_rate</th>\n",
              "      <th>Training_Acc</th>\n",
              "      <th>Validation_Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.7</td>\n",
              "      <td>18%</td>\n",
              "      <td>17%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.5</td>\n",
              "      <td>98%</td>\n",
              "      <td>19%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>20%</td>\n",
              "      <td>17%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100%</td>\n",
              "      <td>23%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.7</td>\n",
              "      <td>21%</td>\n",
              "      <td>17%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.9</td>\n",
              "      <td>62%</td>\n",
              "      <td>30%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.5</td>\n",
              "      <td>19%</td>\n",
              "      <td>26%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.7</td>\n",
              "      <td>21%</td>\n",
              "      <td>17%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.5</td>\n",
              "      <td>98%</td>\n",
              "      <td>26%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.9</td>\n",
              "      <td>55%</td>\n",
              "      <td>23%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Batch-size  Learning_rate Optimization  Dropout_rate Training_Acc  \\\n",
              "0           5         0.1000      RMSprop           0.7          18%   \n",
              "1           9         0.0100          SGD           0.5          98%   \n",
              "2           7         0.1000         Adam           0.5          20%   \n",
              "3           1         0.0010         Adam           0.5         100%   \n",
              "4           5         0.1000         Adam           0.7          21%   \n",
              "5           4         0.0010      RMSprop           0.9          62%   \n",
              "6           4         0.1000          SGD           0.5          19%   \n",
              "7           9         0.0100         Adam           0.7          21%   \n",
              "8           5         0.0001         Adam           0.5          98%   \n",
              "9           1         0.0001         Adam           0.9          55%   \n",
              "\n",
              "  Validation_Acc  \n",
              "0            17%  \n",
              "1            19%  \n",
              "2            17%  \n",
              "3            23%  \n",
              "4            17%  \n",
              "5            30%  \n",
              "6            26%  \n",
              "7            17%  \n",
              "8            26%  \n",
              "9            23%  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjJPR0xDu5EV"
      },
      "source": [
        "The model was rerun with batch size 1, lr = [0.01, 0.001, 0.0001] and dropout rate = [0.7, 0.8,0.9 ] \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze6TstUvv2sy"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_NNI_1(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          #'train_batch_size' : 5,\n",
        "          'Batch_size' : 1,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "          'save_model' : True,\n",
        "          'lr'       :  trial.suggest_categorical('lr', [0.01, 0.001, 0.0001]),          \n",
        "          'optimizer': optim.RMSprop,\n",
        "          'dropout'       : trial.suggest_categorical('dropout', [0.7, 0.8,0.9 ]),\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_NNI_temp(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "\n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  \n",
        "  \n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}% \\t Valid Loss:{: .3f} '.format(epoch, train_loss, train_acc, valid_acc, valid_loss))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"./check_valid_NNI_RMSprops.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_3AGw8QEye-",
        "outputId": "87e00302-63d5-4f47-fb02-572fc2eef271"
      },
      "source": [
        "import joblib\n",
        "\n",
        "study.optimize(train_NNI_1, n_trials=9)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"./optuna_valid_NNI_drop.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.710 \tTrain_Accu: 18%  \tValid_Acc:10% \t Valid Loss: 1.627 \n",
            "Epoch: 2 \tTraining Loss:  1.609 \tTrain_Accu: 20%  \tValid_Acc:10% \t Valid Loss: 1.633 \n",
            "Epoch: 3 \tTraining Loss:  1.604 \tTrain_Accu: 21%  \tValid_Acc:10% \t Valid Loss: 1.628 \n",
            "Epoch: 4 \tTraining Loss:  1.604 \tTrain_Accu: 22%  \tValid_Acc:9% \t Valid Loss: 1.644 \n",
            "Epoch: 5 \tTraining Loss:  1.601 \tTrain_Accu: 24%  \tValid_Acc:19% \t Valid Loss: 1.614 \n",
            "Epoch: 6 \tTraining Loss:  1.602 \tTrain_Accu: 22%  \tValid_Acc:19% \t Valid Loss: 1.628 \n",
            "Epoch: 7 \tTraining Loss:  1.591 \tTrain_Accu: 24%  \tValid_Acc:11% \t Valid Loss: 1.645 \n",
            "Epoch: 8 \tTraining Loss:  1.557 \tTrain_Accu: 27%  \tValid_Acc:16% \t Valid Loss: 1.614 \n",
            "Epoch: 9 \tTraining Loss:  1.582 \tTrain_Accu: 25%  \tValid_Acc:9% \t Valid Loss: 1.633 \n",
            "Epoch: 10 \tTraining Loss:  1.539 \tTrain_Accu: 31%  \tValid_Acc:14% \t Valid Loss: 1.658 \n",
            "Epoch: 11 \tTraining Loss:  1.537 \tTrain_Accu: 24%  \tValid_Acc:14% \t Valid Loss: 1.626 \n",
            "Epoch: 12 \tTraining Loss:  1.556 \tTrain_Accu: 28%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 13 \tTraining Loss:  1.567 \tTrain_Accu: 32%  \tValid_Acc:23% \t Valid Loss: 1.602 \n",
            "Epoch: 14 \tTraining Loss:  1.555 \tTrain_Accu: 31%  \tValid_Acc:20% \t Valid Loss: 1.640 \n",
            "Epoch: 15 \tTraining Loss:  1.507 \tTrain_Accu: 30%  \tValid_Acc:11% \t Valid Loss: 1.652 \n",
            "Epoch: 16 \tTraining Loss:  1.544 \tTrain_Accu: 29%  \tValid_Acc:17% \t Valid Loss: 1.614 \n",
            "Epoch: 17 \tTraining Loss:  1.508 \tTrain_Accu: 32%  \tValid_Acc:19% \t Valid Loss: 1.679 \n",
            "Epoch: 18 \tTraining Loss:  1.535 \tTrain_Accu: 29%  \tValid_Acc:20% \t Valid Loss: 1.659 \n",
            "Epoch: 19 \tTraining Loss:  1.499 \tTrain_Accu: 33%  \tValid_Acc:9% \t Valid Loss: 1.674 \n",
            "Epoch: 20 \tTraining Loss:  1.466 \tTrain_Accu: 32%  \tValid_Acc:24% \t Valid Loss: 1.607 \n",
            "Epoch: 21 \tTraining Loss:  1.506 \tTrain_Accu: 32%  \tValid_Acc:21% \t Valid Loss: 1.655 \n",
            "Epoch: 22 \tTraining Loss:  1.492 \tTrain_Accu: 32%  \tValid_Acc:21% \t Valid Loss: 1.653 \n",
            "Epoch: 23 \tTraining Loss:  1.499 \tTrain_Accu: 27%  \tValid_Acc:14% \t Valid Loss: 1.625 \n",
            "Epoch: 24 \tTraining Loss:  1.471 \tTrain_Accu: 32%  \tValid_Acc:16% \t Valid Loss: 1.665 \n",
            "Epoch: 25 \tTraining Loss:  1.436 \tTrain_Accu: 36%  \tValid_Acc:27% \t Valid Loss: 1.647 \n",
            "Epoch: 26 \tTraining Loss:  1.398 \tTrain_Accu: 39%  \tValid_Acc:17% \t Valid Loss: 1.720 \n",
            "Epoch: 27 \tTraining Loss:  1.407 \tTrain_Accu: 38%  \tValid_Acc:26% \t Valid Loss: 1.525 \n",
            "Epoch: 28 \tTraining Loss:  1.404 \tTrain_Accu: 38%  \tValid_Acc:13% \t Valid Loss: 1.681 \n",
            "Epoch: 29 \tTraining Loss:  1.402 \tTrain_Accu: 38%  \tValid_Acc:23% \t Valid Loss: 1.593 \n",
            "Epoch: 30 \tTraining Loss:  1.410 \tTrain_Accu: 35%  \tValid_Acc:19% \t Valid Loss: 1.700 \n",
            "Epoch: 31 \tTraining Loss:  1.415 \tTrain_Accu: 35%  \tValid_Acc:31% \t Valid Loss: 1.691 \n",
            "Epoch: 32 \tTraining Loss:  1.332 \tTrain_Accu: 42%  \tValid_Acc:20% \t Valid Loss: 1.657 \n",
            "Epoch: 33 \tTraining Loss:  1.357 \tTrain_Accu: 42%  \tValid_Acc:26% \t Valid Loss: 1.683 \n",
            "Epoch: 34 \tTraining Loss:  1.335 \tTrain_Accu: 38%  \tValid_Acc:19% \t Valid Loss: 1.644 \n",
            "Epoch: 35 \tTraining Loss:  1.349 \tTrain_Accu: 42%  \tValid_Acc:27% \t Valid Loss: 1.583 \n",
            "Epoch: 36 \tTraining Loss:  1.368 \tTrain_Accu: 39%  \tValid_Acc:31% \t Valid Loss: 1.531 \n",
            "Epoch: 37 \tTraining Loss:  1.328 \tTrain_Accu: 43%  \tValid_Acc:21% \t Valid Loss: 1.607 \n",
            "Epoch: 38 \tTraining Loss:  1.300 \tTrain_Accu: 41%  \tValid_Acc:21% \t Valid Loss: 1.693 \n",
            "Epoch: 39 \tTraining Loss:  1.263 \tTrain_Accu: 42%  \tValid_Acc:13% \t Valid Loss: 1.751 \n",
            "Epoch: 40 \tTraining Loss:  1.302 \tTrain_Accu: 39%  \tValid_Acc:19% \t Valid Loss: 1.673 \n",
            "Epoch: 41 \tTraining Loss:  1.294 \tTrain_Accu: 43%  \tValid_Acc:23% \t Valid Loss: 1.542 \n",
            "Epoch: 42 \tTraining Loss:  1.265 \tTrain_Accu: 45%  \tValid_Acc:24% \t Valid Loss: 1.653 \n",
            "Epoch: 43 \tTraining Loss:  1.241 \tTrain_Accu: 45%  \tValid_Acc:36% \t Valid Loss: 1.639 \n",
            "Epoch: 44 \tTraining Loss:  1.278 \tTrain_Accu: 42%  \tValid_Acc:21% \t Valid Loss: 1.636 \n",
            "Epoch: 45 \tTraining Loss:  1.244 \tTrain_Accu: 43%  \tValid_Acc:13% \t Valid Loss: 1.793 \n",
            "Epoch: 46 \tTraining Loss:  1.229 \tTrain_Accu: 46%  \tValid_Acc:27% \t Valid Loss: 1.594 \n",
            "Epoch: 47 \tTraining Loss:  1.250 \tTrain_Accu: 46%  \tValid_Acc:27% \t Valid Loss: 1.743 \n",
            "Epoch: 48 \tTraining Loss:  1.230 \tTrain_Accu: 44%  \tValid_Acc:21% \t Valid Loss: 1.794 \n",
            "Epoch: 49 \tTraining Loss:  1.180 \tTrain_Accu: 47%  \tValid_Acc:29% \t Valid Loss: 1.637 \n",
            "Epoch: 50 \tTraining Loss:  1.152 \tTrain_Accu: 47%  \tValid_Acc:20% \t Valid Loss: 1.616 \n",
            "Epoch: 51 \tTraining Loss:  1.133 \tTrain_Accu: 53%  \tValid_Acc:19% \t Valid Loss: 1.739 \n",
            "Epoch: 52 \tTraining Loss:  1.222 \tTrain_Accu: 42%  \tValid_Acc:29% \t Valid Loss: 1.654 \n",
            "Epoch: 53 \tTraining Loss:  1.225 \tTrain_Accu: 47%  \tValid_Acc:27% \t Valid Loss: 1.559 \n",
            "Epoch: 54 \tTraining Loss:  1.068 \tTrain_Accu: 54%  \tValid_Acc:21% \t Valid Loss: 1.662 \n",
            "Epoch: 55 \tTraining Loss:  1.140 \tTrain_Accu: 47%  \tValid_Acc:23% \t Valid Loss: 1.911 \n",
            "Epoch: 56 \tTraining Loss:  1.122 \tTrain_Accu: 52%  \tValid_Acc:26% \t Valid Loss: 1.870 \n",
            "Epoch: 57 \tTraining Loss:  1.128 \tTrain_Accu: 46%  \tValid_Acc:16% \t Valid Loss: 1.881 \n",
            "Epoch: 58 \tTraining Loss:  1.111 \tTrain_Accu: 50%  \tValid_Acc:24% \t Valid Loss: 1.699 \n",
            "Epoch: 59 \tTraining Loss:  1.055 \tTrain_Accu: 51%  \tValid_Acc:30% \t Valid Loss: 1.833 \n",
            "Epoch: 60 \tTraining Loss:  1.122 \tTrain_Accu: 51%  \tValid_Acc:33% \t Valid Loss: 1.704 \n",
            "Epoch: 61 \tTraining Loss:  1.061 \tTrain_Accu: 51%  \tValid_Acc:20% \t Valid Loss: 1.884 \n",
            "Epoch: 62 \tTraining Loss:  1.088 \tTrain_Accu: 52%  \tValid_Acc:24% \t Valid Loss: 1.733 \n",
            "Epoch: 63 \tTraining Loss:  1.035 \tTrain_Accu: 48%  \tValid_Acc:24% \t Valid Loss: 1.817 \n",
            "Epoch: 64 \tTraining Loss:  1.027 \tTrain_Accu: 54%  \tValid_Acc:30% \t Valid Loss: 1.792 \n",
            "Epoch: 65 \tTraining Loss:  1.080 \tTrain_Accu: 52%  \tValid_Acc:27% \t Valid Loss: 2.011 \n",
            "Epoch: 66 \tTraining Loss:  0.986 \tTrain_Accu: 57%  \tValid_Acc:24% \t Valid Loss: 1.981 \n",
            "Epoch: 67 \tTraining Loss:  1.071 \tTrain_Accu: 52%  \tValid_Acc:19% \t Valid Loss: 1.696 \n",
            "Epoch: 68 \tTraining Loss:  1.087 \tTrain_Accu: 50%  \tValid_Acc:23% \t Valid Loss: 1.689 \n",
            "Epoch: 69 \tTraining Loss:  1.048 \tTrain_Accu: 55%  \tValid_Acc:17% \t Valid Loss: 1.878 \n",
            "Epoch: 70 \tTraining Loss:  1.004 \tTrain_Accu: 56%  \tValid_Acc:23% \t Valid Loss: 1.853 \n",
            "Epoch: 71 \tTraining Loss:  0.964 \tTrain_Accu: 53%  \tValid_Acc:20% \t Valid Loss: 2.086 \n",
            "Epoch: 72 \tTraining Loss:  1.030 \tTrain_Accu: 54%  \tValid_Acc:20% \t Valid Loss: 1.809 \n",
            "Epoch: 73 \tTraining Loss:  0.978 \tTrain_Accu: 57%  \tValid_Acc:24% \t Valid Loss: 1.955 \n",
            "Epoch: 74 \tTraining Loss:  0.948 \tTrain_Accu: 59%  \tValid_Acc:24% \t Valid Loss: 2.321 \n",
            "Epoch: 75 \tTraining Loss:  0.996 \tTrain_Accu: 56%  \tValid_Acc:29% \t Valid Loss: 2.208 \n",
            "Epoch: 76 \tTraining Loss:  0.941 \tTrain_Accu: 59%  \tValid_Acc:14% \t Valid Loss: 2.114 \n",
            "Epoch: 77 \tTraining Loss:  0.954 \tTrain_Accu: 58%  \tValid_Acc:23% \t Valid Loss: 2.150 \n",
            "Epoch: 78 \tTraining Loss:  0.923 \tTrain_Accu: 58%  \tValid_Acc:27% \t Valid Loss: 1.718 \n",
            "Epoch: 79 \tTraining Loss:  0.959 \tTrain_Accu: 60%  \tValid_Acc:21% \t Valid Loss: 2.118 \n",
            "Epoch: 80 \tTraining Loss:  0.925 \tTrain_Accu: 60%  \tValid_Acc:29% \t Valid Loss: 1.748 \n",
            "Epoch: 81 \tTraining Loss:  0.934 \tTrain_Accu: 57%  \tValid_Acc:30% \t Valid Loss: 1.941 \n",
            "Epoch: 82 \tTraining Loss:  0.917 \tTrain_Accu: 61%  \tValid_Acc:16% \t Valid Loss: 2.059 \n",
            "Epoch: 83 \tTraining Loss:  0.952 \tTrain_Accu: 60%  \tValid_Acc:31% \t Valid Loss: 1.956 \n",
            "Epoch: 84 \tTraining Loss:  0.955 \tTrain_Accu: 58%  \tValid_Acc:26% \t Valid Loss: 1.958 \n",
            "Epoch: 85 \tTraining Loss:  0.836 \tTrain_Accu: 62%  \tValid_Acc:21% \t Valid Loss: 2.237 \n",
            "Epoch: 86 \tTraining Loss:  0.944 \tTrain_Accu: 58%  \tValid_Acc:16% \t Valid Loss: 1.875 \n",
            "Epoch: 87 \tTraining Loss:  0.850 \tTrain_Accu: 65%  \tValid_Acc:21% \t Valid Loss: 2.027 \n",
            "Epoch: 88 \tTraining Loss:  0.854 \tTrain_Accu: 64%  \tValid_Acc:23% \t Valid Loss: 3.046 \n",
            "Epoch: 89 \tTraining Loss:  0.882 \tTrain_Accu: 61%  \tValid_Acc:29% \t Valid Loss: 2.072 \n",
            "Epoch: 90 \tTraining Loss:  0.896 \tTrain_Accu: 63%  \tValid_Acc:20% \t Valid Loss: 2.160 \n",
            "Epoch: 91 \tTraining Loss:  0.829 \tTrain_Accu: 64%  \tValid_Acc:23% \t Valid Loss: 2.214 \n",
            "Epoch: 92 \tTraining Loss:  0.851 \tTrain_Accu: 62%  \tValid_Acc:29% \t Valid Loss: 2.311 \n",
            "Epoch: 93 \tTraining Loss:  0.871 \tTrain_Accu: 64%  \tValid_Acc:26% \t Valid Loss: 2.667 \n",
            "Epoch: 94 \tTraining Loss:  0.909 \tTrain_Accu: 60%  \tValid_Acc:29% \t Valid Loss: 1.969 \n",
            "Epoch: 95 \tTraining Loss:  0.840 \tTrain_Accu: 62%  \tValid_Acc:23% \t Valid Loss: 2.021 \n",
            "Epoch: 96 \tTraining Loss:  0.895 \tTrain_Accu: 58%  \tValid_Acc:26% \t Valid Loss: 1.876 \n",
            "Epoch: 97 \tTraining Loss:  0.836 \tTrain_Accu: 62%  \tValid_Acc:20% \t Valid Loss: 1.925 \n",
            "Epoch: 98 \tTraining Loss:  0.852 \tTrain_Accu: 65%  \tValid_Acc:21% \t Valid Loss: 2.214 \n",
            "Epoch: 99 \tTraining Loss:  0.777 \tTrain_Accu: 69%  \tValid_Acc:21% \t Valid Loss: 2.604 \n",
            "Epoch: 100 \tTraining Loss:  0.854 \tTrain_Accu: 67%  \tValid_Acc:26% \t Valid Loss: 2.047 \n",
            "Epoch: 101 \tTraining Loss:  0.762 \tTrain_Accu: 67%  \tValid_Acc:30% \t Valid Loss: 1.998 \n",
            "Epoch: 102 \tTraining Loss:  0.831 \tTrain_Accu: 62%  \tValid_Acc:23% \t Valid Loss: 1.838 \n",
            "Epoch: 103 \tTraining Loss:  0.760 \tTrain_Accu: 65%  \tValid_Acc:23% \t Valid Loss: 2.935 \n",
            "Epoch: 104 \tTraining Loss:  0.777 \tTrain_Accu: 67%  \tValid_Acc:24% \t Valid Loss: 2.111 \n",
            "Epoch: 105 \tTraining Loss:  0.754 \tTrain_Accu: 67%  \tValid_Acc:21% \t Valid Loss: 1.922 \n",
            "Epoch: 106 \tTraining Loss:  0.745 \tTrain_Accu: 70%  \tValid_Acc:34% \t Valid Loss: 2.385 \n",
            "Epoch: 107 \tTraining Loss:  0.829 \tTrain_Accu: 65%  \tValid_Acc:14% \t Valid Loss: 2.302 \n",
            "Epoch: 108 \tTraining Loss:  0.753 \tTrain_Accu: 71%  \tValid_Acc:21% \t Valid Loss: 2.541 \n",
            "Epoch: 109 \tTraining Loss:  0.720 \tTrain_Accu: 73%  \tValid_Acc:30% \t Valid Loss: 2.298 \n",
            "Epoch: 110 \tTraining Loss:  0.718 \tTrain_Accu: 71%  \tValid_Acc:20% \t Valid Loss: 2.390 \n",
            "Epoch: 111 \tTraining Loss:  0.793 \tTrain_Accu: 69%  \tValid_Acc:24% \t Valid Loss: 2.273 \n",
            "Epoch: 112 \tTraining Loss:  0.733 \tTrain_Accu: 73%  \tValid_Acc:29% \t Valid Loss: 2.003 \n",
            "Epoch: 113 \tTraining Loss:  0.643 \tTrain_Accu: 70%  \tValid_Acc:23% \t Valid Loss: 2.447 \n",
            "Epoch: 114 \tTraining Loss:  0.723 \tTrain_Accu: 70%  \tValid_Acc:24% \t Valid Loss: 2.492 \n",
            "Epoch: 115 \tTraining Loss:  0.781 \tTrain_Accu: 67%  \tValid_Acc:23% \t Valid Loss: 2.852 \n",
            "Epoch: 116 \tTraining Loss:  0.802 \tTrain_Accu: 67%  \tValid_Acc:36% \t Valid Loss: 2.472 \n",
            "Epoch: 117 \tTraining Loss:  0.706 \tTrain_Accu: 69%  \tValid_Acc:24% \t Valid Loss: 2.050 \n",
            "Epoch: 118 \tTraining Loss:  0.707 \tTrain_Accu: 71%  \tValid_Acc:31% \t Valid Loss: 1.932 \n",
            "Epoch: 119 \tTraining Loss:  0.728 \tTrain_Accu: 71%  \tValid_Acc:23% \t Valid Loss: 2.241 \n",
            "Epoch: 120 \tTraining Loss:  0.733 \tTrain_Accu: 71%  \tValid_Acc:24% \t Valid Loss: 2.194 \n",
            "Epoch: 121 \tTraining Loss:  0.729 \tTrain_Accu: 72%  \tValid_Acc:24% \t Valid Loss: 2.856 \n",
            "Epoch: 122 \tTraining Loss:  0.683 \tTrain_Accu: 71%  \tValid_Acc:23% \t Valid Loss: 2.726 \n",
            "Epoch: 123 \tTraining Loss:  0.620 \tTrain_Accu: 74%  \tValid_Acc:31% \t Valid Loss: 2.404 \n",
            "Epoch: 124 \tTraining Loss:  0.700 \tTrain_Accu: 70%  \tValid_Acc:20% \t Valid Loss: 2.410 \n",
            "Epoch: 125 \tTraining Loss:  0.717 \tTrain_Accu: 69%  \tValid_Acc:31% \t Valid Loss: 2.009 \n",
            "Epoch: 126 \tTraining Loss:  0.717 \tTrain_Accu: 69%  \tValid_Acc:23% \t Valid Loss: 2.041 \n",
            "Epoch: 127 \tTraining Loss:  0.695 \tTrain_Accu: 74%  \tValid_Acc:34% \t Valid Loss: 2.097 \n",
            "Epoch: 128 \tTraining Loss:  0.674 \tTrain_Accu: 71%  \tValid_Acc:31% \t Valid Loss: 2.243 \n",
            "Epoch: 129 \tTraining Loss:  0.764 \tTrain_Accu: 67%  \tValid_Acc:21% \t Valid Loss: 2.002 \n",
            "Epoch: 130 \tTraining Loss:  0.676 \tTrain_Accu: 74%  \tValid_Acc:37% \t Valid Loss: 1.954 \n",
            "Epoch: 131 \tTraining Loss:  0.673 \tTrain_Accu: 72%  \tValid_Acc:37% \t Valid Loss: 2.302 \n",
            "Epoch: 132 \tTraining Loss:  0.661 \tTrain_Accu: 73%  \tValid_Acc:30% \t Valid Loss: 2.961 \n",
            "Epoch: 133 \tTraining Loss:  0.625 \tTrain_Accu: 74%  \tValid_Acc:24% \t Valid Loss: 2.330 \n",
            "Epoch: 134 \tTraining Loss:  0.617 \tTrain_Accu: 73%  \tValid_Acc:24% \t Valid Loss: 2.366 \n",
            "Epoch: 135 \tTraining Loss:  0.609 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 2.376 \n",
            "Epoch: 136 \tTraining Loss:  0.694 \tTrain_Accu: 72%  \tValid_Acc:36% \t Valid Loss: 2.399 \n",
            "Epoch: 137 \tTraining Loss:  0.588 \tTrain_Accu: 73%  \tValid_Acc:30% \t Valid Loss: 2.293 \n",
            "Epoch: 138 \tTraining Loss:  0.567 \tTrain_Accu: 76%  \tValid_Acc:29% \t Valid Loss: 2.754 \n",
            "Epoch: 139 \tTraining Loss:  0.645 \tTrain_Accu: 73%  \tValid_Acc:29% \t Valid Loss: 2.404 \n",
            "Epoch: 140 \tTraining Loss:  0.621 \tTrain_Accu: 74%  \tValid_Acc:36% \t Valid Loss: 2.022 \n",
            "Epoch: 141 \tTraining Loss:  0.656 \tTrain_Accu: 75%  \tValid_Acc:31% \t Valid Loss: 2.185 \n",
            "Epoch: 142 \tTraining Loss:  0.641 \tTrain_Accu: 74%  \tValid_Acc:31% \t Valid Loss: 2.434 \n",
            "Epoch: 143 \tTraining Loss:  0.673 \tTrain_Accu: 72%  \tValid_Acc:29% \t Valid Loss: 2.674 \n",
            "Epoch: 144 \tTraining Loss:  0.623 \tTrain_Accu: 74%  \tValid_Acc:31% \t Valid Loss: 2.258 \n",
            "Epoch: 145 \tTraining Loss:  0.662 \tTrain_Accu: 74%  \tValid_Acc:24% \t Valid Loss: 3.131 \n",
            "Epoch: 146 \tTraining Loss:  0.607 \tTrain_Accu: 75%  \tValid_Acc:33% \t Valid Loss: 2.504 \n",
            "Epoch: 147 \tTraining Loss:  0.650 \tTrain_Accu: 74%  \tValid_Acc:30% \t Valid Loss: 1.896 \n",
            "Epoch: 148 \tTraining Loss:  0.681 \tTrain_Accu: 72%  \tValid_Acc:29% \t Valid Loss: 2.416 \n",
            "Epoch: 149 \tTraining Loss:  0.666 \tTrain_Accu: 73%  \tValid_Acc:23% \t Valid Loss: 2.242 \n",
            "Epoch: 150 \tTraining Loss:  0.609 \tTrain_Accu: 74%  \tValid_Acc:26% \t Valid Loss: 2.482 \n",
            "Epoch: 151 \tTraining Loss:  0.591 \tTrain_Accu: 79%  \tValid_Acc:27% \t Valid Loss: 2.516 \n",
            "Epoch: 152 \tTraining Loss:  0.678 \tTrain_Accu: 73%  \tValid_Acc:36% \t Valid Loss: 2.375 \n",
            "Epoch: 153 \tTraining Loss:  0.647 \tTrain_Accu: 75%  \tValid_Acc:26% \t Valid Loss: 2.569 \n",
            "Epoch: 154 \tTraining Loss:  0.639 \tTrain_Accu: 76%  \tValid_Acc:30% \t Valid Loss: 1.971 \n",
            "Epoch: 155 \tTraining Loss:  0.601 \tTrain_Accu: 74%  \tValid_Acc:34% \t Valid Loss: 3.899 \n",
            "Epoch: 156 \tTraining Loss:  0.613 \tTrain_Accu: 75%  \tValid_Acc:23% \t Valid Loss: 2.644 \n",
            "Epoch: 157 \tTraining Loss:  0.593 \tTrain_Accu: 76%  \tValid_Acc:21% \t Valid Loss: 3.135 \n",
            "Epoch: 158 \tTraining Loss:  0.618 \tTrain_Accu: 75%  \tValid_Acc:24% \t Valid Loss: 2.320 \n",
            "Epoch: 159 \tTraining Loss:  0.565 \tTrain_Accu: 78%  \tValid_Acc:23% \t Valid Loss: 3.458 \n",
            "Epoch: 160 \tTraining Loss:  0.612 \tTrain_Accu: 74%  \tValid_Acc:37% \t Valid Loss: 2.496 \n",
            "Epoch: 161 \tTraining Loss:  0.584 \tTrain_Accu: 76%  \tValid_Acc:21% \t Valid Loss: 3.468 \n",
            "Epoch: 162 \tTraining Loss:  0.608 \tTrain_Accu: 75%  \tValid_Acc:23% \t Valid Loss: 2.844 \n",
            "Epoch: 163 \tTraining Loss:  0.621 \tTrain_Accu: 76%  \tValid_Acc:27% \t Valid Loss: 2.381 \n",
            "Epoch: 164 \tTraining Loss:  0.662 \tTrain_Accu: 74%  \tValid_Acc:29% \t Valid Loss: 2.924 \n",
            "Epoch: 165 \tTraining Loss:  0.573 \tTrain_Accu: 78%  \tValid_Acc:23% \t Valid Loss: 4.069 \n",
            "Epoch: 166 \tTraining Loss:  0.567 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 3.173 \n",
            "Epoch: 167 \tTraining Loss:  0.683 \tTrain_Accu: 74%  \tValid_Acc:29% \t Valid Loss: 2.558 \n",
            "Epoch: 168 \tTraining Loss:  0.580 \tTrain_Accu: 78%  \tValid_Acc:29% \t Valid Loss: 2.606 \n",
            "Epoch: 169 \tTraining Loss:  0.594 \tTrain_Accu: 77%  \tValid_Acc:26% \t Valid Loss: 3.194 \n",
            "Epoch: 170 \tTraining Loss:  0.621 \tTrain_Accu: 75%  \tValid_Acc:24% \t Valid Loss: 2.683 \n",
            "Epoch: 171 \tTraining Loss:  0.593 \tTrain_Accu: 78%  \tValid_Acc:29% \t Valid Loss: 2.512 \n",
            "Epoch: 172 \tTraining Loss:  0.562 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 3.161 \n",
            "Epoch: 173 \tTraining Loss:  0.612 \tTrain_Accu: 76%  \tValid_Acc:34% \t Valid Loss: 2.878 \n",
            "Epoch: 174 \tTraining Loss:  0.509 \tTrain_Accu: 78%  \tValid_Acc:26% \t Valid Loss: 2.744 \n",
            "Epoch: 175 \tTraining Loss:  0.541 \tTrain_Accu: 77%  \tValid_Acc:13% \t Valid Loss: 2.972 \n",
            "Epoch: 176 \tTraining Loss:  0.500 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 3.014 \n",
            "Epoch: 177 \tTraining Loss:  0.604 \tTrain_Accu: 76%  \tValid_Acc:27% \t Valid Loss: 2.902 \n",
            "Epoch: 178 \tTraining Loss:  0.529 \tTrain_Accu: 77%  \tValid_Acc:26% \t Valid Loss: 3.207 \n",
            "Epoch: 179 \tTraining Loss:  0.513 \tTrain_Accu: 81%  \tValid_Acc:33% \t Valid Loss: 2.948 \n",
            "Epoch: 180 \tTraining Loss:  0.578 \tTrain_Accu: 76%  \tValid_Acc:37% \t Valid Loss: 2.815 \n",
            "Epoch: 181 \tTraining Loss:  0.602 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 3.493 \n",
            "Epoch: 182 \tTraining Loss:  0.545 \tTrain_Accu: 77%  \tValid_Acc:24% \t Valid Loss: 3.533 \n",
            "Epoch: 183 \tTraining Loss:  0.549 \tTrain_Accu: 79%  \tValid_Acc:21% \t Valid Loss: 3.811 \n",
            "Epoch: 184 \tTraining Loss:  0.535 \tTrain_Accu: 80%  \tValid_Acc:24% \t Valid Loss: 3.558 \n",
            "Epoch: 185 \tTraining Loss:  0.544 \tTrain_Accu: 78%  \tValid_Acc:21% \t Valid Loss: 3.289 \n",
            "Epoch: 186 \tTraining Loss:  0.516 \tTrain_Accu: 79%  \tValid_Acc:24% \t Valid Loss: 3.094 \n",
            "Epoch: 187 \tTraining Loss:  0.539 \tTrain_Accu: 80%  \tValid_Acc:34% \t Valid Loss: 2.694 \n",
            "Epoch: 188 \tTraining Loss:  0.530 \tTrain_Accu: 78%  \tValid_Acc:34% \t Valid Loss: 3.040 \n",
            "Epoch: 189 \tTraining Loss:  0.602 \tTrain_Accu: 76%  \tValid_Acc:27% \t Valid Loss: 2.760 \n",
            "Epoch: 190 \tTraining Loss:  0.481 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 2.567 \n",
            "Epoch: 191 \tTraining Loss:  0.566 \tTrain_Accu: 78%  \tValid_Acc:19% \t Valid Loss: 3.012 \n",
            "Epoch: 192 \tTraining Loss:  0.524 \tTrain_Accu: 80%  \tValid_Acc:16% \t Valid Loss: 3.434 \n",
            "Epoch: 193 \tTraining Loss:  0.510 \tTrain_Accu: 80%  \tValid_Acc:24% \t Valid Loss: 3.359 \n",
            "Epoch: 194 \tTraining Loss:  0.514 \tTrain_Accu: 82%  \tValid_Acc:34% \t Valid Loss: 2.725 \n",
            "Epoch: 195 \tTraining Loss:  0.521 \tTrain_Accu: 81%  \tValid_Acc:20% \t Valid Loss: 3.960 \n",
            "Epoch: 196 \tTraining Loss:  0.603 \tTrain_Accu: 76%  \tValid_Acc:24% \t Valid Loss: 4.071 \n",
            "Epoch: 197 \tTraining Loss:  0.523 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 2.879 \n",
            "Epoch: 198 \tTraining Loss:  0.514 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 3.296 \n",
            "Epoch: 199 \tTraining Loss:  0.527 \tTrain_Accu: 82%  \tValid_Acc:17% \t Valid Loss: 3.388 \n",
            "Epoch: 200 \tTraining Loss:  0.532 \tTrain_Accu: 80%  \tValid_Acc:33% \t Valid Loss: 2.458 \n",
            "Epoch: 201 \tTraining Loss:  0.566 \tTrain_Accu: 79%  \tValid_Acc:20% \t Valid Loss: 3.198 \n",
            "Epoch: 202 \tTraining Loss:  0.570 \tTrain_Accu: 77%  \tValid_Acc:31% \t Valid Loss: 3.379 \n",
            "Epoch: 203 \tTraining Loss:  0.571 \tTrain_Accu: 79%  \tValid_Acc:37% \t Valid Loss: 2.620 \n",
            "Epoch: 204 \tTraining Loss:  0.516 \tTrain_Accu: 82%  \tValid_Acc:34% \t Valid Loss: 2.985 \n",
            "Epoch: 205 \tTraining Loss:  0.579 \tTrain_Accu: 79%  \tValid_Acc:34% \t Valid Loss: 3.291 \n",
            "Epoch: 206 \tTraining Loss:  0.521 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 3.576 \n",
            "Epoch: 207 \tTraining Loss:  0.555 \tTrain_Accu: 82%  \tValid_Acc:26% \t Valid Loss: 4.085 \n",
            "Epoch: 208 \tTraining Loss:  0.520 \tTrain_Accu: 85%  \tValid_Acc:23% \t Valid Loss: 3.485 \n",
            "Epoch: 209 \tTraining Loss:  0.525 \tTrain_Accu: 80%  \tValid_Acc:27% \t Valid Loss: 2.834 \n",
            "Epoch: 210 \tTraining Loss:  0.494 \tTrain_Accu: 82%  \tValid_Acc:14% \t Valid Loss: 4.955 \n",
            "Epoch: 211 \tTraining Loss:  0.487 \tTrain_Accu: 84%  \tValid_Acc:31% \t Valid Loss: 3.237 \n",
            "Epoch: 212 \tTraining Loss:  0.465 \tTrain_Accu: 83%  \tValid_Acc:23% \t Valid Loss: 4.109 \n",
            "Epoch: 213 \tTraining Loss:  0.457 \tTrain_Accu: 81%  \tValid_Acc:20% \t Valid Loss: 4.766 \n",
            "Epoch: 214 \tTraining Loss:  0.467 \tTrain_Accu: 83%  \tValid_Acc:27% \t Valid Loss: 3.269 \n",
            "Epoch: 215 \tTraining Loss:  0.498 \tTrain_Accu: 83%  \tValid_Acc:30% \t Valid Loss: 2.939 \n",
            "Epoch: 216 \tTraining Loss:  0.523 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 3.941 \n",
            "Epoch: 217 \tTraining Loss:  0.471 \tTrain_Accu: 81%  \tValid_Acc:26% \t Valid Loss: 4.111 \n",
            "Epoch: 218 \tTraining Loss:  0.461 \tTrain_Accu: 81%  \tValid_Acc:21% \t Valid Loss: 4.465 \n",
            "Epoch: 219 \tTraining Loss:  0.494 \tTrain_Accu: 85%  \tValid_Acc:23% \t Valid Loss: 4.165 \n",
            "Epoch: 220 \tTraining Loss:  0.504 \tTrain_Accu: 84%  \tValid_Acc:21% \t Valid Loss: 4.334 \n",
            "Epoch: 221 \tTraining Loss:  0.565 \tTrain_Accu: 79%  \tValid_Acc:33% \t Valid Loss: 2.757 \n",
            "Epoch: 222 \tTraining Loss:  0.380 \tTrain_Accu: 85%  \tValid_Acc:36% \t Valid Loss: 3.829 \n",
            "Epoch: 223 \tTraining Loss:  0.461 \tTrain_Accu: 83%  \tValid_Acc:23% \t Valid Loss: 4.549 \n",
            "Epoch: 224 \tTraining Loss:  0.492 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 4.561 \n",
            "Epoch: 225 \tTraining Loss:  0.520 \tTrain_Accu: 82%  \tValid_Acc:23% \t Valid Loss: 5.121 \n",
            "Epoch: 226 \tTraining Loss:  0.518 \tTrain_Accu: 81%  \tValid_Acc:34% \t Valid Loss: 3.589 \n",
            "Epoch: 227 \tTraining Loss:  0.489 \tTrain_Accu: 83%  \tValid_Acc:41% \t Valid Loss: 3.620 \n",
            "Epoch: 228 \tTraining Loss:  0.513 \tTrain_Accu: 81%  \tValid_Acc:26% \t Valid Loss: 3.755 \n",
            "Epoch: 229 \tTraining Loss:  0.457 \tTrain_Accu: 84%  \tValid_Acc:31% \t Valid Loss: 2.913 \n",
            "Epoch: 230 \tTraining Loss:  0.500 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 4.498 \n",
            "Epoch: 231 \tTraining Loss:  0.462 \tTrain_Accu: 83%  \tValid_Acc:31% \t Valid Loss: 3.866 \n",
            "Epoch: 232 \tTraining Loss:  0.456 \tTrain_Accu: 85%  \tValid_Acc:34% \t Valid Loss: 3.186 \n",
            "Epoch: 233 \tTraining Loss:  0.505 \tTrain_Accu: 80%  \tValid_Acc:21% \t Valid Loss: 4.037 \n",
            "Epoch: 234 \tTraining Loss:  0.507 \tTrain_Accu: 82%  \tValid_Acc:19% \t Valid Loss: 2.800 \n",
            "Epoch: 235 \tTraining Loss:  0.464 \tTrain_Accu: 82%  \tValid_Acc:34% \t Valid Loss: 3.717 \n",
            "Epoch: 236 \tTraining Loss:  0.610 \tTrain_Accu: 78%  \tValid_Acc:26% \t Valid Loss: 3.479 \n",
            "Epoch: 237 \tTraining Loss:  0.451 \tTrain_Accu: 84%  \tValid_Acc:30% \t Valid Loss: 3.743 \n",
            "Epoch: 238 \tTraining Loss:  0.475 \tTrain_Accu: 82%  \tValid_Acc:20% \t Valid Loss: 4.477 \n",
            "Epoch: 239 \tTraining Loss:  0.557 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 4.062 \n",
            "Epoch: 240 \tTraining Loss:  0.413 \tTrain_Accu: 86%  \tValid_Acc:31% \t Valid Loss: 3.657 \n",
            "Epoch: 241 \tTraining Loss:  0.482 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 3.334 \n",
            "Epoch: 242 \tTraining Loss:  0.454 \tTrain_Accu: 82%  \tValid_Acc:19% \t Valid Loss: 5.252 \n",
            "Epoch: 243 \tTraining Loss:  0.416 \tTrain_Accu: 85%  \tValid_Acc:24% \t Valid Loss: 4.622 \n",
            "Epoch: 244 \tTraining Loss:  0.533 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 4.357 \n",
            "Epoch: 245 \tTraining Loss:  0.446 \tTrain_Accu: 84%  \tValid_Acc:24% \t Valid Loss: 3.773 \n",
            "Epoch: 246 \tTraining Loss:  0.554 \tTrain_Accu: 80%  \tValid_Acc:33% \t Valid Loss: 3.068 \n",
            "Epoch: 247 \tTraining Loss:  0.545 \tTrain_Accu: 80%  \tValid_Acc:26% \t Valid Loss: 3.692 \n",
            "Epoch: 248 \tTraining Loss:  0.495 \tTrain_Accu: 83%  \tValid_Acc:27% \t Valid Loss: 2.770 \n",
            "Epoch: 249 \tTraining Loss:  0.447 \tTrain_Accu: 84%  \tValid_Acc:29% \t Valid Loss: 3.224 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 01:39:37,568]\u001b[0m Trial 3 finished with value: 30.0 and parameters: {'lr': 0.0001, 'dropout': 0.8}. Best is trial 3 with value: 30.0.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.520 \tTrain_Accu: 79%  \tValid_Acc:30% \t Valid Loss: 4.819 \n",
            "Epoch: 1 \tTraining Loss:  2.240 \tTrain_Accu: 18%  \tValid_Acc:9% \t Valid Loss: 1.629 \n",
            "Epoch: 2 \tTraining Loss:  1.632 \tTrain_Accu: 21%  \tValid_Acc:9% \t Valid Loss: 1.638 \n",
            "Epoch: 3 \tTraining Loss:  1.624 \tTrain_Accu: 18%  \tValid_Acc:23% \t Valid Loss: 1.625 \n",
            "Epoch: 4 \tTraining Loss:  1.632 \tTrain_Accu: 21%  \tValid_Acc:19% \t Valid Loss: 1.622 \n",
            "Epoch: 5 \tTraining Loss:  1.713 \tTrain_Accu: 19%  \tValid_Acc:20% \t Valid Loss: 1.638 \n",
            "Epoch: 6 \tTraining Loss:  1.794 \tTrain_Accu: 18%  \tValid_Acc:19% \t Valid Loss: 1.616 \n",
            "Epoch: 7 \tTraining Loss:  1.645 \tTrain_Accu: 19%  \tValid_Acc:24% \t Valid Loss: 1.633 \n",
            "Epoch: 8 \tTraining Loss:  1.611 \tTrain_Accu: 22%  \tValid_Acc:23% \t Valid Loss: 1.640 \n",
            "Epoch: 9 \tTraining Loss:  1.610 \tTrain_Accu: 21%  \tValid_Acc:21% \t Valid Loss: 1.631 \n",
            "Epoch: 10 \tTraining Loss:  1.620 \tTrain_Accu: 22%  \tValid_Acc:19% \t Valid Loss: 1.625 \n",
            "Epoch: 11 \tTraining Loss:  1.609 \tTrain_Accu: 20%  \tValid_Acc:16% \t Valid Loss: 1.643 \n",
            "Epoch: 12 \tTraining Loss:  1.617 \tTrain_Accu: 20%  \tValid_Acc:21% \t Valid Loss: 1.632 \n",
            "Epoch: 13 \tTraining Loss:  1.668 \tTrain_Accu: 22%  \tValid_Acc:23% \t Valid Loss: 1.643 \n",
            "Epoch: 14 \tTraining Loss:  1.620 \tTrain_Accu: 21%  \tValid_Acc:19% \t Valid Loss: 1.637 \n",
            "Epoch: 15 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.646 \n",
            "Epoch: 16 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:20% \t Valid Loss: 1.654 \n",
            "Epoch: 17 \tTraining Loss:  1.612 \tTrain_Accu: 16%  \tValid_Acc:19% \t Valid Loss: 1.654 \n",
            "Epoch: 18 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:23% \t Valid Loss: 1.673 \n",
            "Epoch: 19 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:19% \t Valid Loss: 1.639 \n",
            "Epoch: 20 \tTraining Loss:  1.606 \tTrain_Accu: 23%  \tValid_Acc:23% \t Valid Loss: 1.653 \n",
            "Epoch: 21 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 22 \tTraining Loss:  1.605 \tTrain_Accu: 18%  \tValid_Acc:23% \t Valid Loss: 1.633 \n",
            "Epoch: 23 \tTraining Loss:  1.611 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 24 \tTraining Loss:  1.616 \tTrain_Accu: 19%  \tValid_Acc:21% \t Valid Loss: 1.642 \n",
            "Epoch: 25 \tTraining Loss:  1.612 \tTrain_Accu: 19%  \tValid_Acc:20% \t Valid Loss: 1.636 \n",
            "Epoch: 26 \tTraining Loss:  1.610 \tTrain_Accu: 20%  \tValid_Acc:14% \t Valid Loss: 1.656 \n",
            "Epoch: 27 \tTraining Loss:  1.611 \tTrain_Accu: 19%  \tValid_Acc:20% \t Valid Loss: 1.641 \n",
            "Epoch: 28 \tTraining Loss:  1.611 \tTrain_Accu: 24%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 29 \tTraining Loss:  1.606 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 30 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:16% \t Valid Loss: 1.642 \n",
            "Epoch: 31 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 32 \tTraining Loss:  1.612 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 33 \tTraining Loss:  1.604 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 34 \tTraining Loss:  1.610 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.650 \n",
            "Epoch: 35 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:20% \t Valid Loss: 1.638 \n",
            "Epoch: 36 \tTraining Loss:  1.612 \tTrain_Accu: 18%  \tValid_Acc:16% \t Valid Loss: 1.661 \n",
            "Epoch: 37 \tTraining Loss:  1.611 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 38 \tTraining Loss:  1.602 \tTrain_Accu: 22%  \tValid_Acc:16% \t Valid Loss: 1.655 \n",
            "Epoch: 39 \tTraining Loss:  1.612 \tTrain_Accu: 24%  \tValid_Acc:19% \t Valid Loss: 1.638 \n",
            "Epoch: 40 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.647 \n",
            "Epoch: 41 \tTraining Loss:  1.606 \tTrain_Accu: 22%  \tValid_Acc:19% \t Valid Loss: 1.649 \n",
            "Epoch: 42 \tTraining Loss:  1.611 \tTrain_Accu: 23%  \tValid_Acc:21% \t Valid Loss: 1.643 \n",
            "Epoch: 43 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:11% \t Valid Loss: 1.633 \n",
            "Epoch: 44 \tTraining Loss:  1.608 \tTrain_Accu: 23%  \tValid_Acc:10% \t Valid Loss: 1.659 \n",
            "Epoch: 45 \tTraining Loss:  1.603 \tTrain_Accu: 20%  \tValid_Acc:20% \t Valid Loss: 1.633 \n",
            "Epoch: 46 \tTraining Loss:  1.609 \tTrain_Accu: 18%  \tValid_Acc:21% \t Valid Loss: 1.641 \n",
            "Epoch: 47 \tTraining Loss:  1.617 \tTrain_Accu: 18%  \tValid_Acc:19% \t Valid Loss: 1.642 \n",
            "Epoch: 48 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:16% \t Valid Loss: 1.630 \n",
            "Epoch: 49 \tTraining Loss:  1.607 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.642 \n",
            "Epoch: 50 \tTraining Loss:  1.602 \tTrain_Accu: 24%  \tValid_Acc:17% \t Valid Loss: 1.623 \n",
            "Epoch: 51 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:11% \t Valid Loss: 1.653 \n",
            "Epoch: 52 \tTraining Loss:  1.612 \tTrain_Accu: 24%  \tValid_Acc:21% \t Valid Loss: 1.636 \n",
            "Epoch: 53 \tTraining Loss:  1.608 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 54 \tTraining Loss:  1.611 \tTrain_Accu: 22%  \tValid_Acc:13% \t Valid Loss: 1.637 \n",
            "Epoch: 55 \tTraining Loss:  1.608 \tTrain_Accu: 23%  \tValid_Acc:20% \t Valid Loss: 1.629 \n",
            "Epoch: 56 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.647 \n",
            "Epoch: 57 \tTraining Loss:  1.610 \tTrain_Accu: 19%  \tValid_Acc:30% \t Valid Loss: 1.639 \n",
            "Epoch: 58 \tTraining Loss:  1.610 \tTrain_Accu: 18%  \tValid_Acc:21% \t Valid Loss: 1.636 \n",
            "Epoch: 59 \tTraining Loss:  1.606 \tTrain_Accu: 21%  \tValid_Acc:24% \t Valid Loss: 1.652 \n",
            "Epoch: 60 \tTraining Loss:  1.613 \tTrain_Accu: 17%  \tValid_Acc:20% \t Valid Loss: 1.631 \n",
            "Epoch: 61 \tTraining Loss:  1.609 \tTrain_Accu: 18%  \tValid_Acc:21% \t Valid Loss: 1.629 \n",
            "Epoch: 62 \tTraining Loss:  1.608 \tTrain_Accu: 20%  \tValid_Acc:20% \t Valid Loss: 1.632 \n",
            "Epoch: 63 \tTraining Loss:  1.607 \tTrain_Accu: 22%  \tValid_Acc:23% \t Valid Loss: 1.632 \n",
            "Epoch: 64 \tTraining Loss:  1.609 \tTrain_Accu: 25%  \tValid_Acc:23% \t Valid Loss: 1.629 \n",
            "Epoch: 65 \tTraining Loss:  1.610 \tTrain_Accu: 18%  \tValid_Acc:24% \t Valid Loss: 1.630 \n",
            "Epoch: 66 \tTraining Loss:  1.609 \tTrain_Accu: 24%  \tValid_Acc:26% \t Valid Loss: 1.629 \n",
            "Epoch: 67 \tTraining Loss:  1.606 \tTrain_Accu: 22%  \tValid_Acc:24% \t Valid Loss: 1.635 \n",
            "Epoch: 68 \tTraining Loss:  1.608 \tTrain_Accu: 19%  \tValid_Acc:23% \t Valid Loss: 1.631 \n",
            "Epoch: 69 \tTraining Loss:  1.608 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 70 \tTraining Loss:  1.608 \tTrain_Accu: 20%  \tValid_Acc:29% \t Valid Loss: 1.632 \n",
            "Epoch: 71 \tTraining Loss:  1.608 \tTrain_Accu: 17%  \tValid_Acc:21% \t Valid Loss: 1.634 \n",
            "Epoch: 72 \tTraining Loss:  1.608 \tTrain_Accu: 21%  \tValid_Acc:27% \t Valid Loss: 1.634 \n",
            "Epoch: 73 \tTraining Loss:  1.605 \tTrain_Accu: 22%  \tValid_Acc:24% \t Valid Loss: 1.634 \n",
            "Epoch: 74 \tTraining Loss:  1.609 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 75 \tTraining Loss:  1.606 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 76 \tTraining Loss:  1.609 \tTrain_Accu: 14%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 77 \tTraining Loss:  1.608 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 78 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 79 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 80 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 81 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 82 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 83 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 84 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 85 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 86 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 87 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 88 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 89 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 90 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 91 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 92 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 93 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 94 \tTraining Loss:  1.607 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 95 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 96 \tTraining Loss:  1.607 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 97 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 98 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 99 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 100 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 101 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.638 \n",
            "Epoch: 102 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 103 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 104 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 105 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 106 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 107 \tTraining Loss:  1.607 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 108 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 109 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 110 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 111 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 112 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 113 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 114 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 115 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 116 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 117 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 118 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 119 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 120 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 121 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 122 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 123 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 124 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 125 \tTraining Loss:  1.607 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 126 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 127 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 128 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 129 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 130 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.638 \n",
            "Epoch: 131 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 132 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 133 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 134 \tTraining Loss:  1.607 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 135 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 136 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.638 \n",
            "Epoch: 137 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.638 \n",
            "Epoch: 138 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 139 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 140 \tTraining Loss:  1.607 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 141 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 142 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 143 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 144 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 145 \tTraining Loss:  1.607 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 146 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 147 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 148 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 149 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 150 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 151 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 152 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 153 \tTraining Loss:  1.607 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 154 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 155 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 156 \tTraining Loss:  1.607 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 157 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 158 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 159 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 160 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 161 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 162 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 163 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 164 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 165 \tTraining Loss:  1.607 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 166 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 167 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 168 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 169 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 170 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 171 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 172 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 173 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 174 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 175 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 176 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 177 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 178 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 179 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 180 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 181 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 182 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 183 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 184 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 185 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 186 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 187 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 188 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 189 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.638 \n",
            "Epoch: 190 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 191 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 192 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 193 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 194 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 195 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 196 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 197 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 198 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 199 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 200 \tTraining Loss:  1.607 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 201 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 202 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 203 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 204 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 205 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 206 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 207 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 208 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 209 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 210 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 211 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 212 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 213 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.638 \n",
            "Epoch: 214 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 215 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 216 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 217 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 218 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 219 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 220 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 221 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 222 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 223 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 224 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 225 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 226 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 227 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 228 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 229 \tTraining Loss:  1.607 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 230 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 231 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 232 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 233 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 234 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 235 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 236 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 237 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 238 \tTraining Loss:  1.607 \tTrain_Accu: 15%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 239 \tTraining Loss:  1.607 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 240 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 241 \tTraining Loss:  1.607 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 242 \tTraining Loss:  1.607 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 243 \tTraining Loss:  1.607 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 244 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 245 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 246 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 247 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 248 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 249 \tTraining Loss:  1.607 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.637 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 01:43:51,606]\u001b[0m Trial 4 finished with value: 25.7 and parameters: {'lr': 0.001, 'dropout': 0.9}. Best is trial 3 with value: 30.0.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  1.607 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 1 \tTraining Loss:  1.957 \tTrain_Accu: 21%  \tValid_Acc:9% \t Valid Loss: 1.628 \n",
            "Epoch: 2 \tTraining Loss:  1.643 \tTrain_Accu: 22%  \tValid_Acc:14% \t Valid Loss: 1.626 \n",
            "Epoch: 3 \tTraining Loss:  1.612 \tTrain_Accu: 26%  \tValid_Acc:23% \t Valid Loss: 1.623 \n",
            "Epoch: 4 \tTraining Loss:  1.594 \tTrain_Accu: 30%  \tValid_Acc:20% \t Valid Loss: 1.593 \n",
            "Epoch: 5 \tTraining Loss:  1.507 \tTrain_Accu: 34%  \tValid_Acc:23% \t Valid Loss: 1.634 \n",
            "Epoch: 6 \tTraining Loss:  1.505 \tTrain_Accu: 35%  \tValid_Acc:24% \t Valid Loss: 1.669 \n",
            "Epoch: 7 \tTraining Loss:  1.451 \tTrain_Accu: 35%  \tValid_Acc:24% \t Valid Loss: 1.729 \n",
            "Epoch: 8 \tTraining Loss:  1.401 \tTrain_Accu: 42%  \tValid_Acc:24% \t Valid Loss: 1.596 \n",
            "Epoch: 9 \tTraining Loss:  1.351 \tTrain_Accu: 43%  \tValid_Acc:26% \t Valid Loss: 1.579 \n",
            "Epoch: 10 \tTraining Loss:  1.234 \tTrain_Accu: 46%  \tValid_Acc:24% \t Valid Loss: 2.076 \n",
            "Epoch: 11 \tTraining Loss:  1.157 \tTrain_Accu: 50%  \tValid_Acc:20% \t Valid Loss: 2.299 \n",
            "Epoch: 12 \tTraining Loss:  1.096 \tTrain_Accu: 55%  \tValid_Acc:21% \t Valid Loss: 1.697 \n",
            "Epoch: 13 \tTraining Loss:  1.115 \tTrain_Accu: 57%  \tValid_Acc:20% \t Valid Loss: 2.706 \n",
            "Epoch: 14 \tTraining Loss:  1.006 \tTrain_Accu: 57%  \tValid_Acc:23% \t Valid Loss: 2.616 \n",
            "Epoch: 15 \tTraining Loss:  0.949 \tTrain_Accu: 61%  \tValid_Acc:17% \t Valid Loss: 2.381 \n",
            "Epoch: 16 \tTraining Loss:  0.811 \tTrain_Accu: 66%  \tValid_Acc:27% \t Valid Loss: 4.996 \n",
            "Epoch: 17 \tTraining Loss:  0.858 \tTrain_Accu: 64%  \tValid_Acc:16% \t Valid Loss: 3.382 \n",
            "Epoch: 18 \tTraining Loss:  0.841 \tTrain_Accu: 67%  \tValid_Acc:24% \t Valid Loss: 3.226 \n",
            "Epoch: 19 \tTraining Loss:  0.807 \tTrain_Accu: 68%  \tValid_Acc:17% \t Valid Loss: 3.050 \n",
            "Epoch: 20 \tTraining Loss:  0.722 \tTrain_Accu: 70%  \tValid_Acc:24% \t Valid Loss: 5.060 \n",
            "Epoch: 21 \tTraining Loss:  0.698 \tTrain_Accu: 74%  \tValid_Acc:23% \t Valid Loss: 2.630 \n",
            "Epoch: 22 \tTraining Loss:  0.653 \tTrain_Accu: 75%  \tValid_Acc:20% \t Valid Loss: 3.841 \n",
            "Epoch: 23 \tTraining Loss:  0.668 \tTrain_Accu: 73%  \tValid_Acc:20% \t Valid Loss: 3.496 \n",
            "Epoch: 24 \tTraining Loss:  0.573 \tTrain_Accu: 78%  \tValid_Acc:17% \t Valid Loss: 3.985 \n",
            "Epoch: 25 \tTraining Loss:  0.661 \tTrain_Accu: 75%  \tValid_Acc:23% \t Valid Loss: 2.811 \n",
            "Epoch: 26 \tTraining Loss:  0.545 \tTrain_Accu: 79%  \tValid_Acc:23% \t Valid Loss: 3.330 \n",
            "Epoch: 27 \tTraining Loss:  0.501 \tTrain_Accu: 82%  \tValid_Acc:17% \t Valid Loss: 3.046 \n",
            "Epoch: 28 \tTraining Loss:  0.545 \tTrain_Accu: 85%  \tValid_Acc:26% \t Valid Loss: 5.709 \n",
            "Epoch: 29 \tTraining Loss:  0.469 \tTrain_Accu: 83%  \tValid_Acc:30% \t Valid Loss: 5.122 \n",
            "Epoch: 30 \tTraining Loss:  0.452 \tTrain_Accu: 84%  \tValid_Acc:19% \t Valid Loss: 5.104 \n",
            "Epoch: 31 \tTraining Loss:  0.439 \tTrain_Accu: 86%  \tValid_Acc:19% \t Valid Loss: 3.523 \n",
            "Epoch: 32 \tTraining Loss:  0.505 \tTrain_Accu: 85%  \tValid_Acc:24% \t Valid Loss: 3.719 \n",
            "Epoch: 33 \tTraining Loss:  0.410 \tTrain_Accu: 86%  \tValid_Acc:20% \t Valid Loss: 6.037 \n",
            "Epoch: 34 \tTraining Loss:  0.330 \tTrain_Accu: 87%  \tValid_Acc:13% \t Valid Loss: 6.082 \n",
            "Epoch: 35 \tTraining Loss:  0.464 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 2.766 \n",
            "Epoch: 36 \tTraining Loss:  0.406 \tTrain_Accu: 87%  \tValid_Acc:19% \t Valid Loss: 4.049 \n",
            "Epoch: 37 \tTraining Loss:  0.312 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 8.117 \n",
            "Epoch: 38 \tTraining Loss:  0.435 \tTrain_Accu: 86%  \tValid_Acc:13% \t Valid Loss: 6.192 \n",
            "Epoch: 39 \tTraining Loss:  0.380 \tTrain_Accu: 89%  \tValid_Acc:16% \t Valid Loss: 11.669 \n",
            "Epoch: 40 \tTraining Loss:  0.300 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 5.634 \n",
            "Epoch: 41 \tTraining Loss:  0.215 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 4.191 \n",
            "Epoch: 42 \tTraining Loss:  0.336 \tTrain_Accu: 87%  \tValid_Acc:21% \t Valid Loss: 4.080 \n",
            "Epoch: 43 \tTraining Loss:  0.373 \tTrain_Accu: 89%  \tValid_Acc:19% \t Valid Loss: 2.794 \n",
            "Epoch: 44 \tTraining Loss:  0.274 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 7.410 \n",
            "Epoch: 45 \tTraining Loss:  0.326 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 6.318 \n",
            "Epoch: 46 \tTraining Loss:  0.177 \tTrain_Accu: 93%  \tValid_Acc:20% \t Valid Loss: 6.090 \n",
            "Epoch: 47 \tTraining Loss:  0.198 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 10.502 \n",
            "Epoch: 48 \tTraining Loss:  0.338 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 6.927 \n",
            "Epoch: 49 \tTraining Loss:  0.237 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 6.967 \n",
            "Epoch: 50 \tTraining Loss:  0.366 \tTrain_Accu: 90%  \tValid_Acc:20% \t Valid Loss: 4.523 \n",
            "Epoch: 51 \tTraining Loss:  0.242 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 4.320 \n",
            "Epoch: 52 \tTraining Loss:  0.347 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 7.321 \n",
            "Epoch: 53 \tTraining Loss:  0.309 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 5.766 \n",
            "Epoch: 54 \tTraining Loss:  0.283 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 5.119 \n",
            "Epoch: 55 \tTraining Loss:  0.136 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 9.924 \n",
            "Epoch: 56 \tTraining Loss:  0.188 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 10.387 \n",
            "Epoch: 57 \tTraining Loss:  0.668 \tTrain_Accu: 88%  \tValid_Acc:13% \t Valid Loss: 4.054 \n",
            "Epoch: 58 \tTraining Loss:  0.172 \tTrain_Accu: 94%  \tValid_Acc:23% \t Valid Loss: 8.361 \n",
            "Epoch: 59 \tTraining Loss:  0.148 \tTrain_Accu: 96%  \tValid_Acc:20% \t Valid Loss: 11.209 \n",
            "Epoch: 60 \tTraining Loss:  0.308 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 4.031 \n",
            "Epoch: 61 \tTraining Loss:  0.276 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 3.301 \n",
            "Epoch: 62 \tTraining Loss:  0.258 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 4.659 \n",
            "Epoch: 63 \tTraining Loss:  0.247 \tTrain_Accu: 92%  \tValid_Acc:19% \t Valid Loss: 5.870 \n",
            "Epoch: 64 \tTraining Loss:  0.186 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 3.815 \n",
            "Epoch: 65 \tTraining Loss:  0.277 \tTrain_Accu: 94%  \tValid_Acc:23% \t Valid Loss: 4.797 \n",
            "Epoch: 66 \tTraining Loss:  0.229 \tTrain_Accu: 94%  \tValid_Acc:13% \t Valid Loss: 13.458 \n",
            "Epoch: 67 \tTraining Loss:  0.155 \tTrain_Accu: 96%  \tValid_Acc:20% \t Valid Loss: 8.264 \n",
            "Epoch: 68 \tTraining Loss:  0.199 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 4.727 \n",
            "Epoch: 69 \tTraining Loss:  0.315 \tTrain_Accu: 90%  \tValid_Acc:21% \t Valid Loss: 7.393 \n",
            "Epoch: 70 \tTraining Loss:  0.236 \tTrain_Accu: 95%  \tValid_Acc:19% \t Valid Loss: 7.424 \n",
            "Epoch: 71 \tTraining Loss:  0.223 \tTrain_Accu: 95%  \tValid_Acc:14% \t Valid Loss: 33.380 \n",
            "Epoch: 72 \tTraining Loss:  0.216 \tTrain_Accu: 95%  \tValid_Acc:19% \t Valid Loss: 4.952 \n",
            "Epoch: 73 \tTraining Loss:  0.273 \tTrain_Accu: 96%  \tValid_Acc:21% \t Valid Loss: 6.248 \n",
            "Epoch: 74 \tTraining Loss:  0.225 \tTrain_Accu: 95%  \tValid_Acc:16% \t Valid Loss: 6.679 \n",
            "Epoch: 75 \tTraining Loss:  0.239 \tTrain_Accu: 93%  \tValid_Acc:20% \t Valid Loss: 6.965 \n",
            "Epoch: 76 \tTraining Loss:  0.270 \tTrain_Accu: 91%  \tValid_Acc:13% \t Valid Loss: 6.744 \n",
            "Epoch: 77 \tTraining Loss:  0.184 \tTrain_Accu: 94%  \tValid_Acc:16% \t Valid Loss: 11.340 \n",
            "Epoch: 78 \tTraining Loss:  0.176 \tTrain_Accu: 95%  \tValid_Acc:17% \t Valid Loss: 9.485 \n",
            "Epoch: 79 \tTraining Loss:  0.314 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 10.404 \n",
            "Epoch: 80 \tTraining Loss:  0.210 \tTrain_Accu: 96%  \tValid_Acc:14% \t Valid Loss: 11.843 \n",
            "Epoch: 81 \tTraining Loss:  0.279 \tTrain_Accu: 93%  \tValid_Acc:19% \t Valid Loss: 6.629 \n",
            "Epoch: 82 \tTraining Loss:  0.262 \tTrain_Accu: 94%  \tValid_Acc:19% \t Valid Loss: 7.181 \n",
            "Epoch: 83 \tTraining Loss:  0.269 \tTrain_Accu: 95%  \tValid_Acc:14% \t Valid Loss: 13.378 \n",
            "Epoch: 84 \tTraining Loss:  0.212 \tTrain_Accu: 93%  \tValid_Acc:19% \t Valid Loss: 3.746 \n",
            "Epoch: 85 \tTraining Loss:  0.220 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 5.909 \n",
            "Epoch: 86 \tTraining Loss:  0.091 \tTrain_Accu: 98%  \tValid_Acc:19% \t Valid Loss: 11.090 \n",
            "Epoch: 87 \tTraining Loss:  0.297 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 15.092 \n",
            "Epoch: 88 \tTraining Loss:  0.206 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 3.415 \n",
            "Epoch: 89 \tTraining Loss:  0.208 \tTrain_Accu: 94%  \tValid_Acc:19% \t Valid Loss: 9.247 \n",
            "Epoch: 90 \tTraining Loss:  0.189 \tTrain_Accu: 94%  \tValid_Acc:14% \t Valid Loss: 7.623 \n",
            "Epoch: 91 \tTraining Loss:  0.235 \tTrain_Accu: 95%  \tValid_Acc:16% \t Valid Loss: 17.998 \n",
            "Epoch: 92 \tTraining Loss:  0.161 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 10.667 \n",
            "Epoch: 93 \tTraining Loss:  0.235 \tTrain_Accu: 92%  \tValid_Acc:17% \t Valid Loss: 9.613 \n",
            "Epoch: 94 \tTraining Loss:  0.340 \tTrain_Accu: 94%  \tValid_Acc:23% \t Valid Loss: 8.288 \n",
            "Epoch: 95 \tTraining Loss:  0.187 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 6.362 \n",
            "Epoch: 96 \tTraining Loss:  0.335 \tTrain_Accu: 92%  \tValid_Acc:13% \t Valid Loss: 8.577 \n",
            "Epoch: 97 \tTraining Loss:  0.199 \tTrain_Accu: 94%  \tValid_Acc:21% \t Valid Loss: 11.657 \n",
            "Epoch: 98 \tTraining Loss:  0.335 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 4.198 \n",
            "Epoch: 99 \tTraining Loss:  0.213 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 8.309 \n",
            "Epoch: 100 \tTraining Loss:  0.246 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 5.521 \n",
            "Epoch: 101 \tTraining Loss:  0.168 \tTrain_Accu: 96%  \tValid_Acc:20% \t Valid Loss: 4.190 \n",
            "Epoch: 102 \tTraining Loss:  0.152 \tTrain_Accu: 96%  \tValid_Acc:19% \t Valid Loss: 24.258 \n",
            "Epoch: 103 \tTraining Loss:  0.437 \tTrain_Accu: 95%  \tValid_Acc:19% \t Valid Loss: 5.792 \n",
            "Epoch: 104 \tTraining Loss:  0.485 \tTrain_Accu: 91%  \tValid_Acc:16% \t Valid Loss: 8.061 \n",
            "Epoch: 105 \tTraining Loss:  0.187 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 3.848 \n",
            "Epoch: 106 \tTraining Loss:  0.277 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 4.746 \n",
            "Epoch: 107 \tTraining Loss:  0.322 \tTrain_Accu: 92%  \tValid_Acc:10% \t Valid Loss: 11.089 \n",
            "Epoch: 108 \tTraining Loss:  0.307 \tTrain_Accu: 94%  \tValid_Acc:19% \t Valid Loss: 8.588 \n",
            "Epoch: 109 \tTraining Loss:  0.202 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 14.436 \n",
            "Epoch: 110 \tTraining Loss:  0.207 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 4.429 \n",
            "Epoch: 111 \tTraining Loss:  0.159 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 7.650 \n",
            "Epoch: 112 \tTraining Loss:  0.404 \tTrain_Accu: 91%  \tValid_Acc:19% \t Valid Loss: 7.394 \n",
            "Epoch: 113 \tTraining Loss:  0.272 \tTrain_Accu: 93%  \tValid_Acc:16% \t Valid Loss: 4.970 \n",
            "Epoch: 114 \tTraining Loss:  0.259 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 7.321 \n",
            "Epoch: 115 \tTraining Loss:  0.308 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 4.547 \n",
            "Epoch: 116 \tTraining Loss:  0.129 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 6.438 \n",
            "Epoch: 117 \tTraining Loss:  0.389 \tTrain_Accu: 92%  \tValid_Acc:19% \t Valid Loss: 15.600 \n",
            "Epoch: 118 \tTraining Loss:  0.299 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 8.537 \n",
            "Epoch: 119 \tTraining Loss:  0.209 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 8.197 \n",
            "Epoch: 120 \tTraining Loss:  0.278 \tTrain_Accu: 93%  \tValid_Acc:16% \t Valid Loss: 6.609 \n",
            "Epoch: 121 \tTraining Loss:  0.181 \tTrain_Accu: 96%  \tValid_Acc:19% \t Valid Loss: 15.632 \n",
            "Epoch: 122 \tTraining Loss:  0.456 \tTrain_Accu: 94%  \tValid_Acc:16% \t Valid Loss: 2.148 \n",
            "Epoch: 123 \tTraining Loss:  0.124 \tTrain_Accu: 97%  \tValid_Acc:19% \t Valid Loss: 8.940 \n",
            "Epoch: 124 \tTraining Loss:  0.425 \tTrain_Accu: 94%  \tValid_Acc:13% \t Valid Loss: 22.064 \n",
            "Epoch: 125 \tTraining Loss:  0.404 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 5.279 \n",
            "Epoch: 126 \tTraining Loss:  0.267 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 5.672 \n",
            "Epoch: 127 \tTraining Loss:  0.246 \tTrain_Accu: 95%  \tValid_Acc:33% \t Valid Loss: 8.722 \n",
            "Epoch: 128 \tTraining Loss:  0.325 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 8.778 \n",
            "Epoch: 129 \tTraining Loss:  0.171 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 7.996 \n",
            "Epoch: 130 \tTraining Loss:  0.393 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 14.098 \n",
            "Epoch: 131 \tTraining Loss:  0.534 \tTrain_Accu: 90%  \tValid_Acc:37% \t Valid Loss: 2.116 \n",
            "Epoch: 132 \tTraining Loss:  0.115 \tTrain_Accu: 98%  \tValid_Acc:23% \t Valid Loss: 9.855 \n",
            "Epoch: 133 \tTraining Loss:  0.331 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 3.622 \n",
            "Epoch: 134 \tTraining Loss:  0.377 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 7.456 \n",
            "Epoch: 135 \tTraining Loss:  0.364 \tTrain_Accu: 93%  \tValid_Acc:19% \t Valid Loss: 7.484 \n",
            "Epoch: 136 \tTraining Loss:  0.347 \tTrain_Accu: 94%  \tValid_Acc:17% \t Valid Loss: 8.403 \n",
            "Epoch: 137 \tTraining Loss:  0.354 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 5.715 \n",
            "Epoch: 138 \tTraining Loss:  0.134 \tTrain_Accu: 96%  \tValid_Acc:19% \t Valid Loss: 8.884 \n",
            "Epoch: 139 \tTraining Loss:  0.558 \tTrain_Accu: 94%  \tValid_Acc:23% \t Valid Loss: 8.637 \n",
            "Epoch: 140 \tTraining Loss:  0.272 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 7.485 \n",
            "Epoch: 141 \tTraining Loss:  0.213 \tTrain_Accu: 96%  \tValid_Acc:21% \t Valid Loss: 21.376 \n",
            "Epoch: 142 \tTraining Loss:  0.662 \tTrain_Accu: 91%  \tValid_Acc:14% \t Valid Loss: 9.111 \n",
            "Epoch: 143 \tTraining Loss:  0.318 \tTrain_Accu: 94%  \tValid_Acc:21% \t Valid Loss: 12.965 \n",
            "Epoch: 144 \tTraining Loss:  0.284 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 8.028 \n",
            "Epoch: 145 \tTraining Loss:  0.850 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 3.670 \n",
            "Epoch: 146 \tTraining Loss:  0.244 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 5.279 \n",
            "Epoch: 147 \tTraining Loss:  0.129 \tTrain_Accu: 95%  \tValid_Acc:20% \t Valid Loss: 6.022 \n",
            "Epoch: 148 \tTraining Loss:  0.367 \tTrain_Accu: 92%  \tValid_Acc:9% \t Valid Loss: 11.404 \n",
            "Epoch: 149 \tTraining Loss:  0.726 \tTrain_Accu: 86%  \tValid_Acc:20% \t Valid Loss: 8.721 \n",
            "Epoch: 150 \tTraining Loss:  0.379 \tTrain_Accu: 90%  \tValid_Acc:17% \t Valid Loss: 3.290 \n",
            "Epoch: 151 \tTraining Loss:  0.435 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 3.324 \n",
            "Epoch: 152 \tTraining Loss:  0.531 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 2.471 \n",
            "Epoch: 153 \tTraining Loss:  0.352 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 7.343 \n",
            "Epoch: 154 \tTraining Loss:  0.340 \tTrain_Accu: 96%  \tValid_Acc:31% \t Valid Loss: 7.784 \n",
            "Epoch: 155 \tTraining Loss:  0.274 \tTrain_Accu: 96%  \tValid_Acc:20% \t Valid Loss: 5.794 \n",
            "Epoch: 156 \tTraining Loss:  0.315 \tTrain_Accu: 95%  \tValid_Acc:30% \t Valid Loss: 5.794 \n",
            "Epoch: 157 \tTraining Loss:  0.493 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 14.743 \n",
            "Epoch: 158 \tTraining Loss:  0.574 \tTrain_Accu: 94%  \tValid_Acc:23% \t Valid Loss: 6.180 \n",
            "Epoch: 159 \tTraining Loss:  0.285 \tTrain_Accu: 94%  \tValid_Acc:23% \t Valid Loss: 14.517 \n",
            "Epoch: 160 \tTraining Loss:  0.938 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 6.162 \n",
            "Epoch: 161 \tTraining Loss:  0.136 \tTrain_Accu: 97%  \tValid_Acc:21% \t Valid Loss: 4.754 \n",
            "Epoch: 162 \tTraining Loss:  0.296 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 5.680 \n",
            "Epoch: 163 \tTraining Loss:  0.279 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 8.822 \n",
            "Epoch: 164 \tTraining Loss:  0.649 \tTrain_Accu: 90%  \tValid_Acc:37% \t Valid Loss: 2.581 \n",
            "Epoch: 165 \tTraining Loss:  0.488 \tTrain_Accu: 89%  \tValid_Acc:34% \t Valid Loss: 9.761 \n",
            "Epoch: 166 \tTraining Loss:  0.359 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 5.668 \n",
            "Epoch: 167 \tTraining Loss:  0.218 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 7.643 \n",
            "Epoch: 168 \tTraining Loss:  0.336 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 7.708 \n",
            "Epoch: 169 \tTraining Loss:  0.697 \tTrain_Accu: 92%  \tValid_Acc:24% \t Valid Loss: 3.677 \n",
            "Epoch: 170 \tTraining Loss:  0.280 \tTrain_Accu: 92%  \tValid_Acc:20% \t Valid Loss: 9.136 \n",
            "Epoch: 171 \tTraining Loss:  0.134 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 12.026 \n",
            "Epoch: 172 \tTraining Loss:  0.271 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 3.989 \n",
            "Epoch: 173 \tTraining Loss:  0.641 \tTrain_Accu: 90%  \tValid_Acc:19% \t Valid Loss: 5.106 \n",
            "Epoch: 174 \tTraining Loss:  0.238 \tTrain_Accu: 96%  \tValid_Acc:21% \t Valid Loss: 11.157 \n",
            "Epoch: 175 \tTraining Loss:  0.412 \tTrain_Accu: 95%  \tValid_Acc:20% \t Valid Loss: 7.464 \n",
            "Epoch: 176 \tTraining Loss:  0.297 \tTrain_Accu: 94%  \tValid_Acc:23% \t Valid Loss: 12.580 \n",
            "Epoch: 177 \tTraining Loss:  0.604 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 8.518 \n",
            "Epoch: 178 \tTraining Loss:  0.380 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 4.824 \n",
            "Epoch: 179 \tTraining Loss:  0.446 \tTrain_Accu: 90%  \tValid_Acc:31% \t Valid Loss: 3.490 \n",
            "Epoch: 180 \tTraining Loss:  0.406 \tTrain_Accu: 89%  \tValid_Acc:31% \t Valid Loss: 4.967 \n",
            "Epoch: 181 \tTraining Loss:  0.288 \tTrain_Accu: 95%  \tValid_Acc:29% \t Valid Loss: 18.214 \n",
            "Epoch: 182 \tTraining Loss:  0.786 \tTrain_Accu: 92%  \tValid_Acc:23% \t Valid Loss: 23.126 \n",
            "Epoch: 183 \tTraining Loss:  0.368 \tTrain_Accu: 96%  \tValid_Acc:31% \t Valid Loss: 8.925 \n",
            "Epoch: 184 \tTraining Loss:  0.655 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 6.577 \n",
            "Epoch: 185 \tTraining Loss:  0.609 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 6.977 \n",
            "Epoch: 186 \tTraining Loss:  0.271 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 10.003 \n",
            "Epoch: 187 \tTraining Loss:  0.476 \tTrain_Accu: 88%  \tValid_Acc:27% \t Valid Loss: 9.517 \n",
            "Epoch: 188 \tTraining Loss:  0.536 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 9.300 \n",
            "Epoch: 189 \tTraining Loss:  0.265 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 7.925 \n",
            "Epoch: 190 \tTraining Loss:  0.232 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 9.572 \n",
            "Epoch: 191 \tTraining Loss:  0.865 \tTrain_Accu: 95%  \tValid_Acc:19% \t Valid Loss: 12.080 \n",
            "Epoch: 192 \tTraining Loss:  0.577 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 7.295 \n",
            "Epoch: 193 \tTraining Loss:  0.219 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 14.643 \n",
            "Epoch: 194 \tTraining Loss:  0.529 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 7.583 \n",
            "Epoch: 195 \tTraining Loss:  0.468 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 8.786 \n",
            "Epoch: 196 \tTraining Loss:  0.476 \tTrain_Accu: 93%  \tValid_Acc:26% \t Valid Loss: 12.459 \n",
            "Epoch: 197 \tTraining Loss:  0.416 \tTrain_Accu: 91%  \tValid_Acc:21% \t Valid Loss: 6.615 \n",
            "Epoch: 198 \tTraining Loss:  1.051 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 6.231 \n",
            "Epoch: 199 \tTraining Loss:  0.163 \tTrain_Accu: 97%  \tValid_Acc:34% \t Valid Loss: 3.884 \n",
            "Epoch: 200 \tTraining Loss:  0.319 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 12.386 \n",
            "Epoch: 201 \tTraining Loss:  0.242 \tTrain_Accu: 94%  \tValid_Acc:31% \t Valid Loss: 4.456 \n",
            "Epoch: 202 \tTraining Loss:  0.796 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 8.533 \n",
            "Epoch: 203 \tTraining Loss:  0.311 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 7.698 \n",
            "Epoch: 204 \tTraining Loss:  0.842 \tTrain_Accu: 87%  \tValid_Acc:20% \t Valid Loss: 5.079 \n",
            "Epoch: 205 \tTraining Loss:  0.343 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 8.099 \n",
            "Epoch: 206 \tTraining Loss:  0.570 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 9.838 \n",
            "Epoch: 207 \tTraining Loss:  0.328 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 18.992 \n",
            "Epoch: 208 \tTraining Loss:  0.272 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 39.573 \n",
            "Epoch: 209 \tTraining Loss:  0.829 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 17.264 \n",
            "Epoch: 210 \tTraining Loss:  0.403 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 12.624 \n",
            "Epoch: 211 \tTraining Loss:  0.517 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 3.137 \n",
            "Epoch: 212 \tTraining Loss:  0.379 \tTrain_Accu: 94%  \tValid_Acc:31% \t Valid Loss: 5.249 \n",
            "Epoch: 213 \tTraining Loss:  0.133 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 6.743 \n",
            "Epoch: 214 \tTraining Loss:  1.201 \tTrain_Accu: 88%  \tValid_Acc:26% \t Valid Loss: 1.767 \n",
            "Epoch: 215 \tTraining Loss:  0.393 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 9.986 \n",
            "Epoch: 216 \tTraining Loss:  0.458 \tTrain_Accu: 92%  \tValid_Acc:33% \t Valid Loss: 2.222 \n",
            "Epoch: 217 \tTraining Loss:  1.381 \tTrain_Accu: 85%  \tValid_Acc:30% \t Valid Loss: 2.401 \n",
            "Epoch: 218 \tTraining Loss:  0.568 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 5.589 \n",
            "Epoch: 219 \tTraining Loss:  1.225 \tTrain_Accu: 90%  \tValid_Acc:21% \t Valid Loss: 8.850 \n",
            "Epoch: 220 \tTraining Loss:  0.427 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 2.711 \n",
            "Epoch: 221 \tTraining Loss:  0.302 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 16.117 \n",
            "Epoch: 222 \tTraining Loss:  0.756 \tTrain_Accu: 93%  \tValid_Acc:33% \t Valid Loss: 7.019 \n",
            "Epoch: 223 \tTraining Loss:  0.121 \tTrain_Accu: 98%  \tValid_Acc:31% \t Valid Loss: 13.022 \n",
            "Epoch: 224 \tTraining Loss:  0.798 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 6.267 \n",
            "Epoch: 225 \tTraining Loss:  0.478 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 2.710 \n",
            "Epoch: 226 \tTraining Loss:  0.512 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 14.591 \n",
            "Epoch: 227 \tTraining Loss:  0.653 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 7.229 \n",
            "Epoch: 228 \tTraining Loss:  0.678 \tTrain_Accu: 89%  \tValid_Acc:24% \t Valid Loss: 9.798 \n",
            "Epoch: 229 \tTraining Loss:  0.543 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 5.123 \n",
            "Epoch: 230 \tTraining Loss:  0.559 \tTrain_Accu: 91%  \tValid_Acc:14% \t Valid Loss: 22.778 \n",
            "Epoch: 231 \tTraining Loss:  1.371 \tTrain_Accu: 89%  \tValid_Acc:31% \t Valid Loss: 17.494 \n",
            "Epoch: 232 \tTraining Loss:  0.501 \tTrain_Accu: 90%  \tValid_Acc:21% \t Valid Loss: 14.011 \n",
            "Epoch: 233 \tTraining Loss:  1.547 \tTrain_Accu: 86%  \tValid_Acc:23% \t Valid Loss: 12.695 \n",
            "Epoch: 234 \tTraining Loss:  0.813 \tTrain_Accu: 92%  \tValid_Acc:33% \t Valid Loss: 8.557 \n",
            "Epoch: 235 \tTraining Loss:  0.439 \tTrain_Accu: 90%  \tValid_Acc:36% \t Valid Loss: 3.512 \n",
            "Epoch: 236 \tTraining Loss:  0.266 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 4.377 \n",
            "Epoch: 237 \tTraining Loss:  0.360 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 12.637 \n",
            "Epoch: 238 \tTraining Loss:  0.309 \tTrain_Accu: 94%  \tValid_Acc:19% \t Valid Loss: 15.760 \n",
            "Epoch: 239 \tTraining Loss:  0.671 \tTrain_Accu: 89%  \tValid_Acc:21% \t Valid Loss: 7.341 \n",
            "Epoch: 240 \tTraining Loss:  0.327 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 7.121 \n",
            "Epoch: 241 \tTraining Loss:  0.689 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 9.664 \n",
            "Epoch: 242 \tTraining Loss:  0.257 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 14.173 \n",
            "Epoch: 243 \tTraining Loss:  0.192 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 14.547 \n",
            "Epoch: 244 \tTraining Loss:  1.243 \tTrain_Accu: 88%  \tValid_Acc:31% \t Valid Loss: 5.891 \n",
            "Epoch: 245 \tTraining Loss:  0.712 \tTrain_Accu: 93%  \tValid_Acc:19% \t Valid Loss: 9.774 \n",
            "Epoch: 246 \tTraining Loss:  0.906 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 8.038 \n",
            "Epoch: 247 \tTraining Loss:  0.436 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 23.225 \n",
            "Epoch: 248 \tTraining Loss:  1.139 \tTrain_Accu: 88%  \tValid_Acc:26% \t Valid Loss: 24.943 \n",
            "Epoch: 249 \tTraining Loss:  0.445 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 9.221 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 01:48:05,268]\u001b[0m Trial 5 finished with value: 24.3 and parameters: {'lr': 0.001, 'dropout': 0.7}. Best is trial 3 with value: 30.0.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  1.052 \tTrain_Accu: 87%  \tValid_Acc:24% \t Valid Loss: 16.690 \n",
            "Epoch: 1 \tTraining Loss:  338.917 \tTrain_Accu: 18%  \tValid_Acc:21% \t Valid Loss: 1.657 \n",
            "Epoch: 2 \tTraining Loss:  1.664 \tTrain_Accu: 18%  \tValid_Acc:14% \t Valid Loss: 1.641 \n",
            "Epoch: 3 \tTraining Loss:  1.633 \tTrain_Accu: 19%  \tValid_Acc:14% \t Valid Loss: 1.692 \n",
            "Epoch: 4 \tTraining Loss:  2.017 \tTrain_Accu: 21%  \tValid_Acc:9% \t Valid Loss: 1.658 \n",
            "Epoch: 5 \tTraining Loss:  1.622 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 6 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 7 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.643 \n",
            "Epoch: 8 \tTraining Loss:  1.613 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.616 \n",
            "Epoch: 9 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 10 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.640 \n",
            "Epoch: 11 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.621 \n",
            "Epoch: 12 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.645 \n",
            "Epoch: 13 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.638 \n",
            "Epoch: 14 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.642 \n",
            "Epoch: 15 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 16 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 17 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 18 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 19 \tTraining Loss:  1.614 \tTrain_Accu: 14%  \tValid_Acc:7% \t Valid Loss: 1.650 \n",
            "Epoch: 20 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 21 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 22 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.619 \n",
            "Epoch: 23 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.640 \n",
            "Epoch: 24 \tTraining Loss:  1.615 \tTrain_Accu: 15%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 25 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 26 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.651 \n",
            "Epoch: 27 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.653 \n",
            "Epoch: 28 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.627 \n",
            "Epoch: 29 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.645 \n",
            "Epoch: 30 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 31 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 32 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 33 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 34 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 35 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 36 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.630 \n",
            "Epoch: 37 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.633 \n",
            "Epoch: 38 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 39 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.629 \n",
            "Epoch: 40 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 41 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.647 \n",
            "Epoch: 42 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 43 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.627 \n",
            "Epoch: 44 \tTraining Loss:  1.612 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.644 \n",
            "Epoch: 45 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.646 \n",
            "Epoch: 46 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 47 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.642 \n",
            "Epoch: 48 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 49 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 50 \tTraining Loss:  1.612 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.631 \n",
            "Epoch: 51 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.623 \n",
            "Epoch: 52 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 53 \tTraining Loss:  1.612 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.603 \n",
            "Epoch: 54 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 55 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 56 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 57 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 58 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.624 \n",
            "Epoch: 59 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 60 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.638 \n",
            "Epoch: 61 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.640 \n",
            "Epoch: 62 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 63 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 64 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 65 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 66 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 67 \tTraining Loss:  1.615 \tTrain_Accu: 15%  \tValid_Acc:26% \t Valid Loss: 1.641 \n",
            "Epoch: 68 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.626 \n",
            "Epoch: 69 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.638 \n",
            "Epoch: 70 \tTraining Loss:  1.612 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.619 \n",
            "Epoch: 71 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.611 \n",
            "Epoch: 72 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 73 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 74 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 75 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.653 \n",
            "Epoch: 76 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 77 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.656 \n",
            "Epoch: 78 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.646 \n",
            "Epoch: 79 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.644 \n",
            "Epoch: 80 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.646 \n",
            "Epoch: 81 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.654 \n",
            "Epoch: 82 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 83 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.643 \n",
            "Epoch: 84 \tTraining Loss:  1.616 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 85 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.638 \n",
            "Epoch: 86 \tTraining Loss:  1.612 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.625 \n",
            "Epoch: 87 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.620 \n",
            "Epoch: 88 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.638 \n",
            "Epoch: 89 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.627 \n",
            "Epoch: 90 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.646 \n",
            "Epoch: 91 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.637 \n",
            "Epoch: 92 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 93 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 94 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 95 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.630 \n",
            "Epoch: 96 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 97 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.613 \n",
            "Epoch: 98 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.649 \n",
            "Epoch: 99 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.654 \n",
            "Epoch: 100 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 101 \tTraining Loss:  1.614 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.653 \n",
            "Epoch: 102 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.649 \n",
            "Epoch: 103 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 104 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 105 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.620 \n",
            "Epoch: 106 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.621 \n",
            "Epoch: 107 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.642 \n",
            "Epoch: 108 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 109 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 110 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 111 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 112 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.648 \n",
            "Epoch: 113 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 114 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 115 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 116 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.622 \n",
            "Epoch: 117 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.609 \n",
            "Epoch: 118 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.625 \n",
            "Epoch: 119 \tTraining Loss:  1.614 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 120 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 121 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 122 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 123 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.640 \n",
            "Epoch: 124 \tTraining Loss:  1.612 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.623 \n",
            "Epoch: 125 \tTraining Loss:  1.616 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 126 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.638 \n",
            "Epoch: 127 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.662 \n",
            "Epoch: 128 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.644 \n",
            "Epoch: 129 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 130 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.664 \n",
            "Epoch: 131 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.626 \n",
            "Epoch: 132 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 133 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.635 \n",
            "Epoch: 134 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 135 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 136 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.657 \n",
            "Epoch: 137 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 138 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 139 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.623 \n",
            "Epoch: 140 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.627 \n",
            "Epoch: 141 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.627 \n",
            "Epoch: 142 \tTraining Loss:  1.612 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.664 \n",
            "Epoch: 143 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.619 \n",
            "Epoch: 144 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 145 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.641 \n",
            "Epoch: 146 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.648 \n",
            "Epoch: 147 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.645 \n",
            "Epoch: 148 \tTraining Loss:  1.613 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.618 \n",
            "Epoch: 149 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 150 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.640 \n",
            "Epoch: 151 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.627 \n",
            "Epoch: 152 \tTraining Loss:  1.611 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.649 \n",
            "Epoch: 153 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 154 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 155 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.639 \n",
            "Epoch: 156 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 157 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.648 \n",
            "Epoch: 158 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 159 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 160 \tTraining Loss:  1.616 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 161 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.624 \n",
            "Epoch: 162 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.643 \n",
            "Epoch: 163 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 164 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 165 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.621 \n",
            "Epoch: 166 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.622 \n",
            "Epoch: 167 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 168 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.642 \n",
            "Epoch: 169 \tTraining Loss:  1.613 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.633 \n",
            "Epoch: 170 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.640 \n",
            "Epoch: 171 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.631 \n",
            "Epoch: 172 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 173 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 174 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 175 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.640 \n",
            "Epoch: 176 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 177 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.644 \n",
            "Epoch: 178 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.647 \n",
            "Epoch: 179 \tTraining Loss:  1.616 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 180 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.624 \n",
            "Epoch: 181 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 182 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 183 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.640 \n",
            "Epoch: 184 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.641 \n",
            "Epoch: 185 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.651 \n",
            "Epoch: 186 \tTraining Loss:  1.615 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.645 \n",
            "Epoch: 187 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 188 \tTraining Loss:  1.615 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.646 \n",
            "Epoch: 189 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.648 \n",
            "Epoch: 190 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.627 \n",
            "Epoch: 191 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.623 \n",
            "Epoch: 192 \tTraining Loss:  1.616 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.636 \n",
            "Epoch: 193 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.643 \n",
            "Epoch: 194 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.644 \n",
            "Epoch: 195 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.647 \n",
            "Epoch: 196 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 197 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.651 \n",
            "Epoch: 198 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 199 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.640 \n",
            "Epoch: 200 \tTraining Loss:  1.614 \tTrain_Accu: 15%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 201 \tTraining Loss:  1.612 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.623 \n",
            "Epoch: 202 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.638 \n",
            "Epoch: 203 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.627 \n",
            "Epoch: 204 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.634 \n",
            "Epoch: 205 \tTraining Loss:  1.612 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.655 \n",
            "Epoch: 206 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.642 \n",
            "Epoch: 207 \tTraining Loss:  1.616 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 208 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.648 \n",
            "Epoch: 209 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 210 \tTraining Loss:  1.614 \tTrain_Accu: 22%  \tValid_Acc:17% \t Valid Loss: 1.626 \n",
            "Epoch: 211 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.652 \n",
            "Epoch: 212 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.650 \n",
            "Epoch: 213 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.639 \n",
            "Epoch: 214 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:7% \t Valid Loss: 1.643 \n",
            "Epoch: 215 \tTraining Loss:  1.614 \tTrain_Accu: 17%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 216 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 217 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 218 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:26% \t Valid Loss: 1.628 \n",
            "Epoch: 219 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.633 \n",
            "Epoch: 220 \tTraining Loss:  1.614 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.635 \n",
            "Epoch: 221 \tTraining Loss:  1.613 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.619 \n",
            "Epoch: 222 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:17% \t Valid Loss: 1.624 \n",
            "Epoch: 223 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:17% \t Valid Loss: 1.638 \n",
            "Epoch: 224 \tTraining Loss:  1.615 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.624 \n",
            "Epoch: 225 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.658 \n",
            "Epoch: 226 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.637 \n",
            "Epoch: 227 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 228 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 229 \tTraining Loss:  1.615 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.629 \n",
            "Epoch: 230 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.645 \n",
            "Epoch: 231 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.627 \n",
            "Epoch: 232 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 233 \tTraining Loss:  1.613 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.636 \n",
            "Epoch: 234 \tTraining Loss:  1.616 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.633 \n",
            "Epoch: 235 \tTraining Loss:  1.614 \tTrain_Accu: 18%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 236 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:7% \t Valid Loss: 1.637 \n",
            "Epoch: 237 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:7% \t Valid Loss: 1.634 \n",
            "Epoch: 238 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:7% \t Valid Loss: 1.636 \n",
            "Epoch: 239 \tTraining Loss:  1.613 \tTrain_Accu: 17%  \tValid_Acc:26% \t Valid Loss: 1.614 \n",
            "Epoch: 240 \tTraining Loss:  1.615 \tTrain_Accu: 18%  \tValid_Acc:26% \t Valid Loss: 1.619 \n",
            "Epoch: 241 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:7% \t Valid Loss: 1.642 \n",
            "Epoch: 242 \tTraining Loss:  1.612 \tTrain_Accu: 20%  \tValid_Acc:17% \t Valid Loss: 1.632 \n",
            "Epoch: 243 \tTraining Loss:  1.615 \tTrain_Accu: 19%  \tValid_Acc:17% \t Valid Loss: 1.628 \n",
            "Epoch: 244 \tTraining Loss:  1.615 \tTrain_Accu: 22%  \tValid_Acc:26% \t Valid Loss: 1.630 \n",
            "Epoch: 245 \tTraining Loss:  1.612 \tTrain_Accu: 22%  \tValid_Acc:7% \t Valid Loss: 1.650 \n",
            "Epoch: 246 \tTraining Loss:  1.614 \tTrain_Accu: 20%  \tValid_Acc:7% \t Valid Loss: 1.658 \n",
            "Epoch: 247 \tTraining Loss:  1.614 \tTrain_Accu: 23%  \tValid_Acc:26% \t Valid Loss: 1.625 \n",
            "Epoch: 248 \tTraining Loss:  1.615 \tTrain_Accu: 16%  \tValid_Acc:26% \t Valid Loss: 1.629 \n",
            "Epoch: 249 \tTraining Loss:  1.614 \tTrain_Accu: 21%  \tValid_Acc:26% \t Valid Loss: 1.621 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 01:52:19,470]\u001b[0m Trial 6 finished with value: 25.7 and parameters: {'lr': 0.01, 'dropout': 0.8}. Best is trial 3 with value: 30.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:26% \t Valid Loss: 1.632 \n",
            "Epoch: 1 \tTraining Loss:  1.956 \tTrain_Accu: 20%  \tValid_Acc:11% \t Valid Loss: 1.626 \n",
            "Epoch: 2 \tTraining Loss:  1.636 \tTrain_Accu: 24%  \tValid_Acc:13% \t Valid Loss: 1.619 \n",
            "Epoch: 3 \tTraining Loss:  1.610 \tTrain_Accu: 26%  \tValid_Acc:16% \t Valid Loss: 1.653 \n",
            "Epoch: 4 \tTraining Loss:  1.643 \tTrain_Accu: 29%  \tValid_Acc:20% \t Valid Loss: 1.589 \n",
            "Epoch: 5 \tTraining Loss:  1.569 \tTrain_Accu: 32%  \tValid_Acc:21% \t Valid Loss: 1.595 \n",
            "Epoch: 6 \tTraining Loss:  1.535 \tTrain_Accu: 31%  \tValid_Acc:24% \t Valid Loss: 1.608 \n",
            "Epoch: 7 \tTraining Loss:  1.402 \tTrain_Accu: 42%  \tValid_Acc:24% \t Valid Loss: 1.633 \n",
            "Epoch: 8 \tTraining Loss:  1.426 \tTrain_Accu: 41%  \tValid_Acc:33% \t Valid Loss: 1.513 \n",
            "Epoch: 9 \tTraining Loss:  1.342 \tTrain_Accu: 42%  \tValid_Acc:26% \t Valid Loss: 1.609 \n",
            "Epoch: 10 \tTraining Loss:  1.229 \tTrain_Accu: 48%  \tValid_Acc:24% \t Valid Loss: 1.815 \n",
            "Epoch: 11 \tTraining Loss:  1.399 \tTrain_Accu: 49%  \tValid_Acc:21% \t Valid Loss: 1.657 \n",
            "Epoch: 12 \tTraining Loss:  1.060 \tTrain_Accu: 54%  \tValid_Acc:27% \t Valid Loss: 1.826 \n",
            "Epoch: 13 \tTraining Loss:  1.076 \tTrain_Accu: 58%  \tValid_Acc:16% \t Valid Loss: 1.766 \n",
            "Epoch: 14 \tTraining Loss:  0.912 \tTrain_Accu: 63%  \tValid_Acc:30% \t Valid Loss: 2.088 \n",
            "Epoch: 15 \tTraining Loss:  0.894 \tTrain_Accu: 65%  \tValid_Acc:26% \t Valid Loss: 2.249 \n",
            "Epoch: 16 \tTraining Loss:  0.800 \tTrain_Accu: 67%  \tValid_Acc:24% \t Valid Loss: 2.093 \n",
            "Epoch: 17 \tTraining Loss:  0.750 \tTrain_Accu: 70%  \tValid_Acc:29% \t Valid Loss: 2.684 \n",
            "Epoch: 18 \tTraining Loss:  0.766 \tTrain_Accu: 73%  \tValid_Acc:30% \t Valid Loss: 2.035 \n",
            "Epoch: 19 \tTraining Loss:  0.629 \tTrain_Accu: 75%  \tValid_Acc:30% \t Valid Loss: 3.169 \n",
            "Epoch: 20 \tTraining Loss:  0.781 \tTrain_Accu: 77%  \tValid_Acc:23% \t Valid Loss: 3.569 \n",
            "Epoch: 21 \tTraining Loss:  0.577 \tTrain_Accu: 80%  \tValid_Acc:26% \t Valid Loss: 3.109 \n",
            "Epoch: 22 \tTraining Loss:  0.480 \tTrain_Accu: 82%  \tValid_Acc:27% \t Valid Loss: 2.756 \n",
            "Epoch: 23 \tTraining Loss:  0.547 \tTrain_Accu: 80%  \tValid_Acc:21% \t Valid Loss: 4.095 \n",
            "Epoch: 24 \tTraining Loss:  0.538 \tTrain_Accu: 80%  \tValid_Acc:20% \t Valid Loss: 2.886 \n",
            "Epoch: 25 \tTraining Loss:  0.556 \tTrain_Accu: 82%  \tValid_Acc:23% \t Valid Loss: 2.671 \n",
            "Epoch: 26 \tTraining Loss:  0.481 \tTrain_Accu: 82%  \tValid_Acc:24% \t Valid Loss: 3.181 \n",
            "Epoch: 27 \tTraining Loss:  0.344 \tTrain_Accu: 87%  \tValid_Acc:24% \t Valid Loss: 2.899 \n",
            "Epoch: 28 \tTraining Loss:  0.400 \tTrain_Accu: 90%  \tValid_Acc:33% \t Valid Loss: 5.060 \n",
            "Epoch: 29 \tTraining Loss:  0.377 \tTrain_Accu: 89%  \tValid_Acc:36% \t Valid Loss: 3.915 \n",
            "Epoch: 30 \tTraining Loss:  0.319 \tTrain_Accu: 89%  \tValid_Acc:24% \t Valid Loss: 4.058 \n",
            "Epoch: 31 \tTraining Loss:  0.412 \tTrain_Accu: 89%  \tValid_Acc:19% \t Valid Loss: 4.498 \n",
            "Epoch: 32 \tTraining Loss:  0.288 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 2.885 \n",
            "Epoch: 33 \tTraining Loss:  0.249 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 4.794 \n",
            "Epoch: 34 \tTraining Loss:  0.362 \tTrain_Accu: 86%  \tValid_Acc:20% \t Valid Loss: 3.840 \n",
            "Epoch: 35 \tTraining Loss:  0.256 \tTrain_Accu: 90%  \tValid_Acc:33% \t Valid Loss: 4.235 \n",
            "Epoch: 36 \tTraining Loss:  0.248 \tTrain_Accu: 91%  \tValid_Acc:33% \t Valid Loss: 4.715 \n",
            "Epoch: 37 \tTraining Loss:  0.266 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 4.684 \n",
            "Epoch: 38 \tTraining Loss:  0.293 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 5.180 \n",
            "Epoch: 39 \tTraining Loss:  0.264 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 5.947 \n",
            "Epoch: 40 \tTraining Loss:  0.317 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 3.843 \n",
            "Epoch: 41 \tTraining Loss:  0.257 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 2.944 \n",
            "Epoch: 42 \tTraining Loss:  0.248 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 2.808 \n",
            "Epoch: 43 \tTraining Loss:  0.301 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 3.876 \n",
            "Epoch: 44 \tTraining Loss:  0.139 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 4.326 \n",
            "Epoch: 45 \tTraining Loss:  0.194 \tTrain_Accu: 92%  \tValid_Acc:24% \t Valid Loss: 5.305 \n",
            "Epoch: 46 \tTraining Loss:  0.228 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 3.095 \n",
            "Epoch: 47 \tTraining Loss:  0.162 \tTrain_Accu: 95%  \tValid_Acc:29% \t Valid Loss: 7.195 \n",
            "Epoch: 48 \tTraining Loss:  0.257 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 4.746 \n",
            "Epoch: 49 \tTraining Loss:  0.150 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 3.231 \n",
            "Epoch: 50 \tTraining Loss:  0.221 \tTrain_Accu: 94%  \tValid_Acc:19% \t Valid Loss: 7.237 \n",
            "Epoch: 51 \tTraining Loss:  0.149 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 6.070 \n",
            "Epoch: 52 \tTraining Loss:  0.206 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 4.771 \n",
            "Epoch: 53 \tTraining Loss:  0.211 \tTrain_Accu: 95%  \tValid_Acc:29% \t Valid Loss: 4.839 \n",
            "Epoch: 54 \tTraining Loss:  0.191 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 5.143 \n",
            "Epoch: 55 \tTraining Loss:  0.169 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 5.528 \n",
            "Epoch: 56 \tTraining Loss:  0.141 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 5.303 \n",
            "Epoch: 57 \tTraining Loss:  0.198 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 6.502 \n",
            "Epoch: 58 \tTraining Loss:  0.285 \tTrain_Accu: 93%  \tValid_Acc:26% \t Valid Loss: 4.598 \n",
            "Epoch: 59 \tTraining Loss:  0.144 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 5.567 \n",
            "Epoch: 60 \tTraining Loss:  0.313 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 4.274 \n",
            "Epoch: 61 \tTraining Loss:  0.147 \tTrain_Accu: 95%  \tValid_Acc:20% \t Valid Loss: 5.338 \n",
            "Epoch: 62 \tTraining Loss:  0.194 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 6.283 \n",
            "Epoch: 63 \tTraining Loss:  0.105 \tTrain_Accu: 97%  \tValid_Acc:31% \t Valid Loss: 7.570 \n",
            "Epoch: 64 \tTraining Loss:  0.188 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 3.865 \n",
            "Epoch: 65 \tTraining Loss:  0.127 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 4.312 \n",
            "Epoch: 66 \tTraining Loss:  0.163 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 4.978 \n",
            "Epoch: 67 \tTraining Loss:  0.209 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 7.428 \n",
            "Epoch: 68 \tTraining Loss:  0.120 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 6.227 \n",
            "Epoch: 69 \tTraining Loss:  0.146 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 4.580 \n",
            "Epoch: 70 \tTraining Loss:  0.195 \tTrain_Accu: 95%  \tValid_Acc:29% \t Valid Loss: 5.023 \n",
            "Epoch: 71 \tTraining Loss:  0.142 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 5.893 \n",
            "Epoch: 72 \tTraining Loss:  0.192 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 4.776 \n",
            "Epoch: 73 \tTraining Loss:  0.229 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 4.148 \n",
            "Epoch: 74 \tTraining Loss:  0.116 \tTrain_Accu: 97%  \tValid_Acc:31% \t Valid Loss: 3.705 \n",
            "Epoch: 75 \tTraining Loss:  0.181 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 4.801 \n",
            "Epoch: 76 \tTraining Loss:  0.106 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 3.409 \n",
            "Epoch: 77 \tTraining Loss:  0.224 \tTrain_Accu: 94%  \tValid_Acc:34% \t Valid Loss: 3.816 \n",
            "Epoch: 78 \tTraining Loss:  0.131 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 7.603 \n",
            "Epoch: 79 \tTraining Loss:  0.213 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 4.053 \n",
            "Epoch: 80 \tTraining Loss:  0.125 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 10.116 \n",
            "Epoch: 81 \tTraining Loss:  0.161 \tTrain_Accu: 96%  \tValid_Acc:20% \t Valid Loss: 9.200 \n",
            "Epoch: 82 \tTraining Loss:  0.121 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 8.718 \n",
            "Epoch: 83 \tTraining Loss:  0.182 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 5.199 \n",
            "Epoch: 84 \tTraining Loss:  0.226 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 2.474 \n",
            "Epoch: 85 \tTraining Loss:  0.228 \tTrain_Accu: 94%  \tValid_Acc:21% \t Valid Loss: 6.319 \n",
            "Epoch: 86 \tTraining Loss:  0.108 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 9.000 \n",
            "Epoch: 87 \tTraining Loss:  0.156 \tTrain_Accu: 97%  \tValid_Acc:27% \t Valid Loss: 2.255 \n",
            "Epoch: 88 \tTraining Loss:  0.129 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 12.021 \n",
            "Epoch: 89 \tTraining Loss:  0.152 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 4.837 \n",
            "Epoch: 90 \tTraining Loss:  0.124 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 8.057 \n",
            "Epoch: 91 \tTraining Loss:  0.146 \tTrain_Accu: 96%  \tValid_Acc:17% \t Valid Loss: 7.787 \n",
            "Epoch: 92 \tTraining Loss:  0.168 \tTrain_Accu: 97%  \tValid_Acc:27% \t Valid Loss: 5.160 \n",
            "Epoch: 93 \tTraining Loss:  0.176 \tTrain_Accu: 95%  \tValid_Acc:20% \t Valid Loss: 3.579 \n",
            "Epoch: 94 \tTraining Loss:  0.352 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 5.260 \n",
            "Epoch: 95 \tTraining Loss:  0.214 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 4.177 \n",
            "Epoch: 96 \tTraining Loss:  0.191 \tTrain_Accu: 95%  \tValid_Acc:20% \t Valid Loss: 6.229 \n",
            "Epoch: 97 \tTraining Loss:  0.171 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 2.624 \n",
            "Epoch: 98 \tTraining Loss:  0.178 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 2.426 \n",
            "Epoch: 99 \tTraining Loss:  0.248 \tTrain_Accu: 95%  \tValid_Acc:29% \t Valid Loss: 13.970 \n",
            "Epoch: 100 \tTraining Loss:  0.202 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 6.648 \n",
            "Epoch: 101 \tTraining Loss:  0.193 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 2.687 \n",
            "Epoch: 102 \tTraining Loss:  0.137 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 21.552 \n",
            "Epoch: 103 \tTraining Loss:  0.264 \tTrain_Accu: 95%  \tValid_Acc:27% \t Valid Loss: 6.487 \n",
            "Epoch: 104 \tTraining Loss:  0.091 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 4.918 \n",
            "Epoch: 105 \tTraining Loss:  0.194 \tTrain_Accu: 94%  \tValid_Acc:21% \t Valid Loss: 4.612 \n",
            "Epoch: 106 \tTraining Loss:  0.283 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 7.767 \n",
            "Epoch: 107 \tTraining Loss:  0.187 \tTrain_Accu: 95%  \tValid_Acc:27% \t Valid Loss: 5.637 \n",
            "Epoch: 108 \tTraining Loss:  0.163 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 6.488 \n",
            "Epoch: 109 \tTraining Loss:  0.122 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 8.054 \n",
            "Epoch: 110 \tTraining Loss:  0.139 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 10.651 \n",
            "Epoch: 111 \tTraining Loss:  0.105 \tTrain_Accu: 96%  \tValid_Acc:31% \t Valid Loss: 2.978 \n",
            "Epoch: 112 \tTraining Loss:  0.160 \tTrain_Accu: 96%  \tValid_Acc:21% \t Valid Loss: 4.201 \n",
            "Epoch: 113 \tTraining Loss:  0.181 \tTrain_Accu: 95%  \tValid_Acc:29% \t Valid Loss: 5.863 \n",
            "Epoch: 114 \tTraining Loss:  0.237 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 4.854 \n",
            "Epoch: 115 \tTraining Loss:  0.198 \tTrain_Accu: 97%  \tValid_Acc:33% \t Valid Loss: 6.892 \n",
            "Epoch: 116 \tTraining Loss:  0.150 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 6.783 \n",
            "Epoch: 117 \tTraining Loss:  0.216 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 5.102 \n",
            "Epoch: 118 \tTraining Loss:  0.310 \tTrain_Accu: 95%  \tValid_Acc:31% \t Valid Loss: 4.938 \n",
            "Epoch: 119 \tTraining Loss:  0.264 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 7.692 \n",
            "Epoch: 120 \tTraining Loss:  0.220 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 8.631 \n",
            "Epoch: 121 \tTraining Loss:  0.171 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 7.310 \n",
            "Epoch: 122 \tTraining Loss:  0.238 \tTrain_Accu: 95%  \tValid_Acc:20% \t Valid Loss: 6.121 \n",
            "Epoch: 123 \tTraining Loss:  0.093 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 6.068 \n",
            "Epoch: 124 \tTraining Loss:  0.133 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 10.711 \n",
            "Epoch: 125 \tTraining Loss:  0.230 \tTrain_Accu: 96%  \tValid_Acc:19% \t Valid Loss: 5.722 \n",
            "Epoch: 126 \tTraining Loss:  0.144 \tTrain_Accu: 96%  \tValid_Acc:30% \t Valid Loss: 10.593 \n",
            "Epoch: 127 \tTraining Loss:  0.123 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 5.966 \n",
            "Epoch: 128 \tTraining Loss:  0.237 \tTrain_Accu: 96%  \tValid_Acc:19% \t Valid Loss: 13.494 \n",
            "Epoch: 129 \tTraining Loss:  0.430 \tTrain_Accu: 94%  \tValid_Acc:19% \t Valid Loss: 2.658 \n",
            "Epoch: 130 \tTraining Loss:  0.403 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 9.753 \n",
            "Epoch: 131 \tTraining Loss:  0.257 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 8.389 \n",
            "Epoch: 132 \tTraining Loss:  0.229 \tTrain_Accu: 97%  \tValid_Acc:21% \t Valid Loss: 8.517 \n",
            "Epoch: 133 \tTraining Loss:  0.112 \tTrain_Accu: 98%  \tValid_Acc:21% \t Valid Loss: 5.564 \n",
            "Epoch: 134 \tTraining Loss:  0.446 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 6.098 \n",
            "Epoch: 135 \tTraining Loss:  0.328 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 8.456 \n",
            "Epoch: 136 \tTraining Loss:  0.239 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 11.890 \n",
            "Epoch: 137 \tTraining Loss:  0.104 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 12.744 \n",
            "Epoch: 138 \tTraining Loss:  0.445 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 6.557 \n",
            "Epoch: 139 \tTraining Loss:  0.133 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 9.295 \n",
            "Epoch: 140 \tTraining Loss:  0.390 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 6.152 \n",
            "Epoch: 141 \tTraining Loss:  0.069 \tTrain_Accu: 97%  \tValid_Acc:29% \t Valid Loss: 11.538 \n",
            "Epoch: 142 \tTraining Loss:  0.385 \tTrain_Accu: 96%  \tValid_Acc:31% \t Valid Loss: 8.575 \n",
            "Epoch: 143 \tTraining Loss:  0.318 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 3.973 \n",
            "Epoch: 144 \tTraining Loss:  0.111 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 6.853 \n",
            "Epoch: 145 \tTraining Loss:  0.218 \tTrain_Accu: 95%  \tValid_Acc:27% \t Valid Loss: 15.010 \n",
            "Epoch: 146 \tTraining Loss:  0.261 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 4.814 \n",
            "Epoch: 147 \tTraining Loss:  0.137 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 7.049 \n",
            "Epoch: 148 \tTraining Loss:  0.307 \tTrain_Accu: 95%  \tValid_Acc:19% \t Valid Loss: 5.713 \n",
            "Epoch: 149 \tTraining Loss:  0.189 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 4.554 \n",
            "Epoch: 150 \tTraining Loss:  0.104 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 21.605 \n",
            "Epoch: 151 \tTraining Loss:  0.336 \tTrain_Accu: 96%  \tValid_Acc:20% \t Valid Loss: 7.552 \n",
            "Epoch: 152 \tTraining Loss:  0.265 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 13.792 \n",
            "Epoch: 153 \tTraining Loss:  0.106 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 14.465 \n",
            "Epoch: 154 \tTraining Loss:  0.297 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 7.384 \n",
            "Epoch: 155 \tTraining Loss:  0.257 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 3.308 \n",
            "Epoch: 156 \tTraining Loss:  0.192 \tTrain_Accu: 97%  \tValid_Acc:30% \t Valid Loss: 3.979 \n",
            "Epoch: 157 \tTraining Loss:  0.444 \tTrain_Accu: 94%  \tValid_Acc:23% \t Valid Loss: 5.772 \n",
            "Epoch: 158 \tTraining Loss:  0.102 \tTrain_Accu: 98%  \tValid_Acc:20% \t Valid Loss: 7.798 \n",
            "Epoch: 159 \tTraining Loss:  0.438 \tTrain_Accu: 94%  \tValid_Acc:16% \t Valid Loss: 13.853 \n",
            "Epoch: 160 \tTraining Loss:  0.170 \tTrain_Accu: 97%  \tValid_Acc:20% \t Valid Loss: 3.650 \n",
            "Epoch: 161 \tTraining Loss:  0.217 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 6.650 \n",
            "Epoch: 162 \tTraining Loss:  0.116 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 16.547 \n",
            "Epoch: 163 \tTraining Loss:  0.146 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 7.127 \n",
            "Epoch: 164 \tTraining Loss:  0.057 \tTrain_Accu: 98%  \tValid_Acc:21% \t Valid Loss: 5.064 \n",
            "Epoch: 165 \tTraining Loss:  0.675 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 8.200 \n",
            "Epoch: 166 \tTraining Loss:  0.106 \tTrain_Accu: 98%  \tValid_Acc:24% \t Valid Loss: 7.343 \n",
            "Epoch: 167 \tTraining Loss:  0.273 \tTrain_Accu: 94%  \tValid_Acc:19% \t Valid Loss: 33.601 \n",
            "Epoch: 168 \tTraining Loss:  0.745 \tTrain_Accu: 94%  \tValid_Acc:16% \t Valid Loss: 11.888 \n",
            "Epoch: 169 \tTraining Loss:  0.335 \tTrain_Accu: 95%  \tValid_Acc:17% \t Valid Loss: 4.178 \n",
            "Epoch: 170 \tTraining Loss:  0.366 \tTrain_Accu: 94%  \tValid_Acc:19% \t Valid Loss: 9.513 \n",
            "Epoch: 171 \tTraining Loss:  0.223 \tTrain_Accu: 96%  \tValid_Acc:17% \t Valid Loss: 8.810 \n",
            "Epoch: 172 \tTraining Loss:  0.223 \tTrain_Accu: 95%  \tValid_Acc:16% \t Valid Loss: 7.764 \n",
            "Epoch: 173 \tTraining Loss:  0.157 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 11.167 \n",
            "Epoch: 174 \tTraining Loss:  0.351 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 8.987 \n",
            "Epoch: 175 \tTraining Loss:  0.220 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 5.895 \n",
            "Epoch: 176 \tTraining Loss:  0.349 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 13.109 \n",
            "Epoch: 177 \tTraining Loss:  0.072 \tTrain_Accu: 98%  \tValid_Acc:16% \t Valid Loss: 9.351 \n",
            "Epoch: 178 \tTraining Loss:  0.256 \tTrain_Accu: 97%  \tValid_Acc:19% \t Valid Loss: 8.083 \n",
            "Epoch: 179 \tTraining Loss:  0.285 \tTrain_Accu: 95%  \tValid_Acc:19% \t Valid Loss: 9.221 \n",
            "Epoch: 180 \tTraining Loss:  0.382 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 7.221 \n",
            "Epoch: 181 \tTraining Loss:  0.172 \tTrain_Accu: 95%  \tValid_Acc:19% \t Valid Loss: 9.294 \n",
            "Epoch: 182 \tTraining Loss:  0.134 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 6.297 \n",
            "Epoch: 183 \tTraining Loss:  0.146 \tTrain_Accu: 96%  \tValid_Acc:21% \t Valid Loss: 9.007 \n",
            "Epoch: 184 \tTraining Loss:  0.441 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 6.451 \n",
            "Epoch: 185 \tTraining Loss:  0.205 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 16.835 \n",
            "Epoch: 186 \tTraining Loss:  0.214 \tTrain_Accu: 95%  \tValid_Acc:24% \t Valid Loss: 5.434 \n",
            "Epoch: 187 \tTraining Loss:  0.054 \tTrain_Accu: 98%  \tValid_Acc:19% \t Valid Loss: 7.059 \n",
            "Epoch: 188 \tTraining Loss:  0.304 \tTrain_Accu: 98%  \tValid_Acc:34% \t Valid Loss: 8.214 \n",
            "Epoch: 189 \tTraining Loss:  0.201 \tTrain_Accu: 96%  \tValid_Acc:19% \t Valid Loss: 20.429 \n",
            "Epoch: 190 \tTraining Loss:  0.302 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 10.093 \n",
            "Epoch: 191 \tTraining Loss:  0.358 \tTrain_Accu: 95%  \tValid_Acc:20% \t Valid Loss: 3.528 \n",
            "Epoch: 192 \tTraining Loss:  0.333 \tTrain_Accu: 95%  \tValid_Acc:17% \t Valid Loss: 5.584 \n",
            "Epoch: 193 \tTraining Loss:  0.308 \tTrain_Accu: 94%  \tValid_Acc:17% \t Valid Loss: 5.856 \n",
            "Epoch: 194 \tTraining Loss:  0.222 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 6.634 \n",
            "Epoch: 195 \tTraining Loss:  0.650 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 11.233 \n",
            "Epoch: 196 \tTraining Loss:  0.150 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 6.720 \n",
            "Epoch: 197 \tTraining Loss:  0.208 \tTrain_Accu: 97%  \tValid_Acc:27% \t Valid Loss: 11.114 \n",
            "Epoch: 198 \tTraining Loss:  0.243 \tTrain_Accu: 97%  \tValid_Acc:19% \t Valid Loss: 13.198 \n",
            "Epoch: 199 \tTraining Loss:  0.316 \tTrain_Accu: 96%  \tValid_Acc:19% \t Valid Loss: 10.074 \n",
            "Epoch: 200 \tTraining Loss:  0.998 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 13.624 \n",
            "Epoch: 201 \tTraining Loss:  0.304 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 7.969 \n",
            "Epoch: 202 \tTraining Loss:  0.388 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 6.325 \n",
            "Epoch: 203 \tTraining Loss:  0.225 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 11.878 \n",
            "Epoch: 204 \tTraining Loss:  0.244 \tTrain_Accu: 96%  \tValid_Acc:20% \t Valid Loss: 9.750 \n",
            "Epoch: 205 \tTraining Loss:  0.221 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 6.196 \n",
            "Epoch: 206 \tTraining Loss:  0.451 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 13.948 \n",
            "Epoch: 207 \tTraining Loss:  0.939 \tTrain_Accu: 92%  \tValid_Acc:24% \t Valid Loss: 7.914 \n",
            "Epoch: 208 \tTraining Loss:  0.187 \tTrain_Accu: 97%  \tValid_Acc:26% \t Valid Loss: 14.178 \n",
            "Epoch: 209 \tTraining Loss:  0.129 \tTrain_Accu: 96%  \tValid_Acc:24% \t Valid Loss: 5.150 \n",
            "Epoch: 210 \tTraining Loss:  0.155 \tTrain_Accu: 97%  \tValid_Acc:21% \t Valid Loss: 8.247 \n",
            "Epoch: 211 \tTraining Loss:  0.330 \tTrain_Accu: 92%  \tValid_Acc:23% \t Valid Loss: 6.550 \n",
            "Epoch: 212 \tTraining Loss:  0.627 \tTrain_Accu: 94%  \tValid_Acc:14% \t Valid Loss: 1.960 \n",
            "Epoch: 213 \tTraining Loss:  0.588 \tTrain_Accu: 95%  \tValid_Acc:23% \t Valid Loss: 14.157 \n",
            "Epoch: 214 \tTraining Loss:  0.283 \tTrain_Accu: 98%  \tValid_Acc:20% \t Valid Loss: 14.113 \n",
            "Epoch: 215 \tTraining Loss:  0.082 \tTrain_Accu: 96%  \tValid_Acc:20% \t Valid Loss: 8.923 \n",
            "Epoch: 216 \tTraining Loss:  0.340 \tTrain_Accu: 96%  \tValid_Acc:14% \t Valid Loss: 2.569 \n",
            "Epoch: 217 \tTraining Loss:  0.222 \tTrain_Accu: 95%  \tValid_Acc:17% \t Valid Loss: 11.791 \n",
            "Epoch: 218 \tTraining Loss:  0.403 \tTrain_Accu: 94%  \tValid_Acc:21% \t Valid Loss: 16.493 \n",
            "Epoch: 219 \tTraining Loss:  0.650 \tTrain_Accu: 95%  \tValid_Acc:17% \t Valid Loss: 7.412 \n",
            "Epoch: 220 \tTraining Loss:  0.261 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 5.557 \n",
            "Epoch: 221 \tTraining Loss:  0.282 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 2.578 \n",
            "Epoch: 222 \tTraining Loss:  0.081 \tTrain_Accu: 98%  \tValid_Acc:26% \t Valid Loss: 7.230 \n",
            "Epoch: 223 \tTraining Loss:  0.539 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 9.796 \n",
            "Epoch: 224 \tTraining Loss:  0.044 \tTrain_Accu: 98%  \tValid_Acc:17% \t Valid Loss: 19.548 \n",
            "Epoch: 225 \tTraining Loss:  0.425 \tTrain_Accu: 96%  \tValid_Acc:27% \t Valid Loss: 8.764 \n",
            "Epoch: 226 \tTraining Loss:  0.306 \tTrain_Accu: 96%  \tValid_Acc:19% \t Valid Loss: 3.454 \n",
            "Epoch: 227 \tTraining Loss:  0.540 \tTrain_Accu: 96%  \tValid_Acc:21% \t Valid Loss: 6.855 \n",
            "Epoch: 228 \tTraining Loss:  0.335 \tTrain_Accu: 94%  \tValid_Acc:21% \t Valid Loss: 28.253 \n",
            "Epoch: 229 \tTraining Loss:  0.386 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 15.021 \n",
            "Epoch: 230 \tTraining Loss:  0.157 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 11.807 \n",
            "Epoch: 231 \tTraining Loss:  0.699 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 9.908 \n",
            "Epoch: 232 \tTraining Loss:  1.111 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 11.446 \n",
            "Epoch: 233 \tTraining Loss:  0.164 \tTrain_Accu: 98%  \tValid_Acc:21% \t Valid Loss: 21.384 \n",
            "Epoch: 234 \tTraining Loss:  0.244 \tTrain_Accu: 95%  \tValid_Acc:27% \t Valid Loss: 16.944 \n",
            "Epoch: 235 \tTraining Loss:  0.506 \tTrain_Accu: 97%  \tValid_Acc:24% \t Valid Loss: 8.941 \n",
            "Epoch: 236 \tTraining Loss:  0.508 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 2.850 \n",
            "Epoch: 237 \tTraining Loss:  0.126 \tTrain_Accu: 98%  \tValid_Acc:16% \t Valid Loss: 14.179 \n",
            "Epoch: 238 \tTraining Loss:  0.275 \tTrain_Accu: 95%  \tValid_Acc:21% \t Valid Loss: 11.349 \n",
            "Epoch: 239 \tTraining Loss:  0.462 \tTrain_Accu: 96%  \tValid_Acc:21% \t Valid Loss: 6.011 \n",
            "Epoch: 240 \tTraining Loss:  0.293 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 7.561 \n",
            "Epoch: 241 \tTraining Loss:  0.619 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 4.184 \n",
            "Epoch: 242 \tTraining Loss:  0.137 \tTrain_Accu: 97%  \tValid_Acc:16% \t Valid Loss: 20.444 \n",
            "Epoch: 243 \tTraining Loss:  0.747 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 2.230 \n",
            "Epoch: 244 \tTraining Loss:  1.098 \tTrain_Accu: 94%  \tValid_Acc:17% \t Valid Loss: 12.753 \n",
            "Epoch: 245 \tTraining Loss:  0.582 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 13.669 \n",
            "Epoch: 246 \tTraining Loss:  0.211 \tTrain_Accu: 97%  \tValid_Acc:27% \t Valid Loss: 49.350 \n",
            "Epoch: 247 \tTraining Loss:  0.579 \tTrain_Accu: 93%  \tValid_Acc:19% \t Valid Loss: 6.402 \n",
            "Epoch: 248 \tTraining Loss:  0.479 \tTrain_Accu: 95%  \tValid_Acc:17% \t Valid Loss: 8.260 \n",
            "Epoch: 249 \tTraining Loss:  0.281 \tTrain_Accu: 97%  \tValid_Acc:23% \t Valid Loss: 18.045 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 01:56:33,921]\u001b[0m Trial 7 finished with value: 20.0 and parameters: {'lr': 0.001, 'dropout': 0.7}. Best is trial 3 with value: 30.0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.679 \tTrain_Accu: 86%  \tValid_Acc:20% \t Valid Loss: 3.432 \n",
            "Epoch: 1 \tTraining Loss:  1.669 \tTrain_Accu: 21%  \tValid_Acc:14% \t Valid Loss: 1.625 \n",
            "Epoch: 2 \tTraining Loss:  1.605 \tTrain_Accu: 25%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 3 \tTraining Loss:  1.599 \tTrain_Accu: 22%  \tValid_Acc:27% \t Valid Loss: 1.593 \n",
            "Epoch: 4 \tTraining Loss:  1.558 \tTrain_Accu: 30%  \tValid_Acc:20% \t Valid Loss: 1.645 \n",
            "Epoch: 5 \tTraining Loss:  1.545 \tTrain_Accu: 30%  \tValid_Acc:16% \t Valid Loss: 1.665 \n",
            "Epoch: 6 \tTraining Loss:  1.560 \tTrain_Accu: 30%  \tValid_Acc:21% \t Valid Loss: 1.589 \n",
            "Epoch: 7 \tTraining Loss:  1.515 \tTrain_Accu: 32%  \tValid_Acc:11% \t Valid Loss: 1.777 \n",
            "Epoch: 8 \tTraining Loss:  1.493 \tTrain_Accu: 33%  \tValid_Acc:33% \t Valid Loss: 1.573 \n",
            "Epoch: 9 \tTraining Loss:  1.506 \tTrain_Accu: 33%  \tValid_Acc:19% \t Valid Loss: 1.648 \n",
            "Epoch: 10 \tTraining Loss:  1.454 \tTrain_Accu: 35%  \tValid_Acc:33% \t Valid Loss: 1.554 \n",
            "Epoch: 11 \tTraining Loss:  1.416 \tTrain_Accu: 39%  \tValid_Acc:21% \t Valid Loss: 1.684 \n",
            "Epoch: 12 \tTraining Loss:  1.393 \tTrain_Accu: 40%  \tValid_Acc:17% \t Valid Loss: 1.679 \n",
            "Epoch: 13 \tTraining Loss:  1.394 \tTrain_Accu: 40%  \tValid_Acc:24% \t Valid Loss: 1.648 \n",
            "Epoch: 14 \tTraining Loss:  1.373 \tTrain_Accu: 40%  \tValid_Acc:27% \t Valid Loss: 1.657 \n",
            "Epoch: 15 \tTraining Loss:  1.326 \tTrain_Accu: 43%  \tValid_Acc:26% \t Valid Loss: 1.705 \n",
            "Epoch: 16 \tTraining Loss:  1.337 \tTrain_Accu: 43%  \tValid_Acc:27% \t Valid Loss: 1.762 \n",
            "Epoch: 17 \tTraining Loss:  1.315 \tTrain_Accu: 40%  \tValid_Acc:16% \t Valid Loss: 1.761 \n",
            "Epoch: 18 \tTraining Loss:  1.336 \tTrain_Accu: 41%  \tValid_Acc:19% \t Valid Loss: 1.766 \n",
            "Epoch: 19 \tTraining Loss:  1.254 \tTrain_Accu: 45%  \tValid_Acc:27% \t Valid Loss: 1.749 \n",
            "Epoch: 20 \tTraining Loss:  1.219 \tTrain_Accu: 48%  \tValid_Acc:26% \t Valid Loss: 1.775 \n",
            "Epoch: 21 \tTraining Loss:  1.208 \tTrain_Accu: 48%  \tValid_Acc:21% \t Valid Loss: 1.756 \n",
            "Epoch: 22 \tTraining Loss:  1.167 \tTrain_Accu: 50%  \tValid_Acc:27% \t Valid Loss: 1.659 \n",
            "Epoch: 23 \tTraining Loss:  1.163 \tTrain_Accu: 52%  \tValid_Acc:26% \t Valid Loss: 2.021 \n",
            "Epoch: 24 \tTraining Loss:  1.155 \tTrain_Accu: 55%  \tValid_Acc:17% \t Valid Loss: 1.869 \n",
            "Epoch: 25 \tTraining Loss:  1.114 \tTrain_Accu: 51%  \tValid_Acc:27% \t Valid Loss: 1.785 \n",
            "Epoch: 26 \tTraining Loss:  1.028 \tTrain_Accu: 56%  \tValid_Acc:23% \t Valid Loss: 2.274 \n",
            "Epoch: 27 \tTraining Loss:  1.123 \tTrain_Accu: 52%  \tValid_Acc:24% \t Valid Loss: 1.800 \n",
            "Epoch: 28 \tTraining Loss:  0.990 \tTrain_Accu: 58%  \tValid_Acc:26% \t Valid Loss: 1.938 \n",
            "Epoch: 29 \tTraining Loss:  0.949 \tTrain_Accu: 58%  \tValid_Acc:24% \t Valid Loss: 1.911 \n",
            "Epoch: 30 \tTraining Loss:  0.966 \tTrain_Accu: 58%  \tValid_Acc:26% \t Valid Loss: 1.823 \n",
            "Epoch: 31 \tTraining Loss:  0.953 \tTrain_Accu: 56%  \tValid_Acc:27% \t Valid Loss: 1.925 \n",
            "Epoch: 32 \tTraining Loss:  0.974 \tTrain_Accu: 61%  \tValid_Acc:24% \t Valid Loss: 1.724 \n",
            "Epoch: 33 \tTraining Loss:  0.928 \tTrain_Accu: 59%  \tValid_Acc:31% \t Valid Loss: 2.231 \n",
            "Epoch: 34 \tTraining Loss:  0.913 \tTrain_Accu: 63%  \tValid_Acc:21% \t Valid Loss: 2.096 \n",
            "Epoch: 35 \tTraining Loss:  0.862 \tTrain_Accu: 66%  \tValid_Acc:31% \t Valid Loss: 1.827 \n",
            "Epoch: 36 \tTraining Loss:  0.883 \tTrain_Accu: 62%  \tValid_Acc:29% \t Valid Loss: 2.108 \n",
            "Epoch: 37 \tTraining Loss:  0.871 \tTrain_Accu: 65%  \tValid_Acc:33% \t Valid Loss: 2.065 \n",
            "Epoch: 38 \tTraining Loss:  0.754 \tTrain_Accu: 68%  \tValid_Acc:23% \t Valid Loss: 2.501 \n",
            "Epoch: 39 \tTraining Loss:  0.771 \tTrain_Accu: 68%  \tValid_Acc:19% \t Valid Loss: 2.188 \n",
            "Epoch: 40 \tTraining Loss:  0.836 \tTrain_Accu: 68%  \tValid_Acc:36% \t Valid Loss: 1.975 \n",
            "Epoch: 41 \tTraining Loss:  0.781 \tTrain_Accu: 66%  \tValid_Acc:27% \t Valid Loss: 2.551 \n",
            "Epoch: 42 \tTraining Loss:  0.733 \tTrain_Accu: 69%  \tValid_Acc:30% \t Valid Loss: 2.508 \n",
            "Epoch: 43 \tTraining Loss:  0.690 \tTrain_Accu: 70%  \tValid_Acc:30% \t Valid Loss: 2.021 \n",
            "Epoch: 44 \tTraining Loss:  0.786 \tTrain_Accu: 69%  \tValid_Acc:23% \t Valid Loss: 2.058 \n",
            "Epoch: 45 \tTraining Loss:  0.736 \tTrain_Accu: 71%  \tValid_Acc:19% \t Valid Loss: 2.480 \n",
            "Epoch: 46 \tTraining Loss:  0.676 \tTrain_Accu: 77%  \tValid_Acc:23% \t Valid Loss: 2.487 \n",
            "Epoch: 47 \tTraining Loss:  0.638 \tTrain_Accu: 74%  \tValid_Acc:23% \t Valid Loss: 2.566 \n",
            "Epoch: 48 \tTraining Loss:  0.612 \tTrain_Accu: 74%  \tValid_Acc:21% \t Valid Loss: 2.645 \n",
            "Epoch: 49 \tTraining Loss:  0.634 \tTrain_Accu: 74%  \tValid_Acc:27% \t Valid Loss: 2.365 \n",
            "Epoch: 50 \tTraining Loss:  0.585 \tTrain_Accu: 76%  \tValid_Acc:16% \t Valid Loss: 2.630 \n",
            "Epoch: 51 \tTraining Loss:  0.572 \tTrain_Accu: 78%  \tValid_Acc:19% \t Valid Loss: 2.477 \n",
            "Epoch: 52 \tTraining Loss:  0.537 \tTrain_Accu: 81%  \tValid_Acc:24% \t Valid Loss: 2.887 \n",
            "Epoch: 53 \tTraining Loss:  0.580 \tTrain_Accu: 77%  \tValid_Acc:30% \t Valid Loss: 2.584 \n",
            "Epoch: 54 \tTraining Loss:  0.499 \tTrain_Accu: 80%  \tValid_Acc:33% \t Valid Loss: 3.164 \n",
            "Epoch: 55 \tTraining Loss:  0.596 \tTrain_Accu: 76%  \tValid_Acc:29% \t Valid Loss: 2.755 \n",
            "Epoch: 56 \tTraining Loss:  0.524 \tTrain_Accu: 78%  \tValid_Acc:27% \t Valid Loss: 3.280 \n",
            "Epoch: 57 \tTraining Loss:  0.580 \tTrain_Accu: 74%  \tValid_Acc:24% \t Valid Loss: 2.933 \n",
            "Epoch: 58 \tTraining Loss:  0.509 \tTrain_Accu: 81%  \tValid_Acc:36% \t Valid Loss: 2.056 \n",
            "Epoch: 59 \tTraining Loss:  0.436 \tTrain_Accu: 81%  \tValid_Acc:20% \t Valid Loss: 3.457 \n",
            "Epoch: 60 \tTraining Loss:  0.483 \tTrain_Accu: 80%  \tValid_Acc:26% \t Valid Loss: 2.494 \n",
            "Epoch: 61 \tTraining Loss:  0.467 \tTrain_Accu: 81%  \tValid_Acc:33% \t Valid Loss: 3.440 \n",
            "Epoch: 62 \tTraining Loss:  0.620 \tTrain_Accu: 75%  \tValid_Acc:30% \t Valid Loss: 2.911 \n",
            "Epoch: 63 \tTraining Loss:  0.434 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 3.169 \n",
            "Epoch: 64 \tTraining Loss:  0.433 \tTrain_Accu: 83%  \tValid_Acc:30% \t Valid Loss: 2.379 \n",
            "Epoch: 65 \tTraining Loss:  0.493 \tTrain_Accu: 79%  \tValid_Acc:31% \t Valid Loss: 2.766 \n",
            "Epoch: 66 \tTraining Loss:  0.436 \tTrain_Accu: 82%  \tValid_Acc:21% \t Valid Loss: 2.935 \n",
            "Epoch: 67 \tTraining Loss:  0.424 \tTrain_Accu: 84%  \tValid_Acc:24% \t Valid Loss: 3.398 \n",
            "Epoch: 68 \tTraining Loss:  0.474 \tTrain_Accu: 81%  \tValid_Acc:29% \t Valid Loss: 2.894 \n",
            "Epoch: 69 \tTraining Loss:  0.470 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 2.808 \n",
            "Epoch: 70 \tTraining Loss:  0.409 \tTrain_Accu: 86%  \tValid_Acc:30% \t Valid Loss: 3.233 \n",
            "Epoch: 71 \tTraining Loss:  0.409 \tTrain_Accu: 82%  \tValid_Acc:23% \t Valid Loss: 2.921 \n",
            "Epoch: 72 \tTraining Loss:  0.421 \tTrain_Accu: 85%  \tValid_Acc:24% \t Valid Loss: 3.483 \n",
            "Epoch: 73 \tTraining Loss:  0.437 \tTrain_Accu: 83%  \tValid_Acc:27% \t Valid Loss: 2.949 \n",
            "Epoch: 74 \tTraining Loss:  0.385 \tTrain_Accu: 85%  \tValid_Acc:26% \t Valid Loss: 3.590 \n",
            "Epoch: 75 \tTraining Loss:  0.376 \tTrain_Accu: 87%  \tValid_Acc:19% \t Valid Loss: 3.976 \n",
            "Epoch: 76 \tTraining Loss:  0.428 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 3.654 \n",
            "Epoch: 77 \tTraining Loss:  0.412 \tTrain_Accu: 84%  \tValid_Acc:29% \t Valid Loss: 3.286 \n",
            "Epoch: 78 \tTraining Loss:  0.388 \tTrain_Accu: 84%  \tValid_Acc:30% \t Valid Loss: 2.924 \n",
            "Epoch: 79 \tTraining Loss:  0.385 \tTrain_Accu: 84%  \tValid_Acc:30% \t Valid Loss: 3.004 \n",
            "Epoch: 80 \tTraining Loss:  0.367 \tTrain_Accu: 87%  \tValid_Acc:29% \t Valid Loss: 4.018 \n",
            "Epoch: 81 \tTraining Loss:  0.361 \tTrain_Accu: 88%  \tValid_Acc:30% \t Valid Loss: 2.844 \n",
            "Epoch: 82 \tTraining Loss:  0.416 \tTrain_Accu: 84%  \tValid_Acc:27% \t Valid Loss: 3.688 \n",
            "Epoch: 83 \tTraining Loss:  0.341 \tTrain_Accu: 86%  \tValid_Acc:19% \t Valid Loss: 3.428 \n",
            "Epoch: 84 \tTraining Loss:  0.366 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 3.397 \n",
            "Epoch: 85 \tTraining Loss:  0.368 \tTrain_Accu: 86%  \tValid_Acc:31% \t Valid Loss: 3.262 \n",
            "Epoch: 86 \tTraining Loss:  0.318 \tTrain_Accu: 88%  \tValid_Acc:17% \t Valid Loss: 4.180 \n",
            "Epoch: 87 \tTraining Loss:  0.316 \tTrain_Accu: 88%  \tValid_Acc:29% \t Valid Loss: 4.453 \n",
            "Epoch: 88 \tTraining Loss:  0.301 \tTrain_Accu: 87%  \tValid_Acc:33% \t Valid Loss: 4.652 \n",
            "Epoch: 89 \tTraining Loss:  0.324 \tTrain_Accu: 90%  \tValid_Acc:33% \t Valid Loss: 2.865 \n",
            "Epoch: 90 \tTraining Loss:  0.353 \tTrain_Accu: 86%  \tValid_Acc:19% \t Valid Loss: 4.003 \n",
            "Epoch: 91 \tTraining Loss:  0.358 \tTrain_Accu: 85%  \tValid_Acc:20% \t Valid Loss: 3.611 \n",
            "Epoch: 92 \tTraining Loss:  0.271 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 4.418 \n",
            "Epoch: 93 \tTraining Loss:  0.332 \tTrain_Accu: 88%  \tValid_Acc:27% \t Valid Loss: 3.630 \n",
            "Epoch: 94 \tTraining Loss:  0.304 \tTrain_Accu: 89%  \tValid_Acc:36% \t Valid Loss: 4.528 \n",
            "Epoch: 95 \tTraining Loss:  0.309 \tTrain_Accu: 88%  \tValid_Acc:29% \t Valid Loss: 4.342 \n",
            "Epoch: 96 \tTraining Loss:  0.324 \tTrain_Accu: 87%  \tValid_Acc:39% \t Valid Loss: 3.253 \n",
            "Epoch: 97 \tTraining Loss:  0.334 \tTrain_Accu: 86%  \tValid_Acc:30% \t Valid Loss: 3.769 \n",
            "Epoch: 98 \tTraining Loss:  0.334 \tTrain_Accu: 86%  \tValid_Acc:30% \t Valid Loss: 3.774 \n",
            "Epoch: 99 \tTraining Loss:  0.350 \tTrain_Accu: 88%  \tValid_Acc:30% \t Valid Loss: 3.529 \n",
            "Epoch: 100 \tTraining Loss:  0.291 \tTrain_Accu: 88%  \tValid_Acc:33% \t Valid Loss: 4.776 \n",
            "Epoch: 101 \tTraining Loss:  0.261 \tTrain_Accu: 90%  \tValid_Acc:21% \t Valid Loss: 4.810 \n",
            "Epoch: 102 \tTraining Loss:  0.313 \tTrain_Accu: 89%  \tValid_Acc:21% \t Valid Loss: 4.006 \n",
            "Epoch: 103 \tTraining Loss:  0.274 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 4.695 \n",
            "Epoch: 104 \tTraining Loss:  0.282 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 4.044 \n",
            "Epoch: 105 \tTraining Loss:  0.286 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 3.631 \n",
            "Epoch: 106 \tTraining Loss:  0.281 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 3.377 \n",
            "Epoch: 107 \tTraining Loss:  0.285 \tTrain_Accu: 88%  \tValid_Acc:26% \t Valid Loss: 3.937 \n",
            "Epoch: 108 \tTraining Loss:  0.261 \tTrain_Accu: 89%  \tValid_Acc:24% \t Valid Loss: 5.692 \n",
            "Epoch: 109 \tTraining Loss:  0.287 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 3.328 \n",
            "Epoch: 110 \tTraining Loss:  0.342 \tTrain_Accu: 87%  \tValid_Acc:30% \t Valid Loss: 4.156 \n",
            "Epoch: 111 \tTraining Loss:  0.236 \tTrain_Accu: 92%  \tValid_Acc:24% \t Valid Loss: 5.022 \n",
            "Epoch: 112 \tTraining Loss:  0.274 \tTrain_Accu: 88%  \tValid_Acc:26% \t Valid Loss: 3.345 \n",
            "Epoch: 113 \tTraining Loss:  0.219 \tTrain_Accu: 92%  \tValid_Acc:31% \t Valid Loss: 4.503 \n",
            "Epoch: 114 \tTraining Loss:  0.308 \tTrain_Accu: 88%  \tValid_Acc:27% \t Valid Loss: 4.563 \n",
            "Epoch: 115 \tTraining Loss:  0.295 \tTrain_Accu: 90%  \tValid_Acc:24% \t Valid Loss: 4.685 \n",
            "Epoch: 116 \tTraining Loss:  0.225 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 5.179 \n",
            "Epoch: 117 \tTraining Loss:  0.262 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 4.012 \n",
            "Epoch: 118 \tTraining Loss:  0.240 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 4.900 \n",
            "Epoch: 119 \tTraining Loss:  0.307 \tTrain_Accu: 88%  \tValid_Acc:24% \t Valid Loss: 3.042 \n",
            "Epoch: 120 \tTraining Loss:  0.296 \tTrain_Accu: 89%  \tValid_Acc:34% \t Valid Loss: 4.883 \n",
            "Epoch: 121 \tTraining Loss:  0.273 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 4.581 \n",
            "Epoch: 122 \tTraining Loss:  0.192 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 5.896 \n",
            "Epoch: 123 \tTraining Loss:  0.210 \tTrain_Accu: 92%  \tValid_Acc:37% \t Valid Loss: 4.168 \n",
            "Epoch: 124 \tTraining Loss:  0.273 \tTrain_Accu: 90%  \tValid_Acc:24% \t Valid Loss: 5.168 \n",
            "Epoch: 125 \tTraining Loss:  0.288 \tTrain_Accu: 90%  \tValid_Acc:39% \t Valid Loss: 3.534 \n",
            "Epoch: 126 \tTraining Loss:  0.262 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 4.399 \n",
            "Epoch: 127 \tTraining Loss:  0.224 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 3.781 \n",
            "Epoch: 128 \tTraining Loss:  0.285 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 4.307 \n",
            "Epoch: 129 \tTraining Loss:  0.329 \tTrain_Accu: 86%  \tValid_Acc:26% \t Valid Loss: 3.954 \n",
            "Epoch: 130 \tTraining Loss:  0.269 \tTrain_Accu: 87%  \tValid_Acc:27% \t Valid Loss: 3.991 \n",
            "Epoch: 131 \tTraining Loss:  0.242 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 4.030 \n",
            "Epoch: 132 \tTraining Loss:  0.281 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 5.158 \n",
            "Epoch: 133 \tTraining Loss:  0.274 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 4.139 \n",
            "Epoch: 134 \tTraining Loss:  0.335 \tTrain_Accu: 87%  \tValid_Acc:21% \t Valid Loss: 3.517 \n",
            "Epoch: 135 \tTraining Loss:  0.244 \tTrain_Accu: 88%  \tValid_Acc:24% \t Valid Loss: 5.182 \n",
            "Epoch: 136 \tTraining Loss:  0.195 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 5.449 \n",
            "Epoch: 137 \tTraining Loss:  0.275 \tTrain_Accu: 88%  \tValid_Acc:29% \t Valid Loss: 4.589 \n",
            "Epoch: 138 \tTraining Loss:  0.206 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 4.518 \n",
            "Epoch: 139 \tTraining Loss:  0.271 \tTrain_Accu: 88%  \tValid_Acc:19% \t Valid Loss: 5.156 \n",
            "Epoch: 140 \tTraining Loss:  0.252 \tTrain_Accu: 90%  \tValid_Acc:34% \t Valid Loss: 3.666 \n",
            "Epoch: 141 \tTraining Loss:  0.294 \tTrain_Accu: 87%  \tValid_Acc:34% \t Valid Loss: 4.868 \n",
            "Epoch: 142 \tTraining Loss:  0.185 \tTrain_Accu: 92%  \tValid_Acc:37% \t Valid Loss: 4.778 \n",
            "Epoch: 143 \tTraining Loss:  0.184 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 5.014 \n",
            "Epoch: 144 \tTraining Loss:  0.268 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 4.078 \n",
            "Epoch: 145 \tTraining Loss:  0.205 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 4.788 \n",
            "Epoch: 146 \tTraining Loss:  0.241 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 4.450 \n",
            "Epoch: 147 \tTraining Loss:  0.201 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 4.805 \n",
            "Epoch: 148 \tTraining Loss:  0.219 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 6.106 \n",
            "Epoch: 149 \tTraining Loss:  0.355 \tTrain_Accu: 89%  \tValid_Acc:27% \t Valid Loss: 3.592 \n",
            "Epoch: 150 \tTraining Loss:  0.196 \tTrain_Accu: 93%  \tValid_Acc:30% \t Valid Loss: 4.460 \n",
            "Epoch: 151 \tTraining Loss:  0.224 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 4.268 \n",
            "Epoch: 152 \tTraining Loss:  0.229 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 5.405 \n",
            "Epoch: 153 \tTraining Loss:  0.210 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 4.240 \n",
            "Epoch: 154 \tTraining Loss:  0.244 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 5.037 \n",
            "Epoch: 155 \tTraining Loss:  0.236 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 5.002 \n",
            "Epoch: 156 \tTraining Loss:  0.157 \tTrain_Accu: 94%  \tValid_Acc:31% \t Valid Loss: 5.454 \n",
            "Epoch: 157 \tTraining Loss:  0.242 \tTrain_Accu: 90%  \tValid_Acc:21% \t Valid Loss: 5.215 \n",
            "Epoch: 158 \tTraining Loss:  0.232 \tTrain_Accu: 91%  \tValid_Acc:31% \t Valid Loss: 5.154 \n",
            "Epoch: 159 \tTraining Loss:  0.183 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 5.564 \n",
            "Epoch: 160 \tTraining Loss:  0.190 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 4.462 \n",
            "Epoch: 161 \tTraining Loss:  0.190 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 4.604 \n",
            "Epoch: 162 \tTraining Loss:  0.205 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 5.519 \n",
            "Epoch: 163 \tTraining Loss:  0.221 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 5.235 \n",
            "Epoch: 164 \tTraining Loss:  0.212 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 4.333 \n",
            "Epoch: 165 \tTraining Loss:  0.207 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 5.119 \n",
            "Epoch: 166 \tTraining Loss:  0.189 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 5.041 \n",
            "Epoch: 167 \tTraining Loss:  0.211 \tTrain_Accu: 93%  \tValid_Acc:20% \t Valid Loss: 4.949 \n",
            "Epoch: 168 \tTraining Loss:  0.271 \tTrain_Accu: 90%  \tValid_Acc:33% \t Valid Loss: 3.604 \n",
            "Epoch: 169 \tTraining Loss:  0.239 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 5.471 \n",
            "Epoch: 170 \tTraining Loss:  0.272 \tTrain_Accu: 90%  \tValid_Acc:34% \t Valid Loss: 3.641 \n",
            "Epoch: 171 \tTraining Loss:  0.205 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 6.947 \n",
            "Epoch: 172 \tTraining Loss:  0.206 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 5.973 \n",
            "Epoch: 173 \tTraining Loss:  0.256 \tTrain_Accu: 89%  \tValid_Acc:29% \t Valid Loss: 4.265 \n",
            "Epoch: 174 \tTraining Loss:  0.257 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 6.464 \n",
            "Epoch: 175 \tTraining Loss:  0.204 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 5.115 \n",
            "Epoch: 176 \tTraining Loss:  0.206 \tTrain_Accu: 92%  \tValid_Acc:36% \t Valid Loss: 3.975 \n",
            "Epoch: 177 \tTraining Loss:  0.249 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 4.873 \n",
            "Epoch: 178 \tTraining Loss:  0.174 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 5.812 \n",
            "Epoch: 179 \tTraining Loss:  0.215 \tTrain_Accu: 89%  \tValid_Acc:29% \t Valid Loss: 5.882 \n",
            "Epoch: 180 \tTraining Loss:  0.203 \tTrain_Accu: 92%  \tValid_Acc:34% \t Valid Loss: 3.616 \n",
            "Epoch: 181 \tTraining Loss:  0.161 \tTrain_Accu: 94%  \tValid_Acc:21% \t Valid Loss: 5.485 \n",
            "Epoch: 182 \tTraining Loss:  0.303 \tTrain_Accu: 87%  \tValid_Acc:30% \t Valid Loss: 5.175 \n",
            "Epoch: 183 \tTraining Loss:  0.225 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 4.472 \n",
            "Epoch: 184 \tTraining Loss:  0.218 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 4.281 \n",
            "Epoch: 185 \tTraining Loss:  0.209 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 5.067 \n",
            "Epoch: 186 \tTraining Loss:  0.188 \tTrain_Accu: 93%  \tValid_Acc:30% \t Valid Loss: 4.957 \n",
            "Epoch: 187 \tTraining Loss:  0.229 \tTrain_Accu: 92%  \tValid_Acc:23% \t Valid Loss: 4.059 \n",
            "Epoch: 188 \tTraining Loss:  0.176 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 5.715 \n",
            "Epoch: 189 \tTraining Loss:  0.270 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 4.378 \n",
            "Epoch: 190 \tTraining Loss:  0.183 \tTrain_Accu: 92%  \tValid_Acc:31% \t Valid Loss: 5.286 \n",
            "Epoch: 191 \tTraining Loss:  0.167 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 5.400 \n",
            "Epoch: 192 \tTraining Loss:  0.219 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 5.942 \n",
            "Epoch: 193 \tTraining Loss:  0.253 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 5.390 \n",
            "Epoch: 194 \tTraining Loss:  0.192 \tTrain_Accu: 92%  \tValid_Acc:23% \t Valid Loss: 4.775 \n",
            "Epoch: 195 \tTraining Loss:  0.198 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 6.122 \n",
            "Epoch: 196 \tTraining Loss:  0.220 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 5.611 \n",
            "Epoch: 197 \tTraining Loss:  0.254 \tTrain_Accu: 91%  \tValid_Acc:31% \t Valid Loss: 5.203 \n",
            "Epoch: 198 \tTraining Loss:  0.211 \tTrain_Accu: 92%  \tValid_Acc:31% \t Valid Loss: 5.171 \n",
            "Epoch: 199 \tTraining Loss:  0.245 \tTrain_Accu: 90%  \tValid_Acc:31% \t Valid Loss: 4.464 \n",
            "Epoch: 200 \tTraining Loss:  0.246 \tTrain_Accu: 92%  \tValid_Acc:31% \t Valid Loss: 4.180 \n",
            "Epoch: 201 \tTraining Loss:  0.213 \tTrain_Accu: 92%  \tValid_Acc:23% \t Valid Loss: 4.657 \n",
            "Epoch: 202 \tTraining Loss:  0.199 \tTrain_Accu: 91%  \tValid_Acc:31% \t Valid Loss: 5.313 \n",
            "Epoch: 203 \tTraining Loss:  0.240 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 5.876 \n",
            "Epoch: 204 \tTraining Loss:  0.147 \tTrain_Accu: 94%  \tValid_Acc:31% \t Valid Loss: 5.735 \n",
            "Epoch: 205 \tTraining Loss:  0.230 \tTrain_Accu: 90%  \tValid_Acc:34% \t Valid Loss: 4.255 \n",
            "Epoch: 206 \tTraining Loss:  0.207 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 5.262 \n",
            "Epoch: 207 \tTraining Loss:  0.193 \tTrain_Accu: 93%  \tValid_Acc:33% \t Valid Loss: 5.967 \n",
            "Epoch: 208 \tTraining Loss:  0.281 \tTrain_Accu: 90%  \tValid_Acc:24% \t Valid Loss: 4.960 \n",
            "Epoch: 209 \tTraining Loss:  0.199 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 4.636 \n",
            "Epoch: 210 \tTraining Loss:  0.199 \tTrain_Accu: 91%  \tValid_Acc:20% \t Valid Loss: 5.757 \n",
            "Epoch: 211 \tTraining Loss:  0.161 \tTrain_Accu: 93%  \tValid_Acc:39% \t Valid Loss: 5.393 \n",
            "Epoch: 212 \tTraining Loss:  0.194 \tTrain_Accu: 92%  \tValid_Acc:37% \t Valid Loss: 6.339 \n",
            "Epoch: 213 \tTraining Loss:  0.208 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 5.589 \n",
            "Epoch: 214 \tTraining Loss:  0.163 \tTrain_Accu: 94%  \tValid_Acc:31% \t Valid Loss: 5.063 \n",
            "Epoch: 215 \tTraining Loss:  0.183 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 7.384 \n",
            "Epoch: 216 \tTraining Loss:  0.224 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 5.215 \n",
            "Epoch: 217 \tTraining Loss:  0.261 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 6.418 \n",
            "Epoch: 218 \tTraining Loss:  0.226 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 6.418 \n",
            "Epoch: 219 \tTraining Loss:  0.202 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 5.004 \n",
            "Epoch: 220 \tTraining Loss:  0.204 \tTrain_Accu: 94%  \tValid_Acc:19% \t Valid Loss: 6.012 \n",
            "Epoch: 221 \tTraining Loss:  0.157 \tTrain_Accu: 94%  \tValid_Acc:21% \t Valid Loss: 6.619 \n",
            "Epoch: 222 \tTraining Loss:  0.198 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 4.799 \n",
            "Epoch: 223 \tTraining Loss:  0.202 \tTrain_Accu: 92%  \tValid_Acc:24% \t Valid Loss: 5.704 \n",
            "Epoch: 224 \tTraining Loss:  0.131 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 7.086 \n",
            "Epoch: 225 \tTraining Loss:  0.249 \tTrain_Accu: 89%  \tValid_Acc:36% \t Valid Loss: 5.062 \n",
            "Epoch: 226 \tTraining Loss:  0.245 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 4.848 \n",
            "Epoch: 227 \tTraining Loss:  0.201 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 7.051 \n",
            "Epoch: 228 \tTraining Loss:  0.269 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 5.441 \n",
            "Epoch: 229 \tTraining Loss:  0.190 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 6.684 \n",
            "Epoch: 230 \tTraining Loss:  0.163 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 6.178 \n",
            "Epoch: 231 \tTraining Loss:  0.196 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 6.556 \n",
            "Epoch: 232 \tTraining Loss:  0.168 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 5.694 \n",
            "Epoch: 233 \tTraining Loss:  0.209 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 4.163 \n",
            "Epoch: 234 \tTraining Loss:  0.175 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 6.205 \n",
            "Epoch: 235 \tTraining Loss:  0.222 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 5.214 \n",
            "Epoch: 236 \tTraining Loss:  0.198 \tTrain_Accu: 92%  \tValid_Acc:33% \t Valid Loss: 5.440 \n",
            "Epoch: 237 \tTraining Loss:  0.245 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 4.334 \n",
            "Epoch: 238 \tTraining Loss:  0.158 \tTrain_Accu: 94%  \tValid_Acc:31% \t Valid Loss: 6.039 \n",
            "Epoch: 239 \tTraining Loss:  0.216 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 7.950 \n",
            "Epoch: 240 \tTraining Loss:  0.130 \tTrain_Accu: 96%  \tValid_Acc:29% \t Valid Loss: 5.496 \n",
            "Epoch: 241 \tTraining Loss:  0.238 \tTrain_Accu: 90%  \tValid_Acc:31% \t Valid Loss: 5.177 \n",
            "Epoch: 242 \tTraining Loss:  0.183 \tTrain_Accu: 93%  \tValid_Acc:33% \t Valid Loss: 6.047 \n",
            "Epoch: 243 \tTraining Loss:  0.238 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 5.599 \n",
            "Epoch: 244 \tTraining Loss:  0.219 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 5.818 \n",
            "Epoch: 245 \tTraining Loss:  0.168 \tTrain_Accu: 94%  \tValid_Acc:36% \t Valid Loss: 5.291 \n",
            "Epoch: 246 \tTraining Loss:  0.164 \tTrain_Accu: 94%  \tValid_Acc:36% \t Valid Loss: 6.615 \n",
            "Epoch: 247 \tTraining Loss:  0.229 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 5.889 \n",
            "Epoch: 248 \tTraining Loss:  0.237 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 5.411 \n",
            "Epoch: 249 \tTraining Loss:  0.231 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 5.726 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 02:00:48,492]\u001b[0m Trial 8 finished with value: 32.9 and parameters: {'lr': 0.0001, 'dropout': 0.7}. Best is trial 8 with value: 32.9.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.224 \tTrain_Accu: 92%  \tValid_Acc:33% \t Valid Loss: 4.763 \n",
            "Epoch: 1 \tTraining Loss:  1.669 \tTrain_Accu: 21%  \tValid_Acc:14% \t Valid Loss: 1.625 \n",
            "Epoch: 2 \tTraining Loss:  1.604 \tTrain_Accu: 25%  \tValid_Acc:17% \t Valid Loss: 1.634 \n",
            "Epoch: 3 \tTraining Loss:  1.599 \tTrain_Accu: 22%  \tValid_Acc:27% \t Valid Loss: 1.596 \n",
            "Epoch: 4 \tTraining Loss:  1.560 \tTrain_Accu: 28%  \tValid_Acc:17% \t Valid Loss: 1.651 \n",
            "Epoch: 5 \tTraining Loss:  1.543 \tTrain_Accu: 29%  \tValid_Acc:16% \t Valid Loss: 1.666 \n",
            "Epoch: 6 \tTraining Loss:  1.560 \tTrain_Accu: 27%  \tValid_Acc:20% \t Valid Loss: 1.606 \n",
            "Epoch: 7 \tTraining Loss:  1.528 \tTrain_Accu: 31%  \tValid_Acc:16% \t Valid Loss: 1.750 \n",
            "Epoch: 8 \tTraining Loss:  1.493 \tTrain_Accu: 30%  \tValid_Acc:29% \t Valid Loss: 1.562 \n",
            "Epoch: 9 \tTraining Loss:  1.498 \tTrain_Accu: 35%  \tValid_Acc:20% \t Valid Loss: 1.653 \n",
            "Epoch: 10 \tTraining Loss:  1.459 \tTrain_Accu: 37%  \tValid_Acc:23% \t Valid Loss: 1.570 \n",
            "Epoch: 11 \tTraining Loss:  1.413 \tTrain_Accu: 39%  \tValid_Acc:17% \t Valid Loss: 1.680 \n",
            "Epoch: 12 \tTraining Loss:  1.397 \tTrain_Accu: 41%  \tValid_Acc:17% \t Valid Loss: 1.679 \n",
            "Epoch: 13 \tTraining Loss:  1.400 \tTrain_Accu: 42%  \tValid_Acc:20% \t Valid Loss: 1.625 \n",
            "Epoch: 14 \tTraining Loss:  1.380 \tTrain_Accu: 40%  \tValid_Acc:23% \t Valid Loss: 1.655 \n",
            "Epoch: 15 \tTraining Loss:  1.305 \tTrain_Accu: 44%  \tValid_Acc:26% \t Valid Loss: 1.730 \n",
            "Epoch: 16 \tTraining Loss:  1.326 \tTrain_Accu: 42%  \tValid_Acc:26% \t Valid Loss: 1.681 \n",
            "Epoch: 17 \tTraining Loss:  1.303 \tTrain_Accu: 42%  \tValid_Acc:24% \t Valid Loss: 1.733 \n",
            "Epoch: 18 \tTraining Loss:  1.332 \tTrain_Accu: 40%  \tValid_Acc:19% \t Valid Loss: 1.712 \n",
            "Epoch: 19 \tTraining Loss:  1.220 \tTrain_Accu: 47%  \tValid_Acc:23% \t Valid Loss: 1.825 \n",
            "Epoch: 20 \tTraining Loss:  1.173 \tTrain_Accu: 50%  \tValid_Acc:30% \t Valid Loss: 1.767 \n",
            "Epoch: 21 \tTraining Loss:  1.195 \tTrain_Accu: 48%  \tValid_Acc:19% \t Valid Loss: 1.802 \n",
            "Epoch: 22 \tTraining Loss:  1.151 \tTrain_Accu: 51%  \tValid_Acc:27% \t Valid Loss: 1.722 \n",
            "Epoch: 23 \tTraining Loss:  1.145 \tTrain_Accu: 51%  \tValid_Acc:26% \t Valid Loss: 1.964 \n",
            "Epoch: 24 \tTraining Loss:  1.109 \tTrain_Accu: 57%  \tValid_Acc:13% \t Valid Loss: 1.947 \n",
            "Epoch: 25 \tTraining Loss:  1.054 \tTrain_Accu: 56%  \tValid_Acc:29% \t Valid Loss: 1.879 \n",
            "Epoch: 26 \tTraining Loss:  1.013 \tTrain_Accu: 57%  \tValid_Acc:27% \t Valid Loss: 2.330 \n",
            "Epoch: 27 \tTraining Loss:  1.101 \tTrain_Accu: 54%  \tValid_Acc:21% \t Valid Loss: 1.815 \n",
            "Epoch: 28 \tTraining Loss:  0.980 \tTrain_Accu: 60%  \tValid_Acc:29% \t Valid Loss: 1.843 \n",
            "Epoch: 29 \tTraining Loss:  0.924 \tTrain_Accu: 56%  \tValid_Acc:27% \t Valid Loss: 1.851 \n",
            "Epoch: 30 \tTraining Loss:  0.948 \tTrain_Accu: 58%  \tValid_Acc:26% \t Valid Loss: 1.873 \n",
            "Epoch: 31 \tTraining Loss:  0.927 \tTrain_Accu: 58%  \tValid_Acc:26% \t Valid Loss: 1.970 \n",
            "Epoch: 32 \tTraining Loss:  0.940 \tTrain_Accu: 59%  \tValid_Acc:21% \t Valid Loss: 1.819 \n",
            "Epoch: 33 \tTraining Loss:  0.869 \tTrain_Accu: 64%  \tValid_Acc:26% \t Valid Loss: 2.280 \n",
            "Epoch: 34 \tTraining Loss:  0.833 \tTrain_Accu: 68%  \tValid_Acc:29% \t Valid Loss: 2.062 \n",
            "Epoch: 35 \tTraining Loss:  0.821 \tTrain_Accu: 66%  \tValid_Acc:24% \t Valid Loss: 1.855 \n",
            "Epoch: 36 \tTraining Loss:  0.820 \tTrain_Accu: 68%  \tValid_Acc:33% \t Valid Loss: 2.101 \n",
            "Epoch: 37 \tTraining Loss:  0.831 \tTrain_Accu: 65%  \tValid_Acc:33% \t Valid Loss: 1.986 \n",
            "Epoch: 38 \tTraining Loss:  0.717 \tTrain_Accu: 71%  \tValid_Acc:24% \t Valid Loss: 2.567 \n",
            "Epoch: 39 \tTraining Loss:  0.720 \tTrain_Accu: 72%  \tValid_Acc:26% \t Valid Loss: 2.433 \n",
            "Epoch: 40 \tTraining Loss:  0.805 \tTrain_Accu: 66%  \tValid_Acc:30% \t Valid Loss: 1.999 \n",
            "Epoch: 41 \tTraining Loss:  0.809 \tTrain_Accu: 67%  \tValid_Acc:24% \t Valid Loss: 2.283 \n",
            "Epoch: 42 \tTraining Loss:  0.685 \tTrain_Accu: 70%  \tValid_Acc:27% \t Valid Loss: 2.549 \n",
            "Epoch: 43 \tTraining Loss:  0.693 \tTrain_Accu: 69%  \tValid_Acc:27% \t Valid Loss: 1.972 \n",
            "Epoch: 44 \tTraining Loss:  0.729 \tTrain_Accu: 71%  \tValid_Acc:26% \t Valid Loss: 2.220 \n",
            "Epoch: 45 \tTraining Loss:  0.664 \tTrain_Accu: 71%  \tValid_Acc:20% \t Valid Loss: 2.781 \n",
            "Epoch: 46 \tTraining Loss:  0.642 \tTrain_Accu: 76%  \tValid_Acc:26% \t Valid Loss: 2.388 \n",
            "Epoch: 47 \tTraining Loss:  0.598 \tTrain_Accu: 78%  \tValid_Acc:17% \t Valid Loss: 2.827 \n",
            "Epoch: 48 \tTraining Loss:  0.589 \tTrain_Accu: 76%  \tValid_Acc:27% \t Valid Loss: 2.609 \n",
            "Epoch: 49 \tTraining Loss:  0.566 \tTrain_Accu: 79%  \tValid_Acc:27% \t Valid Loss: 2.598 \n",
            "Epoch: 50 \tTraining Loss:  0.554 \tTrain_Accu: 78%  \tValid_Acc:19% \t Valid Loss: 2.855 \n",
            "Epoch: 51 \tTraining Loss:  0.512 \tTrain_Accu: 80%  \tValid_Acc:26% \t Valid Loss: 2.530 \n",
            "Epoch: 52 \tTraining Loss:  0.495 \tTrain_Accu: 79%  \tValid_Acc:31% \t Valid Loss: 2.957 \n",
            "Epoch: 53 \tTraining Loss:  0.527 \tTrain_Accu: 79%  \tValid_Acc:30% \t Valid Loss: 2.397 \n",
            "Epoch: 54 \tTraining Loss:  0.418 \tTrain_Accu: 83%  \tValid_Acc:36% \t Valid Loss: 3.360 \n",
            "Epoch: 55 \tTraining Loss:  0.557 \tTrain_Accu: 75%  \tValid_Acc:29% \t Valid Loss: 2.996 \n",
            "Epoch: 56 \tTraining Loss:  0.506 \tTrain_Accu: 78%  \tValid_Acc:30% \t Valid Loss: 3.028 \n",
            "Epoch: 57 \tTraining Loss:  0.532 \tTrain_Accu: 79%  \tValid_Acc:24% \t Valid Loss: 3.305 \n",
            "Epoch: 58 \tTraining Loss:  0.496 \tTrain_Accu: 80%  \tValid_Acc:33% \t Valid Loss: 2.007 \n",
            "Epoch: 59 \tTraining Loss:  0.383 \tTrain_Accu: 86%  \tValid_Acc:21% \t Valid Loss: 3.614 \n",
            "Epoch: 60 \tTraining Loss:  0.466 \tTrain_Accu: 82%  \tValid_Acc:26% \t Valid Loss: 2.447 \n",
            "Epoch: 61 \tTraining Loss:  0.438 \tTrain_Accu: 83%  \tValid_Acc:27% \t Valid Loss: 2.831 \n",
            "Epoch: 62 \tTraining Loss:  0.581 \tTrain_Accu: 76%  \tValid_Acc:33% \t Valid Loss: 3.076 \n",
            "Epoch: 63 \tTraining Loss:  0.413 \tTrain_Accu: 84%  \tValid_Acc:29% \t Valid Loss: 3.231 \n",
            "Epoch: 64 \tTraining Loss:  0.427 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 2.327 \n",
            "Epoch: 65 \tTraining Loss:  0.440 \tTrain_Accu: 80%  \tValid_Acc:29% \t Valid Loss: 2.932 \n",
            "Epoch: 66 \tTraining Loss:  0.416 \tTrain_Accu: 84%  \tValid_Acc:36% \t Valid Loss: 2.902 \n",
            "Epoch: 67 \tTraining Loss:  0.430 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 3.253 \n",
            "Epoch: 68 \tTraining Loss:  0.454 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 3.081 \n",
            "Epoch: 69 \tTraining Loss:  0.429 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 3.456 \n",
            "Epoch: 70 \tTraining Loss:  0.406 \tTrain_Accu: 84%  \tValid_Acc:24% \t Valid Loss: 3.741 \n",
            "Epoch: 71 \tTraining Loss:  0.399 \tTrain_Accu: 85%  \tValid_Acc:24% \t Valid Loss: 3.241 \n",
            "Epoch: 72 \tTraining Loss:  0.360 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 3.800 \n",
            "Epoch: 73 \tTraining Loss:  0.381 \tTrain_Accu: 85%  \tValid_Acc:27% \t Valid Loss: 3.008 \n",
            "Epoch: 74 \tTraining Loss:  0.368 \tTrain_Accu: 85%  \tValid_Acc:31% \t Valid Loss: 3.505 \n",
            "Epoch: 75 \tTraining Loss:  0.342 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 3.812 \n",
            "Epoch: 76 \tTraining Loss:  0.410 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 3.207 \n",
            "Epoch: 77 \tTraining Loss:  0.369 \tTrain_Accu: 86%  \tValid_Acc:26% \t Valid Loss: 3.437 \n",
            "Epoch: 78 \tTraining Loss:  0.349 \tTrain_Accu: 86%  \tValid_Acc:27% \t Valid Loss: 2.995 \n",
            "Epoch: 79 \tTraining Loss:  0.363 \tTrain_Accu: 85%  \tValid_Acc:27% \t Valid Loss: 3.013 \n",
            "Epoch: 80 \tTraining Loss:  0.369 \tTrain_Accu: 86%  \tValid_Acc:29% \t Valid Loss: 4.615 \n",
            "Epoch: 81 \tTraining Loss:  0.326 \tTrain_Accu: 87%  \tValid_Acc:33% \t Valid Loss: 3.007 \n",
            "Epoch: 82 \tTraining Loss:  0.404 \tTrain_Accu: 85%  \tValid_Acc:27% \t Valid Loss: 3.435 \n",
            "Epoch: 83 \tTraining Loss:  0.339 \tTrain_Accu: 87%  \tValid_Acc:23% \t Valid Loss: 3.711 \n",
            "Epoch: 84 \tTraining Loss:  0.357 \tTrain_Accu: 88%  \tValid_Acc:30% \t Valid Loss: 3.540 \n",
            "Epoch: 85 \tTraining Loss:  0.323 \tTrain_Accu: 87%  \tValid_Acc:21% \t Valid Loss: 3.726 \n",
            "Epoch: 86 \tTraining Loss:  0.314 \tTrain_Accu: 90%  \tValid_Acc:19% \t Valid Loss: 4.753 \n",
            "Epoch: 87 \tTraining Loss:  0.303 \tTrain_Accu: 87%  \tValid_Acc:31% \t Valid Loss: 4.007 \n",
            "Epoch: 88 \tTraining Loss:  0.324 \tTrain_Accu: 87%  \tValid_Acc:31% \t Valid Loss: 4.760 \n",
            "Epoch: 89 \tTraining Loss:  0.284 \tTrain_Accu: 88%  \tValid_Acc:30% \t Valid Loss: 3.209 \n",
            "Epoch: 90 \tTraining Loss:  0.340 \tTrain_Accu: 87%  \tValid_Acc:17% \t Valid Loss: 4.097 \n",
            "Epoch: 91 \tTraining Loss:  0.285 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 3.874 \n",
            "Epoch: 92 \tTraining Loss:  0.280 \tTrain_Accu: 89%  \tValid_Acc:36% \t Valid Loss: 3.374 \n",
            "Epoch: 93 \tTraining Loss:  0.313 \tTrain_Accu: 88%  \tValid_Acc:21% \t Valid Loss: 3.857 \n",
            "Epoch: 94 \tTraining Loss:  0.327 \tTrain_Accu: 89%  \tValid_Acc:29% \t Valid Loss: 4.032 \n",
            "Epoch: 95 \tTraining Loss:  0.272 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 4.081 \n",
            "Epoch: 96 \tTraining Loss:  0.333 \tTrain_Accu: 88%  \tValid_Acc:30% \t Valid Loss: 3.865 \n",
            "Epoch: 97 \tTraining Loss:  0.261 \tTrain_Accu: 90%  \tValid_Acc:33% \t Valid Loss: 4.487 \n",
            "Epoch: 98 \tTraining Loss:  0.302 \tTrain_Accu: 87%  \tValid_Acc:24% \t Valid Loss: 4.229 \n",
            "Epoch: 99 \tTraining Loss:  0.337 \tTrain_Accu: 88%  \tValid_Acc:24% \t Valid Loss: 3.306 \n",
            "Epoch: 100 \tTraining Loss:  0.324 \tTrain_Accu: 86%  \tValid_Acc:33% \t Valid Loss: 4.069 \n",
            "Epoch: 101 \tTraining Loss:  0.252 \tTrain_Accu: 90%  \tValid_Acc:21% \t Valid Loss: 4.263 \n",
            "Epoch: 102 \tTraining Loss:  0.281 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 4.420 \n",
            "Epoch: 103 \tTraining Loss:  0.259 \tTrain_Accu: 89%  \tValid_Acc:33% \t Valid Loss: 4.706 \n",
            "Epoch: 104 \tTraining Loss:  0.301 \tTrain_Accu: 88%  \tValid_Acc:24% \t Valid Loss: 3.711 \n",
            "Epoch: 105 \tTraining Loss:  0.257 \tTrain_Accu: 90%  \tValid_Acc:34% \t Valid Loss: 3.463 \n",
            "Epoch: 106 \tTraining Loss:  0.287 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 3.373 \n",
            "Epoch: 107 \tTraining Loss:  0.292 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 4.976 \n",
            "Epoch: 108 \tTraining Loss:  0.285 \tTrain_Accu: 89%  \tValid_Acc:24% \t Valid Loss: 4.435 \n",
            "Epoch: 109 \tTraining Loss:  0.289 \tTrain_Accu: 88%  \tValid_Acc:24% \t Valid Loss: 4.125 \n",
            "Epoch: 110 \tTraining Loss:  0.254 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 5.367 \n",
            "Epoch: 111 \tTraining Loss:  0.292 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 4.223 \n",
            "Epoch: 112 \tTraining Loss:  0.276 \tTrain_Accu: 87%  \tValid_Acc:24% \t Valid Loss: 3.783 \n",
            "Epoch: 113 \tTraining Loss:  0.223 \tTrain_Accu: 91%  \tValid_Acc:36% \t Valid Loss: 4.737 \n",
            "Epoch: 114 \tTraining Loss:  0.291 \tTrain_Accu: 87%  \tValid_Acc:19% \t Valid Loss: 5.123 \n",
            "Epoch: 115 \tTraining Loss:  0.262 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 5.071 \n",
            "Epoch: 116 \tTraining Loss:  0.254 \tTrain_Accu: 91%  \tValid_Acc:37% \t Valid Loss: 6.055 \n",
            "Epoch: 117 \tTraining Loss:  0.258 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 4.093 \n",
            "Epoch: 118 \tTraining Loss:  0.221 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 4.576 \n",
            "Epoch: 119 \tTraining Loss:  0.255 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 3.099 \n",
            "Epoch: 120 \tTraining Loss:  0.276 \tTrain_Accu: 88%  \tValid_Acc:29% \t Valid Loss: 5.065 \n",
            "Epoch: 121 \tTraining Loss:  0.318 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 4.069 \n",
            "Epoch: 122 \tTraining Loss:  0.225 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 4.195 \n",
            "Epoch: 123 \tTraining Loss:  0.236 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 5.017 \n",
            "Epoch: 124 \tTraining Loss:  0.269 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 4.290 \n",
            "Epoch: 125 \tTraining Loss:  0.293 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 3.194 \n",
            "Epoch: 126 \tTraining Loss:  0.231 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 5.401 \n",
            "Epoch: 127 \tTraining Loss:  0.277 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 3.768 \n",
            "Epoch: 128 \tTraining Loss:  0.280 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 4.429 \n",
            "Epoch: 129 \tTraining Loss:  0.294 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 3.662 \n",
            "Epoch: 130 \tTraining Loss:  0.252 \tTrain_Accu: 89%  \tValid_Acc:20% \t Valid Loss: 4.390 \n",
            "Epoch: 131 \tTraining Loss:  0.202 \tTrain_Accu: 93%  \tValid_Acc:30% \t Valid Loss: 4.801 \n",
            "Epoch: 132 \tTraining Loss:  0.278 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 4.471 \n",
            "Epoch: 133 \tTraining Loss:  0.270 \tTrain_Accu: 90%  \tValid_Acc:20% \t Valid Loss: 4.898 \n",
            "Epoch: 134 \tTraining Loss:  0.308 \tTrain_Accu: 88%  \tValid_Acc:19% \t Valid Loss: 3.483 \n",
            "Epoch: 135 \tTraining Loss:  0.258 \tTrain_Accu: 90%  \tValid_Acc:24% \t Valid Loss: 4.717 \n",
            "Epoch: 136 \tTraining Loss:  0.242 \tTrain_Accu: 90%  \tValid_Acc:20% \t Valid Loss: 5.785 \n",
            "Epoch: 137 \tTraining Loss:  0.237 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 4.029 \n",
            "Epoch: 138 \tTraining Loss:  0.188 \tTrain_Accu: 93%  \tValid_Acc:20% \t Valid Loss: 4.563 \n",
            "Epoch: 139 \tTraining Loss:  0.329 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 5.012 \n",
            "Epoch: 140 \tTraining Loss:  0.258 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 3.429 \n",
            "Epoch: 141 \tTraining Loss:  0.258 \tTrain_Accu: 89%  \tValid_Acc:31% \t Valid Loss: 4.507 \n",
            "Epoch: 142 \tTraining Loss:  0.244 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 4.498 \n",
            "Epoch: 143 \tTraining Loss:  0.190 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 4.634 \n",
            "Epoch: 144 \tTraining Loss:  0.228 \tTrain_Accu: 91%  \tValid_Acc:34% \t Valid Loss: 3.796 \n",
            "Epoch: 145 \tTraining Loss:  0.154 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 4.512 \n",
            "Epoch: 146 \tTraining Loss:  0.247 \tTrain_Accu: 90%  \tValid_Acc:31% \t Valid Loss: 5.282 \n",
            "Epoch: 147 \tTraining Loss:  0.213 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 5.222 \n",
            "Epoch: 148 \tTraining Loss:  0.199 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 5.065 \n",
            "Epoch: 149 \tTraining Loss:  0.344 \tTrain_Accu: 87%  \tValid_Acc:24% \t Valid Loss: 3.328 \n",
            "Epoch: 150 \tTraining Loss:  0.262 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 4.553 \n",
            "Epoch: 151 \tTraining Loss:  0.240 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 4.405 \n",
            "Epoch: 152 \tTraining Loss:  0.226 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 4.386 \n",
            "Epoch: 153 \tTraining Loss:  0.217 \tTrain_Accu: 93%  \tValid_Acc:26% \t Valid Loss: 4.672 \n",
            "Epoch: 154 \tTraining Loss:  0.170 \tTrain_Accu: 93%  \tValid_Acc:31% \t Valid Loss: 5.741 \n",
            "Epoch: 155 \tTraining Loss:  0.218 \tTrain_Accu: 91%  \tValid_Acc:31% \t Valid Loss: 4.370 \n",
            "Epoch: 156 \tTraining Loss:  0.182 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 5.126 \n",
            "Epoch: 157 \tTraining Loss:  0.243 \tTrain_Accu: 90%  \tValid_Acc:20% \t Valid Loss: 5.890 \n",
            "Epoch: 158 \tTraining Loss:  0.237 \tTrain_Accu: 91%  \tValid_Acc:21% \t Valid Loss: 5.013 \n",
            "Epoch: 159 \tTraining Loss:  0.210 \tTrain_Accu: 92%  \tValid_Acc:23% \t Valid Loss: 4.604 \n",
            "Epoch: 160 \tTraining Loss:  0.178 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 5.542 \n",
            "Epoch: 161 \tTraining Loss:  0.208 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 4.372 \n",
            "Epoch: 162 \tTraining Loss:  0.234 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 5.609 \n",
            "Epoch: 163 \tTraining Loss:  0.236 \tTrain_Accu: 90%  \tValid_Acc:20% \t Valid Loss: 5.913 \n",
            "Epoch: 164 \tTraining Loss:  0.217 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 3.517 \n",
            "Epoch: 165 \tTraining Loss:  0.225 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 5.730 \n",
            "Epoch: 166 \tTraining Loss:  0.183 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 4.737 \n",
            "Epoch: 167 \tTraining Loss:  0.203 \tTrain_Accu: 92%  \tValid_Acc:20% \t Valid Loss: 5.347 \n",
            "Epoch: 168 \tTraining Loss:  0.235 \tTrain_Accu: 93%  \tValid_Acc:19% \t Valid Loss: 4.507 \n",
            "Epoch: 169 \tTraining Loss:  0.203 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 6.146 \n",
            "Epoch: 170 \tTraining Loss:  0.316 \tTrain_Accu: 89%  \tValid_Acc:29% \t Valid Loss: 3.977 \n",
            "Epoch: 171 \tTraining Loss:  0.193 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 7.169 \n",
            "Epoch: 172 \tTraining Loss:  0.222 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 6.119 \n",
            "Epoch: 173 \tTraining Loss:  0.232 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 4.813 \n",
            "Epoch: 174 \tTraining Loss:  0.251 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 6.025 \n",
            "Epoch: 175 \tTraining Loss:  0.201 \tTrain_Accu: 93%  \tValid_Acc:30% \t Valid Loss: 5.536 \n",
            "Epoch: 176 \tTraining Loss:  0.241 \tTrain_Accu: 91%  \tValid_Acc:34% \t Valid Loss: 3.363 \n",
            "Epoch: 177 \tTraining Loss:  0.195 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 5.137 \n",
            "Epoch: 178 \tTraining Loss:  0.216 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 5.907 \n",
            "Epoch: 179 \tTraining Loss:  0.214 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 5.291 \n",
            "Epoch: 180 \tTraining Loss:  0.193 \tTrain_Accu: 93%  \tValid_Acc:34% \t Valid Loss: 4.597 \n",
            "Epoch: 181 \tTraining Loss:  0.186 \tTrain_Accu: 93%  \tValid_Acc:19% \t Valid Loss: 6.016 \n",
            "Epoch: 182 \tTraining Loss:  0.263 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 4.960 \n",
            "Epoch: 183 \tTraining Loss:  0.184 \tTrain_Accu: 94%  \tValid_Acc:21% \t Valid Loss: 5.597 \n",
            "Epoch: 184 \tTraining Loss:  0.207 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 4.471 \n",
            "Epoch: 185 \tTraining Loss:  0.225 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 6.248 \n",
            "Epoch: 186 \tTraining Loss:  0.221 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 5.292 \n",
            "Epoch: 187 \tTraining Loss:  0.211 \tTrain_Accu: 93%  \tValid_Acc:30% \t Valid Loss: 5.287 \n",
            "Epoch: 188 \tTraining Loss:  0.204 \tTrain_Accu: 93%  \tValid_Acc:26% \t Valid Loss: 6.544 \n",
            "Epoch: 189 \tTraining Loss:  0.219 \tTrain_Accu: 92%  \tValid_Acc:31% \t Valid Loss: 5.113 \n",
            "Epoch: 190 \tTraining Loss:  0.220 \tTrain_Accu: 92%  \tValid_Acc:33% \t Valid Loss: 4.415 \n",
            "Epoch: 191 \tTraining Loss:  0.153 \tTrain_Accu: 96%  \tValid_Acc:20% \t Valid Loss: 6.495 \n",
            "Epoch: 192 \tTraining Loss:  0.249 \tTrain_Accu: 93%  \tValid_Acc:26% \t Valid Loss: 5.333 \n",
            "Epoch: 193 \tTraining Loss:  0.230 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 5.078 \n",
            "Epoch: 194 \tTraining Loss:  0.222 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 5.724 \n",
            "Epoch: 195 \tTraining Loss:  0.190 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 7.825 \n",
            "Epoch: 196 \tTraining Loss:  0.207 \tTrain_Accu: 92%  \tValid_Acc:24% \t Valid Loss: 8.190 \n",
            "Epoch: 197 \tTraining Loss:  0.246 \tTrain_Accu: 91%  \tValid_Acc:31% \t Valid Loss: 4.938 \n",
            "Epoch: 198 \tTraining Loss:  0.207 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 4.557 \n",
            "Epoch: 199 \tTraining Loss:  0.199 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 5.974 \n",
            "Epoch: 200 \tTraining Loss:  0.223 \tTrain_Accu: 93%  \tValid_Acc:31% \t Valid Loss: 5.038 \n",
            "Epoch: 201 \tTraining Loss:  0.245 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 5.532 \n",
            "Epoch: 202 \tTraining Loss:  0.232 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 6.257 \n",
            "Epoch: 203 \tTraining Loss:  0.229 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 5.174 \n",
            "Epoch: 204 \tTraining Loss:  0.167 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 5.646 \n",
            "Epoch: 205 \tTraining Loss:  0.217 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 4.795 \n",
            "Epoch: 206 \tTraining Loss:  0.179 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 5.963 \n",
            "Epoch: 207 \tTraining Loss:  0.206 \tTrain_Accu: 92%  \tValid_Acc:33% \t Valid Loss: 6.767 \n",
            "Epoch: 208 \tTraining Loss:  0.231 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 6.484 \n",
            "Epoch: 209 \tTraining Loss:  0.160 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 7.934 \n",
            "Epoch: 210 \tTraining Loss:  0.203 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 6.136 \n",
            "Epoch: 211 \tTraining Loss:  0.174 \tTrain_Accu: 93%  \tValid_Acc:26% \t Valid Loss: 5.350 \n",
            "Epoch: 212 \tTraining Loss:  0.212 \tTrain_Accu: 91%  \tValid_Acc:33% \t Valid Loss: 6.136 \n",
            "Epoch: 213 \tTraining Loss:  0.214 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 5.301 \n",
            "Epoch: 214 \tTraining Loss:  0.196 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 3.933 \n",
            "Epoch: 215 \tTraining Loss:  0.172 \tTrain_Accu: 94%  \tValid_Acc:27% \t Valid Loss: 6.154 \n",
            "Epoch: 216 \tTraining Loss:  0.208 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 6.169 \n",
            "Epoch: 217 \tTraining Loss:  0.181 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 6.452 \n",
            "Epoch: 218 \tTraining Loss:  0.237 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 6.142 \n",
            "Epoch: 219 \tTraining Loss:  0.201 \tTrain_Accu: 93%  \tValid_Acc:31% \t Valid Loss: 5.133 \n",
            "Epoch: 220 \tTraining Loss:  0.184 \tTrain_Accu: 94%  \tValid_Acc:19% \t Valid Loss: 8.502 \n",
            "Epoch: 221 \tTraining Loss:  0.192 \tTrain_Accu: 94%  \tValid_Acc:21% \t Valid Loss: 6.158 \n",
            "Epoch: 222 \tTraining Loss:  0.228 \tTrain_Accu: 93%  \tValid_Acc:34% \t Valid Loss: 4.991 \n",
            "Epoch: 223 \tTraining Loss:  0.197 \tTrain_Accu: 93%  \tValid_Acc:26% \t Valid Loss: 6.364 \n",
            "Epoch: 224 \tTraining Loss:  0.189 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 6.277 \n",
            "Epoch: 225 \tTraining Loss:  0.225 \tTrain_Accu: 92%  \tValid_Acc:31% \t Valid Loss: 4.967 \n",
            "Epoch: 226 \tTraining Loss:  0.244 \tTrain_Accu: 92%  \tValid_Acc:24% \t Valid Loss: 4.618 \n",
            "Epoch: 227 \tTraining Loss:  0.165 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 7.753 \n",
            "Epoch: 228 \tTraining Loss:  0.237 \tTrain_Accu: 91%  \tValid_Acc:31% \t Valid Loss: 6.447 \n",
            "Epoch: 229 \tTraining Loss:  0.208 \tTrain_Accu: 94%  \tValid_Acc:19% \t Valid Loss: 7.541 \n",
            "Epoch: 230 \tTraining Loss:  0.150 \tTrain_Accu: 95%  \tValid_Acc:30% \t Valid Loss: 7.180 \n",
            "Epoch: 231 \tTraining Loss:  0.250 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 6.608 \n",
            "Epoch: 232 \tTraining Loss:  0.197 \tTrain_Accu: 93%  \tValid_Acc:34% \t Valid Loss: 4.881 \n",
            "Epoch: 233 \tTraining Loss:  0.188 \tTrain_Accu: 93%  \tValid_Acc:31% \t Valid Loss: 4.172 \n",
            "Epoch: 234 \tTraining Loss:  0.174 \tTrain_Accu: 94%  \tValid_Acc:31% \t Valid Loss: 5.967 \n",
            "Epoch: 235 \tTraining Loss:  0.212 \tTrain_Accu: 93%  \tValid_Acc:30% \t Valid Loss: 5.550 \n",
            "Epoch: 236 \tTraining Loss:  0.201 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 4.511 \n",
            "Epoch: 237 \tTraining Loss:  0.237 \tTrain_Accu: 93%  \tValid_Acc:31% \t Valid Loss: 4.443 \n",
            "Epoch: 238 \tTraining Loss:  0.179 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 5.912 \n",
            "Epoch: 239 \tTraining Loss:  0.250 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 5.884 \n",
            "Epoch: 240 \tTraining Loss:  0.140 \tTrain_Accu: 96%  \tValid_Acc:23% \t Valid Loss: 4.881 \n",
            "Epoch: 241 \tTraining Loss:  0.273 \tTrain_Accu: 91%  \tValid_Acc:33% \t Valid Loss: 5.773 \n",
            "Epoch: 242 \tTraining Loss:  0.223 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 7.652 \n",
            "Epoch: 243 \tTraining Loss:  0.190 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 5.604 \n",
            "Epoch: 244 \tTraining Loss:  0.213 \tTrain_Accu: 92%  \tValid_Acc:24% \t Valid Loss: 5.595 \n",
            "Epoch: 245 \tTraining Loss:  0.199 \tTrain_Accu: 94%  \tValid_Acc:31% \t Valid Loss: 5.781 \n",
            "Epoch: 246 \tTraining Loss:  0.178 \tTrain_Accu: 95%  \tValid_Acc:34% \t Valid Loss: 8.126 \n",
            "Epoch: 247 \tTraining Loss:  0.320 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 6.629 \n",
            "Epoch: 248 \tTraining Loss:  0.204 \tTrain_Accu: 93%  \tValid_Acc:30% \t Valid Loss: 5.384 \n",
            "Epoch: 249 \tTraining Loss:  0.244 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 6.838 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 02:05:03,469]\u001b[0m Trial 9 finished with value: 30.0 and parameters: {'lr': 0.0001, 'dropout': 0.7}. Best is trial 8 with value: 32.9.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.223 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 4.518 \n",
            "Epoch: 1 \tTraining Loss:  2.035 \tTrain_Accu: 18%  \tValid_Acc:9% \t Valid Loss: 1.628 \n",
            "Epoch: 2 \tTraining Loss:  1.617 \tTrain_Accu: 22%  \tValid_Acc:14% \t Valid Loss: 1.626 \n",
            "Epoch: 3 \tTraining Loss:  1.688 \tTrain_Accu: 20%  \tValid_Acc:10% \t Valid Loss: 1.631 \n",
            "Epoch: 4 \tTraining Loss:  1.654 \tTrain_Accu: 27%  \tValid_Acc:21% \t Valid Loss: 1.628 \n",
            "Epoch: 5 \tTraining Loss:  1.680 \tTrain_Accu: 20%  \tValid_Acc:19% \t Valid Loss: 1.627 \n",
            "Epoch: 6 \tTraining Loss:  1.616 \tTrain_Accu: 23%  \tValid_Acc:17% \t Valid Loss: 1.631 \n",
            "Epoch: 7 \tTraining Loss:  1.627 \tTrain_Accu: 21%  \tValid_Acc:14% \t Valid Loss: 1.631 \n",
            "Epoch: 8 \tTraining Loss:  1.631 \tTrain_Accu: 27%  \tValid_Acc:24% \t Valid Loss: 1.642 \n",
            "Epoch: 9 \tTraining Loss:  1.622 \tTrain_Accu: 26%  \tValid_Acc:19% \t Valid Loss: 1.634 \n",
            "Epoch: 10 \tTraining Loss:  1.594 \tTrain_Accu: 26%  \tValid_Acc:19% \t Valid Loss: 1.618 \n",
            "Epoch: 11 \tTraining Loss:  1.573 \tTrain_Accu: 27%  \tValid_Acc:24% \t Valid Loss: 1.638 \n",
            "Epoch: 12 \tTraining Loss:  1.617 \tTrain_Accu: 34%  \tValid_Acc:17% \t Valid Loss: 1.658 \n",
            "Epoch: 13 \tTraining Loss:  1.572 \tTrain_Accu: 29%  \tValid_Acc:21% \t Valid Loss: 1.644 \n",
            "Epoch: 14 \tTraining Loss:  1.529 \tTrain_Accu: 35%  \tValid_Acc:23% \t Valid Loss: 1.597 \n",
            "Epoch: 15 \tTraining Loss:  1.484 \tTrain_Accu: 34%  \tValid_Acc:24% \t Valid Loss: 1.580 \n",
            "Epoch: 16 \tTraining Loss:  1.493 \tTrain_Accu: 32%  \tValid_Acc:30% \t Valid Loss: 1.639 \n",
            "Epoch: 17 \tTraining Loss:  1.478 \tTrain_Accu: 33%  \tValid_Acc:20% \t Valid Loss: 1.664 \n",
            "Epoch: 18 \tTraining Loss:  1.419 \tTrain_Accu: 39%  \tValid_Acc:21% \t Valid Loss: 1.637 \n",
            "Epoch: 19 \tTraining Loss:  1.456 \tTrain_Accu: 39%  \tValid_Acc:20% \t Valid Loss: 1.702 \n",
            "Epoch: 20 \tTraining Loss:  1.387 \tTrain_Accu: 39%  \tValid_Acc:26% \t Valid Loss: 1.592 \n",
            "Epoch: 21 \tTraining Loss:  1.328 \tTrain_Accu: 42%  \tValid_Acc:23% \t Valid Loss: 1.744 \n",
            "Epoch: 22 \tTraining Loss:  1.263 \tTrain_Accu: 41%  \tValid_Acc:24% \t Valid Loss: 1.650 \n",
            "Epoch: 23 \tTraining Loss:  1.297 \tTrain_Accu: 41%  \tValid_Acc:20% \t Valid Loss: 1.753 \n",
            "Epoch: 24 \tTraining Loss:  1.244 \tTrain_Accu: 46%  \tValid_Acc:13% \t Valid Loss: 1.788 \n",
            "Epoch: 25 \tTraining Loss:  1.246 \tTrain_Accu: 46%  \tValid_Acc:20% \t Valid Loss: 1.865 \n",
            "Epoch: 26 \tTraining Loss:  1.242 \tTrain_Accu: 47%  \tValid_Acc:24% \t Valid Loss: 1.650 \n",
            "Epoch: 27 \tTraining Loss:  1.078 \tTrain_Accu: 50%  \tValid_Acc:29% \t Valid Loss: 1.847 \n",
            "Epoch: 28 \tTraining Loss:  1.170 \tTrain_Accu: 48%  \tValid_Acc:16% \t Valid Loss: 2.269 \n",
            "Epoch: 29 \tTraining Loss:  1.138 \tTrain_Accu: 54%  \tValid_Acc:29% \t Valid Loss: 2.022 \n",
            "Epoch: 30 \tTraining Loss:  1.139 \tTrain_Accu: 53%  \tValid_Acc:27% \t Valid Loss: 1.898 \n",
            "Epoch: 31 \tTraining Loss:  1.132 \tTrain_Accu: 49%  \tValid_Acc:24% \t Valid Loss: 2.054 \n",
            "Epoch: 32 \tTraining Loss:  0.986 \tTrain_Accu: 57%  \tValid_Acc:20% \t Valid Loss: 2.031 \n",
            "Epoch: 33 \tTraining Loss:  1.034 \tTrain_Accu: 54%  \tValid_Acc:24% \t Valid Loss: 1.857 \n",
            "Epoch: 34 \tTraining Loss:  1.071 \tTrain_Accu: 53%  \tValid_Acc:21% \t Valid Loss: 1.797 \n",
            "Epoch: 35 \tTraining Loss:  0.988 \tTrain_Accu: 57%  \tValid_Acc:23% \t Valid Loss: 1.997 \n",
            "Epoch: 36 \tTraining Loss:  1.072 \tTrain_Accu: 57%  \tValid_Acc:17% \t Valid Loss: 2.229 \n",
            "Epoch: 37 \tTraining Loss:  0.968 \tTrain_Accu: 60%  \tValid_Acc:30% \t Valid Loss: 1.975 \n",
            "Epoch: 38 \tTraining Loss:  0.936 \tTrain_Accu: 64%  \tValid_Acc:23% \t Valid Loss: 1.807 \n",
            "Epoch: 39 \tTraining Loss:  0.973 \tTrain_Accu: 59%  \tValid_Acc:20% \t Valid Loss: 2.194 \n",
            "Epoch: 40 \tTraining Loss:  0.956 \tTrain_Accu: 63%  \tValid_Acc:24% \t Valid Loss: 1.893 \n",
            "Epoch: 41 \tTraining Loss:  0.953 \tTrain_Accu: 61%  \tValid_Acc:26% \t Valid Loss: 2.209 \n",
            "Epoch: 42 \tTraining Loss:  0.913 \tTrain_Accu: 63%  \tValid_Acc:20% \t Valid Loss: 2.344 \n",
            "Epoch: 43 \tTraining Loss:  0.920 \tTrain_Accu: 67%  \tValid_Acc:29% \t Valid Loss: 2.050 \n",
            "Epoch: 44 \tTraining Loss:  0.927 \tTrain_Accu: 61%  \tValid_Acc:26% \t Valid Loss: 2.302 \n",
            "Epoch: 45 \tTraining Loss:  0.840 \tTrain_Accu: 65%  \tValid_Acc:29% \t Valid Loss: 2.875 \n",
            "Epoch: 46 \tTraining Loss:  0.860 \tTrain_Accu: 63%  \tValid_Acc:14% \t Valid Loss: 2.367 \n",
            "Epoch: 47 \tTraining Loss:  0.836 \tTrain_Accu: 65%  \tValid_Acc:24% \t Valid Loss: 2.774 \n",
            "Epoch: 48 \tTraining Loss:  0.820 \tTrain_Accu: 63%  \tValid_Acc:27% \t Valid Loss: 2.348 \n",
            "Epoch: 49 \tTraining Loss:  0.819 \tTrain_Accu: 67%  \tValid_Acc:27% \t Valid Loss: 1.946 \n",
            "Epoch: 50 \tTraining Loss:  0.831 \tTrain_Accu: 67%  \tValid_Acc:36% \t Valid Loss: 2.833 \n",
            "Epoch: 51 \tTraining Loss:  0.787 \tTrain_Accu: 66%  \tValid_Acc:33% \t Valid Loss: 2.260 \n",
            "Epoch: 52 \tTraining Loss:  0.768 \tTrain_Accu: 68%  \tValid_Acc:29% \t Valid Loss: 2.514 \n",
            "Epoch: 53 \tTraining Loss:  0.825 \tTrain_Accu: 65%  \tValid_Acc:20% \t Valid Loss: 2.620 \n",
            "Epoch: 54 \tTraining Loss:  0.781 \tTrain_Accu: 69%  \tValid_Acc:20% \t Valid Loss: 2.547 \n",
            "Epoch: 55 \tTraining Loss:  0.733 \tTrain_Accu: 69%  \tValid_Acc:23% \t Valid Loss: 2.263 \n",
            "Epoch: 56 \tTraining Loss:  0.726 \tTrain_Accu: 70%  \tValid_Acc:23% \t Valid Loss: 2.673 \n",
            "Epoch: 57 \tTraining Loss:  0.710 \tTrain_Accu: 73%  \tValid_Acc:24% \t Valid Loss: 3.322 \n",
            "Epoch: 58 \tTraining Loss:  0.758 \tTrain_Accu: 73%  \tValid_Acc:24% \t Valid Loss: 2.644 \n",
            "Epoch: 59 \tTraining Loss:  0.654 \tTrain_Accu: 75%  \tValid_Acc:19% \t Valid Loss: 2.850 \n",
            "Epoch: 60 \tTraining Loss:  0.774 \tTrain_Accu: 68%  \tValid_Acc:23% \t Valid Loss: 2.509 \n",
            "Epoch: 61 \tTraining Loss:  0.647 \tTrain_Accu: 73%  \tValid_Acc:21% \t Valid Loss: 2.689 \n",
            "Epoch: 62 \tTraining Loss:  0.701 \tTrain_Accu: 78%  \tValid_Acc:17% \t Valid Loss: 4.385 \n",
            "Epoch: 63 \tTraining Loss:  0.680 \tTrain_Accu: 73%  \tValid_Acc:24% \t Valid Loss: 2.713 \n",
            "Epoch: 64 \tTraining Loss:  0.612 \tTrain_Accu: 74%  \tValid_Acc:30% \t Valid Loss: 2.014 \n",
            "Epoch: 65 \tTraining Loss:  0.919 \tTrain_Accu: 73%  \tValid_Acc:24% \t Valid Loss: 2.205 \n",
            "Epoch: 66 \tTraining Loss:  0.633 \tTrain_Accu: 74%  \tValid_Acc:26% \t Valid Loss: 2.125 \n",
            "Epoch: 67 \tTraining Loss:  0.756 \tTrain_Accu: 75%  \tValid_Acc:31% \t Valid Loss: 2.176 \n",
            "Epoch: 68 \tTraining Loss:  0.711 \tTrain_Accu: 75%  \tValid_Acc:36% \t Valid Loss: 1.926 \n",
            "Epoch: 69 \tTraining Loss:  0.687 \tTrain_Accu: 74%  \tValid_Acc:24% \t Valid Loss: 2.458 \n",
            "Epoch: 70 \tTraining Loss:  0.642 \tTrain_Accu: 74%  \tValid_Acc:29% \t Valid Loss: 2.470 \n",
            "Epoch: 71 \tTraining Loss:  0.702 \tTrain_Accu: 73%  \tValid_Acc:29% \t Valid Loss: 5.406 \n",
            "Epoch: 72 \tTraining Loss:  0.633 \tTrain_Accu: 75%  \tValid_Acc:27% \t Valid Loss: 3.541 \n",
            "Epoch: 73 \tTraining Loss:  0.531 \tTrain_Accu: 80%  \tValid_Acc:33% \t Valid Loss: 3.920 \n",
            "Epoch: 74 \tTraining Loss:  0.744 \tTrain_Accu: 74%  \tValid_Acc:26% \t Valid Loss: 3.162 \n",
            "Epoch: 75 \tTraining Loss:  0.690 \tTrain_Accu: 72%  \tValid_Acc:20% \t Valid Loss: 4.458 \n",
            "Epoch: 76 \tTraining Loss:  0.587 \tTrain_Accu: 77%  \tValid_Acc:29% \t Valid Loss: 3.875 \n",
            "Epoch: 77 \tTraining Loss:  0.725 \tTrain_Accu: 72%  \tValid_Acc:24% \t Valid Loss: 2.829 \n",
            "Epoch: 78 \tTraining Loss:  0.572 \tTrain_Accu: 80%  \tValid_Acc:36% \t Valid Loss: 2.920 \n",
            "Epoch: 79 \tTraining Loss:  0.578 \tTrain_Accu: 80%  \tValid_Acc:29% \t Valid Loss: 3.982 \n",
            "Epoch: 80 \tTraining Loss:  0.510 \tTrain_Accu: 82%  \tValid_Acc:31% \t Valid Loss: 3.065 \n",
            "Epoch: 81 \tTraining Loss:  0.672 \tTrain_Accu: 76%  \tValid_Acc:36% \t Valid Loss: 2.757 \n",
            "Epoch: 82 \tTraining Loss:  0.612 \tTrain_Accu: 80%  \tValid_Acc:31% \t Valid Loss: 3.586 \n",
            "Epoch: 83 \tTraining Loss:  0.636 \tTrain_Accu: 76%  \tValid_Acc:23% \t Valid Loss: 2.231 \n",
            "Epoch: 84 \tTraining Loss:  0.538 \tTrain_Accu: 81%  \tValid_Acc:33% \t Valid Loss: 2.637 \n",
            "Epoch: 85 \tTraining Loss:  0.896 \tTrain_Accu: 75%  \tValid_Acc:27% \t Valid Loss: 4.825 \n",
            "Epoch: 86 \tTraining Loss:  0.658 \tTrain_Accu: 78%  \tValid_Acc:31% \t Valid Loss: 3.142 \n",
            "Epoch: 87 \tTraining Loss:  0.523 \tTrain_Accu: 80%  \tValid_Acc:37% \t Valid Loss: 3.275 \n",
            "Epoch: 88 \tTraining Loss:  0.568 \tTrain_Accu: 80%  \tValid_Acc:23% \t Valid Loss: 6.865 \n",
            "Epoch: 89 \tTraining Loss:  0.610 \tTrain_Accu: 77%  \tValid_Acc:30% \t Valid Loss: 2.498 \n",
            "Epoch: 90 \tTraining Loss:  0.517 \tTrain_Accu: 78%  \tValid_Acc:27% \t Valid Loss: 3.272 \n",
            "Epoch: 91 \tTraining Loss:  0.531 \tTrain_Accu: 78%  \tValid_Acc:30% \t Valid Loss: 3.220 \n",
            "Epoch: 92 \tTraining Loss:  0.594 \tTrain_Accu: 80%  \tValid_Acc:36% \t Valid Loss: 2.653 \n",
            "Epoch: 93 \tTraining Loss:  0.534 \tTrain_Accu: 81%  \tValid_Acc:27% \t Valid Loss: 4.015 \n",
            "Epoch: 94 \tTraining Loss:  0.706 \tTrain_Accu: 79%  \tValid_Acc:34% \t Valid Loss: 2.960 \n",
            "Epoch: 95 \tTraining Loss:  0.529 \tTrain_Accu: 76%  \tValid_Acc:31% \t Valid Loss: 3.767 \n",
            "Epoch: 96 \tTraining Loss:  0.545 \tTrain_Accu: 79%  \tValid_Acc:24% \t Valid Loss: 5.379 \n",
            "Epoch: 97 \tTraining Loss:  0.504 \tTrain_Accu: 82%  \tValid_Acc:36% \t Valid Loss: 2.598 \n",
            "Epoch: 98 \tTraining Loss:  0.574 \tTrain_Accu: 80%  \tValid_Acc:30% \t Valid Loss: 3.140 \n",
            "Epoch: 99 \tTraining Loss:  0.537 \tTrain_Accu: 81%  \tValid_Acc:26% \t Valid Loss: 3.517 \n",
            "Epoch: 100 \tTraining Loss:  0.554 \tTrain_Accu: 79%  \tValid_Acc:24% \t Valid Loss: 4.721 \n",
            "Epoch: 101 \tTraining Loss:  0.502 \tTrain_Accu: 84%  \tValid_Acc:31% \t Valid Loss: 5.071 \n",
            "Epoch: 102 \tTraining Loss:  0.561 \tTrain_Accu: 81%  \tValid_Acc:24% \t Valid Loss: 4.887 \n",
            "Epoch: 103 \tTraining Loss:  0.738 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 4.072 \n",
            "Epoch: 104 \tTraining Loss:  0.523 \tTrain_Accu: 84%  \tValid_Acc:34% \t Valid Loss: 2.907 \n",
            "Epoch: 105 \tTraining Loss:  0.837 \tTrain_Accu: 80%  \tValid_Acc:36% \t Valid Loss: 2.801 \n",
            "Epoch: 106 \tTraining Loss:  0.534 \tTrain_Accu: 83%  \tValid_Acc:30% \t Valid Loss: 2.300 \n",
            "Epoch: 107 \tTraining Loss:  0.593 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 4.283 \n",
            "Epoch: 108 \tTraining Loss:  0.503 \tTrain_Accu: 79%  \tValid_Acc:33% \t Valid Loss: 3.711 \n",
            "Epoch: 109 \tTraining Loss:  0.508 \tTrain_Accu: 77%  \tValid_Acc:34% \t Valid Loss: 3.784 \n",
            "Epoch: 110 \tTraining Loss:  0.810 \tTrain_Accu: 79%  \tValid_Acc:26% \t Valid Loss: 4.812 \n",
            "Epoch: 111 \tTraining Loss:  0.512 \tTrain_Accu: 82%  \tValid_Acc:31% \t Valid Loss: 1.912 \n",
            "Epoch: 112 \tTraining Loss:  0.735 \tTrain_Accu: 81%  \tValid_Acc:34% \t Valid Loss: 3.021 \n",
            "Epoch: 113 \tTraining Loss:  0.564 \tTrain_Accu: 83%  \tValid_Acc:33% \t Valid Loss: 3.408 \n",
            "Epoch: 114 \tTraining Loss:  0.600 \tTrain_Accu: 78%  \tValid_Acc:33% \t Valid Loss: 8.283 \n",
            "Epoch: 115 \tTraining Loss:  0.669 \tTrain_Accu: 81%  \tValid_Acc:36% \t Valid Loss: 3.535 \n",
            "Epoch: 116 \tTraining Loss:  0.536 \tTrain_Accu: 84%  \tValid_Acc:31% \t Valid Loss: 3.053 \n",
            "Epoch: 117 \tTraining Loss:  0.488 \tTrain_Accu: 80%  \tValid_Acc:29% \t Valid Loss: 3.717 \n",
            "Epoch: 118 \tTraining Loss:  0.586 \tTrain_Accu: 83%  \tValid_Acc:26% \t Valid Loss: 10.310 \n",
            "Epoch: 119 \tTraining Loss:  0.514 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 5.822 \n",
            "Epoch: 120 \tTraining Loss:  0.733 \tTrain_Accu: 77%  \tValid_Acc:36% \t Valid Loss: 4.396 \n",
            "Epoch: 121 \tTraining Loss:  0.638 \tTrain_Accu: 79%  \tValid_Acc:33% \t Valid Loss: 3.819 \n",
            "Epoch: 122 \tTraining Loss:  1.042 \tTrain_Accu: 81%  \tValid_Acc:36% \t Valid Loss: 2.801 \n",
            "Epoch: 123 \tTraining Loss:  0.591 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 3.113 \n",
            "Epoch: 124 \tTraining Loss:  0.482 \tTrain_Accu: 85%  \tValid_Acc:39% \t Valid Loss: 2.752 \n",
            "Epoch: 125 \tTraining Loss:  0.651 \tTrain_Accu: 79%  \tValid_Acc:27% \t Valid Loss: 3.060 \n",
            "Epoch: 126 \tTraining Loss:  0.632 \tTrain_Accu: 82%  \tValid_Acc:33% \t Valid Loss: 3.520 \n",
            "Epoch: 127 \tTraining Loss:  0.575 \tTrain_Accu: 81%  \tValid_Acc:33% \t Valid Loss: 3.816 \n",
            "Epoch: 128 \tTraining Loss:  0.598 \tTrain_Accu: 79%  \tValid_Acc:37% \t Valid Loss: 2.314 \n",
            "Epoch: 129 \tTraining Loss:  0.716 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 4.431 \n",
            "Epoch: 130 \tTraining Loss:  0.459 \tTrain_Accu: 84%  \tValid_Acc:36% \t Valid Loss: 3.231 \n",
            "Epoch: 131 \tTraining Loss:  0.534 \tTrain_Accu: 81%  \tValid_Acc:33% \t Valid Loss: 6.381 \n",
            "Epoch: 132 \tTraining Loss:  0.636 \tTrain_Accu: 76%  \tValid_Acc:31% \t Valid Loss: 4.859 \n",
            "Epoch: 133 \tTraining Loss:  0.661 \tTrain_Accu: 82%  \tValid_Acc:34% \t Valid Loss: 2.809 \n",
            "Epoch: 134 \tTraining Loss:  0.724 \tTrain_Accu: 82%  \tValid_Acc:37% \t Valid Loss: 1.937 \n",
            "Epoch: 135 \tTraining Loss:  0.448 \tTrain_Accu: 81%  \tValid_Acc:33% \t Valid Loss: 3.400 \n",
            "Epoch: 136 \tTraining Loss:  0.857 \tTrain_Accu: 80%  \tValid_Acc:34% \t Valid Loss: 2.741 \n",
            "Epoch: 137 \tTraining Loss:  0.703 \tTrain_Accu: 81%  \tValid_Acc:29% \t Valid Loss: 2.488 \n",
            "Epoch: 138 \tTraining Loss:  0.506 \tTrain_Accu: 83%  \tValid_Acc:30% \t Valid Loss: 3.691 \n",
            "Epoch: 139 \tTraining Loss:  0.604 \tTrain_Accu: 81%  \tValid_Acc:30% \t Valid Loss: 4.569 \n",
            "Epoch: 140 \tTraining Loss:  0.533 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 3.381 \n",
            "Epoch: 141 \tTraining Loss:  0.415 \tTrain_Accu: 85%  \tValid_Acc:36% \t Valid Loss: 4.760 \n",
            "Epoch: 142 \tTraining Loss:  0.678 \tTrain_Accu: 83%  \tValid_Acc:31% \t Valid Loss: 4.399 \n",
            "Epoch: 143 \tTraining Loss:  0.449 \tTrain_Accu: 87%  \tValid_Acc:29% \t Valid Loss: 4.979 \n",
            "Epoch: 144 \tTraining Loss:  0.796 \tTrain_Accu: 76%  \tValid_Acc:24% \t Valid Loss: 5.074 \n",
            "Epoch: 145 \tTraining Loss:  0.501 \tTrain_Accu: 83%  \tValid_Acc:34% \t Valid Loss: 3.893 \n",
            "Epoch: 146 \tTraining Loss:  0.711 \tTrain_Accu: 80%  \tValid_Acc:36% \t Valid Loss: 3.367 \n",
            "Epoch: 147 \tTraining Loss:  0.408 \tTrain_Accu: 86%  \tValid_Acc:34% \t Valid Loss: 5.048 \n",
            "Epoch: 148 \tTraining Loss:  0.620 \tTrain_Accu: 83%  \tValid_Acc:31% \t Valid Loss: 5.235 \n",
            "Epoch: 149 \tTraining Loss:  0.581 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 4.591 \n",
            "Epoch: 150 \tTraining Loss:  0.641 \tTrain_Accu: 78%  \tValid_Acc:33% \t Valid Loss: 3.416 \n",
            "Epoch: 151 \tTraining Loss:  0.562 \tTrain_Accu: 81%  \tValid_Acc:30% \t Valid Loss: 2.466 \n",
            "Epoch: 152 \tTraining Loss:  0.647 \tTrain_Accu: 83%  \tValid_Acc:31% \t Valid Loss: 3.725 \n",
            "Epoch: 153 \tTraining Loss:  0.530 \tTrain_Accu: 81%  \tValid_Acc:33% \t Valid Loss: 2.796 \n",
            "Epoch: 154 \tTraining Loss:  0.480 \tTrain_Accu: 83%  \tValid_Acc:33% \t Valid Loss: 8.176 \n",
            "Epoch: 155 \tTraining Loss:  0.557 \tTrain_Accu: 84%  \tValid_Acc:34% \t Valid Loss: 6.114 \n",
            "Epoch: 156 \tTraining Loss:  0.595 \tTrain_Accu: 82%  \tValid_Acc:36% \t Valid Loss: 2.422 \n",
            "Epoch: 157 \tTraining Loss:  0.492 \tTrain_Accu: 85%  \tValid_Acc:29% \t Valid Loss: 3.605 \n",
            "Epoch: 158 \tTraining Loss:  0.586 \tTrain_Accu: 86%  \tValid_Acc:30% \t Valid Loss: 2.674 \n",
            "Epoch: 159 \tTraining Loss:  0.600 \tTrain_Accu: 83%  \tValid_Acc:31% \t Valid Loss: 6.150 \n",
            "Epoch: 160 \tTraining Loss:  0.601 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 3.973 \n",
            "Epoch: 161 \tTraining Loss:  0.534 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 3.537 \n",
            "Epoch: 162 \tTraining Loss:  0.562 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 4.676 \n",
            "Epoch: 163 \tTraining Loss:  0.548 \tTrain_Accu: 84%  \tValid_Acc:30% \t Valid Loss: 3.794 \n",
            "Epoch: 164 \tTraining Loss:  0.457 \tTrain_Accu: 84%  \tValid_Acc:26% \t Valid Loss: 6.735 \n",
            "Epoch: 165 \tTraining Loss:  0.723 \tTrain_Accu: 78%  \tValid_Acc:41% \t Valid Loss: 4.715 \n",
            "Epoch: 166 \tTraining Loss:  0.494 \tTrain_Accu: 83%  \tValid_Acc:20% \t Valid Loss: 4.114 \n",
            "Epoch: 167 \tTraining Loss:  0.550 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 6.878 \n",
            "Epoch: 168 \tTraining Loss:  0.555 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 7.210 \n",
            "Epoch: 169 \tTraining Loss:  0.594 \tTrain_Accu: 81%  \tValid_Acc:30% \t Valid Loss: 4.166 \n",
            "Epoch: 170 \tTraining Loss:  0.654 \tTrain_Accu: 85%  \tValid_Acc:39% \t Valid Loss: 5.560 \n",
            "Epoch: 171 \tTraining Loss:  0.657 \tTrain_Accu: 86%  \tValid_Acc:37% \t Valid Loss: 3.861 \n",
            "Epoch: 172 \tTraining Loss:  0.729 \tTrain_Accu: 82%  \tValid_Acc:33% \t Valid Loss: 3.690 \n",
            "Epoch: 173 \tTraining Loss:  0.543 \tTrain_Accu: 84%  \tValid_Acc:23% \t Valid Loss: 5.646 \n",
            "Epoch: 174 \tTraining Loss:  0.416 \tTrain_Accu: 86%  \tValid_Acc:19% \t Valid Loss: 6.567 \n",
            "Epoch: 175 \tTraining Loss:  0.560 \tTrain_Accu: 82%  \tValid_Acc:31% \t Valid Loss: 6.843 \n",
            "Epoch: 176 \tTraining Loss:  0.673 \tTrain_Accu: 82%  \tValid_Acc:34% \t Valid Loss: 4.642 \n",
            "Epoch: 177 \tTraining Loss:  0.404 \tTrain_Accu: 85%  \tValid_Acc:24% \t Valid Loss: 4.864 \n",
            "Epoch: 178 \tTraining Loss:  0.694 \tTrain_Accu: 82%  \tValid_Acc:20% \t Valid Loss: 5.996 \n",
            "Epoch: 179 \tTraining Loss:  0.745 \tTrain_Accu: 81%  \tValid_Acc:30% \t Valid Loss: 4.560 \n",
            "Epoch: 180 \tTraining Loss:  0.650 \tTrain_Accu: 79%  \tValid_Acc:27% \t Valid Loss: 4.347 \n",
            "Epoch: 181 \tTraining Loss:  0.699 \tTrain_Accu: 79%  \tValid_Acc:21% \t Valid Loss: 6.788 \n",
            "Epoch: 182 \tTraining Loss:  0.789 \tTrain_Accu: 82%  \tValid_Acc:27% \t Valid Loss: 7.024 \n",
            "Epoch: 183 \tTraining Loss:  0.642 \tTrain_Accu: 81%  \tValid_Acc:24% \t Valid Loss: 4.386 \n",
            "Epoch: 184 \tTraining Loss:  0.844 \tTrain_Accu: 81%  \tValid_Acc:24% \t Valid Loss: 3.464 \n",
            "Epoch: 185 \tTraining Loss:  0.550 \tTrain_Accu: 80%  \tValid_Acc:30% \t Valid Loss: 4.722 \n",
            "Epoch: 186 \tTraining Loss:  0.708 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 5.924 \n",
            "Epoch: 187 \tTraining Loss:  0.483 \tTrain_Accu: 83%  \tValid_Acc:33% \t Valid Loss: 8.612 \n",
            "Epoch: 188 \tTraining Loss:  0.616 \tTrain_Accu: 80%  \tValid_Acc:36% \t Valid Loss: 3.379 \n",
            "Epoch: 189 \tTraining Loss:  0.798 \tTrain_Accu: 79%  \tValid_Acc:29% \t Valid Loss: 4.693 \n",
            "Epoch: 190 \tTraining Loss:  0.901 \tTrain_Accu: 74%  \tValid_Acc:26% \t Valid Loss: 5.778 \n",
            "Epoch: 191 \tTraining Loss:  0.839 \tTrain_Accu: 78%  \tValid_Acc:31% \t Valid Loss: 4.240 \n",
            "Epoch: 192 \tTraining Loss:  0.550 \tTrain_Accu: 82%  \tValid_Acc:26% \t Valid Loss: 17.344 \n",
            "Epoch: 193 \tTraining Loss:  0.549 \tTrain_Accu: 80%  \tValid_Acc:26% \t Valid Loss: 7.058 \n",
            "Epoch: 194 \tTraining Loss:  0.560 \tTrain_Accu: 84%  \tValid_Acc:26% \t Valid Loss: 4.781 \n",
            "Epoch: 195 \tTraining Loss:  0.410 \tTrain_Accu: 86%  \tValid_Acc:36% \t Valid Loss: 5.853 \n",
            "Epoch: 196 \tTraining Loss:  0.936 \tTrain_Accu: 69%  \tValid_Acc:33% \t Valid Loss: 9.889 \n",
            "Epoch: 197 \tTraining Loss:  1.167 \tTrain_Accu: 77%  \tValid_Acc:21% \t Valid Loss: 4.637 \n",
            "Epoch: 198 \tTraining Loss:  0.780 \tTrain_Accu: 78%  \tValid_Acc:27% \t Valid Loss: 5.405 \n",
            "Epoch: 199 \tTraining Loss:  0.871 \tTrain_Accu: 75%  \tValid_Acc:23% \t Valid Loss: 7.991 \n",
            "Epoch: 200 \tTraining Loss:  0.551 \tTrain_Accu: 82%  \tValid_Acc:23% \t Valid Loss: 7.000 \n",
            "Epoch: 201 \tTraining Loss:  1.071 \tTrain_Accu: 74%  \tValid_Acc:24% \t Valid Loss: 4.268 \n",
            "Epoch: 202 \tTraining Loss:  0.838 \tTrain_Accu: 77%  \tValid_Acc:39% \t Valid Loss: 9.006 \n",
            "Epoch: 203 \tTraining Loss:  1.078 \tTrain_Accu: 76%  \tValid_Acc:29% \t Valid Loss: 9.819 \n",
            "Epoch: 204 \tTraining Loss:  0.942 \tTrain_Accu: 76%  \tValid_Acc:34% \t Valid Loss: 4.823 \n",
            "Epoch: 205 \tTraining Loss:  1.066 \tTrain_Accu: 74%  \tValid_Acc:23% \t Valid Loss: 3.974 \n",
            "Epoch: 206 \tTraining Loss:  0.778 \tTrain_Accu: 77%  \tValid_Acc:26% \t Valid Loss: 4.481 \n",
            "Epoch: 207 \tTraining Loss:  0.715 \tTrain_Accu: 77%  \tValid_Acc:27% \t Valid Loss: 6.566 \n",
            "Epoch: 208 \tTraining Loss:  0.801 \tTrain_Accu: 78%  \tValid_Acc:30% \t Valid Loss: 3.490 \n",
            "Epoch: 209 \tTraining Loss:  0.642 \tTrain_Accu: 84%  \tValid_Acc:26% \t Valid Loss: 5.183 \n",
            "Epoch: 210 \tTraining Loss:  0.958 \tTrain_Accu: 72%  \tValid_Acc:30% \t Valid Loss: 4.732 \n",
            "Epoch: 211 \tTraining Loss:  1.017 \tTrain_Accu: 75%  \tValid_Acc:24% \t Valid Loss: 3.887 \n",
            "Epoch: 212 \tTraining Loss:  0.526 \tTrain_Accu: 80%  \tValid_Acc:23% \t Valid Loss: 6.636 \n",
            "Epoch: 213 \tTraining Loss:  0.736 \tTrain_Accu: 78%  \tValid_Acc:26% \t Valid Loss: 6.014 \n",
            "Epoch: 214 \tTraining Loss:  0.995 \tTrain_Accu: 80%  \tValid_Acc:33% \t Valid Loss: 7.163 \n",
            "Epoch: 215 \tTraining Loss:  0.990 \tTrain_Accu: 79%  \tValid_Acc:29% \t Valid Loss: 4.955 \n",
            "Epoch: 216 \tTraining Loss:  0.979 \tTrain_Accu: 68%  \tValid_Acc:29% \t Valid Loss: 5.180 \n",
            "Epoch: 217 \tTraining Loss:  0.995 \tTrain_Accu: 75%  \tValid_Acc:33% \t Valid Loss: 7.425 \n",
            "Epoch: 218 \tTraining Loss:  0.780 \tTrain_Accu: 77%  \tValid_Acc:21% \t Valid Loss: 10.458 \n",
            "Epoch: 219 \tTraining Loss:  0.787 \tTrain_Accu: 78%  \tValid_Acc:29% \t Valid Loss: 8.565 \n",
            "Epoch: 220 \tTraining Loss:  0.653 \tTrain_Accu: 76%  \tValid_Acc:26% \t Valid Loss: 9.657 \n",
            "Epoch: 221 \tTraining Loss:  0.705 \tTrain_Accu: 79%  \tValid_Acc:31% \t Valid Loss: 6.899 \n",
            "Epoch: 222 \tTraining Loss:  0.865 \tTrain_Accu: 76%  \tValid_Acc:27% \t Valid Loss: 4.128 \n",
            "Epoch: 223 \tTraining Loss:  1.158 \tTrain_Accu: 77%  \tValid_Acc:20% \t Valid Loss: 8.192 \n",
            "Epoch: 224 \tTraining Loss:  0.513 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 6.054 \n",
            "Epoch: 225 \tTraining Loss:  1.084 \tTrain_Accu: 76%  \tValid_Acc:23% \t Valid Loss: 4.909 \n",
            "Epoch: 226 \tTraining Loss:  0.632 \tTrain_Accu: 78%  \tValid_Acc:27% \t Valid Loss: 3.201 \n",
            "Epoch: 227 \tTraining Loss:  0.970 \tTrain_Accu: 78%  \tValid_Acc:27% \t Valid Loss: 5.314 \n",
            "Epoch: 228 \tTraining Loss:  0.727 \tTrain_Accu: 80%  \tValid_Acc:31% \t Valid Loss: 3.317 \n",
            "Epoch: 229 \tTraining Loss:  0.943 \tTrain_Accu: 76%  \tValid_Acc:31% \t Valid Loss: 6.658 \n",
            "Epoch: 230 \tTraining Loss:  0.642 \tTrain_Accu: 82%  \tValid_Acc:26% \t Valid Loss: 5.965 \n",
            "Epoch: 231 \tTraining Loss:  0.527 \tTrain_Accu: 83%  \tValid_Acc:27% \t Valid Loss: 12.111 \n",
            "Epoch: 232 \tTraining Loss:  0.726 \tTrain_Accu: 82%  \tValid_Acc:26% \t Valid Loss: 13.318 \n",
            "Epoch: 233 \tTraining Loss:  1.024 \tTrain_Accu: 82%  \tValid_Acc:26% \t Valid Loss: 9.939 \n",
            "Epoch: 234 \tTraining Loss:  1.087 \tTrain_Accu: 78%  \tValid_Acc:31% \t Valid Loss: 6.564 \n",
            "Epoch: 235 \tTraining Loss:  0.747 \tTrain_Accu: 77%  \tValid_Acc:30% \t Valid Loss: 4.242 \n",
            "Epoch: 236 \tTraining Loss:  0.556 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 6.971 \n",
            "Epoch: 237 \tTraining Loss:  0.525 \tTrain_Accu: 84%  \tValid_Acc:37% \t Valid Loss: 3.224 \n",
            "Epoch: 238 \tTraining Loss:  0.813 \tTrain_Accu: 82%  \tValid_Acc:33% \t Valid Loss: 9.034 \n",
            "Epoch: 239 \tTraining Loss:  0.953 \tTrain_Accu: 82%  \tValid_Acc:26% \t Valid Loss: 6.044 \n",
            "Epoch: 240 \tTraining Loss:  0.640 \tTrain_Accu: 79%  \tValid_Acc:24% \t Valid Loss: 4.254 \n",
            "Epoch: 241 \tTraining Loss:  0.627 \tTrain_Accu: 79%  \tValid_Acc:34% \t Valid Loss: 5.419 \n",
            "Epoch: 242 \tTraining Loss:  1.207 \tTrain_Accu: 73%  \tValid_Acc:27% \t Valid Loss: 5.267 \n",
            "Epoch: 243 \tTraining Loss:  0.513 \tTrain_Accu: 82%  \tValid_Acc:37% \t Valid Loss: 8.787 \n",
            "Epoch: 244 \tTraining Loss:  1.356 \tTrain_Accu: 74%  \tValid_Acc:31% \t Valid Loss: 5.864 \n",
            "Epoch: 245 \tTraining Loss:  0.478 \tTrain_Accu: 83%  \tValid_Acc:23% \t Valid Loss: 13.584 \n",
            "Epoch: 246 \tTraining Loss:  0.809 \tTrain_Accu: 83%  \tValid_Acc:31% \t Valid Loss: 4.464 \n",
            "Epoch: 247 \tTraining Loss:  0.846 \tTrain_Accu: 76%  \tValid_Acc:27% \t Valid Loss: 5.202 \n",
            "Epoch: 248 \tTraining Loss:  0.599 \tTrain_Accu: 85%  \tValid_Acc:29% \t Valid Loss: 6.855 \n",
            "Epoch: 249 \tTraining Loss:  1.013 \tTrain_Accu: 74%  \tValid_Acc:31% \t Valid Loss: 3.249 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 02:09:17,546]\u001b[0m Trial 10 finished with value: 28.6 and parameters: {'lr': 0.001, 'dropout': 0.8}. Best is trial 8 with value: 32.9.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.923 \tTrain_Accu: 66%  \tValid_Acc:29% \t Valid Loss: 7.383 \n",
            "Epoch: 1 \tTraining Loss:  1.710 \tTrain_Accu: 18%  \tValid_Acc:10% \t Valid Loss: 1.627 \n",
            "Epoch: 2 \tTraining Loss:  1.609 \tTrain_Accu: 20%  \tValid_Acc:10% \t Valid Loss: 1.633 \n",
            "Epoch: 3 \tTraining Loss:  1.603 \tTrain_Accu: 23%  \tValid_Acc:7% \t Valid Loss: 1.634 \n",
            "Epoch: 4 \tTraining Loss:  1.606 \tTrain_Accu: 24%  \tValid_Acc:7% \t Valid Loss: 1.638 \n",
            "Epoch: 5 \tTraining Loss:  1.602 \tTrain_Accu: 24%  \tValid_Acc:20% \t Valid Loss: 1.617 \n",
            "Epoch: 6 \tTraining Loss:  1.600 \tTrain_Accu: 23%  \tValid_Acc:20% \t Valid Loss: 1.629 \n",
            "Epoch: 7 \tTraining Loss:  1.595 \tTrain_Accu: 23%  \tValid_Acc:14% \t Valid Loss: 1.629 \n",
            "Epoch: 8 \tTraining Loss:  1.569 \tTrain_Accu: 24%  \tValid_Acc:17% \t Valid Loss: 1.599 \n",
            "Epoch: 9 \tTraining Loss:  1.584 \tTrain_Accu: 25%  \tValid_Acc:11% \t Valid Loss: 1.631 \n",
            "Epoch: 10 \tTraining Loss:  1.542 \tTrain_Accu: 30%  \tValid_Acc:21% \t Valid Loss: 1.611 \n",
            "Epoch: 11 \tTraining Loss:  1.533 \tTrain_Accu: 27%  \tValid_Acc:16% \t Valid Loss: 1.637 \n",
            "Epoch: 12 \tTraining Loss:  1.563 \tTrain_Accu: 28%  \tValid_Acc:6% \t Valid Loss: 1.657 \n",
            "Epoch: 13 \tTraining Loss:  1.578 \tTrain_Accu: 27%  \tValid_Acc:17% \t Valid Loss: 1.596 \n",
            "Epoch: 14 \tTraining Loss:  1.568 \tTrain_Accu: 30%  \tValid_Acc:20% \t Valid Loss: 1.612 \n",
            "Epoch: 15 \tTraining Loss:  1.527 \tTrain_Accu: 27%  \tValid_Acc:17% \t Valid Loss: 1.625 \n",
            "Epoch: 16 \tTraining Loss:  1.537 \tTrain_Accu: 30%  \tValid_Acc:23% \t Valid Loss: 1.612 \n",
            "Epoch: 17 \tTraining Loss:  1.519 \tTrain_Accu: 29%  \tValid_Acc:20% \t Valid Loss: 1.667 \n",
            "Epoch: 18 \tTraining Loss:  1.536 \tTrain_Accu: 27%  \tValid_Acc:20% \t Valid Loss: 1.661 \n",
            "Epoch: 19 \tTraining Loss:  1.532 \tTrain_Accu: 29%  \tValid_Acc:21% \t Valid Loss: 1.656 \n",
            "Epoch: 20 \tTraining Loss:  1.458 \tTrain_Accu: 30%  \tValid_Acc:24% \t Valid Loss: 1.602 \n",
            "Epoch: 21 \tTraining Loss:  1.495 \tTrain_Accu: 32%  \tValid_Acc:26% \t Valid Loss: 1.640 \n",
            "Epoch: 22 \tTraining Loss:  1.493 \tTrain_Accu: 31%  \tValid_Acc:24% \t Valid Loss: 1.639 \n",
            "Epoch: 23 \tTraining Loss:  1.504 \tTrain_Accu: 29%  \tValid_Acc:10% \t Valid Loss: 1.632 \n",
            "Epoch: 24 \tTraining Loss:  1.457 \tTrain_Accu: 34%  \tValid_Acc:13% \t Valid Loss: 1.693 \n",
            "Epoch: 25 \tTraining Loss:  1.448 \tTrain_Accu: 30%  \tValid_Acc:24% \t Valid Loss: 1.671 \n",
            "Epoch: 26 \tTraining Loss:  1.420 \tTrain_Accu: 38%  \tValid_Acc:19% \t Valid Loss: 1.689 \n",
            "Epoch: 27 \tTraining Loss:  1.428 \tTrain_Accu: 35%  \tValid_Acc:19% \t Valid Loss: 1.559 \n",
            "Epoch: 28 \tTraining Loss:  1.397 \tTrain_Accu: 38%  \tValid_Acc:17% \t Valid Loss: 1.672 \n",
            "Epoch: 29 \tTraining Loss:  1.401 \tTrain_Accu: 37%  \tValid_Acc:24% \t Valid Loss: 1.599 \n",
            "Epoch: 30 \tTraining Loss:  1.397 \tTrain_Accu: 36%  \tValid_Acc:21% \t Valid Loss: 1.690 \n",
            "Epoch: 31 \tTraining Loss:  1.395 \tTrain_Accu: 35%  \tValid_Acc:20% \t Valid Loss: 1.759 \n",
            "Epoch: 32 \tTraining Loss:  1.333 \tTrain_Accu: 39%  \tValid_Acc:20% \t Valid Loss: 1.650 \n",
            "Epoch: 33 \tTraining Loss:  1.354 \tTrain_Accu: 45%  \tValid_Acc:24% \t Valid Loss: 1.656 \n",
            "Epoch: 34 \tTraining Loss:  1.346 \tTrain_Accu: 39%  \tValid_Acc:20% \t Valid Loss: 1.641 \n",
            "Epoch: 35 \tTraining Loss:  1.333 \tTrain_Accu: 45%  \tValid_Acc:21% \t Valid Loss: 1.608 \n",
            "Epoch: 36 \tTraining Loss:  1.365 \tTrain_Accu: 37%  \tValid_Acc:29% \t Valid Loss: 1.540 \n",
            "Epoch: 37 \tTraining Loss:  1.340 \tTrain_Accu: 41%  \tValid_Acc:20% \t Valid Loss: 1.641 \n",
            "Epoch: 38 \tTraining Loss:  1.340 \tTrain_Accu: 40%  \tValid_Acc:24% \t Valid Loss: 1.638 \n",
            "Epoch: 39 \tTraining Loss:  1.284 \tTrain_Accu: 43%  \tValid_Acc:13% \t Valid Loss: 1.725 \n",
            "Epoch: 40 \tTraining Loss:  1.263 \tTrain_Accu: 41%  \tValid_Acc:26% \t Valid Loss: 1.719 \n",
            "Epoch: 41 \tTraining Loss:  1.298 \tTrain_Accu: 41%  \tValid_Acc:20% \t Valid Loss: 1.610 \n",
            "Epoch: 42 \tTraining Loss:  1.272 \tTrain_Accu: 45%  \tValid_Acc:23% \t Valid Loss: 1.685 \n",
            "Epoch: 43 \tTraining Loss:  1.265 \tTrain_Accu: 44%  \tValid_Acc:27% \t Valid Loss: 1.660 \n",
            "Epoch: 44 \tTraining Loss:  1.269 \tTrain_Accu: 42%  \tValid_Acc:31% \t Valid Loss: 1.660 \n",
            "Epoch: 45 \tTraining Loss:  1.251 \tTrain_Accu: 45%  \tValid_Acc:13% \t Valid Loss: 1.824 \n",
            "Epoch: 46 \tTraining Loss:  1.267 \tTrain_Accu: 44%  \tValid_Acc:21% \t Valid Loss: 1.575 \n",
            "Epoch: 47 \tTraining Loss:  1.256 \tTrain_Accu: 46%  \tValid_Acc:14% \t Valid Loss: 1.785 \n",
            "Epoch: 48 \tTraining Loss:  1.211 \tTrain_Accu: 47%  \tValid_Acc:19% \t Valid Loss: 1.727 \n",
            "Epoch: 49 \tTraining Loss:  1.189 \tTrain_Accu: 49%  \tValid_Acc:30% \t Valid Loss: 1.634 \n",
            "Epoch: 50 \tTraining Loss:  1.156 \tTrain_Accu: 51%  \tValid_Acc:27% \t Valid Loss: 1.620 \n",
            "Epoch: 51 \tTraining Loss:  1.151 \tTrain_Accu: 50%  \tValid_Acc:19% \t Valid Loss: 1.785 \n",
            "Epoch: 52 \tTraining Loss:  1.240 \tTrain_Accu: 42%  \tValid_Acc:16% \t Valid Loss: 1.704 \n",
            "Epoch: 53 \tTraining Loss:  1.200 \tTrain_Accu: 47%  \tValid_Acc:26% \t Valid Loss: 1.623 \n",
            "Epoch: 54 \tTraining Loss:  1.107 \tTrain_Accu: 49%  \tValid_Acc:31% \t Valid Loss: 1.594 \n",
            "Epoch: 55 \tTraining Loss:  1.156 \tTrain_Accu: 43%  \tValid_Acc:21% \t Valid Loss: 1.893 \n",
            "Epoch: 56 \tTraining Loss:  1.131 \tTrain_Accu: 54%  \tValid_Acc:11% \t Valid Loss: 1.883 \n",
            "Epoch: 57 \tTraining Loss:  1.136 \tTrain_Accu: 50%  \tValid_Acc:23% \t Valid Loss: 1.887 \n",
            "Epoch: 58 \tTraining Loss:  1.101 \tTrain_Accu: 50%  \tValid_Acc:21% \t Valid Loss: 1.741 \n",
            "Epoch: 59 \tTraining Loss:  1.079 \tTrain_Accu: 49%  \tValid_Acc:26% \t Valid Loss: 2.054 \n",
            "Epoch: 60 \tTraining Loss:  1.134 \tTrain_Accu: 51%  \tValid_Acc:26% \t Valid Loss: 1.759 \n",
            "Epoch: 61 \tTraining Loss:  1.072 \tTrain_Accu: 54%  \tValid_Acc:24% \t Valid Loss: 1.777 \n",
            "Epoch: 62 \tTraining Loss:  1.132 \tTrain_Accu: 51%  \tValid_Acc:21% \t Valid Loss: 1.795 \n",
            "Epoch: 63 \tTraining Loss:  1.028 \tTrain_Accu: 53%  \tValid_Acc:21% \t Valid Loss: 1.962 \n",
            "Epoch: 64 \tTraining Loss:  1.074 \tTrain_Accu: 55%  \tValid_Acc:30% \t Valid Loss: 1.624 \n",
            "Epoch: 65 \tTraining Loss:  1.104 \tTrain_Accu: 50%  \tValid_Acc:23% \t Valid Loss: 1.795 \n",
            "Epoch: 66 \tTraining Loss:  1.010 \tTrain_Accu: 55%  \tValid_Acc:24% \t Valid Loss: 1.802 \n",
            "Epoch: 67 \tTraining Loss:  1.088 \tTrain_Accu: 47%  \tValid_Acc:27% \t Valid Loss: 1.647 \n",
            "Epoch: 68 \tTraining Loss:  1.077 \tTrain_Accu: 50%  \tValid_Acc:23% \t Valid Loss: 1.789 \n",
            "Epoch: 69 \tTraining Loss:  1.098 \tTrain_Accu: 51%  \tValid_Acc:20% \t Valid Loss: 1.871 \n",
            "Epoch: 70 \tTraining Loss:  1.070 \tTrain_Accu: 51%  \tValid_Acc:23% \t Valid Loss: 1.669 \n",
            "Epoch: 71 \tTraining Loss:  1.016 \tTrain_Accu: 55%  \tValid_Acc:21% \t Valid Loss: 2.132 \n",
            "Epoch: 72 \tTraining Loss:  1.044 \tTrain_Accu: 55%  \tValid_Acc:30% \t Valid Loss: 1.977 \n",
            "Epoch: 73 \tTraining Loss:  1.000 \tTrain_Accu: 56%  \tValid_Acc:24% \t Valid Loss: 2.000 \n",
            "Epoch: 74 \tTraining Loss:  0.966 \tTrain_Accu: 56%  \tValid_Acc:23% \t Valid Loss: 2.243 \n",
            "Epoch: 75 \tTraining Loss:  0.985 \tTrain_Accu: 53%  \tValid_Acc:26% \t Valid Loss: 2.336 \n",
            "Epoch: 76 \tTraining Loss:  0.975 \tTrain_Accu: 59%  \tValid_Acc:13% \t Valid Loss: 2.010 \n",
            "Epoch: 77 \tTraining Loss:  1.005 \tTrain_Accu: 55%  \tValid_Acc:16% \t Valid Loss: 2.130 \n",
            "Epoch: 78 \tTraining Loss:  0.948 \tTrain_Accu: 54%  \tValid_Acc:20% \t Valid Loss: 1.965 \n",
            "Epoch: 79 \tTraining Loss:  0.991 \tTrain_Accu: 57%  \tValid_Acc:20% \t Valid Loss: 2.247 \n",
            "Epoch: 80 \tTraining Loss:  0.954 \tTrain_Accu: 58%  \tValid_Acc:16% \t Valid Loss: 1.957 \n",
            "Epoch: 81 \tTraining Loss:  0.965 \tTrain_Accu: 56%  \tValid_Acc:23% \t Valid Loss: 2.097 \n",
            "Epoch: 82 \tTraining Loss:  1.014 \tTrain_Accu: 56%  \tValid_Acc:19% \t Valid Loss: 1.868 \n",
            "Epoch: 83 \tTraining Loss:  1.006 \tTrain_Accu: 54%  \tValid_Acc:21% \t Valid Loss: 1.887 \n",
            "Epoch: 84 \tTraining Loss:  0.972 \tTrain_Accu: 54%  \tValid_Acc:21% \t Valid Loss: 1.902 \n",
            "Epoch: 85 \tTraining Loss:  0.872 \tTrain_Accu: 62%  \tValid_Acc:21% \t Valid Loss: 2.080 \n",
            "Epoch: 86 \tTraining Loss:  0.981 \tTrain_Accu: 59%  \tValid_Acc:23% \t Valid Loss: 1.872 \n",
            "Epoch: 87 \tTraining Loss:  0.948 \tTrain_Accu: 63%  \tValid_Acc:26% \t Valid Loss: 1.855 \n",
            "Epoch: 88 \tTraining Loss:  0.911 \tTrain_Accu: 59%  \tValid_Acc:34% \t Valid Loss: 2.391 \n",
            "Epoch: 89 \tTraining Loss:  0.896 \tTrain_Accu: 60%  \tValid_Acc:30% \t Valid Loss: 2.102 \n",
            "Epoch: 90 \tTraining Loss:  0.976 \tTrain_Accu: 55%  \tValid_Acc:26% \t Valid Loss: 2.232 \n",
            "Epoch: 91 \tTraining Loss:  0.883 \tTrain_Accu: 60%  \tValid_Acc:26% \t Valid Loss: 2.087 \n",
            "Epoch: 92 \tTraining Loss:  0.895 \tTrain_Accu: 62%  \tValid_Acc:30% \t Valid Loss: 2.435 \n",
            "Epoch: 93 \tTraining Loss:  0.932 \tTrain_Accu: 61%  \tValid_Acc:23% \t Valid Loss: 2.532 \n",
            "Epoch: 94 \tTraining Loss:  0.957 \tTrain_Accu: 61%  \tValid_Acc:24% \t Valid Loss: 2.074 \n",
            "Epoch: 95 \tTraining Loss:  0.930 \tTrain_Accu: 56%  \tValid_Acc:30% \t Valid Loss: 1.727 \n",
            "Epoch: 96 \tTraining Loss:  0.915 \tTrain_Accu: 56%  \tValid_Acc:20% \t Valid Loss: 2.230 \n",
            "Epoch: 97 \tTraining Loss:  0.868 \tTrain_Accu: 62%  \tValid_Acc:20% \t Valid Loss: 1.765 \n",
            "Epoch: 98 \tTraining Loss:  0.871 \tTrain_Accu: 61%  \tValid_Acc:21% \t Valid Loss: 2.017 \n",
            "Epoch: 99 \tTraining Loss:  0.820 \tTrain_Accu: 66%  \tValid_Acc:21% \t Valid Loss: 2.308 \n",
            "Epoch: 100 \tTraining Loss:  0.880 \tTrain_Accu: 61%  \tValid_Acc:24% \t Valid Loss: 1.905 \n",
            "Epoch: 101 \tTraining Loss:  0.855 \tTrain_Accu: 64%  \tValid_Acc:30% \t Valid Loss: 1.815 \n",
            "Epoch: 102 \tTraining Loss:  0.870 \tTrain_Accu: 63%  \tValid_Acc:19% \t Valid Loss: 2.169 \n",
            "Epoch: 103 \tTraining Loss:  0.804 \tTrain_Accu: 65%  \tValid_Acc:30% \t Valid Loss: 2.472 \n",
            "Epoch: 104 \tTraining Loss:  0.816 \tTrain_Accu: 63%  \tValid_Acc:21% \t Valid Loss: 2.287 \n",
            "Epoch: 105 \tTraining Loss:  0.895 \tTrain_Accu: 61%  \tValid_Acc:30% \t Valid Loss: 1.743 \n",
            "Epoch: 106 \tTraining Loss:  0.830 \tTrain_Accu: 67%  \tValid_Acc:29% \t Valid Loss: 2.115 \n",
            "Epoch: 107 \tTraining Loss:  0.851 \tTrain_Accu: 62%  \tValid_Acc:17% \t Valid Loss: 2.465 \n",
            "Epoch: 108 \tTraining Loss:  0.830 \tTrain_Accu: 65%  \tValid_Acc:16% \t Valid Loss: 2.451 \n",
            "Epoch: 109 \tTraining Loss:  0.761 \tTrain_Accu: 69%  \tValid_Acc:24% \t Valid Loss: 2.165 \n",
            "Epoch: 110 \tTraining Loss:  0.769 \tTrain_Accu: 66%  \tValid_Acc:24% \t Valid Loss: 2.021 \n",
            "Epoch: 111 \tTraining Loss:  0.842 \tTrain_Accu: 65%  \tValid_Acc:23% \t Valid Loss: 2.350 \n",
            "Epoch: 112 \tTraining Loss:  0.761 \tTrain_Accu: 66%  \tValid_Acc:16% \t Valid Loss: 2.294 \n",
            "Epoch: 113 \tTraining Loss:  0.702 \tTrain_Accu: 70%  \tValid_Acc:19% \t Valid Loss: 2.998 \n",
            "Epoch: 114 \tTraining Loss:  0.836 \tTrain_Accu: 64%  \tValid_Acc:20% \t Valid Loss: 2.598 \n",
            "Epoch: 115 \tTraining Loss:  0.797 \tTrain_Accu: 64%  \tValid_Acc:19% \t Valid Loss: 2.478 \n",
            "Epoch: 116 \tTraining Loss:  0.873 \tTrain_Accu: 62%  \tValid_Acc:30% \t Valid Loss: 2.306 \n",
            "Epoch: 117 \tTraining Loss:  0.796 \tTrain_Accu: 68%  \tValid_Acc:30% \t Valid Loss: 1.881 \n",
            "Epoch: 118 \tTraining Loss:  0.798 \tTrain_Accu: 64%  \tValid_Acc:36% \t Valid Loss: 2.121 \n",
            "Epoch: 119 \tTraining Loss:  0.787 \tTrain_Accu: 62%  \tValid_Acc:24% \t Valid Loss: 2.294 \n",
            "Epoch: 120 \tTraining Loss:  0.750 \tTrain_Accu: 67%  \tValid_Acc:30% \t Valid Loss: 1.806 \n",
            "Epoch: 121 \tTraining Loss:  0.796 \tTrain_Accu: 67%  \tValid_Acc:19% \t Valid Loss: 3.118 \n",
            "Epoch: 122 \tTraining Loss:  0.743 \tTrain_Accu: 67%  \tValid_Acc:30% \t Valid Loss: 2.502 \n",
            "Epoch: 123 \tTraining Loss:  0.729 \tTrain_Accu: 67%  \tValid_Acc:23% \t Valid Loss: 1.929 \n",
            "Epoch: 124 \tTraining Loss:  0.764 \tTrain_Accu: 67%  \tValid_Acc:23% \t Valid Loss: 2.396 \n",
            "Epoch: 125 \tTraining Loss:  0.788 \tTrain_Accu: 65%  \tValid_Acc:33% \t Valid Loss: 2.254 \n",
            "Epoch: 126 \tTraining Loss:  0.788 \tTrain_Accu: 64%  \tValid_Acc:26% \t Valid Loss: 2.003 \n",
            "Epoch: 127 \tTraining Loss:  0.772 \tTrain_Accu: 66%  \tValid_Acc:36% \t Valid Loss: 2.064 \n",
            "Epoch: 128 \tTraining Loss:  0.771 \tTrain_Accu: 66%  \tValid_Acc:23% \t Valid Loss: 2.197 \n",
            "Epoch: 129 \tTraining Loss:  0.853 \tTrain_Accu: 65%  \tValid_Acc:26% \t Valid Loss: 1.924 \n",
            "Epoch: 130 \tTraining Loss:  0.714 \tTrain_Accu: 71%  \tValid_Acc:19% \t Valid Loss: 2.614 \n",
            "Epoch: 131 \tTraining Loss:  0.763 \tTrain_Accu: 67%  \tValid_Acc:26% \t Valid Loss: 2.290 \n",
            "Epoch: 132 \tTraining Loss:  0.749 \tTrain_Accu: 66%  \tValid_Acc:23% \t Valid Loss: 3.165 \n",
            "Epoch: 133 \tTraining Loss:  0.714 \tTrain_Accu: 71%  \tValid_Acc:27% \t Valid Loss: 2.469 \n",
            "Epoch: 134 \tTraining Loss:  0.742 \tTrain_Accu: 69%  \tValid_Acc:24% \t Valid Loss: 2.067 \n",
            "Epoch: 135 \tTraining Loss:  0.689 \tTrain_Accu: 72%  \tValid_Acc:17% \t Valid Loss: 2.688 \n",
            "Epoch: 136 \tTraining Loss:  0.694 \tTrain_Accu: 71%  \tValid_Acc:31% \t Valid Loss: 2.702 \n",
            "Epoch: 137 \tTraining Loss:  0.675 \tTrain_Accu: 72%  \tValid_Acc:33% \t Valid Loss: 2.163 \n",
            "Epoch: 138 \tTraining Loss:  0.581 \tTrain_Accu: 76%  \tValid_Acc:24% \t Valid Loss: 3.060 \n",
            "Epoch: 139 \tTraining Loss:  0.686 \tTrain_Accu: 70%  \tValid_Acc:29% \t Valid Loss: 2.212 \n",
            "Epoch: 140 \tTraining Loss:  0.650 \tTrain_Accu: 73%  \tValid_Acc:14% \t Valid Loss: 2.694 \n",
            "Epoch: 141 \tTraining Loss:  0.764 \tTrain_Accu: 70%  \tValid_Acc:26% \t Valid Loss: 2.110 \n",
            "Epoch: 142 \tTraining Loss:  0.753 \tTrain_Accu: 67%  \tValid_Acc:29% \t Valid Loss: 2.454 \n",
            "Epoch: 143 \tTraining Loss:  0.696 \tTrain_Accu: 69%  \tValid_Acc:19% \t Valid Loss: 2.376 \n",
            "Epoch: 144 \tTraining Loss:  0.664 \tTrain_Accu: 72%  \tValid_Acc:23% \t Valid Loss: 2.947 \n",
            "Epoch: 145 \tTraining Loss:  0.679 \tTrain_Accu: 71%  \tValid_Acc:23% \t Valid Loss: 3.423 \n",
            "Epoch: 146 \tTraining Loss:  0.688 \tTrain_Accu: 73%  \tValid_Acc:14% \t Valid Loss: 2.698 \n",
            "Epoch: 147 \tTraining Loss:  0.674 \tTrain_Accu: 74%  \tValid_Acc:30% \t Valid Loss: 2.376 \n",
            "Epoch: 148 \tTraining Loss:  0.730 \tTrain_Accu: 66%  \tValid_Acc:27% \t Valid Loss: 2.288 \n",
            "Epoch: 149 \tTraining Loss:  0.745 \tTrain_Accu: 70%  \tValid_Acc:24% \t Valid Loss: 2.177 \n",
            "Epoch: 150 \tTraining Loss:  0.722 \tTrain_Accu: 70%  \tValid_Acc:19% \t Valid Loss: 2.379 \n",
            "Epoch: 151 \tTraining Loss:  0.678 \tTrain_Accu: 74%  \tValid_Acc:19% \t Valid Loss: 2.931 \n",
            "Epoch: 152 \tTraining Loss:  0.684 \tTrain_Accu: 74%  \tValid_Acc:29% \t Valid Loss: 2.280 \n",
            "Epoch: 153 \tTraining Loss:  0.667 \tTrain_Accu: 74%  \tValid_Acc:17% \t Valid Loss: 2.975 \n",
            "Epoch: 154 \tTraining Loss:  0.690 \tTrain_Accu: 72%  \tValid_Acc:27% \t Valid Loss: 2.829 \n",
            "Epoch: 155 \tTraining Loss:  0.666 \tTrain_Accu: 70%  \tValid_Acc:24% \t Valid Loss: 3.079 \n",
            "Epoch: 156 \tTraining Loss:  0.664 \tTrain_Accu: 74%  \tValid_Acc:30% \t Valid Loss: 3.252 \n",
            "Epoch: 157 \tTraining Loss:  0.707 \tTrain_Accu: 69%  \tValid_Acc:29% \t Valid Loss: 2.485 \n",
            "Epoch: 158 \tTraining Loss:  0.684 \tTrain_Accu: 70%  \tValid_Acc:16% \t Valid Loss: 2.439 \n",
            "Epoch: 159 \tTraining Loss:  0.629 \tTrain_Accu: 72%  \tValid_Acc:23% \t Valid Loss: 3.669 \n",
            "Epoch: 160 \tTraining Loss:  0.616 \tTrain_Accu: 75%  \tValid_Acc:26% \t Valid Loss: 2.526 \n",
            "Epoch: 161 \tTraining Loss:  0.628 \tTrain_Accu: 74%  \tValid_Acc:21% \t Valid Loss: 3.384 \n",
            "Epoch: 162 \tTraining Loss:  0.656 \tTrain_Accu: 74%  \tValid_Acc:24% \t Valid Loss: 2.937 \n",
            "Epoch: 163 \tTraining Loss:  0.661 \tTrain_Accu: 71%  \tValid_Acc:27% \t Valid Loss: 2.358 \n",
            "Epoch: 164 \tTraining Loss:  0.759 \tTrain_Accu: 66%  \tValid_Acc:23% \t Valid Loss: 2.890 \n",
            "Epoch: 165 \tTraining Loss:  0.630 \tTrain_Accu: 75%  \tValid_Acc:27% \t Valid Loss: 2.898 \n",
            "Epoch: 166 \tTraining Loss:  0.635 \tTrain_Accu: 74%  \tValid_Acc:17% \t Valid Loss: 3.570 \n",
            "Epoch: 167 \tTraining Loss:  0.666 \tTrain_Accu: 70%  \tValid_Acc:14% \t Valid Loss: 2.936 \n",
            "Epoch: 168 \tTraining Loss:  0.622 \tTrain_Accu: 74%  \tValid_Acc:23% \t Valid Loss: 2.594 \n",
            "Epoch: 169 \tTraining Loss:  0.644 \tTrain_Accu: 73%  \tValid_Acc:14% \t Valid Loss: 3.026 \n",
            "Epoch: 170 \tTraining Loss:  0.650 \tTrain_Accu: 74%  \tValid_Acc:16% \t Valid Loss: 3.942 \n",
            "Epoch: 171 \tTraining Loss:  0.589 \tTrain_Accu: 77%  \tValid_Acc:24% \t Valid Loss: 3.052 \n",
            "Epoch: 172 \tTraining Loss:  0.615 \tTrain_Accu: 75%  \tValid_Acc:24% \t Valid Loss: 3.517 \n",
            "Epoch: 173 \tTraining Loss:  0.633 \tTrain_Accu: 72%  \tValid_Acc:24% \t Valid Loss: 3.684 \n",
            "Epoch: 174 \tTraining Loss:  0.577 \tTrain_Accu: 74%  \tValid_Acc:26% \t Valid Loss: 3.047 \n",
            "Epoch: 175 \tTraining Loss:  0.611 \tTrain_Accu: 76%  \tValid_Acc:26% \t Valid Loss: 2.887 \n",
            "Epoch: 176 \tTraining Loss:  0.636 \tTrain_Accu: 76%  \tValid_Acc:29% \t Valid Loss: 3.201 \n",
            "Epoch: 177 \tTraining Loss:  0.732 \tTrain_Accu: 70%  \tValid_Acc:21% \t Valid Loss: 2.631 \n",
            "Epoch: 178 \tTraining Loss:  0.593 \tTrain_Accu: 73%  \tValid_Acc:30% \t Valid Loss: 2.701 \n",
            "Epoch: 179 \tTraining Loss:  0.612 \tTrain_Accu: 74%  \tValid_Acc:19% \t Valid Loss: 3.307 \n",
            "Epoch: 180 \tTraining Loss:  0.671 \tTrain_Accu: 75%  \tValid_Acc:29% \t Valid Loss: 2.453 \n",
            "Epoch: 181 \tTraining Loss:  0.638 \tTrain_Accu: 75%  \tValid_Acc:29% \t Valid Loss: 3.281 \n",
            "Epoch: 182 \tTraining Loss:  0.652 \tTrain_Accu: 74%  \tValid_Acc:20% \t Valid Loss: 4.113 \n",
            "Epoch: 183 \tTraining Loss:  0.652 \tTrain_Accu: 73%  \tValid_Acc:20% \t Valid Loss: 3.849 \n",
            "Epoch: 184 \tTraining Loss:  0.628 \tTrain_Accu: 77%  \tValid_Acc:21% \t Valid Loss: 3.016 \n",
            "Epoch: 185 \tTraining Loss:  0.575 \tTrain_Accu: 75%  \tValid_Acc:17% \t Valid Loss: 3.671 \n",
            "Epoch: 186 \tTraining Loss:  0.626 \tTrain_Accu: 75%  \tValid_Acc:19% \t Valid Loss: 3.266 \n",
            "Epoch: 187 \tTraining Loss:  0.597 \tTrain_Accu: 74%  \tValid_Acc:36% \t Valid Loss: 2.581 \n",
            "Epoch: 188 \tTraining Loss:  0.567 \tTrain_Accu: 79%  \tValid_Acc:24% \t Valid Loss: 4.029 \n",
            "Epoch: 189 \tTraining Loss:  0.646 \tTrain_Accu: 75%  \tValid_Acc:20% \t Valid Loss: 2.779 \n",
            "Epoch: 190 \tTraining Loss:  0.591 \tTrain_Accu: 76%  \tValid_Acc:29% \t Valid Loss: 2.261 \n",
            "Epoch: 191 \tTraining Loss:  0.527 \tTrain_Accu: 77%  \tValid_Acc:21% \t Valid Loss: 3.393 \n",
            "Epoch: 192 \tTraining Loss:  0.662 \tTrain_Accu: 71%  \tValid_Acc:17% \t Valid Loss: 3.909 \n",
            "Epoch: 193 \tTraining Loss:  0.617 \tTrain_Accu: 72%  \tValid_Acc:29% \t Valid Loss: 3.567 \n",
            "Epoch: 194 \tTraining Loss:  0.588 \tTrain_Accu: 76%  \tValid_Acc:30% \t Valid Loss: 3.718 \n",
            "Epoch: 195 \tTraining Loss:  0.587 \tTrain_Accu: 76%  \tValid_Acc:16% \t Valid Loss: 4.359 \n",
            "Epoch: 196 \tTraining Loss:  0.662 \tTrain_Accu: 74%  \tValid_Acc:23% \t Valid Loss: 4.482 \n",
            "Epoch: 197 \tTraining Loss:  0.637 \tTrain_Accu: 73%  \tValid_Acc:14% \t Valid Loss: 2.987 \n",
            "Epoch: 198 \tTraining Loss:  0.575 \tTrain_Accu: 78%  \tValid_Acc:19% \t Valid Loss: 4.280 \n",
            "Epoch: 199 \tTraining Loss:  0.624 \tTrain_Accu: 73%  \tValid_Acc:29% \t Valid Loss: 2.446 \n",
            "Epoch: 200 \tTraining Loss:  0.590 \tTrain_Accu: 76%  \tValid_Acc:20% \t Valid Loss: 3.429 \n",
            "Epoch: 201 \tTraining Loss:  0.551 \tTrain_Accu: 76%  \tValid_Acc:21% \t Valid Loss: 2.801 \n",
            "Epoch: 202 \tTraining Loss:  0.615 \tTrain_Accu: 73%  \tValid_Acc:27% \t Valid Loss: 2.539 \n",
            "Epoch: 203 \tTraining Loss:  0.659 \tTrain_Accu: 73%  \tValid_Acc:30% \t Valid Loss: 2.581 \n",
            "Epoch: 204 \tTraining Loss:  0.565 \tTrain_Accu: 76%  \tValid_Acc:23% \t Valid Loss: 3.379 \n",
            "Epoch: 205 \tTraining Loss:  0.616 \tTrain_Accu: 73%  \tValid_Acc:24% \t Valid Loss: 3.572 \n",
            "Epoch: 206 \tTraining Loss:  0.533 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 3.604 \n",
            "Epoch: 207 \tTraining Loss:  0.653 \tTrain_Accu: 75%  \tValid_Acc:23% \t Valid Loss: 3.687 \n",
            "Epoch: 208 \tTraining Loss:  0.504 \tTrain_Accu: 79%  \tValid_Acc:23% \t Valid Loss: 3.219 \n",
            "Epoch: 209 \tTraining Loss:  0.532 \tTrain_Accu: 78%  \tValid_Acc:21% \t Valid Loss: 3.870 \n",
            "Epoch: 210 \tTraining Loss:  0.590 \tTrain_Accu: 74%  \tValid_Acc:27% \t Valid Loss: 3.704 \n",
            "Epoch: 211 \tTraining Loss:  0.493 \tTrain_Accu: 80%  \tValid_Acc:17% \t Valid Loss: 4.170 \n",
            "Epoch: 212 \tTraining Loss:  0.504 \tTrain_Accu: 80%  \tValid_Acc:21% \t Valid Loss: 3.135 \n",
            "Epoch: 213 \tTraining Loss:  0.519 \tTrain_Accu: 78%  \tValid_Acc:21% \t Valid Loss: 5.586 \n",
            "Epoch: 214 \tTraining Loss:  0.530 \tTrain_Accu: 79%  \tValid_Acc:29% \t Valid Loss: 3.795 \n",
            "Epoch: 215 \tTraining Loss:  0.563 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 3.935 \n",
            "Epoch: 216 \tTraining Loss:  0.547 \tTrain_Accu: 78%  \tValid_Acc:26% \t Valid Loss: 4.518 \n",
            "Epoch: 217 \tTraining Loss:  0.507 \tTrain_Accu: 78%  \tValid_Acc:30% \t Valid Loss: 4.174 \n",
            "Epoch: 218 \tTraining Loss:  0.554 \tTrain_Accu: 80%  \tValid_Acc:26% \t Valid Loss: 3.906 \n",
            "Epoch: 219 \tTraining Loss:  0.569 \tTrain_Accu: 79%  \tValid_Acc:20% \t Valid Loss: 4.121 \n",
            "Epoch: 220 \tTraining Loss:  0.472 \tTrain_Accu: 80%  \tValid_Acc:30% \t Valid Loss: 3.820 \n",
            "Epoch: 221 \tTraining Loss:  0.540 \tTrain_Accu: 78%  \tValid_Acc:33% \t Valid Loss: 3.042 \n",
            "Epoch: 222 \tTraining Loss:  0.466 \tTrain_Accu: 82%  \tValid_Acc:24% \t Valid Loss: 3.122 \n",
            "Epoch: 223 \tTraining Loss:  0.504 \tTrain_Accu: 79%  \tValid_Acc:20% \t Valid Loss: 4.117 \n",
            "Epoch: 224 \tTraining Loss:  0.541 \tTrain_Accu: 77%  \tValid_Acc:29% \t Valid Loss: 4.347 \n",
            "Epoch: 225 \tTraining Loss:  0.561 \tTrain_Accu: 77%  \tValid_Acc:21% \t Valid Loss: 5.095 \n",
            "Epoch: 226 \tTraining Loss:  0.573 \tTrain_Accu: 77%  \tValid_Acc:26% \t Valid Loss: 4.128 \n",
            "Epoch: 227 \tTraining Loss:  0.567 \tTrain_Accu: 79%  \tValid_Acc:23% \t Valid Loss: 4.232 \n",
            "Epoch: 228 \tTraining Loss:  0.601 \tTrain_Accu: 74%  \tValid_Acc:30% \t Valid Loss: 4.495 \n",
            "Epoch: 229 \tTraining Loss:  0.481 \tTrain_Accu: 82%  \tValid_Acc:24% \t Valid Loss: 4.083 \n",
            "Epoch: 230 \tTraining Loss:  0.625 \tTrain_Accu: 76%  \tValid_Acc:24% \t Valid Loss: 3.930 \n",
            "Epoch: 231 \tTraining Loss:  0.524 \tTrain_Accu: 80%  \tValid_Acc:23% \t Valid Loss: 3.812 \n",
            "Epoch: 232 \tTraining Loss:  0.557 \tTrain_Accu: 78%  \tValid_Acc:26% \t Valid Loss: 3.255 \n",
            "Epoch: 233 \tTraining Loss:  0.540 \tTrain_Accu: 76%  \tValid_Acc:24% \t Valid Loss: 4.434 \n",
            "Epoch: 234 \tTraining Loss:  0.456 \tTrain_Accu: 82%  \tValid_Acc:23% \t Valid Loss: 3.312 \n",
            "Epoch: 235 \tTraining Loss:  0.546 \tTrain_Accu: 80%  \tValid_Acc:20% \t Valid Loss: 4.622 \n",
            "Epoch: 236 \tTraining Loss:  0.584 \tTrain_Accu: 80%  \tValid_Acc:21% \t Valid Loss: 3.880 \n",
            "Epoch: 237 \tTraining Loss:  0.474 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 3.344 \n",
            "Epoch: 238 \tTraining Loss:  0.538 \tTrain_Accu: 81%  \tValid_Acc:13% \t Valid Loss: 5.264 \n",
            "Epoch: 239 \tTraining Loss:  0.571 \tTrain_Accu: 77%  \tValid_Acc:23% \t Valid Loss: 4.818 \n",
            "Epoch: 240 \tTraining Loss:  0.452 \tTrain_Accu: 83%  \tValid_Acc:21% \t Valid Loss: 3.494 \n",
            "Epoch: 241 \tTraining Loss:  0.557 \tTrain_Accu: 77%  \tValid_Acc:36% \t Valid Loss: 2.976 \n",
            "Epoch: 242 \tTraining Loss:  0.501 \tTrain_Accu: 81%  \tValid_Acc:26% \t Valid Loss: 4.897 \n",
            "Epoch: 243 \tTraining Loss:  0.498 \tTrain_Accu: 79%  \tValid_Acc:24% \t Valid Loss: 3.383 \n",
            "Epoch: 244 \tTraining Loss:  0.486 \tTrain_Accu: 83%  \tValid_Acc:23% \t Valid Loss: 3.521 \n",
            "Epoch: 245 \tTraining Loss:  0.532 \tTrain_Accu: 80%  \tValid_Acc:21% \t Valid Loss: 3.482 \n",
            "Epoch: 246 \tTraining Loss:  0.505 \tTrain_Accu: 81%  \tValid_Acc:26% \t Valid Loss: 4.961 \n",
            "Epoch: 247 \tTraining Loss:  0.520 \tTrain_Accu: 80%  \tValid_Acc:24% \t Valid Loss: 4.313 \n",
            "Epoch: 248 \tTraining Loss:  0.528 \tTrain_Accu: 82%  \tValid_Acc:23% \t Valid Loss: 4.227 \n",
            "Epoch: 249 \tTraining Loss:  0.518 \tTrain_Accu: 81%  \tValid_Acc:34% \t Valid Loss: 4.033 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 02:13:31,301]\u001b[0m Trial 11 finished with value: 30.0 and parameters: {'lr': 0.0001, 'dropout': 0.8}. Best is trial 8 with value: 32.9.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.529 \tTrain_Accu: 77%  \tValid_Acc:30% \t Valid Loss: 5.141 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./optuna_valid_NNI_drop.torch']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "Ygu4gAxNE-bx",
        "outputId": "400c3be6-3c00-4739-cc45-8493d22f03f0"
      },
      "source": [
        "df_NNI = study.trials_dataframe().drop(['duration','state','datetime_start','datetime_complete'], axis=1)\n",
        "df_NNI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>params_dropout</th>\n",
              "      <th>params_lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>25.7</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>24.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>25.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.0100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>28.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    number  value  params_dropout  params_lr\n",
              "0        0    NaN             0.7     0.0010\n",
              "1        1   20.0             0.9     0.0001\n",
              "2        2    NaN             0.9     0.0100\n",
              "3        3   30.0             0.8     0.0001\n",
              "4        4   25.7             0.9     0.0010\n",
              "5        5   24.3             0.7     0.0010\n",
              "6        6   25.7             0.8     0.0100\n",
              "7        7   20.0             0.7     0.0010\n",
              "8        8   32.9             0.7     0.0001\n",
              "9        9   30.0             0.7     0.0001\n",
              "10      10   28.6             0.8     0.0010\n",
              "11      11   30.0             0.8     0.0001"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYKP2t7mx1ml"
      },
      "source": [
        "The model was rerun with batch size 1, lr 0.0001, RMSprop optimiser, epoch 350 and dropout rate [0.7, 0.8,0.9 ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0x31FG3bLKP"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_NNI_1(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          #'train_batch_size' : 5,\n",
        "          'Batch_size' : 1,\n",
        "          'n_epochs' : 350,\n",
        "          'seed' : 32,\n",
        "          'save_model' : True,\n",
        "          'lr'       :   0.0001,          \n",
        "          'optimizer': optim.RMSprop,\n",
        "          'dropout'       : trial.suggest_categorical('dropout', [0.7, 0.8,0.9 ]),\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_NNI_temp(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "\n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  \n",
        "  \n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}% \\t Valid Loss:{: .3f} '.format(epoch, train_loss, train_acc, valid_acc, valid_loss))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"./check_valid_NNI_RMSprops.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzPIO0hdbgVp",
        "outputId": "7bc08429-59ca-4c52-9fb4-2b71ac3fd7d8"
      },
      "source": [
        "import joblib\n",
        "\n",
        "study.optimize(train_NNI_1, n_trials=3)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"./optuna_valid_NNI_drop.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.669 \tTrain_Accu: 21%  \tValid_Acc:16% \t Valid Loss: 1.625 \n",
            "Epoch: 2 \tTraining Loss:  1.604 \tTrain_Accu: 27%  \tValid_Acc:19% \t Valid Loss: 1.628 \n",
            "Epoch: 3 \tTraining Loss:  1.593 \tTrain_Accu: 21%  \tValid_Acc:30% \t Valid Loss: 1.585 \n",
            "Epoch: 4 \tTraining Loss:  1.562 \tTrain_Accu: 27%  \tValid_Acc:20% \t Valid Loss: 1.614 \n",
            "Epoch: 5 \tTraining Loss:  1.549 \tTrain_Accu: 26%  \tValid_Acc:17% \t Valid Loss: 1.665 \n",
            "Epoch: 6 \tTraining Loss:  1.559 \tTrain_Accu: 30%  \tValid_Acc:17% \t Valid Loss: 1.583 \n",
            "Epoch: 7 \tTraining Loss:  1.514 \tTrain_Accu: 31%  \tValid_Acc:21% \t Valid Loss: 1.742 \n",
            "Epoch: 8 \tTraining Loss:  1.483 \tTrain_Accu: 32%  \tValid_Acc:31% \t Valid Loss: 1.577 \n",
            "Epoch: 9 \tTraining Loss:  1.487 \tTrain_Accu: 35%  \tValid_Acc:20% \t Valid Loss: 1.670 \n",
            "Epoch: 10 \tTraining Loss:  1.458 \tTrain_Accu: 38%  \tValid_Acc:23% \t Valid Loss: 1.570 \n",
            "Epoch: 11 \tTraining Loss:  1.404 \tTrain_Accu: 40%  \tValid_Acc:19% \t Valid Loss: 1.690 \n",
            "Epoch: 12 \tTraining Loss:  1.411 \tTrain_Accu: 39%  \tValid_Acc:21% \t Valid Loss: 1.655 \n",
            "Epoch: 13 \tTraining Loss:  1.402 \tTrain_Accu: 38%  \tValid_Acc:17% \t Valid Loss: 1.691 \n",
            "Epoch: 14 \tTraining Loss:  1.361 \tTrain_Accu: 45%  \tValid_Acc:14% \t Valid Loss: 1.716 \n",
            "Epoch: 15 \tTraining Loss:  1.335 \tTrain_Accu: 42%  \tValid_Acc:14% \t Valid Loss: 1.786 \n",
            "Epoch: 16 \tTraining Loss:  1.328 \tTrain_Accu: 46%  \tValid_Acc:24% \t Valid Loss: 1.734 \n",
            "Epoch: 17 \tTraining Loss:  1.300 \tTrain_Accu: 42%  \tValid_Acc:20% \t Valid Loss: 1.749 \n",
            "Epoch: 18 \tTraining Loss:  1.333 \tTrain_Accu: 41%  \tValid_Acc:17% \t Valid Loss: 1.728 \n",
            "Epoch: 19 \tTraining Loss:  1.220 \tTrain_Accu: 47%  \tValid_Acc:21% \t Valid Loss: 1.830 \n",
            "Epoch: 20 \tTraining Loss:  1.181 \tTrain_Accu: 48%  \tValid_Acc:29% \t Valid Loss: 1.763 \n",
            "Epoch: 21 \tTraining Loss:  1.183 \tTrain_Accu: 52%  \tValid_Acc:24% \t Valid Loss: 1.947 \n",
            "Epoch: 22 \tTraining Loss:  1.177 \tTrain_Accu: 48%  \tValid_Acc:27% \t Valid Loss: 1.683 \n",
            "Epoch: 23 \tTraining Loss:  1.148 \tTrain_Accu: 50%  \tValid_Acc:26% \t Valid Loss: 2.061 \n",
            "Epoch: 24 \tTraining Loss:  1.105 \tTrain_Accu: 54%  \tValid_Acc:16% \t Valid Loss: 2.021 \n",
            "Epoch: 25 \tTraining Loss:  1.065 \tTrain_Accu: 54%  \tValid_Acc:27% \t Valid Loss: 1.848 \n",
            "Epoch: 26 \tTraining Loss:  1.021 \tTrain_Accu: 56%  \tValid_Acc:21% \t Valid Loss: 2.337 \n",
            "Epoch: 27 \tTraining Loss:  1.107 \tTrain_Accu: 52%  \tValid_Acc:20% \t Valid Loss: 1.841 \n",
            "Epoch: 28 \tTraining Loss:  0.969 \tTrain_Accu: 60%  \tValid_Acc:23% \t Valid Loss: 1.830 \n",
            "Epoch: 29 \tTraining Loss:  0.921 \tTrain_Accu: 61%  \tValid_Acc:20% \t Valid Loss: 1.866 \n",
            "Epoch: 30 \tTraining Loss:  0.930 \tTrain_Accu: 61%  \tValid_Acc:33% \t Valid Loss: 1.856 \n",
            "Epoch: 31 \tTraining Loss:  0.922 \tTrain_Accu: 57%  \tValid_Acc:21% \t Valid Loss: 1.979 \n",
            "Epoch: 32 \tTraining Loss:  0.978 \tTrain_Accu: 58%  \tValid_Acc:26% \t Valid Loss: 1.794 \n",
            "Epoch: 33 \tTraining Loss:  0.856 \tTrain_Accu: 66%  \tValid_Acc:33% \t Valid Loss: 2.326 \n",
            "Epoch: 34 \tTraining Loss:  0.827 \tTrain_Accu: 66%  \tValid_Acc:26% \t Valid Loss: 2.110 \n",
            "Epoch: 35 \tTraining Loss:  0.821 \tTrain_Accu: 65%  \tValid_Acc:30% \t Valid Loss: 1.891 \n",
            "Epoch: 36 \tTraining Loss:  0.824 \tTrain_Accu: 65%  \tValid_Acc:31% \t Valid Loss: 2.123 \n",
            "Epoch: 37 \tTraining Loss:  0.806 \tTrain_Accu: 67%  \tValid_Acc:31% \t Valid Loss: 2.073 \n",
            "Epoch: 38 \tTraining Loss:  0.769 \tTrain_Accu: 67%  \tValid_Acc:26% \t Valid Loss: 2.646 \n",
            "Epoch: 39 \tTraining Loss:  0.755 \tTrain_Accu: 70%  \tValid_Acc:17% \t Valid Loss: 2.265 \n",
            "Epoch: 40 \tTraining Loss:  0.798 \tTrain_Accu: 68%  \tValid_Acc:33% \t Valid Loss: 1.942 \n",
            "Epoch: 41 \tTraining Loss:  0.769 \tTrain_Accu: 67%  \tValid_Acc:24% \t Valid Loss: 2.165 \n",
            "Epoch: 42 \tTraining Loss:  0.703 \tTrain_Accu: 69%  \tValid_Acc:27% \t Valid Loss: 2.460 \n",
            "Epoch: 43 \tTraining Loss:  0.740 \tTrain_Accu: 69%  \tValid_Acc:29% \t Valid Loss: 1.930 \n",
            "Epoch: 44 \tTraining Loss:  0.730 \tTrain_Accu: 72%  \tValid_Acc:30% \t Valid Loss: 2.109 \n",
            "Epoch: 45 \tTraining Loss:  0.675 \tTrain_Accu: 74%  \tValid_Acc:21% \t Valid Loss: 2.591 \n",
            "Epoch: 46 \tTraining Loss:  0.649 \tTrain_Accu: 77%  \tValid_Acc:23% \t Valid Loss: 2.329 \n",
            "Epoch: 47 \tTraining Loss:  0.643 \tTrain_Accu: 74%  \tValid_Acc:21% \t Valid Loss: 2.957 \n",
            "Epoch: 48 \tTraining Loss:  0.587 \tTrain_Accu: 75%  \tValid_Acc:24% \t Valid Loss: 3.064 \n",
            "Epoch: 49 \tTraining Loss:  0.572 \tTrain_Accu: 78%  \tValid_Acc:27% \t Valid Loss: 2.422 \n",
            "Epoch: 50 \tTraining Loss:  0.552 \tTrain_Accu: 77%  \tValid_Acc:23% \t Valid Loss: 2.737 \n",
            "Epoch: 51 \tTraining Loss:  0.554 \tTrain_Accu: 79%  \tValid_Acc:27% \t Valid Loss: 2.479 \n",
            "Epoch: 52 \tTraining Loss:  0.542 \tTrain_Accu: 78%  \tValid_Acc:31% \t Valid Loss: 2.418 \n",
            "Epoch: 53 \tTraining Loss:  0.574 \tTrain_Accu: 75%  \tValid_Acc:36% \t Valid Loss: 2.603 \n",
            "Epoch: 54 \tTraining Loss:  0.470 \tTrain_Accu: 80%  \tValid_Acc:29% \t Valid Loss: 3.285 \n",
            "Epoch: 55 \tTraining Loss:  0.553 \tTrain_Accu: 77%  \tValid_Acc:31% \t Valid Loss: 2.771 \n",
            "Epoch: 56 \tTraining Loss:  0.543 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 3.338 \n",
            "Epoch: 57 \tTraining Loss:  0.548 \tTrain_Accu: 75%  \tValid_Acc:23% \t Valid Loss: 2.933 \n",
            "Epoch: 58 \tTraining Loss:  0.529 \tTrain_Accu: 77%  \tValid_Acc:34% \t Valid Loss: 2.148 \n",
            "Epoch: 59 \tTraining Loss:  0.447 \tTrain_Accu: 81%  \tValid_Acc:27% \t Valid Loss: 3.264 \n",
            "Epoch: 60 \tTraining Loss:  0.502 \tTrain_Accu: 79%  \tValid_Acc:23% \t Valid Loss: 2.365 \n",
            "Epoch: 61 \tTraining Loss:  0.443 \tTrain_Accu: 83%  \tValid_Acc:31% \t Valid Loss: 3.083 \n",
            "Epoch: 62 \tTraining Loss:  0.584 \tTrain_Accu: 76%  \tValid_Acc:31% \t Valid Loss: 3.157 \n",
            "Epoch: 63 \tTraining Loss:  0.444 \tTrain_Accu: 83%  \tValid_Acc:30% \t Valid Loss: 3.412 \n",
            "Epoch: 64 \tTraining Loss:  0.462 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 2.040 \n",
            "Epoch: 65 \tTraining Loss:  0.516 \tTrain_Accu: 77%  \tValid_Acc:34% \t Valid Loss: 2.594 \n",
            "Epoch: 66 \tTraining Loss:  0.516 \tTrain_Accu: 79%  \tValid_Acc:24% \t Valid Loss: 2.735 \n",
            "Epoch: 67 \tTraining Loss:  0.424 \tTrain_Accu: 86%  \tValid_Acc:21% \t Valid Loss: 3.176 \n",
            "Epoch: 68 \tTraining Loss:  0.516 \tTrain_Accu: 78%  \tValid_Acc:26% \t Valid Loss: 2.982 \n",
            "Epoch: 69 \tTraining Loss:  0.474 \tTrain_Accu: 81%  \tValid_Acc:20% \t Valid Loss: 3.731 \n",
            "Epoch: 70 \tTraining Loss:  0.448 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 3.031 \n",
            "Epoch: 71 \tTraining Loss:  0.442 \tTrain_Accu: 82%  \tValid_Acc:26% \t Valid Loss: 2.818 \n",
            "Epoch: 72 \tTraining Loss:  0.399 \tTrain_Accu: 83%  \tValid_Acc:23% \t Valid Loss: 3.640 \n",
            "Epoch: 73 \tTraining Loss:  0.413 \tTrain_Accu: 82%  \tValid_Acc:31% \t Valid Loss: 2.963 \n",
            "Epoch: 74 \tTraining Loss:  0.429 \tTrain_Accu: 82%  \tValid_Acc:23% \t Valid Loss: 3.589 \n",
            "Epoch: 75 \tTraining Loss:  0.408 \tTrain_Accu: 84%  \tValid_Acc:19% \t Valid Loss: 4.048 \n",
            "Epoch: 76 \tTraining Loss:  0.465 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 2.845 \n",
            "Epoch: 77 \tTraining Loss:  0.401 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 3.391 \n",
            "Epoch: 78 \tTraining Loss:  0.422 \tTrain_Accu: 83%  \tValid_Acc:31% \t Valid Loss: 2.705 \n",
            "Epoch: 79 \tTraining Loss:  0.394 \tTrain_Accu: 86%  \tValid_Acc:27% \t Valid Loss: 2.925 \n",
            "Epoch: 80 \tTraining Loss:  0.389 \tTrain_Accu: 85%  \tValid_Acc:29% \t Valid Loss: 4.504 \n",
            "Epoch: 81 \tTraining Loss:  0.385 \tTrain_Accu: 84%  \tValid_Acc:40% \t Valid Loss: 2.856 \n",
            "Epoch: 82 \tTraining Loss:  0.385 \tTrain_Accu: 85%  \tValid_Acc:30% \t Valid Loss: 3.981 \n",
            "Epoch: 83 \tTraining Loss:  0.411 \tTrain_Accu: 84%  \tValid_Acc:20% \t Valid Loss: 3.839 \n",
            "Epoch: 84 \tTraining Loss:  0.428 \tTrain_Accu: 83%  \tValid_Acc:33% \t Valid Loss: 3.540 \n",
            "Epoch: 85 \tTraining Loss:  0.361 \tTrain_Accu: 85%  \tValid_Acc:26% \t Valid Loss: 3.799 \n",
            "Epoch: 86 \tTraining Loss:  0.385 \tTrain_Accu: 86%  \tValid_Acc:19% \t Valid Loss: 4.090 \n",
            "Epoch: 87 \tTraining Loss:  0.377 \tTrain_Accu: 85%  \tValid_Acc:27% \t Valid Loss: 3.980 \n",
            "Epoch: 88 \tTraining Loss:  0.335 \tTrain_Accu: 86%  \tValid_Acc:30% \t Valid Loss: 4.372 \n",
            "Epoch: 89 \tTraining Loss:  0.354 \tTrain_Accu: 85%  \tValid_Acc:30% \t Valid Loss: 3.305 \n",
            "Epoch: 90 \tTraining Loss:  0.360 \tTrain_Accu: 85%  \tValid_Acc:21% \t Valid Loss: 4.363 \n",
            "Epoch: 91 \tTraining Loss:  0.351 \tTrain_Accu: 87%  \tValid_Acc:24% \t Valid Loss: 3.793 \n",
            "Epoch: 92 \tTraining Loss:  0.321 \tTrain_Accu: 87%  \tValid_Acc:30% \t Valid Loss: 3.839 \n",
            "Epoch: 93 \tTraining Loss:  0.317 \tTrain_Accu: 86%  \tValid_Acc:20% \t Valid Loss: 4.560 \n",
            "Epoch: 94 \tTraining Loss:  0.342 \tTrain_Accu: 86%  \tValid_Acc:30% \t Valid Loss: 4.306 \n",
            "Epoch: 95 \tTraining Loss:  0.335 \tTrain_Accu: 86%  \tValid_Acc:29% \t Valid Loss: 4.473 \n",
            "Epoch: 96 \tTraining Loss:  0.330 \tTrain_Accu: 87%  \tValid_Acc:33% \t Valid Loss: 4.265 \n",
            "Epoch: 97 \tTraining Loss:  0.345 \tTrain_Accu: 87%  \tValid_Acc:36% \t Valid Loss: 3.320 \n",
            "Epoch: 98 \tTraining Loss:  0.288 \tTrain_Accu: 88%  \tValid_Acc:23% \t Valid Loss: 4.182 \n",
            "Epoch: 99 \tTraining Loss:  0.333 \tTrain_Accu: 86%  \tValid_Acc:20% \t Valid Loss: 3.741 \n",
            "Epoch: 100 \tTraining Loss:  0.331 \tTrain_Accu: 88%  \tValid_Acc:40% \t Valid Loss: 5.035 \n",
            "Epoch: 101 \tTraining Loss:  0.305 \tTrain_Accu: 88%  \tValid_Acc:30% \t Valid Loss: 4.413 \n",
            "Epoch: 102 \tTraining Loss:  0.333 \tTrain_Accu: 87%  \tValid_Acc:33% \t Valid Loss: 3.314 \n",
            "Epoch: 103 \tTraining Loss:  0.322 \tTrain_Accu: 87%  \tValid_Acc:33% \t Valid Loss: 4.088 \n",
            "Epoch: 104 \tTraining Loss:  0.314 \tTrain_Accu: 87%  \tValid_Acc:29% \t Valid Loss: 4.166 \n",
            "Epoch: 105 \tTraining Loss:  0.319 \tTrain_Accu: 86%  \tValid_Acc:24% \t Valid Loss: 4.330 \n",
            "Epoch: 106 \tTraining Loss:  0.334 \tTrain_Accu: 87%  \tValid_Acc:30% \t Valid Loss: 3.310 \n",
            "Epoch: 107 \tTraining Loss:  0.335 \tTrain_Accu: 87%  \tValid_Acc:24% \t Valid Loss: 5.139 \n",
            "Epoch: 108 \tTraining Loss:  0.307 \tTrain_Accu: 89%  \tValid_Acc:27% \t Valid Loss: 5.134 \n",
            "Epoch: 109 \tTraining Loss:  0.283 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 3.930 \n",
            "Epoch: 110 \tTraining Loss:  0.324 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 3.919 \n",
            "Epoch: 111 \tTraining Loss:  0.311 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 4.559 \n",
            "Epoch: 112 \tTraining Loss:  0.265 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 4.093 \n",
            "Epoch: 113 \tTraining Loss:  0.282 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 5.549 \n",
            "Epoch: 114 \tTraining Loss:  0.322 \tTrain_Accu: 85%  \tValid_Acc:27% \t Valid Loss: 5.418 \n",
            "Epoch: 115 \tTraining Loss:  0.361 \tTrain_Accu: 87%  \tValid_Acc:17% \t Valid Loss: 5.061 \n",
            "Epoch: 116 \tTraining Loss:  0.313 \tTrain_Accu: 86%  \tValid_Acc:27% \t Valid Loss: 4.495 \n",
            "Epoch: 117 \tTraining Loss:  0.297 \tTrain_Accu: 89%  \tValid_Acc:31% \t Valid Loss: 3.989 \n",
            "Epoch: 118 \tTraining Loss:  0.264 \tTrain_Accu: 89%  \tValid_Acc:29% \t Valid Loss: 4.621 \n",
            "Epoch: 119 \tTraining Loss:  0.315 \tTrain_Accu: 88%  \tValid_Acc:29% \t Valid Loss: 3.290 \n",
            "Epoch: 120 \tTraining Loss:  0.283 \tTrain_Accu: 87%  \tValid_Acc:33% \t Valid Loss: 4.130 \n",
            "Epoch: 121 \tTraining Loss:  0.363 \tTrain_Accu: 88%  \tValid_Acc:26% \t Valid Loss: 4.030 \n",
            "Epoch: 122 \tTraining Loss:  0.279 \tTrain_Accu: 89%  \tValid_Acc:34% \t Valid Loss: 4.328 \n",
            "Epoch: 123 \tTraining Loss:  0.232 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 5.084 \n",
            "Epoch: 124 \tTraining Loss:  0.312 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 4.341 \n",
            "Epoch: 125 \tTraining Loss:  0.297 \tTrain_Accu: 89%  \tValid_Acc:33% \t Valid Loss: 4.041 \n",
            "Epoch: 126 \tTraining Loss:  0.308 \tTrain_Accu: 87%  \tValid_Acc:21% \t Valid Loss: 4.525 \n",
            "Epoch: 127 \tTraining Loss:  0.294 \tTrain_Accu: 90%  \tValid_Acc:33% \t Valid Loss: 3.709 \n",
            "Epoch: 128 \tTraining Loss:  0.323 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 5.177 \n",
            "Epoch: 129 \tTraining Loss:  0.326 \tTrain_Accu: 86%  \tValid_Acc:26% \t Valid Loss: 4.832 \n",
            "Epoch: 130 \tTraining Loss:  0.266 \tTrain_Accu: 88%  \tValid_Acc:31% \t Valid Loss: 4.457 \n",
            "Epoch: 131 \tTraining Loss:  0.279 \tTrain_Accu: 87%  \tValid_Acc:34% \t Valid Loss: 4.551 \n",
            "Epoch: 132 \tTraining Loss:  0.283 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 5.820 \n",
            "Epoch: 133 \tTraining Loss:  0.276 \tTrain_Accu: 89%  \tValid_Acc:24% \t Valid Loss: 4.938 \n",
            "Epoch: 134 \tTraining Loss:  0.316 \tTrain_Accu: 87%  \tValid_Acc:24% \t Valid Loss: 3.690 \n",
            "Epoch: 135 \tTraining Loss:  0.279 \tTrain_Accu: 87%  \tValid_Acc:29% \t Valid Loss: 4.664 \n",
            "Epoch: 136 \tTraining Loss:  0.295 \tTrain_Accu: 88%  \tValid_Acc:23% \t Valid Loss: 5.146 \n",
            "Epoch: 137 \tTraining Loss:  0.265 \tTrain_Accu: 90%  \tValid_Acc:33% \t Valid Loss: 4.008 \n",
            "Epoch: 138 \tTraining Loss:  0.217 \tTrain_Accu: 90%  \tValid_Acc:31% \t Valid Loss: 4.057 \n",
            "Epoch: 139 \tTraining Loss:  0.340 \tTrain_Accu: 88%  \tValid_Acc:21% \t Valid Loss: 5.069 \n",
            "Epoch: 140 \tTraining Loss:  0.317 \tTrain_Accu: 89%  \tValid_Acc:31% \t Valid Loss: 3.593 \n",
            "Epoch: 141 \tTraining Loss:  0.358 \tTrain_Accu: 86%  \tValid_Acc:30% \t Valid Loss: 3.867 \n",
            "Epoch: 142 \tTraining Loss:  0.247 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 4.510 \n",
            "Epoch: 143 \tTraining Loss:  0.254 \tTrain_Accu: 90%  \tValid_Acc:31% \t Valid Loss: 4.630 \n",
            "Epoch: 144 \tTraining Loss:  0.255 \tTrain_Accu: 90%  \tValid_Acc:36% \t Valid Loss: 3.587 \n",
            "Epoch: 145 \tTraining Loss:  0.230 \tTrain_Accu: 92%  \tValid_Acc:33% \t Valid Loss: 4.304 \n",
            "Epoch: 146 \tTraining Loss:  0.333 \tTrain_Accu: 87%  \tValid_Acc:27% \t Valid Loss: 5.052 \n",
            "Epoch: 147 \tTraining Loss:  0.264 \tTrain_Accu: 88%  \tValid_Acc:29% \t Valid Loss: 4.410 \n",
            "Epoch: 148 \tTraining Loss:  0.244 \tTrain_Accu: 90%  \tValid_Acc:34% \t Valid Loss: 5.140 \n",
            "Epoch: 149 \tTraining Loss:  0.325 \tTrain_Accu: 87%  \tValid_Acc:30% \t Valid Loss: 3.858 \n",
            "Epoch: 150 \tTraining Loss:  0.268 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 4.188 \n",
            "Epoch: 151 \tTraining Loss:  0.319 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 4.014 \n",
            "Epoch: 152 \tTraining Loss:  0.260 \tTrain_Accu: 88%  \tValid_Acc:30% \t Valid Loss: 4.717 \n",
            "Epoch: 153 \tTraining Loss:  0.289 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 4.477 \n",
            "Epoch: 154 \tTraining Loss:  0.249 \tTrain_Accu: 89%  \tValid_Acc:27% \t Valid Loss: 4.568 \n",
            "Epoch: 155 \tTraining Loss:  0.236 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 4.810 \n",
            "Epoch: 156 \tTraining Loss:  0.255 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 5.211 \n",
            "Epoch: 157 \tTraining Loss:  0.225 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 6.435 \n",
            "Epoch: 158 \tTraining Loss:  0.238 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 4.947 \n",
            "Epoch: 159 \tTraining Loss:  0.239 \tTrain_Accu: 89%  \tValid_Acc:21% \t Valid Loss: 5.491 \n",
            "Epoch: 160 \tTraining Loss:  0.214 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 5.649 \n",
            "Epoch: 161 \tTraining Loss:  0.261 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 5.911 \n",
            "Epoch: 162 \tTraining Loss:  0.228 \tTrain_Accu: 92%  \tValid_Acc:33% \t Valid Loss: 5.292 \n",
            "Epoch: 163 \tTraining Loss:  0.227 \tTrain_Accu: 90%  \tValid_Acc:24% \t Valid Loss: 5.663 \n",
            "Epoch: 164 \tTraining Loss:  0.287 \tTrain_Accu: 90%  \tValid_Acc:33% \t Valid Loss: 4.751 \n",
            "Epoch: 165 \tTraining Loss:  0.246 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 5.480 \n",
            "Epoch: 166 \tTraining Loss:  0.202 \tTrain_Accu: 92%  \tValid_Acc:23% \t Valid Loss: 6.199 \n",
            "Epoch: 167 \tTraining Loss:  0.263 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 5.653 \n",
            "Epoch: 168 \tTraining Loss:  0.309 \tTrain_Accu: 89%  \tValid_Acc:26% \t Valid Loss: 3.843 \n",
            "Epoch: 169 \tTraining Loss:  0.229 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 4.933 \n",
            "Epoch: 170 \tTraining Loss:  0.292 \tTrain_Accu: 88%  \tValid_Acc:36% \t Valid Loss: 4.112 \n",
            "Epoch: 171 \tTraining Loss:  0.266 \tTrain_Accu: 88%  \tValid_Acc:30% \t Valid Loss: 6.780 \n",
            "Epoch: 172 \tTraining Loss:  0.258 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 6.354 \n",
            "Epoch: 173 \tTraining Loss:  0.263 \tTrain_Accu: 89%  \tValid_Acc:31% \t Valid Loss: 4.850 \n",
            "Epoch: 174 \tTraining Loss:  0.307 \tTrain_Accu: 86%  \tValid_Acc:36% \t Valid Loss: 4.377 \n",
            "Epoch: 175 \tTraining Loss:  0.224 \tTrain_Accu: 92%  \tValid_Acc:33% \t Valid Loss: 4.900 \n",
            "Epoch: 176 \tTraining Loss:  0.236 \tTrain_Accu: 91%  \tValid_Acc:33% \t Valid Loss: 3.561 \n",
            "Epoch: 177 \tTraining Loss:  0.247 \tTrain_Accu: 90%  \tValid_Acc:31% \t Valid Loss: 6.834 \n",
            "Epoch: 178 \tTraining Loss:  0.282 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 4.504 \n",
            "Epoch: 179 \tTraining Loss:  0.208 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 6.683 \n",
            "Epoch: 180 \tTraining Loss:  0.282 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 5.143 \n",
            "Epoch: 181 \tTraining Loss:  0.173 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 5.956 \n",
            "Epoch: 182 \tTraining Loss:  0.263 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 6.223 \n",
            "Epoch: 183 \tTraining Loss:  0.262 \tTrain_Accu: 88%  \tValid_Acc:24% \t Valid Loss: 5.760 \n",
            "Epoch: 184 \tTraining Loss:  0.250 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 4.675 \n",
            "Epoch: 185 \tTraining Loss:  0.226 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 6.741 \n",
            "Epoch: 186 \tTraining Loss:  0.252 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 5.197 \n",
            "Epoch: 187 \tTraining Loss:  0.213 \tTrain_Accu: 92%  \tValid_Acc:31% \t Valid Loss: 4.970 \n",
            "Epoch: 188 \tTraining Loss:  0.266 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 6.882 \n",
            "Epoch: 189 \tTraining Loss:  0.301 \tTrain_Accu: 90%  \tValid_Acc:19% \t Valid Loss: 5.848 \n",
            "Epoch: 190 \tTraining Loss:  0.196 \tTrain_Accu: 93%  \tValid_Acc:33% \t Valid Loss: 6.069 \n",
            "Epoch: 191 \tTraining Loss:  0.243 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 5.507 \n",
            "Epoch: 192 \tTraining Loss:  0.277 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 6.023 \n",
            "Epoch: 193 \tTraining Loss:  0.227 \tTrain_Accu: 90%  \tValid_Acc:17% \t Valid Loss: 6.788 \n",
            "Epoch: 194 \tTraining Loss:  0.231 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 5.753 \n",
            "Epoch: 195 \tTraining Loss:  0.265 \tTrain_Accu: 88%  \tValid_Acc:29% \t Valid Loss: 5.480 \n",
            "Epoch: 196 \tTraining Loss:  0.259 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 7.025 \n",
            "Epoch: 197 \tTraining Loss:  0.247 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 4.655 \n",
            "Epoch: 198 \tTraining Loss:  0.286 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 5.526 \n",
            "Epoch: 199 \tTraining Loss:  0.301 \tTrain_Accu: 88%  \tValid_Acc:27% \t Valid Loss: 5.213 \n",
            "Epoch: 200 \tTraining Loss:  0.242 \tTrain_Accu: 92%  \tValid_Acc:34% \t Valid Loss: 4.742 \n",
            "Epoch: 201 \tTraining Loss:  0.302 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 4.811 \n",
            "Epoch: 202 \tTraining Loss:  0.261 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 6.682 \n",
            "Epoch: 203 \tTraining Loss:  0.285 \tTrain_Accu: 90%  \tValid_Acc:31% \t Valid Loss: 4.590 \n",
            "Epoch: 204 \tTraining Loss:  0.202 \tTrain_Accu: 91%  \tValid_Acc:39% \t Valid Loss: 6.313 \n",
            "Epoch: 205 \tTraining Loss:  0.280 \tTrain_Accu: 88%  \tValid_Acc:27% \t Valid Loss: 4.755 \n",
            "Epoch: 206 \tTraining Loss:  0.231 \tTrain_Accu: 90%  \tValid_Acc:27% \t Valid Loss: 7.439 \n",
            "Epoch: 207 \tTraining Loss:  0.259 \tTrain_Accu: 91%  \tValid_Acc:27% \t Valid Loss: 6.764 \n",
            "Epoch: 208 \tTraining Loss:  0.359 \tTrain_Accu: 89%  \tValid_Acc:24% \t Valid Loss: 4.742 \n",
            "Epoch: 209 \tTraining Loss:  0.235 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 5.202 \n",
            "Epoch: 210 \tTraining Loss:  0.200 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 7.085 \n",
            "Epoch: 211 \tTraining Loss:  0.284 \tTrain_Accu: 87%  \tValid_Acc:29% \t Valid Loss: 4.840 \n",
            "Epoch: 212 \tTraining Loss:  0.236 \tTrain_Accu: 91%  \tValid_Acc:39% \t Valid Loss: 5.442 \n",
            "Epoch: 213 \tTraining Loss:  0.231 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 6.367 \n",
            "Epoch: 214 \tTraining Loss:  0.232 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 6.896 \n",
            "Epoch: 215 \tTraining Loss:  0.210 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 7.446 \n",
            "Epoch: 216 \tTraining Loss:  0.254 \tTrain_Accu: 89%  \tValid_Acc:34% \t Valid Loss: 6.074 \n",
            "Epoch: 217 \tTraining Loss:  0.333 \tTrain_Accu: 87%  \tValid_Acc:29% \t Valid Loss: 6.668 \n",
            "Epoch: 218 \tTraining Loss:  0.238 \tTrain_Accu: 90%  \tValid_Acc:24% \t Valid Loss: 5.197 \n",
            "Epoch: 219 \tTraining Loss:  0.209 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 5.177 \n",
            "Epoch: 220 \tTraining Loss:  0.188 \tTrain_Accu: 93%  \tValid_Acc:13% \t Valid Loss: 6.486 \n",
            "Epoch: 221 \tTraining Loss:  0.216 \tTrain_Accu: 92%  \tValid_Acc:20% \t Valid Loss: 6.572 \n",
            "Epoch: 222 \tTraining Loss:  0.240 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 4.081 \n",
            "Epoch: 223 \tTraining Loss:  0.252 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 6.149 \n",
            "Epoch: 224 \tTraining Loss:  0.240 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 5.530 \n",
            "Epoch: 225 \tTraining Loss:  0.259 \tTrain_Accu: 89%  \tValid_Acc:24% \t Valid Loss: 6.236 \n",
            "Epoch: 226 \tTraining Loss:  0.313 \tTrain_Accu: 89%  \tValid_Acc:29% \t Valid Loss: 6.390 \n",
            "Epoch: 227 \tTraining Loss:  0.235 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 6.080 \n",
            "Epoch: 228 \tTraining Loss:  0.332 \tTrain_Accu: 88%  \tValid_Acc:29% \t Valid Loss: 5.623 \n",
            "Epoch: 229 \tTraining Loss:  0.267 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 7.404 \n",
            "Epoch: 230 \tTraining Loss:  0.253 \tTrain_Accu: 91%  \tValid_Acc:34% \t Valid Loss: 4.730 \n",
            "Epoch: 231 \tTraining Loss:  0.208 \tTrain_Accu: 93%  \tValid_Acc:20% \t Valid Loss: 8.159 \n",
            "Epoch: 232 \tTraining Loss:  0.185 \tTrain_Accu: 94%  \tValid_Acc:23% \t Valid Loss: 5.474 \n",
            "Epoch: 233 \tTraining Loss:  0.230 \tTrain_Accu: 90%  \tValid_Acc:31% \t Valid Loss: 4.713 \n",
            "Epoch: 234 \tTraining Loss:  0.233 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 5.256 \n",
            "Epoch: 235 \tTraining Loss:  0.261 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 4.991 \n",
            "Epoch: 236 \tTraining Loss:  0.243 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 5.229 \n",
            "Epoch: 237 \tTraining Loss:  0.278 \tTrain_Accu: 88%  \tValid_Acc:24% \t Valid Loss: 5.504 \n",
            "Epoch: 238 \tTraining Loss:  0.249 \tTrain_Accu: 92%  \tValid_Acc:23% \t Valid Loss: 7.938 \n",
            "Epoch: 239 \tTraining Loss:  0.233 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 6.746 \n",
            "Epoch: 240 \tTraining Loss:  0.183 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 6.612 \n",
            "Epoch: 241 \tTraining Loss:  0.302 \tTrain_Accu: 89%  \tValid_Acc:30% \t Valid Loss: 5.683 \n",
            "Epoch: 242 \tTraining Loss:  0.200 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 6.494 \n",
            "Epoch: 243 \tTraining Loss:  0.242 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 4.845 \n",
            "Epoch: 244 \tTraining Loss:  0.281 \tTrain_Accu: 89%  \tValid_Acc:31% \t Valid Loss: 5.236 \n",
            "Epoch: 245 \tTraining Loss:  0.238 \tTrain_Accu: 91%  \tValid_Acc:30% \t Valid Loss: 5.312 \n",
            "Epoch: 246 \tTraining Loss:  0.232 \tTrain_Accu: 91%  \tValid_Acc:33% \t Valid Loss: 7.152 \n",
            "Epoch: 247 \tTraining Loss:  0.236 \tTrain_Accu: 91%  \tValid_Acc:21% \t Valid Loss: 6.908 \n",
            "Epoch: 248 \tTraining Loss:  0.250 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 7.516 \n",
            "Epoch: 249 \tTraining Loss:  0.309 \tTrain_Accu: 88%  \tValid_Acc:27% \t Valid Loss: 5.982 \n",
            "Epoch: 250 \tTraining Loss:  0.358 \tTrain_Accu: 88%  \tValid_Acc:29% \t Valid Loss: 4.684 \n",
            "Epoch: 251 \tTraining Loss:  0.255 \tTrain_Accu: 90%  \tValid_Acc:17% \t Valid Loss: 6.654 \n",
            "Epoch: 252 \tTraining Loss:  0.230 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 4.969 \n",
            "Epoch: 253 \tTraining Loss:  0.218 \tTrain_Accu: 93%  \tValid_Acc:27% \t Valid Loss: 4.934 \n",
            "Epoch: 254 \tTraining Loss:  0.208 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 6.551 \n",
            "Epoch: 255 \tTraining Loss:  0.279 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 7.097 \n",
            "Epoch: 256 \tTraining Loss:  0.252 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 6.540 \n",
            "Epoch: 257 \tTraining Loss:  0.269 \tTrain_Accu: 89%  \tValid_Acc:27% \t Valid Loss: 7.157 \n",
            "Epoch: 258 \tTraining Loss:  0.251 \tTrain_Accu: 90%  \tValid_Acc:20% \t Valid Loss: 6.112 \n",
            "Epoch: 259 \tTraining Loss:  0.278 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 5.591 \n",
            "Epoch: 260 \tTraining Loss:  0.256 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 7.973 \n",
            "Epoch: 261 \tTraining Loss:  0.210 \tTrain_Accu: 91%  \tValid_Acc:19% \t Valid Loss: 7.930 \n",
            "Epoch: 262 \tTraining Loss:  0.239 \tTrain_Accu: 92%  \tValid_Acc:29% \t Valid Loss: 5.263 \n",
            "Epoch: 263 \tTraining Loss:  0.340 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 3.841 \n",
            "Epoch: 264 \tTraining Loss:  0.222 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 9.365 \n",
            "Epoch: 265 \tTraining Loss:  0.260 \tTrain_Accu: 92%  \tValid_Acc:34% \t Valid Loss: 6.444 \n",
            "Epoch: 266 \tTraining Loss:  0.230 \tTrain_Accu: 92%  \tValid_Acc:26% \t Valid Loss: 7.782 \n",
            "Epoch: 267 \tTraining Loss:  0.236 \tTrain_Accu: 91%  \tValid_Acc:17% \t Valid Loss: 6.258 \n",
            "Epoch: 268 \tTraining Loss:  0.231 \tTrain_Accu: 93%  \tValid_Acc:19% \t Valid Loss: 8.584 \n",
            "Epoch: 269 \tTraining Loss:  0.224 \tTrain_Accu: 91%  \tValid_Acc:33% \t Valid Loss: 6.739 \n",
            "Epoch: 270 \tTraining Loss:  0.262 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 5.738 \n",
            "Epoch: 271 \tTraining Loss:  0.230 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 6.297 \n",
            "Epoch: 272 \tTraining Loss:  0.201 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 7.318 \n",
            "Epoch: 273 \tTraining Loss:  0.224 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 9.908 \n",
            "Epoch: 274 \tTraining Loss:  0.256 \tTrain_Accu: 91%  \tValid_Acc:26% \t Valid Loss: 6.366 \n",
            "Epoch: 275 \tTraining Loss:  0.239 \tTrain_Accu: 90%  \tValid_Acc:34% \t Valid Loss: 6.540 \n",
            "Epoch: 276 \tTraining Loss:  0.265 \tTrain_Accu: 90%  \tValid_Acc:24% \t Valid Loss: 6.662 \n",
            "Epoch: 277 \tTraining Loss:  0.245 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 7.408 \n",
            "Epoch: 278 \tTraining Loss:  0.207 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 7.235 \n",
            "Epoch: 279 \tTraining Loss:  0.251 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 9.083 \n",
            "Epoch: 280 \tTraining Loss:  0.312 \tTrain_Accu: 90%  \tValid_Acc:24% \t Valid Loss: 7.841 \n",
            "Epoch: 281 \tTraining Loss:  0.216 \tTrain_Accu: 93%  \tValid_Acc:26% \t Valid Loss: 8.034 \n",
            "Epoch: 282 \tTraining Loss:  0.217 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 7.363 \n",
            "Epoch: 283 \tTraining Loss:  0.211 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 7.890 \n",
            "Epoch: 284 \tTraining Loss:  0.163 \tTrain_Accu: 92%  \tValid_Acc:23% \t Valid Loss: 6.702 \n",
            "Epoch: 285 \tTraining Loss:  0.295 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 6.831 \n",
            "Epoch: 286 \tTraining Loss:  0.263 \tTrain_Accu: 89%  \tValid_Acc:21% \t Valid Loss: 7.141 \n",
            "Epoch: 287 \tTraining Loss:  0.193 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 7.773 \n",
            "Epoch: 288 \tTraining Loss:  0.255 \tTrain_Accu: 91%  \tValid_Acc:21% \t Valid Loss: 5.617 \n",
            "Epoch: 289 \tTraining Loss:  0.275 \tTrain_Accu: 91%  \tValid_Acc:33% \t Valid Loss: 6.036 \n",
            "Epoch: 290 \tTraining Loss:  0.251 \tTrain_Accu: 88%  \tValid_Acc:26% \t Valid Loss: 8.165 \n",
            "Epoch: 291 \tTraining Loss:  0.275 \tTrain_Accu: 89%  \tValid_Acc:26% \t Valid Loss: 6.733 \n",
            "Epoch: 292 \tTraining Loss:  0.202 \tTrain_Accu: 93%  \tValid_Acc:40% \t Valid Loss: 5.749 \n",
            "Epoch: 293 \tTraining Loss:  0.304 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 6.023 \n",
            "Epoch: 294 \tTraining Loss:  0.301 \tTrain_Accu: 88%  \tValid_Acc:19% \t Valid Loss: 6.820 \n",
            "Epoch: 295 \tTraining Loss:  0.196 \tTrain_Accu: 94%  \tValid_Acc:26% \t Valid Loss: 6.028 \n",
            "Epoch: 296 \tTraining Loss:  0.188 \tTrain_Accu: 94%  \tValid_Acc:29% \t Valid Loss: 8.892 \n",
            "Epoch: 297 \tTraining Loss:  0.250 \tTrain_Accu: 90%  \tValid_Acc:21% \t Valid Loss: 7.696 \n",
            "Epoch: 298 \tTraining Loss:  0.163 \tTrain_Accu: 93%  \tValid_Acc:24% \t Valid Loss: 9.087 \n",
            "Epoch: 299 \tTraining Loss:  0.190 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 9.651 \n",
            "Epoch: 300 \tTraining Loss:  0.357 \tTrain_Accu: 89%  \tValid_Acc:24% \t Valid Loss: 7.481 \n",
            "Epoch: 301 \tTraining Loss:  0.227 \tTrain_Accu: 92%  \tValid_Acc:20% \t Valid Loss: 7.801 \n",
            "Epoch: 302 \tTraining Loss:  0.201 \tTrain_Accu: 94%  \tValid_Acc:30% \t Valid Loss: 6.047 \n",
            "Epoch: 303 \tTraining Loss:  0.221 \tTrain_Accu: 90%  \tValid_Acc:26% \t Valid Loss: 7.966 \n",
            "Epoch: 304 \tTraining Loss:  0.290 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 5.714 \n",
            "Epoch: 305 \tTraining Loss:  0.175 \tTrain_Accu: 95%  \tValid_Acc:26% \t Valid Loss: 7.103 \n",
            "Epoch: 306 \tTraining Loss:  0.215 \tTrain_Accu: 94%  \tValid_Acc:17% \t Valid Loss: 9.077 \n",
            "Epoch: 307 \tTraining Loss:  0.227 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 4.867 \n",
            "Epoch: 308 \tTraining Loss:  0.167 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 8.978 \n",
            "Epoch: 309 \tTraining Loss:  0.239 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 7.378 \n",
            "Epoch: 310 \tTraining Loss:  0.245 \tTrain_Accu: 93%  \tValid_Acc:20% \t Valid Loss: 6.701 \n",
            "Epoch: 311 \tTraining Loss:  0.252 \tTrain_Accu: 90%  \tValid_Acc:21% \t Valid Loss: 9.768 \n",
            "Epoch: 312 \tTraining Loss:  0.282 \tTrain_Accu: 89%  \tValid_Acc:26% \t Valid Loss: 5.446 \n",
            "Epoch: 313 \tTraining Loss:  0.232 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 8.433 \n",
            "Epoch: 314 \tTraining Loss:  0.238 \tTrain_Accu: 94%  \tValid_Acc:20% \t Valid Loss: 7.201 \n",
            "Epoch: 315 \tTraining Loss:  0.233 \tTrain_Accu: 92%  \tValid_Acc:20% \t Valid Loss: 8.422 \n",
            "Epoch: 316 \tTraining Loss:  0.309 \tTrain_Accu: 90%  \tValid_Acc:17% \t Valid Loss: 7.023 \n",
            "Epoch: 317 \tTraining Loss:  0.262 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 7.890 \n",
            "Epoch: 318 \tTraining Loss:  0.268 \tTrain_Accu: 89%  \tValid_Acc:24% \t Valid Loss: 8.350 \n",
            "Epoch: 319 \tTraining Loss:  0.235 \tTrain_Accu: 90%  \tValid_Acc:23% \t Valid Loss: 10.277 \n",
            "Epoch: 320 \tTraining Loss:  0.196 \tTrain_Accu: 92%  \tValid_Acc:24% \t Valid Loss: 7.661 \n",
            "Epoch: 321 \tTraining Loss:  0.262 \tTrain_Accu: 90%  \tValid_Acc:29% \t Valid Loss: 7.436 \n",
            "Epoch: 322 \tTraining Loss:  0.191 \tTrain_Accu: 93%  \tValid_Acc:29% \t Valid Loss: 7.548 \n",
            "Epoch: 323 \tTraining Loss:  0.194 \tTrain_Accu: 92%  \tValid_Acc:21% \t Valid Loss: 8.176 \n",
            "Epoch: 324 \tTraining Loss:  0.271 \tTrain_Accu: 90%  \tValid_Acc:21% \t Valid Loss: 8.395 \n",
            "Epoch: 325 \tTraining Loss:  0.138 \tTrain_Accu: 96%  \tValid_Acc:26% \t Valid Loss: 9.530 \n",
            "Epoch: 326 \tTraining Loss:  0.234 \tTrain_Accu: 90%  \tValid_Acc:20% \t Valid Loss: 8.118 \n",
            "Epoch: 327 \tTraining Loss:  0.221 \tTrain_Accu: 91%  \tValid_Acc:29% \t Valid Loss: 6.191 \n",
            "Epoch: 328 \tTraining Loss:  0.253 \tTrain_Accu: 90%  \tValid_Acc:24% \t Valid Loss: 8.328 \n",
            "Epoch: 329 \tTraining Loss:  0.257 \tTrain_Accu: 92%  \tValid_Acc:30% \t Valid Loss: 7.208 \n",
            "Epoch: 330 \tTraining Loss:  0.170 \tTrain_Accu: 94%  \tValid_Acc:24% \t Valid Loss: 8.195 \n",
            "Epoch: 331 \tTraining Loss:  0.289 \tTrain_Accu: 91%  \tValid_Acc:24% \t Valid Loss: 7.789 \n",
            "Epoch: 332 \tTraining Loss:  0.170 \tTrain_Accu: 94%  \tValid_Acc:21% \t Valid Loss: 9.158 \n",
            "Epoch: 333 \tTraining Loss:  0.221 \tTrain_Accu: 93%  \tValid_Acc:21% \t Valid Loss: 8.122 \n",
            "Epoch: 334 \tTraining Loss:  0.274 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 7.916 \n",
            "Epoch: 335 \tTraining Loss:  0.227 \tTrain_Accu: 90%  \tValid_Acc:31% \t Valid Loss: 7.864 \n",
            "Epoch: 336 \tTraining Loss:  0.277 \tTrain_Accu: 89%  \tValid_Acc:17% \t Valid Loss: 8.242 \n",
            "Epoch: 337 \tTraining Loss:  0.277 \tTrain_Accu: 88%  \tValid_Acc:23% \t Valid Loss: 8.366 \n",
            "Epoch: 338 \tTraining Loss:  0.213 \tTrain_Accu: 93%  \tValid_Acc:23% \t Valid Loss: 10.888 \n",
            "Epoch: 339 \tTraining Loss:  0.286 \tTrain_Accu: 89%  \tValid_Acc:23% \t Valid Loss: 6.024 \n",
            "Epoch: 340 \tTraining Loss:  0.221 \tTrain_Accu: 91%  \tValid_Acc:23% \t Valid Loss: 8.483 \n",
            "Epoch: 341 \tTraining Loss:  0.265 \tTrain_Accu: 92%  \tValid_Acc:23% \t Valid Loss: 8.296 \n",
            "Epoch: 342 \tTraining Loss:  0.212 \tTrain_Accu: 91%  \tValid_Acc:19% \t Valid Loss: 7.316 \n",
            "Epoch: 343 \tTraining Loss:  0.267 \tTrain_Accu: 90%  \tValid_Acc:30% \t Valid Loss: 8.541 \n",
            "Epoch: 344 \tTraining Loss:  0.219 \tTrain_Accu: 92%  \tValid_Acc:27% \t Valid Loss: 7.212 \n",
            "Epoch: 345 \tTraining Loss:  0.205 \tTrain_Accu: 91%  \tValid_Acc:16% \t Valid Loss: 11.474 \n",
            "Epoch: 346 \tTraining Loss:  0.217 \tTrain_Accu: 92%  \tValid_Acc:24% \t Valid Loss: 7.660 \n",
            "Epoch: 347 \tTraining Loss:  0.236 \tTrain_Accu: 94%  \tValid_Acc:23% \t Valid Loss: 9.160 \n",
            "Epoch: 348 \tTraining Loss:  0.315 \tTrain_Accu: 89%  \tValid_Acc:24% \t Valid Loss: 7.761 \n",
            "Epoch: 349 \tTraining Loss:  0.208 \tTrain_Accu: 93%  \tValid_Acc:26% \t Valid Loss: 7.780 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 02:33:08,625]\u001b[0m Trial 12 finished with value: 20.0 and parameters: {'dropout': 0.7}. Best is trial 8 with value: 32.9.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 350 \tTraining Loss:  0.238 \tTrain_Accu: 91%  \tValid_Acc:20% \t Valid Loss: 9.087 \n",
            "Epoch: 1 \tTraining Loss:  1.710 \tTrain_Accu: 18%  \tValid_Acc:10% \t Valid Loss: 1.626 \n",
            "Epoch: 2 \tTraining Loss:  1.610 \tTrain_Accu: 20%  \tValid_Acc:9% \t Valid Loss: 1.633 \n",
            "Epoch: 3 \tTraining Loss:  1.603 \tTrain_Accu: 21%  \tValid_Acc:9% \t Valid Loss: 1.629 \n",
            "Epoch: 4 \tTraining Loss:  1.599 \tTrain_Accu: 26%  \tValid_Acc:7% \t Valid Loss: 1.665 \n",
            "Epoch: 5 \tTraining Loss:  1.603 \tTrain_Accu: 25%  \tValid_Acc:17% \t Valid Loss: 1.620 \n",
            "Epoch: 6 \tTraining Loss:  1.603 \tTrain_Accu: 24%  \tValid_Acc:19% \t Valid Loss: 1.626 \n",
            "Epoch: 7 \tTraining Loss:  1.593 \tTrain_Accu: 23%  \tValid_Acc:14% \t Valid Loss: 1.615 \n",
            "Epoch: 8 \tTraining Loss:  1.567 \tTrain_Accu: 24%  \tValid_Acc:17% \t Valid Loss: 1.604 \n",
            "Epoch: 9 \tTraining Loss:  1.572 \tTrain_Accu: 25%  \tValid_Acc:14% \t Valid Loss: 1.651 \n",
            "Epoch: 10 \tTraining Loss:  1.553 \tTrain_Accu: 28%  \tValid_Acc:20% \t Valid Loss: 1.651 \n",
            "Epoch: 11 \tTraining Loss:  1.538 \tTrain_Accu: 24%  \tValid_Acc:17% \t Valid Loss: 1.641 \n",
            "Epoch: 12 \tTraining Loss:  1.560 \tTrain_Accu: 27%  \tValid_Acc:11% \t Valid Loss: 1.658 \n",
            "Epoch: 13 \tTraining Loss:  1.567 \tTrain_Accu: 28%  \tValid_Acc:19% \t Valid Loss: 1.600 \n",
            "Epoch: 14 \tTraining Loss:  1.565 \tTrain_Accu: 29%  \tValid_Acc:23% \t Valid Loss: 1.611 \n",
            "Epoch: 15 \tTraining Loss:  1.518 \tTrain_Accu: 31%  \tValid_Acc:16% \t Valid Loss: 1.640 \n",
            "Epoch: 16 \tTraining Loss:  1.535 \tTrain_Accu: 32%  \tValid_Acc:21% \t Valid Loss: 1.619 \n",
            "Epoch: 17 \tTraining Loss:  1.530 \tTrain_Accu: 29%  \tValid_Acc:21% \t Valid Loss: 1.634 \n",
            "Epoch: 18 \tTraining Loss:  1.543 \tTrain_Accu: 26%  \tValid_Acc:17% \t Valid Loss: 1.661 \n",
            "Epoch: 19 \tTraining Loss:  1.525 \tTrain_Accu: 32%  \tValid_Acc:16% \t Valid Loss: 1.654 \n",
            "Epoch: 20 \tTraining Loss:  1.452 \tTrain_Accu: 32%  \tValid_Acc:23% \t Valid Loss: 1.608 \n",
            "Epoch: 21 \tTraining Loss:  1.496 \tTrain_Accu: 33%  \tValid_Acc:16% \t Valid Loss: 1.652 \n",
            "Epoch: 22 \tTraining Loss:  1.485 \tTrain_Accu: 34%  \tValid_Acc:24% \t Valid Loss: 1.651 \n",
            "Epoch: 23 \tTraining Loss:  1.496 \tTrain_Accu: 30%  \tValid_Acc:13% \t Valid Loss: 1.618 \n",
            "Epoch: 24 \tTraining Loss:  1.468 \tTrain_Accu: 35%  \tValid_Acc:11% \t Valid Loss: 1.718 \n",
            "Epoch: 25 \tTraining Loss:  1.431 \tTrain_Accu: 34%  \tValid_Acc:23% \t Valid Loss: 1.664 \n",
            "Epoch: 26 \tTraining Loss:  1.410 \tTrain_Accu: 36%  \tValid_Acc:21% \t Valid Loss: 1.718 \n",
            "Epoch: 27 \tTraining Loss:  1.438 \tTrain_Accu: 38%  \tValid_Acc:21% \t Valid Loss: 1.547 \n",
            "Epoch: 28 \tTraining Loss:  1.383 \tTrain_Accu: 39%  \tValid_Acc:20% \t Valid Loss: 1.661 \n",
            "Epoch: 29 \tTraining Loss:  1.380 \tTrain_Accu: 40%  \tValid_Acc:31% \t Valid Loss: 1.548 \n",
            "Epoch: 30 \tTraining Loss:  1.404 \tTrain_Accu: 38%  \tValid_Acc:21% \t Valid Loss: 1.705 \n",
            "Epoch: 31 \tTraining Loss:  1.388 \tTrain_Accu: 37%  \tValid_Acc:29% \t Valid Loss: 1.734 \n",
            "Epoch: 32 \tTraining Loss:  1.312 \tTrain_Accu: 40%  \tValid_Acc:23% \t Valid Loss: 1.665 \n",
            "Epoch: 33 \tTraining Loss:  1.334 \tTrain_Accu: 42%  \tValid_Acc:24% \t Valid Loss: 1.688 \n",
            "Epoch: 34 \tTraining Loss:  1.368 \tTrain_Accu: 38%  \tValid_Acc:23% \t Valid Loss: 1.618 \n",
            "Epoch: 35 \tTraining Loss:  1.309 \tTrain_Accu: 44%  \tValid_Acc:17% \t Valid Loss: 1.639 \n",
            "Epoch: 36 \tTraining Loss:  1.335 \tTrain_Accu: 42%  \tValid_Acc:30% \t Valid Loss: 1.543 \n",
            "Epoch: 37 \tTraining Loss:  1.323 \tTrain_Accu: 41%  \tValid_Acc:27% \t Valid Loss: 1.618 \n",
            "Epoch: 38 \tTraining Loss:  1.304 \tTrain_Accu: 40%  \tValid_Acc:19% \t Valid Loss: 1.655 \n",
            "Epoch: 39 \tTraining Loss:  1.234 \tTrain_Accu: 45%  \tValid_Acc:11% \t Valid Loss: 1.694 \n",
            "Epoch: 40 \tTraining Loss:  1.281 \tTrain_Accu: 41%  \tValid_Acc:23% \t Valid Loss: 1.780 \n",
            "Epoch: 41 \tTraining Loss:  1.278 \tTrain_Accu: 45%  \tValid_Acc:24% \t Valid Loss: 1.535 \n",
            "Epoch: 42 \tTraining Loss:  1.264 \tTrain_Accu: 44%  \tValid_Acc:14% \t Valid Loss: 1.702 \n",
            "Epoch: 43 \tTraining Loss:  1.253 \tTrain_Accu: 44%  \tValid_Acc:31% \t Valid Loss: 1.674 \n",
            "Epoch: 44 \tTraining Loss:  1.311 \tTrain_Accu: 39%  \tValid_Acc:19% \t Valid Loss: 1.685 \n",
            "Epoch: 45 \tTraining Loss:  1.207 \tTrain_Accu: 46%  \tValid_Acc:20% \t Valid Loss: 1.736 \n",
            "Epoch: 46 \tTraining Loss:  1.248 \tTrain_Accu: 45%  \tValid_Acc:21% \t Valid Loss: 1.578 \n",
            "Epoch: 47 \tTraining Loss:  1.213 \tTrain_Accu: 49%  \tValid_Acc:19% \t Valid Loss: 1.723 \n",
            "Epoch: 48 \tTraining Loss:  1.148 \tTrain_Accu: 48%  \tValid_Acc:16% \t Valid Loss: 1.835 \n",
            "Epoch: 49 \tTraining Loss:  1.127 \tTrain_Accu: 50%  \tValid_Acc:29% \t Valid Loss: 1.718 \n",
            "Epoch: 50 \tTraining Loss:  1.122 \tTrain_Accu: 51%  \tValid_Acc:21% \t Valid Loss: 1.640 \n",
            "Epoch: 51 \tTraining Loss:  1.122 \tTrain_Accu: 49%  \tValid_Acc:20% \t Valid Loss: 1.695 \n",
            "Epoch: 52 \tTraining Loss:  1.212 \tTrain_Accu: 45%  \tValid_Acc:23% \t Valid Loss: 1.674 \n",
            "Epoch: 53 \tTraining Loss:  1.173 \tTrain_Accu: 48%  \tValid_Acc:23% \t Valid Loss: 1.671 \n",
            "Epoch: 54 \tTraining Loss:  1.103 \tTrain_Accu: 50%  \tValid_Acc:27% \t Valid Loss: 1.644 \n",
            "Epoch: 55 \tTraining Loss:  1.161 \tTrain_Accu: 46%  \tValid_Acc:23% \t Valid Loss: 1.826 \n",
            "Epoch: 56 \tTraining Loss:  1.104 \tTrain_Accu: 54%  \tValid_Acc:17% \t Valid Loss: 1.949 \n",
            "Epoch: 57 \tTraining Loss:  1.132 \tTrain_Accu: 48%  \tValid_Acc:23% \t Valid Loss: 1.953 \n",
            "Epoch: 58 \tTraining Loss:  1.078 \tTrain_Accu: 55%  \tValid_Acc:29% \t Valid Loss: 1.702 \n",
            "Epoch: 59 \tTraining Loss:  1.019 \tTrain_Accu: 56%  \tValid_Acc:21% \t Valid Loss: 2.049 \n",
            "Epoch: 60 \tTraining Loss:  1.048 \tTrain_Accu: 54%  \tValid_Acc:27% \t Valid Loss: 1.735 \n",
            "Epoch: 61 \tTraining Loss:  1.045 \tTrain_Accu: 56%  \tValid_Acc:21% \t Valid Loss: 1.999 \n",
            "Epoch: 62 \tTraining Loss:  1.079 \tTrain_Accu: 47%  \tValid_Acc:26% \t Valid Loss: 1.761 \n",
            "Epoch: 63 \tTraining Loss:  1.052 \tTrain_Accu: 53%  \tValid_Acc:20% \t Valid Loss: 1.948 \n",
            "Epoch: 64 \tTraining Loss:  1.007 \tTrain_Accu: 55%  \tValid_Acc:29% \t Valid Loss: 1.732 \n",
            "Epoch: 65 \tTraining Loss:  1.076 \tTrain_Accu: 52%  \tValid_Acc:24% \t Valid Loss: 1.906 \n",
            "Epoch: 66 \tTraining Loss:  0.999 \tTrain_Accu: 58%  \tValid_Acc:30% \t Valid Loss: 1.909 \n",
            "Epoch: 67 \tTraining Loss:  1.016 \tTrain_Accu: 54%  \tValid_Acc:21% \t Valid Loss: 1.859 \n",
            "Epoch: 68 \tTraining Loss:  1.042 \tTrain_Accu: 52%  \tValid_Acc:29% \t Valid Loss: 1.709 \n",
            "Epoch: 69 \tTraining Loss:  1.046 \tTrain_Accu: 55%  \tValid_Acc:13% \t Valid Loss: 1.962 \n",
            "Epoch: 70 \tTraining Loss:  1.018 \tTrain_Accu: 55%  \tValid_Acc:21% \t Valid Loss: 1.710 \n",
            "Epoch: 71 \tTraining Loss:  0.952 \tTrain_Accu: 60%  \tValid_Acc:20% \t Valid Loss: 2.117 \n",
            "Epoch: 72 \tTraining Loss:  1.042 \tTrain_Accu: 55%  \tValid_Acc:23% \t Valid Loss: 1.768 \n",
            "Epoch: 73 \tTraining Loss:  0.946 \tTrain_Accu: 59%  \tValid_Acc:17% \t Valid Loss: 2.083 \n",
            "Epoch: 74 \tTraining Loss:  0.953 \tTrain_Accu: 59%  \tValid_Acc:17% \t Valid Loss: 2.144 \n",
            "Epoch: 75 \tTraining Loss:  0.951 \tTrain_Accu: 56%  \tValid_Acc:23% \t Valid Loss: 2.072 \n",
            "Epoch: 76 \tTraining Loss:  0.952 \tTrain_Accu: 57%  \tValid_Acc:14% \t Valid Loss: 2.044 \n",
            "Epoch: 77 \tTraining Loss:  0.909 \tTrain_Accu: 59%  \tValid_Acc:21% \t Valid Loss: 2.060 \n",
            "Epoch: 78 \tTraining Loss:  0.887 \tTrain_Accu: 60%  \tValid_Acc:23% \t Valid Loss: 2.168 \n",
            "Epoch: 79 \tTraining Loss:  0.940 \tTrain_Accu: 58%  \tValid_Acc:20% \t Valid Loss: 2.098 \n",
            "Epoch: 80 \tTraining Loss:  0.919 \tTrain_Accu: 62%  \tValid_Acc:21% \t Valid Loss: 1.858 \n",
            "Epoch: 81 \tTraining Loss:  0.940 \tTrain_Accu: 57%  \tValid_Acc:31% \t Valid Loss: 1.908 \n",
            "Epoch: 82 \tTraining Loss:  0.943 \tTrain_Accu: 58%  \tValid_Acc:26% \t Valid Loss: 2.064 \n",
            "Epoch: 83 \tTraining Loss:  0.911 \tTrain_Accu: 61%  \tValid_Acc:26% \t Valid Loss: 1.853 \n",
            "Epoch: 84 \tTraining Loss:  0.932 \tTrain_Accu: 59%  \tValid_Acc:29% \t Valid Loss: 1.955 \n",
            "Epoch: 85 \tTraining Loss:  0.834 \tTrain_Accu: 64%  \tValid_Acc:23% \t Valid Loss: 2.459 \n",
            "Epoch: 86 \tTraining Loss:  0.946 \tTrain_Accu: 58%  \tValid_Acc:21% \t Valid Loss: 1.985 \n",
            "Epoch: 87 \tTraining Loss:  0.841 \tTrain_Accu: 62%  \tValid_Acc:23% \t Valid Loss: 2.121 \n",
            "Epoch: 88 \tTraining Loss:  0.827 \tTrain_Accu: 64%  \tValid_Acc:21% \t Valid Loss: 3.210 \n",
            "Epoch: 89 \tTraining Loss:  0.866 \tTrain_Accu: 65%  \tValid_Acc:23% \t Valid Loss: 2.050 \n",
            "Epoch: 90 \tTraining Loss:  0.852 \tTrain_Accu: 64%  \tValid_Acc:16% \t Valid Loss: 2.561 \n",
            "Epoch: 91 \tTraining Loss:  0.835 \tTrain_Accu: 65%  \tValid_Acc:23% \t Valid Loss: 2.185 \n",
            "Epoch: 92 \tTraining Loss:  0.856 \tTrain_Accu: 64%  \tValid_Acc:26% \t Valid Loss: 2.486 \n",
            "Epoch: 93 \tTraining Loss:  0.874 \tTrain_Accu: 62%  \tValid_Acc:21% \t Valid Loss: 2.842 \n",
            "Epoch: 94 \tTraining Loss:  0.905 \tTrain_Accu: 61%  \tValid_Acc:31% \t Valid Loss: 1.949 \n",
            "Epoch: 95 \tTraining Loss:  0.867 \tTrain_Accu: 62%  \tValid_Acc:27% \t Valid Loss: 1.823 \n",
            "Epoch: 96 \tTraining Loss:  0.864 \tTrain_Accu: 62%  \tValid_Acc:29% \t Valid Loss: 2.005 \n",
            "Epoch: 97 \tTraining Loss:  0.837 \tTrain_Accu: 60%  \tValid_Acc:23% \t Valid Loss: 2.098 \n",
            "Epoch: 98 \tTraining Loss:  0.853 \tTrain_Accu: 65%  \tValid_Acc:31% \t Valid Loss: 1.942 \n",
            "Epoch: 99 \tTraining Loss:  0.785 \tTrain_Accu: 68%  \tValid_Acc:16% \t Valid Loss: 2.434 \n",
            "Epoch: 100 \tTraining Loss:  0.869 \tTrain_Accu: 65%  \tValid_Acc:33% \t Valid Loss: 1.999 \n",
            "Epoch: 101 \tTraining Loss:  0.781 \tTrain_Accu: 65%  \tValid_Acc:34% \t Valid Loss: 2.068 \n",
            "Epoch: 102 \tTraining Loss:  0.863 \tTrain_Accu: 61%  \tValid_Acc:23% \t Valid Loss: 2.027 \n",
            "Epoch: 103 \tTraining Loss:  0.759 \tTrain_Accu: 65%  \tValid_Acc:27% \t Valid Loss: 3.129 \n",
            "Epoch: 104 \tTraining Loss:  0.763 \tTrain_Accu: 68%  \tValid_Acc:21% \t Valid Loss: 2.373 \n",
            "Epoch: 105 \tTraining Loss:  0.814 \tTrain_Accu: 64%  \tValid_Acc:11% \t Valid Loss: 2.465 \n",
            "Epoch: 106 \tTraining Loss:  0.763 \tTrain_Accu: 68%  \tValid_Acc:24% \t Valid Loss: 2.789 \n",
            "Epoch: 107 \tTraining Loss:  0.762 \tTrain_Accu: 69%  \tValid_Acc:26% \t Valid Loss: 2.686 \n",
            "Epoch: 108 \tTraining Loss:  0.795 \tTrain_Accu: 68%  \tValid_Acc:24% \t Valid Loss: 2.868 \n",
            "Epoch: 109 \tTraining Loss:  0.726 \tTrain_Accu: 69%  \tValid_Acc:36% \t Valid Loss: 2.037 \n",
            "Epoch: 110 \tTraining Loss:  0.688 \tTrain_Accu: 71%  \tValid_Acc:26% \t Valid Loss: 2.700 \n",
            "Epoch: 111 \tTraining Loss:  0.765 \tTrain_Accu: 68%  \tValid_Acc:31% \t Valid Loss: 2.050 \n",
            "Epoch: 112 \tTraining Loss:  0.693 \tTrain_Accu: 69%  \tValid_Acc:16% \t Valid Loss: 2.417 \n",
            "Epoch: 113 \tTraining Loss:  0.660 \tTrain_Accu: 71%  \tValid_Acc:21% \t Valid Loss: 2.608 \n",
            "Epoch: 114 \tTraining Loss:  0.849 \tTrain_Accu: 66%  \tValid_Acc:26% \t Valid Loss: 2.410 \n",
            "Epoch: 115 \tTraining Loss:  0.775 \tTrain_Accu: 67%  \tValid_Acc:21% \t Valid Loss: 2.699 \n",
            "Epoch: 116 \tTraining Loss:  0.766 \tTrain_Accu: 66%  \tValid_Acc:33% \t Valid Loss: 2.442 \n",
            "Epoch: 117 \tTraining Loss:  0.690 \tTrain_Accu: 68%  \tValid_Acc:26% \t Valid Loss: 2.099 \n",
            "Epoch: 118 \tTraining Loss:  0.738 \tTrain_Accu: 68%  \tValid_Acc:29% \t Valid Loss: 1.781 \n",
            "Epoch: 119 \tTraining Loss:  0.694 \tTrain_Accu: 72%  \tValid_Acc:29% \t Valid Loss: 2.265 \n",
            "Epoch: 120 \tTraining Loss:  0.716 \tTrain_Accu: 67%  \tValid_Acc:24% \t Valid Loss: 2.328 \n",
            "Epoch: 121 \tTraining Loss:  0.733 \tTrain_Accu: 71%  \tValid_Acc:20% \t Valid Loss: 3.513 \n",
            "Epoch: 122 \tTraining Loss:  0.683 \tTrain_Accu: 74%  \tValid_Acc:19% \t Valid Loss: 3.312 \n",
            "Epoch: 123 \tTraining Loss:  0.665 \tTrain_Accu: 73%  \tValid_Acc:27% \t Valid Loss: 2.880 \n",
            "Epoch: 124 \tTraining Loss:  0.723 \tTrain_Accu: 68%  \tValid_Acc:29% \t Valid Loss: 2.002 \n",
            "Epoch: 125 \tTraining Loss:  0.743 \tTrain_Accu: 68%  \tValid_Acc:31% \t Valid Loss: 2.347 \n",
            "Epoch: 126 \tTraining Loss:  0.728 \tTrain_Accu: 69%  \tValid_Acc:23% \t Valid Loss: 2.391 \n",
            "Epoch: 127 \tTraining Loss:  0.651 \tTrain_Accu: 72%  \tValid_Acc:37% \t Valid Loss: 2.098 \n",
            "Epoch: 128 \tTraining Loss:  0.681 \tTrain_Accu: 72%  \tValid_Acc:29% \t Valid Loss: 2.149 \n",
            "Epoch: 129 \tTraining Loss:  0.772 \tTrain_Accu: 68%  \tValid_Acc:31% \t Valid Loss: 1.885 \n",
            "Epoch: 130 \tTraining Loss:  0.650 \tTrain_Accu: 77%  \tValid_Acc:29% \t Valid Loss: 2.511 \n",
            "Epoch: 131 \tTraining Loss:  0.716 \tTrain_Accu: 67%  \tValid_Acc:36% \t Valid Loss: 2.081 \n",
            "Epoch: 132 \tTraining Loss:  0.650 \tTrain_Accu: 74%  \tValid_Acc:39% \t Valid Loss: 2.736 \n",
            "Epoch: 133 \tTraining Loss:  0.651 \tTrain_Accu: 71%  \tValid_Acc:26% \t Valid Loss: 2.183 \n",
            "Epoch: 134 \tTraining Loss:  0.712 \tTrain_Accu: 74%  \tValid_Acc:27% \t Valid Loss: 1.814 \n",
            "Epoch: 135 \tTraining Loss:  0.661 \tTrain_Accu: 73%  \tValid_Acc:20% \t Valid Loss: 2.545 \n",
            "Epoch: 136 \tTraining Loss:  0.634 \tTrain_Accu: 73%  \tValid_Acc:31% \t Valid Loss: 2.478 \n",
            "Epoch: 137 \tTraining Loss:  0.655 \tTrain_Accu: 72%  \tValid_Acc:29% \t Valid Loss: 2.519 \n",
            "Epoch: 138 \tTraining Loss:  0.617 \tTrain_Accu: 74%  \tValid_Acc:26% \t Valid Loss: 2.681 \n",
            "Epoch: 139 \tTraining Loss:  0.684 \tTrain_Accu: 73%  \tValid_Acc:37% \t Valid Loss: 1.945 \n",
            "Epoch: 140 \tTraining Loss:  0.681 \tTrain_Accu: 72%  \tValid_Acc:27% \t Valid Loss: 2.386 \n",
            "Epoch: 141 \tTraining Loss:  0.649 \tTrain_Accu: 74%  \tValid_Acc:34% \t Valid Loss: 2.061 \n",
            "Epoch: 142 \tTraining Loss:  0.684 \tTrain_Accu: 71%  \tValid_Acc:33% \t Valid Loss: 3.619 \n",
            "Epoch: 143 \tTraining Loss:  0.678 \tTrain_Accu: 70%  \tValid_Acc:27% \t Valid Loss: 2.065 \n",
            "Epoch: 144 \tTraining Loss:  0.679 \tTrain_Accu: 70%  \tValid_Acc:33% \t Valid Loss: 2.532 \n",
            "Epoch: 145 \tTraining Loss:  0.659 \tTrain_Accu: 73%  \tValid_Acc:37% \t Valid Loss: 2.563 \n",
            "Epoch: 146 \tTraining Loss:  0.657 \tTrain_Accu: 74%  \tValid_Acc:29% \t Valid Loss: 3.097 \n",
            "Epoch: 147 \tTraining Loss:  0.666 \tTrain_Accu: 73%  \tValid_Acc:36% \t Valid Loss: 1.929 \n",
            "Epoch: 148 \tTraining Loss:  0.643 \tTrain_Accu: 73%  \tValid_Acc:23% \t Valid Loss: 2.213 \n",
            "Epoch: 149 \tTraining Loss:  0.686 \tTrain_Accu: 74%  \tValid_Acc:31% \t Valid Loss: 2.246 \n",
            "Epoch: 150 \tTraining Loss:  0.643 \tTrain_Accu: 75%  \tValid_Acc:31% \t Valid Loss: 2.135 \n",
            "Epoch: 151 \tTraining Loss:  0.679 \tTrain_Accu: 72%  \tValid_Acc:29% \t Valid Loss: 2.088 \n",
            "Epoch: 152 \tTraining Loss:  0.666 \tTrain_Accu: 72%  \tValid_Acc:31% \t Valid Loss: 2.570 \n",
            "Epoch: 153 \tTraining Loss:  0.666 \tTrain_Accu: 75%  \tValid_Acc:21% \t Valid Loss: 2.817 \n",
            "Epoch: 154 \tTraining Loss:  0.731 \tTrain_Accu: 71%  \tValid_Acc:33% \t Valid Loss: 2.407 \n",
            "Epoch: 155 \tTraining Loss:  0.633 \tTrain_Accu: 74%  \tValid_Acc:30% \t Valid Loss: 3.879 \n",
            "Epoch: 156 \tTraining Loss:  0.580 \tTrain_Accu: 76%  \tValid_Acc:27% \t Valid Loss: 2.418 \n",
            "Epoch: 157 \tTraining Loss:  0.700 \tTrain_Accu: 71%  \tValid_Acc:36% \t Valid Loss: 2.377 \n",
            "Epoch: 158 \tTraining Loss:  0.714 \tTrain_Accu: 70%  \tValid_Acc:21% \t Valid Loss: 2.501 \n",
            "Epoch: 159 \tTraining Loss:  0.640 \tTrain_Accu: 75%  \tValid_Acc:30% \t Valid Loss: 2.794 \n",
            "Epoch: 160 \tTraining Loss:  0.646 \tTrain_Accu: 76%  \tValid_Acc:29% \t Valid Loss: 1.762 \n",
            "Epoch: 161 \tTraining Loss:  0.607 \tTrain_Accu: 75%  \tValid_Acc:23% \t Valid Loss: 4.092 \n",
            "Epoch: 162 \tTraining Loss:  0.668 \tTrain_Accu: 72%  \tValid_Acc:29% \t Valid Loss: 3.385 \n",
            "Epoch: 163 \tTraining Loss:  0.635 \tTrain_Accu: 75%  \tValid_Acc:36% \t Valid Loss: 2.001 \n",
            "Epoch: 164 \tTraining Loss:  0.710 \tTrain_Accu: 74%  \tValid_Acc:26% \t Valid Loss: 2.653 \n",
            "Epoch: 165 \tTraining Loss:  0.652 \tTrain_Accu: 76%  \tValid_Acc:29% \t Valid Loss: 2.896 \n",
            "Epoch: 166 \tTraining Loss:  0.646 \tTrain_Accu: 71%  \tValid_Acc:21% \t Valid Loss: 2.856 \n",
            "Epoch: 167 \tTraining Loss:  0.692 \tTrain_Accu: 72%  \tValid_Acc:31% \t Valid Loss: 2.732 \n",
            "Epoch: 168 \tTraining Loss:  0.611 \tTrain_Accu: 76%  \tValid_Acc:29% \t Valid Loss: 2.319 \n",
            "Epoch: 169 \tTraining Loss:  0.646 \tTrain_Accu: 73%  \tValid_Acc:30% \t Valid Loss: 2.941 \n",
            "Epoch: 170 \tTraining Loss:  0.671 \tTrain_Accu: 70%  \tValid_Acc:29% \t Valid Loss: 2.739 \n",
            "Epoch: 171 \tTraining Loss:  0.603 \tTrain_Accu: 76%  \tValid_Acc:29% \t Valid Loss: 3.294 \n",
            "Epoch: 172 \tTraining Loss:  0.593 \tTrain_Accu: 75%  \tValid_Acc:30% \t Valid Loss: 2.899 \n",
            "Epoch: 173 \tTraining Loss:  0.604 \tTrain_Accu: 75%  \tValid_Acc:31% \t Valid Loss: 3.318 \n",
            "Epoch: 174 \tTraining Loss:  0.607 \tTrain_Accu: 76%  \tValid_Acc:26% \t Valid Loss: 2.866 \n",
            "Epoch: 175 \tTraining Loss:  0.600 \tTrain_Accu: 74%  \tValid_Acc:30% \t Valid Loss: 3.319 \n",
            "Epoch: 176 \tTraining Loss:  0.570 \tTrain_Accu: 76%  \tValid_Acc:34% \t Valid Loss: 3.050 \n",
            "Epoch: 177 \tTraining Loss:  0.682 \tTrain_Accu: 71%  \tValid_Acc:27% \t Valid Loss: 2.177 \n",
            "Epoch: 178 \tTraining Loss:  0.592 \tTrain_Accu: 77%  \tValid_Acc:31% \t Valid Loss: 2.402 \n",
            "Epoch: 179 \tTraining Loss:  0.582 \tTrain_Accu: 78%  \tValid_Acc:21% \t Valid Loss: 3.373 \n",
            "Epoch: 180 \tTraining Loss:  0.629 \tTrain_Accu: 77%  \tValid_Acc:26% \t Valid Loss: 3.442 \n",
            "Epoch: 181 \tTraining Loss:  0.615 \tTrain_Accu: 74%  \tValid_Acc:27% \t Valid Loss: 3.916 \n",
            "Epoch: 182 \tTraining Loss:  0.603 \tTrain_Accu: 76%  \tValid_Acc:26% \t Valid Loss: 2.853 \n",
            "Epoch: 183 \tTraining Loss:  0.567 \tTrain_Accu: 79%  \tValid_Acc:23% \t Valid Loss: 3.886 \n",
            "Epoch: 184 \tTraining Loss:  0.566 \tTrain_Accu: 78%  \tValid_Acc:26% \t Valid Loss: 3.043 \n",
            "Epoch: 185 \tTraining Loss:  0.562 \tTrain_Accu: 77%  \tValid_Acc:27% \t Valid Loss: 3.499 \n",
            "Epoch: 186 \tTraining Loss:  0.509 \tTrain_Accu: 77%  \tValid_Acc:29% \t Valid Loss: 3.422 \n",
            "Epoch: 187 \tTraining Loss:  0.577 \tTrain_Accu: 78%  \tValid_Acc:39% \t Valid Loss: 3.462 \n",
            "Epoch: 188 \tTraining Loss:  0.605 \tTrain_Accu: 78%  \tValid_Acc:33% \t Valid Loss: 2.862 \n",
            "Epoch: 189 \tTraining Loss:  0.643 \tTrain_Accu: 76%  \tValid_Acc:27% \t Valid Loss: 2.275 \n",
            "Epoch: 190 \tTraining Loss:  0.628 \tTrain_Accu: 77%  \tValid_Acc:30% \t Valid Loss: 2.254 \n",
            "Epoch: 191 \tTraining Loss:  0.623 \tTrain_Accu: 76%  \tValid_Acc:19% \t Valid Loss: 2.802 \n",
            "Epoch: 192 \tTraining Loss:  0.599 \tTrain_Accu: 78%  \tValid_Acc:21% \t Valid Loss: 3.656 \n",
            "Epoch: 193 \tTraining Loss:  0.586 \tTrain_Accu: 77%  \tValid_Acc:36% \t Valid Loss: 3.231 \n",
            "Epoch: 194 \tTraining Loss:  0.524 \tTrain_Accu: 76%  \tValid_Acc:34% \t Valid Loss: 3.285 \n",
            "Epoch: 195 \tTraining Loss:  0.583 \tTrain_Accu: 78%  \tValid_Acc:19% \t Valid Loss: 4.764 \n",
            "Epoch: 196 \tTraining Loss:  0.641 \tTrain_Accu: 73%  \tValid_Acc:30% \t Valid Loss: 3.161 \n",
            "Epoch: 197 \tTraining Loss:  0.633 \tTrain_Accu: 72%  \tValid_Acc:23% \t Valid Loss: 3.393 \n",
            "Epoch: 198 \tTraining Loss:  0.548 \tTrain_Accu: 77%  \tValid_Acc:27% \t Valid Loss: 3.475 \n",
            "Epoch: 199 \tTraining Loss:  0.586 \tTrain_Accu: 75%  \tValid_Acc:26% \t Valid Loss: 2.559 \n",
            "Epoch: 200 \tTraining Loss:  0.551 \tTrain_Accu: 78%  \tValid_Acc:31% \t Valid Loss: 3.740 \n",
            "Epoch: 201 \tTraining Loss:  0.560 \tTrain_Accu: 77%  \tValid_Acc:31% \t Valid Loss: 2.676 \n",
            "Epoch: 202 \tTraining Loss:  0.626 \tTrain_Accu: 73%  \tValid_Acc:29% \t Valid Loss: 3.334 \n",
            "Epoch: 203 \tTraining Loss:  0.645 \tTrain_Accu: 75%  \tValid_Acc:31% \t Valid Loss: 3.180 \n",
            "Epoch: 204 \tTraining Loss:  0.536 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 4.243 \n",
            "Epoch: 205 \tTraining Loss:  0.530 \tTrain_Accu: 81%  \tValid_Acc:34% \t Valid Loss: 3.792 \n",
            "Epoch: 206 \tTraining Loss:  0.532 \tTrain_Accu: 80%  \tValid_Acc:30% \t Valid Loss: 3.427 \n",
            "Epoch: 207 \tTraining Loss:  0.592 \tTrain_Accu: 77%  \tValid_Acc:34% \t Valid Loss: 3.718 \n",
            "Epoch: 208 \tTraining Loss:  0.569 \tTrain_Accu: 77%  \tValid_Acc:33% \t Valid Loss: 2.790 \n",
            "Epoch: 209 \tTraining Loss:  0.580 \tTrain_Accu: 78%  \tValid_Acc:30% \t Valid Loss: 3.831 \n",
            "Epoch: 210 \tTraining Loss:  0.607 \tTrain_Accu: 75%  \tValid_Acc:27% \t Valid Loss: 3.432 \n",
            "Epoch: 211 \tTraining Loss:  0.551 \tTrain_Accu: 79%  \tValid_Acc:36% \t Valid Loss: 3.141 \n",
            "Epoch: 212 \tTraining Loss:  0.521 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 3.564 \n",
            "Epoch: 213 \tTraining Loss:  0.508 \tTrain_Accu: 79%  \tValid_Acc:27% \t Valid Loss: 4.525 \n",
            "Epoch: 214 \tTraining Loss:  0.486 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 4.505 \n",
            "Epoch: 215 \tTraining Loss:  0.575 \tTrain_Accu: 75%  \tValid_Acc:39% \t Valid Loss: 3.673 \n",
            "Epoch: 216 \tTraining Loss:  0.533 \tTrain_Accu: 77%  \tValid_Acc:30% \t Valid Loss: 3.688 \n",
            "Epoch: 217 \tTraining Loss:  0.527 \tTrain_Accu: 79%  \tValid_Acc:27% \t Valid Loss: 3.641 \n",
            "Epoch: 218 \tTraining Loss:  0.540 \tTrain_Accu: 77%  \tValid_Acc:23% \t Valid Loss: 5.060 \n",
            "Epoch: 219 \tTraining Loss:  0.518 \tTrain_Accu: 78%  \tValid_Acc:21% \t Valid Loss: 4.645 \n",
            "Epoch: 220 \tTraining Loss:  0.514 \tTrain_Accu: 78%  \tValid_Acc:21% \t Valid Loss: 4.574 \n",
            "Epoch: 221 \tTraining Loss:  0.493 \tTrain_Accu: 79%  \tValid_Acc:33% \t Valid Loss: 3.581 \n",
            "Epoch: 222 \tTraining Loss:  0.422 \tTrain_Accu: 84%  \tValid_Acc:41% \t Valid Loss: 3.656 \n",
            "Epoch: 223 \tTraining Loss:  0.522 \tTrain_Accu: 77%  \tValid_Acc:26% \t Valid Loss: 4.221 \n",
            "Epoch: 224 \tTraining Loss:  0.501 \tTrain_Accu: 79%  \tValid_Acc:33% \t Valid Loss: 4.279 \n",
            "Epoch: 225 \tTraining Loss:  0.528 \tTrain_Accu: 79%  \tValid_Acc:20% \t Valid Loss: 5.435 \n",
            "Epoch: 226 \tTraining Loss:  0.537 \tTrain_Accu: 80%  \tValid_Acc:29% \t Valid Loss: 3.736 \n",
            "Epoch: 227 \tTraining Loss:  0.569 \tTrain_Accu: 80%  \tValid_Acc:37% \t Valid Loss: 3.729 \n",
            "Epoch: 228 \tTraining Loss:  0.576 \tTrain_Accu: 75%  \tValid_Acc:27% \t Valid Loss: 4.292 \n",
            "Epoch: 229 \tTraining Loss:  0.497 \tTrain_Accu: 81%  \tValid_Acc:26% \t Valid Loss: 3.849 \n",
            "Epoch: 230 \tTraining Loss:  0.618 \tTrain_Accu: 76%  \tValid_Acc:33% \t Valid Loss: 3.910 \n",
            "Epoch: 231 \tTraining Loss:  0.548 \tTrain_Accu: 80%  \tValid_Acc:31% \t Valid Loss: 4.731 \n",
            "Epoch: 232 \tTraining Loss:  0.515 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 3.225 \n",
            "Epoch: 233 \tTraining Loss:  0.525 \tTrain_Accu: 79%  \tValid_Acc:20% \t Valid Loss: 4.455 \n",
            "Epoch: 234 \tTraining Loss:  0.506 \tTrain_Accu: 82%  \tValid_Acc:31% \t Valid Loss: 3.048 \n",
            "Epoch: 235 \tTraining Loss:  0.501 \tTrain_Accu: 83%  \tValid_Acc:26% \t Valid Loss: 4.827 \n",
            "Epoch: 236 \tTraining Loss:  0.582 \tTrain_Accu: 75%  \tValid_Acc:26% \t Valid Loss: 4.477 \n",
            "Epoch: 237 \tTraining Loss:  0.524 \tTrain_Accu: 81%  \tValid_Acc:27% \t Valid Loss: 4.490 \n",
            "Epoch: 238 \tTraining Loss:  0.491 \tTrain_Accu: 81%  \tValid_Acc:17% \t Valid Loss: 6.014 \n",
            "Epoch: 239 \tTraining Loss:  0.509 \tTrain_Accu: 81%  \tValid_Acc:29% \t Valid Loss: 4.665 \n",
            "Epoch: 240 \tTraining Loss:  0.468 \tTrain_Accu: 81%  \tValid_Acc:24% \t Valid Loss: 4.827 \n",
            "Epoch: 241 \tTraining Loss:  0.561 \tTrain_Accu: 76%  \tValid_Acc:34% \t Valid Loss: 3.344 \n",
            "Epoch: 242 \tTraining Loss:  0.550 \tTrain_Accu: 79%  \tValid_Acc:36% \t Valid Loss: 3.929 \n",
            "Epoch: 243 \tTraining Loss:  0.503 \tTrain_Accu: 79%  \tValid_Acc:29% \t Valid Loss: 3.342 \n",
            "Epoch: 244 \tTraining Loss:  0.560 \tTrain_Accu: 79%  \tValid_Acc:30% \t Valid Loss: 4.766 \n",
            "Epoch: 245 \tTraining Loss:  0.452 \tTrain_Accu: 82%  \tValid_Acc:21% \t Valid Loss: 4.297 \n",
            "Epoch: 246 \tTraining Loss:  0.534 \tTrain_Accu: 78%  \tValid_Acc:33% \t Valid Loss: 4.643 \n",
            "Epoch: 247 \tTraining Loss:  0.531 \tTrain_Accu: 76%  \tValid_Acc:29% \t Valid Loss: 4.265 \n",
            "Epoch: 248 \tTraining Loss:  0.542 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 3.107 \n",
            "Epoch: 249 \tTraining Loss:  0.463 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 4.460 \n",
            "Epoch: 250 \tTraining Loss:  0.518 \tTrain_Accu: 82%  \tValid_Acc:31% \t Valid Loss: 4.651 \n",
            "Epoch: 251 \tTraining Loss:  0.593 \tTrain_Accu: 78%  \tValid_Acc:16% \t Valid Loss: 5.825 \n",
            "Epoch: 252 \tTraining Loss:  0.509 \tTrain_Accu: 79%  \tValid_Acc:31% \t Valid Loss: 4.800 \n",
            "Epoch: 253 \tTraining Loss:  0.504 \tTrain_Accu: 79%  \tValid_Acc:36% \t Valid Loss: 3.622 \n",
            "Epoch: 254 \tTraining Loss:  0.451 \tTrain_Accu: 82%  \tValid_Acc:33% \t Valid Loss: 3.630 \n",
            "Epoch: 255 \tTraining Loss:  0.451 \tTrain_Accu: 82%  \tValid_Acc:33% \t Valid Loss: 4.929 \n",
            "Epoch: 256 \tTraining Loss:  0.516 \tTrain_Accu: 77%  \tValid_Acc:30% \t Valid Loss: 4.712 \n",
            "Epoch: 257 \tTraining Loss:  0.570 \tTrain_Accu: 77%  \tValid_Acc:29% \t Valid Loss: 3.792 \n",
            "Epoch: 258 \tTraining Loss:  0.569 \tTrain_Accu: 79%  \tValid_Acc:30% \t Valid Loss: 4.271 \n",
            "Epoch: 259 \tTraining Loss:  0.436 \tTrain_Accu: 84%  \tValid_Acc:26% \t Valid Loss: 5.551 \n",
            "Epoch: 260 \tTraining Loss:  0.488 \tTrain_Accu: 84%  \tValid_Acc:29% \t Valid Loss: 3.722 \n",
            "Epoch: 261 \tTraining Loss:  0.556 \tTrain_Accu: 79%  \tValid_Acc:29% \t Valid Loss: 4.800 \n",
            "Epoch: 262 \tTraining Loss:  0.505 \tTrain_Accu: 80%  \tValid_Acc:19% \t Valid Loss: 4.815 \n",
            "Epoch: 263 \tTraining Loss:  0.444 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 4.261 \n",
            "Epoch: 264 \tTraining Loss:  0.517 \tTrain_Accu: 80%  \tValid_Acc:29% \t Valid Loss: 5.456 \n",
            "Epoch: 265 \tTraining Loss:  0.549 \tTrain_Accu: 79%  \tValid_Acc:34% \t Valid Loss: 5.128 \n",
            "Epoch: 266 \tTraining Loss:  0.461 \tTrain_Accu: 80%  \tValid_Acc:26% \t Valid Loss: 4.714 \n",
            "Epoch: 267 \tTraining Loss:  0.497 \tTrain_Accu: 81%  \tValid_Acc:30% \t Valid Loss: 5.208 \n",
            "Epoch: 268 \tTraining Loss:  0.505 \tTrain_Accu: 77%  \tValid_Acc:24% \t Valid Loss: 5.444 \n",
            "Epoch: 269 \tTraining Loss:  0.443 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 4.946 \n",
            "Epoch: 270 \tTraining Loss:  0.451 \tTrain_Accu: 85%  \tValid_Acc:27% \t Valid Loss: 5.076 \n",
            "Epoch: 271 \tTraining Loss:  0.520 \tTrain_Accu: 78%  \tValid_Acc:27% \t Valid Loss: 3.271 \n",
            "Epoch: 272 \tTraining Loss:  0.464 \tTrain_Accu: 79%  \tValid_Acc:26% \t Valid Loss: 7.062 \n",
            "Epoch: 273 \tTraining Loss:  0.496 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 3.999 \n",
            "Epoch: 274 \tTraining Loss:  0.466 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 3.951 \n",
            "Epoch: 275 \tTraining Loss:  0.602 \tTrain_Accu: 78%  \tValid_Acc:30% \t Valid Loss: 3.657 \n",
            "Epoch: 276 \tTraining Loss:  0.463 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 4.279 \n",
            "Epoch: 277 \tTraining Loss:  0.494 \tTrain_Accu: 83%  \tValid_Acc:33% \t Valid Loss: 5.146 \n",
            "Epoch: 278 \tTraining Loss:  0.496 \tTrain_Accu: 80%  \tValid_Acc:29% \t Valid Loss: 5.808 \n",
            "Epoch: 279 \tTraining Loss:  0.443 \tTrain_Accu: 82%  \tValid_Acc:31% \t Valid Loss: 3.850 \n",
            "Epoch: 280 \tTraining Loss:  0.461 \tTrain_Accu: 81%  \tValid_Acc:36% \t Valid Loss: 5.084 \n",
            "Epoch: 281 \tTraining Loss:  0.482 \tTrain_Accu: 81%  \tValid_Acc:26% \t Valid Loss: 4.538 \n",
            "Epoch: 282 \tTraining Loss:  0.496 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 4.455 \n",
            "Epoch: 283 \tTraining Loss:  0.445 \tTrain_Accu: 84%  \tValid_Acc:37% \t Valid Loss: 3.828 \n",
            "Epoch: 284 \tTraining Loss:  0.554 \tTrain_Accu: 77%  \tValid_Acc:33% \t Valid Loss: 3.512 \n",
            "Epoch: 285 \tTraining Loss:  0.575 \tTrain_Accu: 75%  \tValid_Acc:26% \t Valid Loss: 4.954 \n",
            "Epoch: 286 \tTraining Loss:  0.538 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 4.430 \n",
            "Epoch: 287 \tTraining Loss:  0.489 \tTrain_Accu: 81%  \tValid_Acc:33% \t Valid Loss: 4.248 \n",
            "Epoch: 288 \tTraining Loss:  0.497 \tTrain_Accu: 80%  \tValid_Acc:24% \t Valid Loss: 6.102 \n",
            "Epoch: 289 \tTraining Loss:  0.456 \tTrain_Accu: 83%  \tValid_Acc:27% \t Valid Loss: 4.113 \n",
            "Epoch: 290 \tTraining Loss:  0.454 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 4.326 \n",
            "Epoch: 291 \tTraining Loss:  0.549 \tTrain_Accu: 79%  \tValid_Acc:30% \t Valid Loss: 3.761 \n",
            "Epoch: 292 \tTraining Loss:  0.449 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 5.134 \n",
            "Epoch: 293 \tTraining Loss:  0.550 \tTrain_Accu: 81%  \tValid_Acc:27% \t Valid Loss: 5.536 \n",
            "Epoch: 294 \tTraining Loss:  0.486 \tTrain_Accu: 81%  \tValid_Acc:27% \t Valid Loss: 4.802 \n",
            "Epoch: 295 \tTraining Loss:  0.440 \tTrain_Accu: 82%  \tValid_Acc:21% \t Valid Loss: 5.219 \n",
            "Epoch: 296 \tTraining Loss:  0.536 \tTrain_Accu: 80%  \tValid_Acc:34% \t Valid Loss: 4.545 \n",
            "Epoch: 297 \tTraining Loss:  0.540 \tTrain_Accu: 80%  \tValid_Acc:26% \t Valid Loss: 5.936 \n",
            "Epoch: 298 \tTraining Loss:  0.476 \tTrain_Accu: 79%  \tValid_Acc:23% \t Valid Loss: 7.063 \n",
            "Epoch: 299 \tTraining Loss:  0.450 \tTrain_Accu: 86%  \tValid_Acc:29% \t Valid Loss: 4.969 \n",
            "Epoch: 300 \tTraining Loss:  0.530 \tTrain_Accu: 81%  \tValid_Acc:19% \t Valid Loss: 5.639 \n",
            "Epoch: 301 \tTraining Loss:  0.536 \tTrain_Accu: 78%  \tValid_Acc:30% \t Valid Loss: 3.795 \n",
            "Epoch: 302 \tTraining Loss:  0.457 \tTrain_Accu: 82%  \tValid_Acc:31% \t Valid Loss: 4.839 \n",
            "Epoch: 303 \tTraining Loss:  0.483 \tTrain_Accu: 82%  \tValid_Acc:26% \t Valid Loss: 4.421 \n",
            "Epoch: 304 \tTraining Loss:  0.474 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 5.992 \n",
            "Epoch: 305 \tTraining Loss:  0.401 \tTrain_Accu: 86%  \tValid_Acc:29% \t Valid Loss: 7.598 \n",
            "Epoch: 306 \tTraining Loss:  0.475 \tTrain_Accu: 83%  \tValid_Acc:31% \t Valid Loss: 4.069 \n",
            "Epoch: 307 \tTraining Loss:  0.436 \tTrain_Accu: 84%  \tValid_Acc:33% \t Valid Loss: 5.071 \n",
            "Epoch: 308 \tTraining Loss:  0.462 \tTrain_Accu: 80%  \tValid_Acc:29% \t Valid Loss: 4.959 \n",
            "Epoch: 309 \tTraining Loss:  0.485 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 6.027 \n",
            "Epoch: 310 \tTraining Loss:  0.422 \tTrain_Accu: 84%  \tValid_Acc:30% \t Valid Loss: 7.530 \n",
            "Epoch: 311 \tTraining Loss:  0.454 \tTrain_Accu: 85%  \tValid_Acc:26% \t Valid Loss: 5.636 \n",
            "Epoch: 312 \tTraining Loss:  0.477 \tTrain_Accu: 79%  \tValid_Acc:33% \t Valid Loss: 3.396 \n",
            "Epoch: 313 \tTraining Loss:  0.430 \tTrain_Accu: 82%  \tValid_Acc:24% \t Valid Loss: 6.828 \n",
            "Epoch: 314 \tTraining Loss:  0.494 \tTrain_Accu: 78%  \tValid_Acc:29% \t Valid Loss: 6.154 \n",
            "Epoch: 315 \tTraining Loss:  0.442 \tTrain_Accu: 82%  \tValid_Acc:33% \t Valid Loss: 5.314 \n",
            "Epoch: 316 \tTraining Loss:  0.512 \tTrain_Accu: 80%  \tValid_Acc:26% \t Valid Loss: 5.303 \n",
            "Epoch: 317 \tTraining Loss:  0.510 \tTrain_Accu: 79%  \tValid_Acc:26% \t Valid Loss: 5.858 \n",
            "Epoch: 318 \tTraining Loss:  0.443 \tTrain_Accu: 81%  \tValid_Acc:24% \t Valid Loss: 5.727 \n",
            "Epoch: 319 \tTraining Loss:  0.450 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 6.983 \n",
            "Epoch: 320 \tTraining Loss:  0.425 \tTrain_Accu: 86%  \tValid_Acc:29% \t Valid Loss: 4.994 \n",
            "Epoch: 321 \tTraining Loss:  0.440 \tTrain_Accu: 82%  \tValid_Acc:23% \t Valid Loss: 5.874 \n",
            "Epoch: 322 \tTraining Loss:  0.481 \tTrain_Accu: 80%  \tValid_Acc:30% \t Valid Loss: 5.079 \n",
            "Epoch: 323 \tTraining Loss:  0.448 \tTrain_Accu: 84%  \tValid_Acc:24% \t Valid Loss: 4.775 \n",
            "Epoch: 324 \tTraining Loss:  0.499 \tTrain_Accu: 83%  \tValid_Acc:33% \t Valid Loss: 4.815 \n",
            "Epoch: 325 \tTraining Loss:  0.413 \tTrain_Accu: 84%  \tValid_Acc:23% \t Valid Loss: 6.324 \n",
            "Epoch: 326 \tTraining Loss:  0.420 \tTrain_Accu: 83%  \tValid_Acc:23% \t Valid Loss: 5.297 \n",
            "Epoch: 327 \tTraining Loss:  0.480 \tTrain_Accu: 82%  \tValid_Acc:33% \t Valid Loss: 4.112 \n",
            "Epoch: 328 \tTraining Loss:  0.439 \tTrain_Accu: 85%  \tValid_Acc:33% \t Valid Loss: 4.942 \n",
            "Epoch: 329 \tTraining Loss:  0.503 \tTrain_Accu: 82%  \tValid_Acc:31% \t Valid Loss: 5.593 \n",
            "Epoch: 330 \tTraining Loss:  0.486 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 3.522 \n",
            "Epoch: 331 \tTraining Loss:  0.402 \tTrain_Accu: 86%  \tValid_Acc:34% \t Valid Loss: 5.015 \n",
            "Epoch: 332 \tTraining Loss:  0.438 \tTrain_Accu: 82%  \tValid_Acc:27% \t Valid Loss: 5.147 \n",
            "Epoch: 333 \tTraining Loss:  0.348 \tTrain_Accu: 85%  \tValid_Acc:36% \t Valid Loss: 5.008 \n",
            "Epoch: 334 \tTraining Loss:  0.441 \tTrain_Accu: 84%  \tValid_Acc:31% \t Valid Loss: 5.721 \n",
            "Epoch: 335 \tTraining Loss:  0.399 \tTrain_Accu: 86%  \tValid_Acc:30% \t Valid Loss: 3.658 \n",
            "Epoch: 336 \tTraining Loss:  0.446 \tTrain_Accu: 84%  \tValid_Acc:29% \t Valid Loss: 6.805 \n",
            "Epoch: 337 \tTraining Loss:  0.408 \tTrain_Accu: 83%  \tValid_Acc:27% \t Valid Loss: 4.590 \n",
            "Epoch: 338 \tTraining Loss:  0.440 \tTrain_Accu: 83%  \tValid_Acc:29% \t Valid Loss: 5.899 \n",
            "Epoch: 339 \tTraining Loss:  0.469 \tTrain_Accu: 82%  \tValid_Acc:24% \t Valid Loss: 5.152 \n",
            "Epoch: 340 \tTraining Loss:  0.505 \tTrain_Accu: 81%  \tValid_Acc:29% \t Valid Loss: 5.563 \n",
            "Epoch: 341 \tTraining Loss:  0.478 \tTrain_Accu: 84%  \tValid_Acc:36% \t Valid Loss: 5.783 \n",
            "Epoch: 342 \tTraining Loss:  0.474 \tTrain_Accu: 83%  \tValid_Acc:26% \t Valid Loss: 5.791 \n",
            "Epoch: 343 \tTraining Loss:  0.419 \tTrain_Accu: 84%  \tValid_Acc:27% \t Valid Loss: 5.787 \n",
            "Epoch: 344 \tTraining Loss:  0.440 \tTrain_Accu: 84%  \tValid_Acc:31% \t Valid Loss: 4.768 \n",
            "Epoch: 345 \tTraining Loss:  0.460 \tTrain_Accu: 81%  \tValid_Acc:30% \t Valid Loss: 4.588 \n",
            "Epoch: 346 \tTraining Loss:  0.458 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 5.336 \n",
            "Epoch: 347 \tTraining Loss:  0.499 \tTrain_Accu: 83%  \tValid_Acc:27% \t Valid Loss: 5.266 \n",
            "Epoch: 348 \tTraining Loss:  0.451 \tTrain_Accu: 81%  \tValid_Acc:26% \t Valid Loss: 4.171 \n",
            "Epoch: 349 \tTraining Loss:  0.433 \tTrain_Accu: 83%  \tValid_Acc:30% \t Valid Loss: 5.739 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 02:39:05,862]\u001b[0m Trial 13 finished with value: 32.9 and parameters: {'dropout': 0.8}. Best is trial 8 with value: 32.9.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 350 \tTraining Loss:  0.477 \tTrain_Accu: 83%  \tValid_Acc:33% \t Valid Loss: 6.503 \n",
            "Epoch: 1 \tTraining Loss:  1.710 \tTrain_Accu: 18%  \tValid_Acc:10% \t Valid Loss: 1.627 \n",
            "Epoch: 2 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:9% \t Valid Loss: 1.634 \n",
            "Epoch: 3 \tTraining Loss:  1.604 \tTrain_Accu: 21%  \tValid_Acc:11% \t Valid Loss: 1.628 \n",
            "Epoch: 4 \tTraining Loss:  1.602 \tTrain_Accu: 25%  \tValid_Acc:9% \t Valid Loss: 1.651 \n",
            "Epoch: 5 \tTraining Loss:  1.603 \tTrain_Accu: 23%  \tValid_Acc:16% \t Valid Loss: 1.618 \n",
            "Epoch: 6 \tTraining Loss:  1.601 \tTrain_Accu: 21%  \tValid_Acc:19% \t Valid Loss: 1.633 \n",
            "Epoch: 7 \tTraining Loss:  1.595 \tTrain_Accu: 24%  \tValid_Acc:16% \t Valid Loss: 1.622 \n",
            "Epoch: 8 \tTraining Loss:  1.568 \tTrain_Accu: 26%  \tValid_Acc:14% \t Valid Loss: 1.591 \n",
            "Epoch: 9 \tTraining Loss:  1.577 \tTrain_Accu: 25%  \tValid_Acc:10% \t Valid Loss: 1.634 \n",
            "Epoch: 10 \tTraining Loss:  1.550 \tTrain_Accu: 30%  \tValid_Acc:17% \t Valid Loss: 1.660 \n",
            "Epoch: 11 \tTraining Loss:  1.547 \tTrain_Accu: 24%  \tValid_Acc:13% \t Valid Loss: 1.639 \n",
            "Epoch: 12 \tTraining Loss:  1.538 \tTrain_Accu: 26%  \tValid_Acc:6% \t Valid Loss: 1.674 \n",
            "Epoch: 13 \tTraining Loss:  1.583 \tTrain_Accu: 27%  \tValid_Acc:14% \t Valid Loss: 1.601 \n",
            "Epoch: 14 \tTraining Loss:  1.560 \tTrain_Accu: 29%  \tValid_Acc:13% \t Valid Loss: 1.633 \n",
            "Epoch: 15 \tTraining Loss:  1.503 \tTrain_Accu: 28%  \tValid_Acc:20% \t Valid Loss: 1.608 \n",
            "Epoch: 16 \tTraining Loss:  1.540 \tTrain_Accu: 29%  \tValid_Acc:23% \t Valid Loss: 1.611 \n",
            "Epoch: 17 \tTraining Loss:  1.520 \tTrain_Accu: 34%  \tValid_Acc:17% \t Valid Loss: 1.651 \n",
            "Epoch: 18 \tTraining Loss:  1.539 \tTrain_Accu: 30%  \tValid_Acc:21% \t Valid Loss: 1.661 \n",
            "Epoch: 19 \tTraining Loss:  1.511 \tTrain_Accu: 30%  \tValid_Acc:14% \t Valid Loss: 1.667 \n",
            "Epoch: 20 \tTraining Loss:  1.454 \tTrain_Accu: 32%  \tValid_Acc:21% \t Valid Loss: 1.635 \n",
            "Epoch: 21 \tTraining Loss:  1.505 \tTrain_Accu: 32%  \tValid_Acc:16% \t Valid Loss: 1.652 \n",
            "Epoch: 22 \tTraining Loss:  1.486 \tTrain_Accu: 33%  \tValid_Acc:26% \t Valid Loss: 1.662 \n",
            "Epoch: 23 \tTraining Loss:  1.500 \tTrain_Accu: 29%  \tValid_Acc:16% \t Valid Loss: 1.648 \n",
            "Epoch: 24 \tTraining Loss:  1.464 \tTrain_Accu: 31%  \tValid_Acc:17% \t Valid Loss: 1.705 \n",
            "Epoch: 25 \tTraining Loss:  1.431 \tTrain_Accu: 33%  \tValid_Acc:24% \t Valid Loss: 1.652 \n",
            "Epoch: 26 \tTraining Loss:  1.422 \tTrain_Accu: 38%  \tValid_Acc:23% \t Valid Loss: 1.649 \n",
            "Epoch: 27 \tTraining Loss:  1.399 \tTrain_Accu: 40%  \tValid_Acc:21% \t Valid Loss: 1.552 \n",
            "Epoch: 28 \tTraining Loss:  1.401 \tTrain_Accu: 35%  \tValid_Acc:20% \t Valid Loss: 1.668 \n",
            "Epoch: 29 \tTraining Loss:  1.377 \tTrain_Accu: 37%  \tValid_Acc:27% \t Valid Loss: 1.600 \n",
            "Epoch: 30 \tTraining Loss:  1.399 \tTrain_Accu: 37%  \tValid_Acc:19% \t Valid Loss: 1.691 \n",
            "Epoch: 31 \tTraining Loss:  1.409 \tTrain_Accu: 37%  \tValid_Acc:23% \t Valid Loss: 1.731 \n",
            "Epoch: 32 \tTraining Loss:  1.307 \tTrain_Accu: 43%  \tValid_Acc:20% \t Valid Loss: 1.697 \n",
            "Epoch: 33 \tTraining Loss:  1.338 \tTrain_Accu: 44%  \tValid_Acc:27% \t Valid Loss: 1.630 \n",
            "Epoch: 34 \tTraining Loss:  1.344 \tTrain_Accu: 40%  \tValid_Acc:20% \t Valid Loss: 1.651 \n",
            "Epoch: 35 \tTraining Loss:  1.334 \tTrain_Accu: 40%  \tValid_Acc:23% \t Valid Loss: 1.582 \n",
            "Epoch: 36 \tTraining Loss:  1.339 \tTrain_Accu: 42%  \tValid_Acc:33% \t Valid Loss: 1.530 \n",
            "Epoch: 37 \tTraining Loss:  1.344 \tTrain_Accu: 42%  \tValid_Acc:17% \t Valid Loss: 1.626 \n",
            "Epoch: 38 \tTraining Loss:  1.338 \tTrain_Accu: 41%  \tValid_Acc:19% \t Valid Loss: 1.633 \n",
            "Epoch: 39 \tTraining Loss:  1.258 \tTrain_Accu: 46%  \tValid_Acc:17% \t Valid Loss: 1.719 \n",
            "Epoch: 40 \tTraining Loss:  1.265 \tTrain_Accu: 41%  \tValid_Acc:30% \t Valid Loss: 1.643 \n",
            "Epoch: 41 \tTraining Loss:  1.269 \tTrain_Accu: 43%  \tValid_Acc:21% \t Valid Loss: 1.603 \n",
            "Epoch: 42 \tTraining Loss:  1.284 \tTrain_Accu: 42%  \tValid_Acc:21% \t Valid Loss: 1.670 \n",
            "Epoch: 43 \tTraining Loss:  1.239 \tTrain_Accu: 47%  \tValid_Acc:31% \t Valid Loss: 1.698 \n",
            "Epoch: 44 \tTraining Loss:  1.280 \tTrain_Accu: 42%  \tValid_Acc:24% \t Valid Loss: 1.770 \n",
            "Epoch: 45 \tTraining Loss:  1.237 \tTrain_Accu: 47%  \tValid_Acc:19% \t Valid Loss: 1.790 \n",
            "Epoch: 46 \tTraining Loss:  1.235 \tTrain_Accu: 44%  \tValid_Acc:24% \t Valid Loss: 1.587 \n",
            "Epoch: 47 \tTraining Loss:  1.240 \tTrain_Accu: 45%  \tValid_Acc:14% \t Valid Loss: 1.749 \n",
            "Epoch: 48 \tTraining Loss:  1.191 \tTrain_Accu: 48%  \tValid_Acc:20% \t Valid Loss: 1.774 \n",
            "Epoch: 49 \tTraining Loss:  1.197 \tTrain_Accu: 47%  \tValid_Acc:29% \t Valid Loss: 1.561 \n",
            "Epoch: 50 \tTraining Loss:  1.160 \tTrain_Accu: 49%  \tValid_Acc:24% \t Valid Loss: 1.624 \n",
            "Epoch: 51 \tTraining Loss:  1.134 \tTrain_Accu: 51%  \tValid_Acc:20% \t Valid Loss: 1.758 \n",
            "Epoch: 52 \tTraining Loss:  1.228 \tTrain_Accu: 45%  \tValid_Acc:21% \t Valid Loss: 1.675 \n",
            "Epoch: 53 \tTraining Loss:  1.255 \tTrain_Accu: 46%  \tValid_Acc:26% \t Valid Loss: 1.580 \n",
            "Epoch: 54 \tTraining Loss:  1.057 \tTrain_Accu: 55%  \tValid_Acc:27% \t Valid Loss: 1.747 \n",
            "Epoch: 55 \tTraining Loss:  1.126 \tTrain_Accu: 50%  \tValid_Acc:26% \t Valid Loss: 1.855 \n",
            "Epoch: 56 \tTraining Loss:  1.085 \tTrain_Accu: 53%  \tValid_Acc:20% \t Valid Loss: 2.000 \n",
            "Epoch: 57 \tTraining Loss:  1.145 \tTrain_Accu: 50%  \tValid_Acc:23% \t Valid Loss: 2.018 \n",
            "Epoch: 58 \tTraining Loss:  1.096 \tTrain_Accu: 50%  \tValid_Acc:26% \t Valid Loss: 1.642 \n",
            "Epoch: 59 \tTraining Loss:  1.033 \tTrain_Accu: 54%  \tValid_Acc:23% \t Valid Loss: 1.890 \n",
            "Epoch: 60 \tTraining Loss:  1.082 \tTrain_Accu: 50%  \tValid_Acc:26% \t Valid Loss: 1.713 \n",
            "Epoch: 61 \tTraining Loss:  1.048 \tTrain_Accu: 55%  \tValid_Acc:23% \t Valid Loss: 1.918 \n",
            "Epoch: 62 \tTraining Loss:  1.093 \tTrain_Accu: 51%  \tValid_Acc:26% \t Valid Loss: 1.760 \n",
            "Epoch: 63 \tTraining Loss:  1.028 \tTrain_Accu: 55%  \tValid_Acc:24% \t Valid Loss: 1.797 \n",
            "Epoch: 64 \tTraining Loss:  1.034 \tTrain_Accu: 54%  \tValid_Acc:36% \t Valid Loss: 1.703 \n",
            "Epoch: 65 \tTraining Loss:  1.054 \tTrain_Accu: 53%  \tValid_Acc:27% \t Valid Loss: 1.852 \n",
            "Epoch: 66 \tTraining Loss:  0.981 \tTrain_Accu: 53%  \tValid_Acc:26% \t Valid Loss: 1.961 \n",
            "Epoch: 67 \tTraining Loss:  1.046 \tTrain_Accu: 54%  \tValid_Acc:24% \t Valid Loss: 1.750 \n",
            "Epoch: 68 \tTraining Loss:  1.041 \tTrain_Accu: 53%  \tValid_Acc:30% \t Valid Loss: 1.804 \n",
            "Epoch: 69 \tTraining Loss:  1.013 \tTrain_Accu: 55%  \tValid_Acc:19% \t Valid Loss: 2.093 \n",
            "Epoch: 70 \tTraining Loss:  1.046 \tTrain_Accu: 55%  \tValid_Acc:20% \t Valid Loss: 1.787 \n",
            "Epoch: 71 \tTraining Loss:  1.005 \tTrain_Accu: 57%  \tValid_Acc:26% \t Valid Loss: 1.978 \n",
            "Epoch: 72 \tTraining Loss:  1.049 \tTrain_Accu: 53%  \tValid_Acc:21% \t Valid Loss: 1.768 \n",
            "Epoch: 73 \tTraining Loss:  1.019 \tTrain_Accu: 55%  \tValid_Acc:27% \t Valid Loss: 1.762 \n",
            "Epoch: 74 \tTraining Loss:  0.910 \tTrain_Accu: 60%  \tValid_Acc:29% \t Valid Loss: 2.392 \n",
            "Epoch: 75 \tTraining Loss:  0.976 \tTrain_Accu: 55%  \tValid_Acc:24% \t Valid Loss: 2.199 \n",
            "Epoch: 76 \tTraining Loss:  0.940 \tTrain_Accu: 54%  \tValid_Acc:20% \t Valid Loss: 2.093 \n",
            "Epoch: 77 \tTraining Loss:  0.971 \tTrain_Accu: 57%  \tValid_Acc:27% \t Valid Loss: 2.212 \n",
            "Epoch: 78 \tTraining Loss:  0.936 \tTrain_Accu: 58%  \tValid_Acc:24% \t Valid Loss: 1.976 \n",
            "Epoch: 79 \tTraining Loss:  0.964 \tTrain_Accu: 57%  \tValid_Acc:26% \t Valid Loss: 2.186 \n",
            "Epoch: 80 \tTraining Loss:  0.923 \tTrain_Accu: 61%  \tValid_Acc:26% \t Valid Loss: 2.057 \n",
            "Epoch: 81 \tTraining Loss:  0.919 \tTrain_Accu: 59%  \tValid_Acc:26% \t Valid Loss: 2.085 \n",
            "Epoch: 82 \tTraining Loss:  0.942 \tTrain_Accu: 57%  \tValid_Acc:24% \t Valid Loss: 1.923 \n",
            "Epoch: 83 \tTraining Loss:  0.945 \tTrain_Accu: 56%  \tValid_Acc:21% \t Valid Loss: 1.950 \n",
            "Epoch: 84 \tTraining Loss:  0.976 \tTrain_Accu: 54%  \tValid_Acc:27% \t Valid Loss: 1.937 \n",
            "Epoch: 85 \tTraining Loss:  0.862 \tTrain_Accu: 64%  \tValid_Acc:24% \t Valid Loss: 2.259 \n",
            "Epoch: 86 \tTraining Loss:  0.905 \tTrain_Accu: 56%  \tValid_Acc:27% \t Valid Loss: 1.771 \n",
            "Epoch: 87 \tTraining Loss:  0.863 \tTrain_Accu: 66%  \tValid_Acc:23% \t Valid Loss: 1.999 \n",
            "Epoch: 88 \tTraining Loss:  0.845 \tTrain_Accu: 64%  \tValid_Acc:30% \t Valid Loss: 2.604 \n",
            "Epoch: 89 \tTraining Loss:  0.903 \tTrain_Accu: 60%  \tValid_Acc:34% \t Valid Loss: 2.142 \n",
            "Epoch: 90 \tTraining Loss:  0.879 \tTrain_Accu: 62%  \tValid_Acc:24% \t Valid Loss: 2.423 \n",
            "Epoch: 91 \tTraining Loss:  0.835 \tTrain_Accu: 65%  \tValid_Acc:24% \t Valid Loss: 2.334 \n",
            "Epoch: 92 \tTraining Loss:  0.868 \tTrain_Accu: 60%  \tValid_Acc:26% \t Valid Loss: 2.612 \n",
            "Epoch: 93 \tTraining Loss:  0.841 \tTrain_Accu: 60%  \tValid_Acc:26% \t Valid Loss: 2.913 \n",
            "Epoch: 94 \tTraining Loss:  0.902 \tTrain_Accu: 64%  \tValid_Acc:20% \t Valid Loss: 2.168 \n",
            "Epoch: 95 \tTraining Loss:  0.823 \tTrain_Accu: 66%  \tValid_Acc:24% \t Valid Loss: 1.883 \n",
            "Epoch: 96 \tTraining Loss:  0.883 \tTrain_Accu: 60%  \tValid_Acc:30% \t Valid Loss: 2.134 \n",
            "Epoch: 97 \tTraining Loss:  0.846 \tTrain_Accu: 64%  \tValid_Acc:23% \t Valid Loss: 2.082 \n",
            "Epoch: 98 \tTraining Loss:  0.840 \tTrain_Accu: 64%  \tValid_Acc:29% \t Valid Loss: 2.136 \n",
            "Epoch: 99 \tTraining Loss:  0.822 \tTrain_Accu: 69%  \tValid_Acc:24% \t Valid Loss: 2.280 \n",
            "Epoch: 100 \tTraining Loss:  0.858 \tTrain_Accu: 66%  \tValid_Acc:31% \t Valid Loss: 1.988 \n",
            "Epoch: 101 \tTraining Loss:  0.788 \tTrain_Accu: 63%  \tValid_Acc:33% \t Valid Loss: 2.154 \n",
            "Epoch: 102 \tTraining Loss:  0.818 \tTrain_Accu: 62%  \tValid_Acc:21% \t Valid Loss: 2.248 \n",
            "Epoch: 103 \tTraining Loss:  0.774 \tTrain_Accu: 65%  \tValid_Acc:26% \t Valid Loss: 2.812 \n",
            "Epoch: 104 \tTraining Loss:  0.741 \tTrain_Accu: 68%  \tValid_Acc:26% \t Valid Loss: 2.536 \n",
            "Epoch: 105 \tTraining Loss:  0.777 \tTrain_Accu: 67%  \tValid_Acc:20% \t Valid Loss: 2.279 \n",
            "Epoch: 106 \tTraining Loss:  0.741 \tTrain_Accu: 65%  \tValid_Acc:26% \t Valid Loss: 3.080 \n",
            "Epoch: 107 \tTraining Loss:  0.770 \tTrain_Accu: 66%  \tValid_Acc:16% \t Valid Loss: 2.524 \n",
            "Epoch: 108 \tTraining Loss:  0.790 \tTrain_Accu: 66%  \tValid_Acc:23% \t Valid Loss: 2.662 \n",
            "Epoch: 109 \tTraining Loss:  0.744 \tTrain_Accu: 70%  \tValid_Acc:27% \t Valid Loss: 1.969 \n",
            "Epoch: 110 \tTraining Loss:  0.736 \tTrain_Accu: 71%  \tValid_Acc:36% \t Valid Loss: 2.246 \n",
            "Epoch: 111 \tTraining Loss:  0.768 \tTrain_Accu: 70%  \tValid_Acc:31% \t Valid Loss: 2.155 \n",
            "Epoch: 112 \tTraining Loss:  0.704 \tTrain_Accu: 69%  \tValid_Acc:31% \t Valid Loss: 1.896 \n",
            "Epoch: 113 \tTraining Loss:  0.738 \tTrain_Accu: 69%  \tValid_Acc:21% \t Valid Loss: 2.386 \n",
            "Epoch: 114 \tTraining Loss:  0.792 \tTrain_Accu: 69%  \tValid_Acc:24% \t Valid Loss: 2.497 \n",
            "Epoch: 115 \tTraining Loss:  0.800 \tTrain_Accu: 66%  \tValid_Acc:23% \t Valid Loss: 2.361 \n",
            "Epoch: 116 \tTraining Loss:  0.813 \tTrain_Accu: 64%  \tValid_Acc:36% \t Valid Loss: 2.252 \n",
            "Epoch: 117 \tTraining Loss:  0.721 \tTrain_Accu: 71%  \tValid_Acc:31% \t Valid Loss: 2.273 \n",
            "Epoch: 118 \tTraining Loss:  0.777 \tTrain_Accu: 68%  \tValid_Acc:30% \t Valid Loss: 2.154 \n",
            "Epoch: 119 \tTraining Loss:  0.798 \tTrain_Accu: 66%  \tValid_Acc:27% \t Valid Loss: 2.968 \n",
            "Epoch: 120 \tTraining Loss:  0.765 \tTrain_Accu: 70%  \tValid_Acc:23% \t Valid Loss: 2.132 \n",
            "Epoch: 121 \tTraining Loss:  0.752 \tTrain_Accu: 70%  \tValid_Acc:21% \t Valid Loss: 3.122 \n",
            "Epoch: 122 \tTraining Loss:  0.670 \tTrain_Accu: 71%  \tValid_Acc:27% \t Valid Loss: 3.174 \n",
            "Epoch: 123 \tTraining Loss:  0.655 \tTrain_Accu: 72%  \tValid_Acc:29% \t Valid Loss: 2.622 \n",
            "Epoch: 124 \tTraining Loss:  0.708 \tTrain_Accu: 72%  \tValid_Acc:29% \t Valid Loss: 2.795 \n",
            "Epoch: 125 \tTraining Loss:  0.771 \tTrain_Accu: 66%  \tValid_Acc:30% \t Valid Loss: 2.492 \n",
            "Epoch: 126 \tTraining Loss:  0.697 \tTrain_Accu: 71%  \tValid_Acc:27% \t Valid Loss: 2.753 \n",
            "Epoch: 127 \tTraining Loss:  0.708 \tTrain_Accu: 71%  \tValid_Acc:33% \t Valid Loss: 2.650 \n",
            "Epoch: 128 \tTraining Loss:  0.652 \tTrain_Accu: 72%  \tValid_Acc:29% \t Valid Loss: 2.409 \n",
            "Epoch: 129 \tTraining Loss:  0.783 \tTrain_Accu: 68%  \tValid_Acc:29% \t Valid Loss: 1.931 \n",
            "Epoch: 130 \tTraining Loss:  0.648 \tTrain_Accu: 75%  \tValid_Acc:21% \t Valid Loss: 2.456 \n",
            "Epoch: 131 \tTraining Loss:  0.708 \tTrain_Accu: 71%  \tValid_Acc:40% \t Valid Loss: 2.085 \n",
            "Epoch: 132 \tTraining Loss:  0.601 \tTrain_Accu: 75%  \tValid_Acc:33% \t Valid Loss: 3.647 \n",
            "Epoch: 133 \tTraining Loss:  0.616 \tTrain_Accu: 75%  \tValid_Acc:23% \t Valid Loss: 2.888 \n",
            "Epoch: 134 \tTraining Loss:  0.636 \tTrain_Accu: 74%  \tValid_Acc:27% \t Valid Loss: 2.439 \n",
            "Epoch: 135 \tTraining Loss:  0.621 \tTrain_Accu: 75%  \tValid_Acc:19% \t Valid Loss: 3.024 \n",
            "Epoch: 136 \tTraining Loss:  0.676 \tTrain_Accu: 73%  \tValid_Acc:21% \t Valid Loss: 2.260 \n",
            "Epoch: 137 \tTraining Loss:  0.637 \tTrain_Accu: 73%  \tValid_Acc:37% \t Valid Loss: 1.984 \n",
            "Epoch: 138 \tTraining Loss:  0.598 \tTrain_Accu: 74%  \tValid_Acc:27% \t Valid Loss: 2.919 \n",
            "Epoch: 139 \tTraining Loss:  0.624 \tTrain_Accu: 73%  \tValid_Acc:31% \t Valid Loss: 2.514 \n",
            "Epoch: 140 \tTraining Loss:  0.693 \tTrain_Accu: 70%  \tValid_Acc:30% \t Valid Loss: 2.295 \n",
            "Epoch: 141 \tTraining Loss:  0.679 \tTrain_Accu: 71%  \tValid_Acc:27% \t Valid Loss: 2.810 \n",
            "Epoch: 142 \tTraining Loss:  0.698 \tTrain_Accu: 71%  \tValid_Acc:34% \t Valid Loss: 2.859 \n",
            "Epoch: 143 \tTraining Loss:  0.680 \tTrain_Accu: 74%  \tValid_Acc:27% \t Valid Loss: 3.063 \n",
            "Epoch: 144 \tTraining Loss:  0.615 \tTrain_Accu: 76%  \tValid_Acc:23% \t Valid Loss: 2.183 \n",
            "Epoch: 145 \tTraining Loss:  0.708 \tTrain_Accu: 69%  \tValid_Acc:30% \t Valid Loss: 3.113 \n",
            "Epoch: 146 \tTraining Loss:  0.654 \tTrain_Accu: 76%  \tValid_Acc:26% \t Valid Loss: 2.428 \n",
            "Epoch: 147 \tTraining Loss:  0.587 \tTrain_Accu: 75%  \tValid_Acc:30% \t Valid Loss: 2.032 \n",
            "Epoch: 148 \tTraining Loss:  0.713 \tTrain_Accu: 70%  \tValid_Acc:21% \t Valid Loss: 2.327 \n",
            "Epoch: 149 \tTraining Loss:  0.687 \tTrain_Accu: 72%  \tValid_Acc:27% \t Valid Loss: 2.808 \n",
            "Epoch: 150 \tTraining Loss:  0.641 \tTrain_Accu: 74%  \tValid_Acc:13% \t Valid Loss: 2.806 \n",
            "Epoch: 151 \tTraining Loss:  0.624 \tTrain_Accu: 74%  \tValid_Acc:26% \t Valid Loss: 2.647 \n",
            "Epoch: 152 \tTraining Loss:  0.656 \tTrain_Accu: 74%  \tValid_Acc:33% \t Valid Loss: 2.472 \n",
            "Epoch: 153 \tTraining Loss:  0.642 \tTrain_Accu: 73%  \tValid_Acc:23% \t Valid Loss: 2.435 \n",
            "Epoch: 154 \tTraining Loss:  0.674 \tTrain_Accu: 74%  \tValid_Acc:40% \t Valid Loss: 2.184 \n",
            "Epoch: 155 \tTraining Loss:  0.602 \tTrain_Accu: 73%  \tValid_Acc:21% \t Valid Loss: 3.569 \n",
            "Epoch: 156 \tTraining Loss:  0.574 \tTrain_Accu: 74%  \tValid_Acc:37% \t Valid Loss: 2.275 \n",
            "Epoch: 157 \tTraining Loss:  0.680 \tTrain_Accu: 70%  \tValid_Acc:33% \t Valid Loss: 3.101 \n",
            "Epoch: 158 \tTraining Loss:  0.655 \tTrain_Accu: 71%  \tValid_Acc:19% \t Valid Loss: 2.228 \n",
            "Epoch: 159 \tTraining Loss:  0.608 \tTrain_Accu: 75%  \tValid_Acc:19% \t Valid Loss: 3.496 \n",
            "Epoch: 160 \tTraining Loss:  0.642 \tTrain_Accu: 72%  \tValid_Acc:30% \t Valid Loss: 2.427 \n",
            "Epoch: 161 \tTraining Loss:  0.614 \tTrain_Accu: 75%  \tValid_Acc:27% \t Valid Loss: 3.729 \n",
            "Epoch: 162 \tTraining Loss:  0.602 \tTrain_Accu: 76%  \tValid_Acc:23% \t Valid Loss: 3.220 \n",
            "Epoch: 163 \tTraining Loss:  0.594 \tTrain_Accu: 77%  \tValid_Acc:24% \t Valid Loss: 3.144 \n",
            "Epoch: 164 \tTraining Loss:  0.662 \tTrain_Accu: 74%  \tValid_Acc:36% \t Valid Loss: 2.693 \n",
            "Epoch: 165 \tTraining Loss:  0.604 \tTrain_Accu: 78%  \tValid_Acc:30% \t Valid Loss: 2.594 \n",
            "Epoch: 166 \tTraining Loss:  0.577 \tTrain_Accu: 77%  \tValid_Acc:21% \t Valid Loss: 3.568 \n",
            "Epoch: 167 \tTraining Loss:  0.646 \tTrain_Accu: 70%  \tValid_Acc:27% \t Valid Loss: 2.932 \n",
            "Epoch: 168 \tTraining Loss:  0.605 \tTrain_Accu: 74%  \tValid_Acc:26% \t Valid Loss: 3.087 \n",
            "Epoch: 169 \tTraining Loss:  0.621 \tTrain_Accu: 77%  \tValid_Acc:27% \t Valid Loss: 3.134 \n",
            "Epoch: 170 \tTraining Loss:  0.616 \tTrain_Accu: 73%  \tValid_Acc:33% \t Valid Loss: 3.266 \n",
            "Epoch: 171 \tTraining Loss:  0.576 \tTrain_Accu: 76%  \tValid_Acc:26% \t Valid Loss: 2.799 \n",
            "Epoch: 172 \tTraining Loss:  0.564 \tTrain_Accu: 77%  \tValid_Acc:19% \t Valid Loss: 3.775 \n",
            "Epoch: 173 \tTraining Loss:  0.596 \tTrain_Accu: 75%  \tValid_Acc:31% \t Valid Loss: 3.108 \n",
            "Epoch: 174 \tTraining Loss:  0.533 \tTrain_Accu: 78%  \tValid_Acc:29% \t Valid Loss: 3.528 \n",
            "Epoch: 175 \tTraining Loss:  0.611 \tTrain_Accu: 74%  \tValid_Acc:27% \t Valid Loss: 2.954 \n",
            "Epoch: 176 \tTraining Loss:  0.532 \tTrain_Accu: 77%  \tValid_Acc:31% \t Valid Loss: 2.923 \n",
            "Epoch: 177 \tTraining Loss:  0.603 \tTrain_Accu: 73%  \tValid_Acc:31% \t Valid Loss: 2.456 \n",
            "Epoch: 178 \tTraining Loss:  0.530 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 3.115 \n",
            "Epoch: 179 \tTraining Loss:  0.543 \tTrain_Accu: 78%  \tValid_Acc:29% \t Valid Loss: 3.283 \n",
            "Epoch: 180 \tTraining Loss:  0.518 \tTrain_Accu: 80%  \tValid_Acc:23% \t Valid Loss: 3.041 \n",
            "Epoch: 181 \tTraining Loss:  0.611 \tTrain_Accu: 75%  \tValid_Acc:23% \t Valid Loss: 3.288 \n",
            "Epoch: 182 \tTraining Loss:  0.588 \tTrain_Accu: 77%  \tValid_Acc:24% \t Valid Loss: 3.634 \n",
            "Epoch: 183 \tTraining Loss:  0.588 \tTrain_Accu: 78%  \tValid_Acc:27% \t Valid Loss: 3.328 \n",
            "Epoch: 184 \tTraining Loss:  0.559 \tTrain_Accu: 78%  \tValid_Acc:27% \t Valid Loss: 3.221 \n",
            "Epoch: 185 \tTraining Loss:  0.569 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 4.293 \n",
            "Epoch: 186 \tTraining Loss:  0.542 \tTrain_Accu: 80%  \tValid_Acc:13% \t Valid Loss: 2.846 \n",
            "Epoch: 187 \tTraining Loss:  0.562 \tTrain_Accu: 77%  \tValid_Acc:24% \t Valid Loss: 3.858 \n",
            "Epoch: 188 \tTraining Loss:  0.588 \tTrain_Accu: 76%  \tValid_Acc:27% \t Valid Loss: 3.646 \n",
            "Epoch: 189 \tTraining Loss:  0.563 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 3.484 \n",
            "Epoch: 190 \tTraining Loss:  0.523 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 3.000 \n",
            "Epoch: 191 \tTraining Loss:  0.516 \tTrain_Accu: 80%  \tValid_Acc:23% \t Valid Loss: 2.654 \n",
            "Epoch: 192 \tTraining Loss:  0.548 \tTrain_Accu: 76%  \tValid_Acc:30% \t Valid Loss: 3.261 \n",
            "Epoch: 193 \tTraining Loss:  0.576 \tTrain_Accu: 77%  \tValid_Acc:31% \t Valid Loss: 3.463 \n",
            "Epoch: 194 \tTraining Loss:  0.577 \tTrain_Accu: 75%  \tValid_Acc:33% \t Valid Loss: 2.999 \n",
            "Epoch: 195 \tTraining Loss:  0.503 \tTrain_Accu: 80%  \tValid_Acc:19% \t Valid Loss: 3.818 \n",
            "Epoch: 196 \tTraining Loss:  0.582 \tTrain_Accu: 76%  \tValid_Acc:17% \t Valid Loss: 4.708 \n",
            "Epoch: 197 \tTraining Loss:  0.596 \tTrain_Accu: 76%  \tValid_Acc:21% \t Valid Loss: 3.508 \n",
            "Epoch: 198 \tTraining Loss:  0.503 \tTrain_Accu: 80%  \tValid_Acc:24% \t Valid Loss: 3.807 \n",
            "Epoch: 199 \tTraining Loss:  0.608 \tTrain_Accu: 75%  \tValid_Acc:23% \t Valid Loss: 3.061 \n",
            "Epoch: 200 \tTraining Loss:  0.499 \tTrain_Accu: 80%  \tValid_Acc:26% \t Valid Loss: 3.841 \n",
            "Epoch: 201 \tTraining Loss:  0.496 \tTrain_Accu: 78%  \tValid_Acc:24% \t Valid Loss: 3.125 \n",
            "Epoch: 202 \tTraining Loss:  0.552 \tTrain_Accu: 78%  \tValid_Acc:20% \t Valid Loss: 3.597 \n",
            "Epoch: 203 \tTraining Loss:  0.558 \tTrain_Accu: 77%  \tValid_Acc:27% \t Valid Loss: 3.484 \n",
            "Epoch: 204 \tTraining Loss:  0.529 \tTrain_Accu: 80%  \tValid_Acc:14% \t Valid Loss: 3.824 \n",
            "Epoch: 205 \tTraining Loss:  0.576 \tTrain_Accu: 78%  \tValid_Acc:29% \t Valid Loss: 3.214 \n",
            "Epoch: 206 \tTraining Loss:  0.512 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 2.874 \n",
            "Epoch: 207 \tTraining Loss:  0.560 \tTrain_Accu: 78%  \tValid_Acc:21% \t Valid Loss: 4.488 \n",
            "Epoch: 208 \tTraining Loss:  0.524 \tTrain_Accu: 79%  \tValid_Acc:31% \t Valid Loss: 3.140 \n",
            "Epoch: 209 \tTraining Loss:  0.540 \tTrain_Accu: 79%  \tValid_Acc:24% \t Valid Loss: 3.899 \n",
            "Epoch: 210 \tTraining Loss:  0.494 \tTrain_Accu: 81%  \tValid_Acc:24% \t Valid Loss: 5.625 \n",
            "Epoch: 211 \tTraining Loss:  0.455 \tTrain_Accu: 80%  \tValid_Acc:24% \t Valid Loss: 3.022 \n",
            "Epoch: 212 \tTraining Loss:  0.440 \tTrain_Accu: 81%  \tValid_Acc:26% \t Valid Loss: 4.274 \n",
            "Epoch: 213 \tTraining Loss:  0.503 \tTrain_Accu: 80%  \tValid_Acc:24% \t Valid Loss: 4.000 \n",
            "Epoch: 214 \tTraining Loss:  0.504 \tTrain_Accu: 80%  \tValid_Acc:31% \t Valid Loss: 4.299 \n",
            "Epoch: 215 \tTraining Loss:  0.513 \tTrain_Accu: 79%  \tValid_Acc:24% \t Valid Loss: 3.869 \n",
            "Epoch: 216 \tTraining Loss:  0.523 \tTrain_Accu: 79%  \tValid_Acc:26% \t Valid Loss: 3.995 \n",
            "Epoch: 217 \tTraining Loss:  0.510 \tTrain_Accu: 79%  \tValid_Acc:23% \t Valid Loss: 3.817 \n",
            "Epoch: 218 \tTraining Loss:  0.553 \tTrain_Accu: 80%  \tValid_Acc:23% \t Valid Loss: 3.858 \n",
            "Epoch: 219 \tTraining Loss:  0.530 \tTrain_Accu: 79%  \tValid_Acc:21% \t Valid Loss: 3.423 \n",
            "Epoch: 220 \tTraining Loss:  0.482 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 4.484 \n",
            "Epoch: 221 \tTraining Loss:  0.548 \tTrain_Accu: 79%  \tValid_Acc:39% \t Valid Loss: 2.851 \n",
            "Epoch: 222 \tTraining Loss:  0.452 \tTrain_Accu: 84%  \tValid_Acc:24% \t Valid Loss: 3.372 \n",
            "Epoch: 223 \tTraining Loss:  0.461 \tTrain_Accu: 80%  \tValid_Acc:23% \t Valid Loss: 4.144 \n",
            "Epoch: 224 \tTraining Loss:  0.490 \tTrain_Accu: 82%  \tValid_Acc:33% \t Valid Loss: 4.254 \n",
            "Epoch: 225 \tTraining Loss:  0.547 \tTrain_Accu: 77%  \tValid_Acc:27% \t Valid Loss: 4.699 \n",
            "Epoch: 226 \tTraining Loss:  0.483 \tTrain_Accu: 80%  \tValid_Acc:21% \t Valid Loss: 4.875 \n",
            "Epoch: 227 \tTraining Loss:  0.486 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 4.209 \n",
            "Epoch: 228 \tTraining Loss:  0.506 \tTrain_Accu: 81%  \tValid_Acc:27% \t Valid Loss: 4.516 \n",
            "Epoch: 229 \tTraining Loss:  0.427 \tTrain_Accu: 85%  \tValid_Acc:21% \t Valid Loss: 3.399 \n",
            "Epoch: 230 \tTraining Loss:  0.537 \tTrain_Accu: 79%  \tValid_Acc:29% \t Valid Loss: 5.192 \n",
            "Epoch: 231 \tTraining Loss:  0.464 \tTrain_Accu: 85%  \tValid_Acc:30% \t Valid Loss: 5.171 \n",
            "Epoch: 232 \tTraining Loss:  0.507 \tTrain_Accu: 80%  \tValid_Acc:30% \t Valid Loss: 3.232 \n",
            "Epoch: 233 \tTraining Loss:  0.559 \tTrain_Accu: 82%  \tValid_Acc:26% \t Valid Loss: 3.649 \n",
            "Epoch: 234 \tTraining Loss:  0.475 \tTrain_Accu: 78%  \tValid_Acc:26% \t Valid Loss: 2.887 \n",
            "Epoch: 235 \tTraining Loss:  0.474 \tTrain_Accu: 80%  \tValid_Acc:23% \t Valid Loss: 4.675 \n",
            "Epoch: 236 \tTraining Loss:  0.548 \tTrain_Accu: 80%  \tValid_Acc:24% \t Valid Loss: 3.351 \n",
            "Epoch: 237 \tTraining Loss:  0.431 \tTrain_Accu: 82%  \tValid_Acc:27% \t Valid Loss: 4.571 \n",
            "Epoch: 238 \tTraining Loss:  0.457 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 7.155 \n",
            "Epoch: 239 \tTraining Loss:  0.445 \tTrain_Accu: 82%  \tValid_Acc:27% \t Valid Loss: 4.779 \n",
            "Epoch: 240 \tTraining Loss:  0.425 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 4.206 \n",
            "Epoch: 241 \tTraining Loss:  0.531 \tTrain_Accu: 79%  \tValid_Acc:34% \t Valid Loss: 3.919 \n",
            "Epoch: 242 \tTraining Loss:  0.483 \tTrain_Accu: 82%  \tValid_Acc:23% \t Valid Loss: 4.883 \n",
            "Epoch: 243 \tTraining Loss:  0.444 \tTrain_Accu: 84%  \tValid_Acc:27% \t Valid Loss: 4.128 \n",
            "Epoch: 244 \tTraining Loss:  0.422 \tTrain_Accu: 86%  \tValid_Acc:26% \t Valid Loss: 4.027 \n",
            "Epoch: 245 \tTraining Loss:  0.431 \tTrain_Accu: 84%  \tValid_Acc:21% \t Valid Loss: 4.441 \n",
            "Epoch: 246 \tTraining Loss:  0.505 \tTrain_Accu: 77%  \tValid_Acc:26% \t Valid Loss: 4.116 \n",
            "Epoch: 247 \tTraining Loss:  0.502 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 4.196 \n",
            "Epoch: 248 \tTraining Loss:  0.438 \tTrain_Accu: 84%  \tValid_Acc:19% \t Valid Loss: 4.466 \n",
            "Epoch: 249 \tTraining Loss:  0.458 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 3.838 \n",
            "Epoch: 250 \tTraining Loss:  0.507 \tTrain_Accu: 78%  \tValid_Acc:27% \t Valid Loss: 4.966 \n",
            "Epoch: 251 \tTraining Loss:  0.479 \tTrain_Accu: 79%  \tValid_Acc:17% \t Valid Loss: 6.000 \n",
            "Epoch: 252 \tTraining Loss:  0.451 \tTrain_Accu: 81%  \tValid_Acc:31% \t Valid Loss: 5.735 \n",
            "Epoch: 253 \tTraining Loss:  0.471 \tTrain_Accu: 82%  \tValid_Acc:24% \t Valid Loss: 4.021 \n",
            "Epoch: 254 \tTraining Loss:  0.418 \tTrain_Accu: 84%  \tValid_Acc:39% \t Valid Loss: 2.784 \n",
            "Epoch: 255 \tTraining Loss:  0.460 \tTrain_Accu: 83%  \tValid_Acc:30% \t Valid Loss: 3.310 \n",
            "Epoch: 256 \tTraining Loss:  0.481 \tTrain_Accu: 79%  \tValid_Acc:20% \t Valid Loss: 4.279 \n",
            "Epoch: 257 \tTraining Loss:  0.517 \tTrain_Accu: 80%  \tValid_Acc:27% \t Valid Loss: 4.083 \n",
            "Epoch: 258 \tTraining Loss:  0.568 \tTrain_Accu: 76%  \tValid_Acc:26% \t Valid Loss: 4.642 \n",
            "Epoch: 259 \tTraining Loss:  0.438 \tTrain_Accu: 84%  \tValid_Acc:21% \t Valid Loss: 6.183 \n",
            "Epoch: 260 \tTraining Loss:  0.436 \tTrain_Accu: 86%  \tValid_Acc:27% \t Valid Loss: 4.940 \n",
            "Epoch: 261 \tTraining Loss:  0.447 \tTrain_Accu: 83%  \tValid_Acc:20% \t Valid Loss: 5.920 \n",
            "Epoch: 262 \tTraining Loss:  0.500 \tTrain_Accu: 81%  \tValid_Acc:23% \t Valid Loss: 4.299 \n",
            "Epoch: 263 \tTraining Loss:  0.454 \tTrain_Accu: 81%  \tValid_Acc:33% \t Valid Loss: 3.383 \n",
            "Epoch: 264 \tTraining Loss:  0.444 \tTrain_Accu: 80%  \tValid_Acc:29% \t Valid Loss: 4.763 \n",
            "Epoch: 265 \tTraining Loss:  0.511 \tTrain_Accu: 80%  \tValid_Acc:30% \t Valid Loss: 4.406 \n",
            "Epoch: 266 \tTraining Loss:  0.406 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 4.934 \n",
            "Epoch: 267 \tTraining Loss:  0.429 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 4.782 \n",
            "Epoch: 268 \tTraining Loss:  0.418 \tTrain_Accu: 82%  \tValid_Acc:24% \t Valid Loss: 4.314 \n",
            "Epoch: 269 \tTraining Loss:  0.420 \tTrain_Accu: 85%  \tValid_Acc:33% \t Valid Loss: 4.180 \n",
            "Epoch: 270 \tTraining Loss:  0.452 \tTrain_Accu: 83%  \tValid_Acc:30% \t Valid Loss: 5.215 \n",
            "Epoch: 271 \tTraining Loss:  0.468 \tTrain_Accu: 83%  \tValid_Acc:23% \t Valid Loss: 3.801 \n",
            "Epoch: 272 \tTraining Loss:  0.400 \tTrain_Accu: 83%  \tValid_Acc:21% \t Valid Loss: 6.384 \n",
            "Epoch: 273 \tTraining Loss:  0.442 \tTrain_Accu: 86%  \tValid_Acc:23% \t Valid Loss: 5.118 \n",
            "Epoch: 274 \tTraining Loss:  0.429 \tTrain_Accu: 82%  \tValid_Acc:20% \t Valid Loss: 5.645 \n",
            "Epoch: 275 \tTraining Loss:  0.510 \tTrain_Accu: 81%  \tValid_Acc:20% \t Valid Loss: 4.618 \n",
            "Epoch: 276 \tTraining Loss:  0.488 \tTrain_Accu: 82%  \tValid_Acc:30% \t Valid Loss: 4.474 \n",
            "Epoch: 277 \tTraining Loss:  0.430 \tTrain_Accu: 84%  \tValid_Acc:23% \t Valid Loss: 6.379 \n",
            "Epoch: 278 \tTraining Loss:  0.423 \tTrain_Accu: 84%  \tValid_Acc:23% \t Valid Loss: 5.058 \n",
            "Epoch: 279 \tTraining Loss:  0.393 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 6.120 \n",
            "Epoch: 280 \tTraining Loss:  0.452 \tTrain_Accu: 86%  \tValid_Acc:27% \t Valid Loss: 7.564 \n",
            "Epoch: 281 \tTraining Loss:  0.380 \tTrain_Accu: 86%  \tValid_Acc:27% \t Valid Loss: 5.198 \n",
            "Epoch: 282 \tTraining Loss:  0.490 \tTrain_Accu: 82%  \tValid_Acc:19% \t Valid Loss: 4.664 \n",
            "Epoch: 283 \tTraining Loss:  0.458 \tTrain_Accu: 84%  \tValid_Acc:27% \t Valid Loss: 4.312 \n",
            "Epoch: 284 \tTraining Loss:  0.451 \tTrain_Accu: 83%  \tValid_Acc:27% \t Valid Loss: 4.241 \n",
            "Epoch: 285 \tTraining Loss:  0.513 \tTrain_Accu: 78%  \tValid_Acc:21% \t Valid Loss: 5.712 \n",
            "Epoch: 286 \tTraining Loss:  0.440 \tTrain_Accu: 85%  \tValid_Acc:24% \t Valid Loss: 4.953 \n",
            "Epoch: 287 \tTraining Loss:  0.480 \tTrain_Accu: 80%  \tValid_Acc:21% \t Valid Loss: 5.365 \n",
            "Epoch: 288 \tTraining Loss:  0.406 \tTrain_Accu: 85%  \tValid_Acc:30% \t Valid Loss: 5.675 \n",
            "Epoch: 289 \tTraining Loss:  0.381 \tTrain_Accu: 85%  \tValid_Acc:27% \t Valid Loss: 3.023 \n",
            "Epoch: 290 \tTraining Loss:  0.493 \tTrain_Accu: 82%  \tValid_Acc:29% \t Valid Loss: 4.593 \n",
            "Epoch: 291 \tTraining Loss:  0.455 \tTrain_Accu: 84%  \tValid_Acc:31% \t Valid Loss: 3.908 \n",
            "Epoch: 292 \tTraining Loss:  0.378 \tTrain_Accu: 86%  \tValid_Acc:34% \t Valid Loss: 5.412 \n",
            "Epoch: 293 \tTraining Loss:  0.535 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 5.431 \n",
            "Epoch: 294 \tTraining Loss:  0.476 \tTrain_Accu: 83%  \tValid_Acc:31% \t Valid Loss: 5.281 \n",
            "Epoch: 295 \tTraining Loss:  0.393 \tTrain_Accu: 84%  \tValid_Acc:27% \t Valid Loss: 5.220 \n",
            "Epoch: 296 \tTraining Loss:  0.461 \tTrain_Accu: 84%  \tValid_Acc:33% \t Valid Loss: 4.192 \n",
            "Epoch: 297 \tTraining Loss:  0.446 \tTrain_Accu: 82%  \tValid_Acc:16% \t Valid Loss: 6.187 \n",
            "Epoch: 298 \tTraining Loss:  0.460 \tTrain_Accu: 80%  \tValid_Acc:31% \t Valid Loss: 4.458 \n",
            "Epoch: 299 \tTraining Loss:  0.415 \tTrain_Accu: 86%  \tValid_Acc:20% \t Valid Loss: 5.689 \n",
            "Epoch: 300 \tTraining Loss:  0.460 \tTrain_Accu: 83%  \tValid_Acc:19% \t Valid Loss: 4.982 \n",
            "Epoch: 301 \tTraining Loss:  0.462 \tTrain_Accu: 80%  \tValid_Acc:24% \t Valid Loss: 5.799 \n",
            "Epoch: 302 \tTraining Loss:  0.375 \tTrain_Accu: 87%  \tValid_Acc:24% \t Valid Loss: 5.463 \n",
            "Epoch: 303 \tTraining Loss:  0.421 \tTrain_Accu: 83%  \tValid_Acc:23% \t Valid Loss: 5.862 \n",
            "Epoch: 304 \tTraining Loss:  0.411 \tTrain_Accu: 83%  \tValid_Acc:33% \t Valid Loss: 5.323 \n",
            "Epoch: 305 \tTraining Loss:  0.400 \tTrain_Accu: 85%  \tValid_Acc:33% \t Valid Loss: 6.141 \n",
            "Epoch: 306 \tTraining Loss:  0.512 \tTrain_Accu: 81%  \tValid_Acc:24% \t Valid Loss: 6.312 \n",
            "Epoch: 307 \tTraining Loss:  0.375 \tTrain_Accu: 87%  \tValid_Acc:36% \t Valid Loss: 3.823 \n",
            "Epoch: 308 \tTraining Loss:  0.427 \tTrain_Accu: 85%  \tValid_Acc:29% \t Valid Loss: 5.300 \n",
            "Epoch: 309 \tTraining Loss:  0.390 \tTrain_Accu: 85%  \tValid_Acc:26% \t Valid Loss: 6.019 \n",
            "Epoch: 310 \tTraining Loss:  0.390 \tTrain_Accu: 84%  \tValid_Acc:23% \t Valid Loss: 7.243 \n",
            "Epoch: 311 \tTraining Loss:  0.409 \tTrain_Accu: 87%  \tValid_Acc:24% \t Valid Loss: 6.048 \n",
            "Epoch: 312 \tTraining Loss:  0.358 \tTrain_Accu: 86%  \tValid_Acc:34% \t Valid Loss: 4.358 \n",
            "Epoch: 313 \tTraining Loss:  0.419 \tTrain_Accu: 82%  \tValid_Acc:21% \t Valid Loss: 6.246 \n",
            "Epoch: 314 \tTraining Loss:  0.428 \tTrain_Accu: 83%  \tValid_Acc:23% \t Valid Loss: 6.025 \n",
            "Epoch: 315 \tTraining Loss:  0.407 \tTrain_Accu: 84%  \tValid_Acc:37% \t Valid Loss: 5.987 \n",
            "Epoch: 316 \tTraining Loss:  0.412 \tTrain_Accu: 82%  \tValid_Acc:24% \t Valid Loss: 5.842 \n",
            "Epoch: 317 \tTraining Loss:  0.410 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 5.926 \n",
            "Epoch: 318 \tTraining Loss:  0.420 \tTrain_Accu: 83%  \tValid_Acc:31% \t Valid Loss: 5.242 \n",
            "Epoch: 319 \tTraining Loss:  0.531 \tTrain_Accu: 81%  \tValid_Acc:24% \t Valid Loss: 6.164 \n",
            "Epoch: 320 \tTraining Loss:  0.379 \tTrain_Accu: 87%  \tValid_Acc:29% \t Valid Loss: 5.290 \n",
            "Epoch: 321 \tTraining Loss:  0.389 \tTrain_Accu: 86%  \tValid_Acc:21% \t Valid Loss: 7.093 \n",
            "Epoch: 322 \tTraining Loss:  0.436 \tTrain_Accu: 83%  \tValid_Acc:27% \t Valid Loss: 5.991 \n",
            "Epoch: 323 \tTraining Loss:  0.387 \tTrain_Accu: 86%  \tValid_Acc:24% \t Valid Loss: 5.356 \n",
            "Epoch: 324 \tTraining Loss:  0.443 \tTrain_Accu: 84%  \tValid_Acc:30% \t Valid Loss: 4.230 \n",
            "Epoch: 325 \tTraining Loss:  0.391 \tTrain_Accu: 88%  \tValid_Acc:27% \t Valid Loss: 7.320 \n",
            "Epoch: 326 \tTraining Loss:  0.371 \tTrain_Accu: 85%  \tValid_Acc:24% \t Valid Loss: 4.753 \n",
            "Epoch: 327 \tTraining Loss:  0.419 \tTrain_Accu: 83%  \tValid_Acc:27% \t Valid Loss: 3.507 \n",
            "Epoch: 328 \tTraining Loss:  0.391 \tTrain_Accu: 85%  \tValid_Acc:26% \t Valid Loss: 7.083 \n",
            "Epoch: 329 \tTraining Loss:  0.499 \tTrain_Accu: 82%  \tValid_Acc:24% \t Valid Loss: 5.422 \n",
            "Epoch: 330 \tTraining Loss:  0.407 \tTrain_Accu: 82%  \tValid_Acc:23% \t Valid Loss: 4.668 \n",
            "Epoch: 331 \tTraining Loss:  0.386 \tTrain_Accu: 86%  \tValid_Acc:31% \t Valid Loss: 3.924 \n",
            "Epoch: 332 \tTraining Loss:  0.388 \tTrain_Accu: 85%  \tValid_Acc:27% \t Valid Loss: 5.035 \n",
            "Epoch: 333 \tTraining Loss:  0.339 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 6.580 \n",
            "Epoch: 334 \tTraining Loss:  0.466 \tTrain_Accu: 81%  \tValid_Acc:26% \t Valid Loss: 6.016 \n",
            "Epoch: 335 \tTraining Loss:  0.402 \tTrain_Accu: 83%  \tValid_Acc:30% \t Valid Loss: 4.641 \n",
            "Epoch: 336 \tTraining Loss:  0.486 \tTrain_Accu: 83%  \tValid_Acc:24% \t Valid Loss: 6.506 \n",
            "Epoch: 337 \tTraining Loss:  0.349 \tTrain_Accu: 89%  \tValid_Acc:29% \t Valid Loss: 4.685 \n",
            "Epoch: 338 \tTraining Loss:  0.396 \tTrain_Accu: 84%  \tValid_Acc:24% \t Valid Loss: 5.009 \n",
            "Epoch: 339 \tTraining Loss:  0.400 \tTrain_Accu: 85%  \tValid_Acc:24% \t Valid Loss: 5.187 \n",
            "Epoch: 340 \tTraining Loss:  0.384 \tTrain_Accu: 87%  \tValid_Acc:26% \t Valid Loss: 5.029 \n",
            "Epoch: 341 \tTraining Loss:  0.405 \tTrain_Accu: 86%  \tValid_Acc:29% \t Valid Loss: 6.041 \n",
            "Epoch: 342 \tTraining Loss:  0.389 \tTrain_Accu: 84%  \tValid_Acc:27% \t Valid Loss: 5.319 \n",
            "Epoch: 343 \tTraining Loss:  0.357 \tTrain_Accu: 87%  \tValid_Acc:29% \t Valid Loss: 5.147 \n",
            "Epoch: 344 \tTraining Loss:  0.440 \tTrain_Accu: 82%  \tValid_Acc:23% \t Valid Loss: 5.627 \n",
            "Epoch: 345 \tTraining Loss:  0.334 \tTrain_Accu: 87%  \tValid_Acc:24% \t Valid Loss: 5.302 \n",
            "Epoch: 346 \tTraining Loss:  0.463 \tTrain_Accu: 86%  \tValid_Acc:30% \t Valid Loss: 4.845 \n",
            "Epoch: 347 \tTraining Loss:  0.348 \tTrain_Accu: 87%  \tValid_Acc:24% \t Valid Loss: 6.129 \n",
            "Epoch: 348 \tTraining Loss:  0.377 \tTrain_Accu: 85%  \tValid_Acc:26% \t Valid Loss: 5.450 \n",
            "Epoch: 349 \tTraining Loss:  0.397 \tTrain_Accu: 84%  \tValid_Acc:27% \t Valid Loss: 6.610 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 02:45:01,013]\u001b[0m Trial 14 finished with value: 21.4 and parameters: {'dropout': 0.8}. Best is trial 8 with value: 32.9.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 350 \tTraining Loss:  0.388 \tTrain_Accu: 85%  \tValid_Acc:21% \t Valid Loss: 7.366 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./optuna_valid_NNI_drop.torch']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "DL5PbIABLNSq",
        "outputId": "bda7e461-7fcf-4316-d31d-84f41e1bcf53"
      },
      "source": [
        "data = {  'Dropout_rate':[0.7, 0.8, 0.9], 'Training_Acc':['91%', '83%', '85%'], 'Validation_Acc':['20%', '33%', '21%']  }\n",
        "Table = pd.DataFrame(data)\n",
        "Table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dropout_rate</th>\n",
              "      <th>Training_Acc</th>\n",
              "      <th>Validation_Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.7</td>\n",
              "      <td>91%</td>\n",
              "      <td>20%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.8</td>\n",
              "      <td>83%</td>\n",
              "      <td>33%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9</td>\n",
              "      <td>85%</td>\n",
              "      <td>21%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dropout_rate Training_Acc Validation_Acc\n",
              "0           0.7          91%            20%\n",
              "1           0.8          83%            33%\n",
              "2           0.9          85%            21%"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlUQjVulLQr9"
      },
      "source": [
        "The best hyperparameter combination are batch size 1, learning rate 0.0001, RMSprop optimiser, drop out rate 0.8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llh-61P8Fvkc"
      },
      "source": [
        "## NNI_temp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFvtw2OQHRo9"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_temp_NNI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 1,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           'dropout'       : 0.8,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_NNI_temp(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_NNI[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_NNI[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 1\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_temp_NNI[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_temp_NNI[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_NNI_temp_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3-VrX38FyDb",
        "outputId": "5ccce7ec-1f63-4f22-94aa-3679562a1336"
      },
      "source": [
        "import joblib\n",
        "\n",
        "study.optimize(train_temp_NNI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"./optuna_valid_NNI_drop.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.710 \tTrain_Accu: 18%  \tValid_Acc:10%  \tVal_kappa : -0.002  \n",
            "Epoch: 2 \tTraining Loss:  1.609 \tTrain_Accu: 21%  \tValid_Acc:10%  \tVal_kappa : -0.207  \n",
            "Epoch: 3 \tTraining Loss:  1.604 \tTrain_Accu: 22%  \tValid_Acc:10%  \tVal_kappa : -0.054  \n",
            "Epoch: 4 \tTraining Loss:  1.604 \tTrain_Accu: 26%  \tValid_Acc:7%  \tVal_kappa : 0.108  \n",
            "Epoch: 5 \tTraining Loss:  1.600 \tTrain_Accu: 23%  \tValid_Acc:19%  \tVal_kappa : 0.194  \n",
            "Epoch: 6 \tTraining Loss:  1.601 \tTrain_Accu: 22%  \tValid_Acc:16%  \tVal_kappa : -0.051  \n",
            "Epoch: 7 \tTraining Loss:  1.587 \tTrain_Accu: 26%  \tValid_Acc:14%  \tVal_kappa : 0.423  \n",
            "Epoch: 8 \tTraining Loss:  1.569 \tTrain_Accu: 24%  \tValid_Acc:19%  \tVal_kappa : 0.381  \n",
            "Epoch: 9 \tTraining Loss:  1.578 \tTrain_Accu: 28%  \tValid_Acc:10%  \tVal_kappa : 0.295  \n",
            "Epoch: 10 \tTraining Loss:  1.543 \tTrain_Accu: 30%  \tValid_Acc:16%  \tVal_kappa : -0.176  \n",
            "Epoch: 11 \tTraining Loss:  1.536 \tTrain_Accu: 25%  \tValid_Acc:14%  \tVal_kappa : -0.531  \n",
            "Epoch: 12 \tTraining Loss:  1.554 \tTrain_Accu: 26%  \tValid_Acc:10%  \tVal_kappa : -0.220  \n",
            "Epoch: 13 \tTraining Loss:  1.555 \tTrain_Accu: 28%  \tValid_Acc:19%  \tVal_kappa : -0.358  \n",
            "Epoch: 14 \tTraining Loss:  1.566 \tTrain_Accu: 28%  \tValid_Acc:16%  \tVal_kappa : 0.125  \n",
            "Epoch: 15 \tTraining Loss:  1.508 \tTrain_Accu: 30%  \tValid_Acc:16%  \tVal_kappa : -0.266  \n",
            "Epoch: 16 \tTraining Loss:  1.542 \tTrain_Accu: 28%  \tValid_Acc:24%  \tVal_kappa : 0.271  \n",
            "Epoch: 17 \tTraining Loss:  1.505 \tTrain_Accu: 29%  \tValid_Acc:16%  \tVal_kappa : -0.224  \n",
            "Epoch: 18 \tTraining Loss:  1.534 \tTrain_Accu: 27%  \tValid_Acc:20%  \tVal_kappa : -0.185  \n",
            "Epoch: 19 \tTraining Loss:  1.510 \tTrain_Accu: 30%  \tValid_Acc:13%  \tVal_kappa : -0.034  \n",
            "Epoch: 20 \tTraining Loss:  1.444 \tTrain_Accu: 33%  \tValid_Acc:30%  \tVal_kappa : 0.579  \n",
            "Epoch: 21 \tTraining Loss:  1.510 \tTrain_Accu: 31%  \tValid_Acc:17%  \tVal_kappa : -0.299  \n",
            "Epoch: 22 \tTraining Loss:  1.476 \tTrain_Accu: 34%  \tValid_Acc:19%  \tVal_kappa : 0.384  \n",
            "Epoch: 23 \tTraining Loss:  1.495 \tTrain_Accu: 27%  \tValid_Acc:16%  \tVal_kappa : 0.265  \n",
            "Epoch: 24 \tTraining Loss:  1.469 \tTrain_Accu: 34%  \tValid_Acc:17%  \tVal_kappa : -0.031  \n",
            "Epoch: 25 \tTraining Loss:  1.430 \tTrain_Accu: 33%  \tValid_Acc:30%  \tVal_kappa : -0.226  \n",
            "Epoch: 26 \tTraining Loss:  1.401 \tTrain_Accu: 36%  \tValid_Acc:23%  \tVal_kappa : -0.235  \n",
            "Epoch: 27 \tTraining Loss:  1.431 \tTrain_Accu: 35%  \tValid_Acc:24%  \tVal_kappa : 0.437  \n",
            "Epoch: 28 \tTraining Loss:  1.390 \tTrain_Accu: 37%  \tValid_Acc:16%  \tVal_kappa : 0.017  \n",
            "Epoch: 29 \tTraining Loss:  1.385 \tTrain_Accu: 35%  \tValid_Acc:21%  \tVal_kappa : -0.106  \n",
            "Epoch: 30 \tTraining Loss:  1.391 \tTrain_Accu: 36%  \tValid_Acc:24%  \tVal_kappa : -0.200  \n",
            "Epoch: 31 \tTraining Loss:  1.398 \tTrain_Accu: 36%  \tValid_Acc:21%  \tVal_kappa : 0.007  \n",
            "Epoch: 32 \tTraining Loss:  1.301 \tTrain_Accu: 42%  \tValid_Acc:24%  \tVal_kappa : 0.124  \n",
            "Epoch: 33 \tTraining Loss:  1.364 \tTrain_Accu: 38%  \tValid_Acc:29%  \tVal_kappa : 0.008  \n",
            "Epoch: 34 \tTraining Loss:  1.332 \tTrain_Accu: 40%  \tValid_Acc:30%  \tVal_kappa : 0.152  \n",
            "Epoch: 35 \tTraining Loss:  1.315 \tTrain_Accu: 45%  \tValid_Acc:21%  \tVal_kappa : -0.236  \n",
            "Epoch: 36 \tTraining Loss:  1.311 \tTrain_Accu: 42%  \tValid_Acc:27%  \tVal_kappa : 0.194  \n",
            "Epoch: 37 \tTraining Loss:  1.333 \tTrain_Accu: 42%  \tValid_Acc:26%  \tVal_kappa : -0.069  \n",
            "Epoch: 38 \tTraining Loss:  1.312 \tTrain_Accu: 37%  \tValid_Acc:20%  \tVal_kappa : 0.500  \n",
            "Epoch: 39 \tTraining Loss:  1.260 \tTrain_Accu: 43%  \tValid_Acc:17%  \tVal_kappa : 0.036  \n",
            "Epoch: 40 \tTraining Loss:  1.257 \tTrain_Accu: 41%  \tValid_Acc:24%  \tVal_kappa : -0.162  \n",
            "Epoch: 41 \tTraining Loss:  1.277 \tTrain_Accu: 43%  \tValid_Acc:29%  \tVal_kappa : 0.160  \n",
            "Epoch: 42 \tTraining Loss:  1.255 \tTrain_Accu: 43%  \tValid_Acc:21%  \tVal_kappa : 0.005  \n",
            "Epoch: 43 \tTraining Loss:  1.247 \tTrain_Accu: 45%  \tValid_Acc:31%  \tVal_kappa : 0.188  \n",
            "Epoch: 44 \tTraining Loss:  1.280 \tTrain_Accu: 40%  \tValid_Acc:27%  \tVal_kappa : 0.173  \n",
            "Epoch: 45 \tTraining Loss:  1.227 \tTrain_Accu: 46%  \tValid_Acc:19%  \tVal_kappa : 0.175  \n",
            "Epoch: 46 \tTraining Loss:  1.244 \tTrain_Accu: 44%  \tValid_Acc:19%  \tVal_kappa : -0.164  \n",
            "Epoch: 47 \tTraining Loss:  1.225 \tTrain_Accu: 45%  \tValid_Acc:20%  \tVal_kappa : 0.000  \n",
            "Epoch: 48 \tTraining Loss:  1.198 \tTrain_Accu: 48%  \tValid_Acc:17%  \tVal_kappa : -0.289  \n",
            "Epoch: 49 \tTraining Loss:  1.152 \tTrain_Accu: 51%  \tValid_Acc:26%  \tVal_kappa : -0.096  \n",
            "Epoch: 50 \tTraining Loss:  1.135 \tTrain_Accu: 48%  \tValid_Acc:21%  \tVal_kappa : 0.515  \n",
            "Epoch: 51 \tTraining Loss:  1.138 \tTrain_Accu: 50%  \tValid_Acc:16%  \tVal_kappa : 0.008  \n",
            "Epoch: 52 \tTraining Loss:  1.217 \tTrain_Accu: 44%  \tValid_Acc:20%  \tVal_kappa : 0.016  \n",
            "Epoch: 53 \tTraining Loss:  1.209 \tTrain_Accu: 45%  \tValid_Acc:26%  \tVal_kappa : -0.224  \n",
            "Epoch: 54 \tTraining Loss:  1.103 \tTrain_Accu: 51%  \tValid_Acc:21%  \tVal_kappa : 0.005  \n",
            "Epoch: 55 \tTraining Loss:  1.168 \tTrain_Accu: 45%  \tValid_Acc:27%  \tVal_kappa : 0.102  \n",
            "Epoch: 56 \tTraining Loss:  1.108 \tTrain_Accu: 49%  \tValid_Acc:19%  \tVal_kappa : 0.555  \n",
            "Epoch: 57 \tTraining Loss:  1.131 \tTrain_Accu: 50%  \tValid_Acc:23%  \tVal_kappa : 0.403  \n",
            "Epoch: 58 \tTraining Loss:  1.096 \tTrain_Accu: 52%  \tValid_Acc:24%  \tVal_kappa : 0.220  \n",
            "Epoch: 59 \tTraining Loss:  1.028 \tTrain_Accu: 54%  \tValid_Acc:21%  \tVal_kappa : -0.344  \n",
            "Epoch: 60 \tTraining Loss:  1.056 \tTrain_Accu: 49%  \tValid_Acc:24%  \tVal_kappa : 0.256  \n",
            "Epoch: 61 \tTraining Loss:  1.031 \tTrain_Accu: 54%  \tValid_Acc:30%  \tVal_kappa : 0.188  \n",
            "Epoch: 62 \tTraining Loss:  1.107 \tTrain_Accu: 50%  \tValid_Acc:20%  \tVal_kappa : 0.013  \n",
            "Epoch: 63 \tTraining Loss:  1.043 \tTrain_Accu: 50%  \tValid_Acc:20%  \tVal_kappa : 0.122  \n",
            "Epoch: 64 \tTraining Loss:  1.005 \tTrain_Accu: 55%  \tValid_Acc:31%  \tVal_kappa : 0.074  \n",
            "Epoch: 65 \tTraining Loss:  1.085 \tTrain_Accu: 50%  \tValid_Acc:27%  \tVal_kappa : 0.365  \n",
            "Epoch: 66 \tTraining Loss:  1.005 \tTrain_Accu: 53%  \tValid_Acc:26%  \tVal_kappa : -0.279  \n",
            "Epoch: 67 \tTraining Loss:  1.031 \tTrain_Accu: 53%  \tValid_Acc:19%  \tVal_kappa : -0.223  \n",
            "Epoch: 68 \tTraining Loss:  1.056 \tTrain_Accu: 48%  \tValid_Acc:23%  \tVal_kappa : 0.188  \n",
            "Epoch: 69 \tTraining Loss:  1.058 \tTrain_Accu: 51%  \tValid_Acc:17%  \tVal_kappa : 0.000  \n",
            "Epoch: 70 \tTraining Loss:  1.016 \tTrain_Accu: 54%  \tValid_Acc:16%  \tVal_kappa : -0.323  \n",
            "Epoch: 71 \tTraining Loss:  0.978 \tTrain_Accu: 59%  \tValid_Acc:11%  \tVal_kappa : 0.000  \n",
            "Epoch: 72 \tTraining Loss:  1.057 \tTrain_Accu: 53%  \tValid_Acc:29%  \tVal_kappa : -0.011  \n",
            "Epoch: 73 \tTraining Loss:  0.981 \tTrain_Accu: 53%  \tValid_Acc:21%  \tVal_kappa : -0.006  \n",
            "Epoch: 74 \tTraining Loss:  0.958 \tTrain_Accu: 55%  \tValid_Acc:29%  \tVal_kappa : 0.195  \n",
            "Epoch: 75 \tTraining Loss:  0.933 \tTrain_Accu: 57%  \tValid_Acc:23%  \tVal_kappa : 0.104  \n",
            "Epoch: 76 \tTraining Loss:  0.948 \tTrain_Accu: 56%  \tValid_Acc:11%  \tVal_kappa : 0.243  \n",
            "Epoch: 77 \tTraining Loss:  0.966 \tTrain_Accu: 56%  \tValid_Acc:19%  \tVal_kappa : -0.164  \n",
            "Epoch: 78 \tTraining Loss:  0.933 \tTrain_Accu: 58%  \tValid_Acc:23%  \tVal_kappa : -0.224  \n",
            "Epoch: 79 \tTraining Loss:  0.902 \tTrain_Accu: 57%  \tValid_Acc:21%  \tVal_kappa : -0.293  \n",
            "Epoch: 80 \tTraining Loss:  0.927 \tTrain_Accu: 55%  \tValid_Acc:24%  \tVal_kappa : -0.023  \n",
            "Epoch: 81 \tTraining Loss:  0.926 \tTrain_Accu: 59%  \tValid_Acc:26%  \tVal_kappa : -0.054  \n",
            "Epoch: 82 \tTraining Loss:  0.966 \tTrain_Accu: 55%  \tValid_Acc:19%  \tVal_kappa : 0.197  \n",
            "Epoch: 83 \tTraining Loss:  0.979 \tTrain_Accu: 55%  \tValid_Acc:20%  \tVal_kappa : 0.094  \n",
            "Epoch: 84 \tTraining Loss:  0.994 \tTrain_Accu: 55%  \tValid_Acc:21%  \tVal_kappa : 0.366  \n",
            "Epoch: 85 \tTraining Loss:  0.881 \tTrain_Accu: 62%  \tValid_Acc:23%  \tVal_kappa : 0.014  \n",
            "Epoch: 86 \tTraining Loss:  0.984 \tTrain_Accu: 55%  \tValid_Acc:20%  \tVal_kappa : -0.456  \n",
            "Epoch: 87 \tTraining Loss:  0.891 \tTrain_Accu: 63%  \tValid_Acc:16%  \tVal_kappa : -0.546  \n",
            "Epoch: 88 \tTraining Loss:  0.906 \tTrain_Accu: 60%  \tValid_Acc:20%  \tVal_kappa : -0.203  \n",
            "Epoch: 89 \tTraining Loss:  0.881 \tTrain_Accu: 62%  \tValid_Acc:34%  \tVal_kappa : -0.291  \n",
            "Epoch: 90 \tTraining Loss:  0.891 \tTrain_Accu: 61%  \tValid_Acc:24%  \tVal_kappa : 0.094  \n",
            "Epoch: 91 \tTraining Loss:  0.844 \tTrain_Accu: 61%  \tValid_Acc:17%  \tVal_kappa : -0.291  \n",
            "Epoch: 92 \tTraining Loss:  0.876 \tTrain_Accu: 64%  \tValid_Acc:27%  \tVal_kappa : 0.009  \n",
            "Epoch: 93 \tTraining Loss:  0.870 \tTrain_Accu: 63%  \tValid_Acc:19%  \tVal_kappa : 0.002  \n",
            "Epoch: 94 \tTraining Loss:  0.922 \tTrain_Accu: 62%  \tValid_Acc:26%  \tVal_kappa : -0.204  \n",
            "Epoch: 95 \tTraining Loss:  0.876 \tTrain_Accu: 62%  \tValid_Acc:33%  \tVal_kappa : 0.250  \n",
            "Epoch: 96 \tTraining Loss:  0.903 \tTrain_Accu: 61%  \tValid_Acc:30%  \tVal_kappa : 0.221  \n",
            "Epoch: 97 \tTraining Loss:  0.873 \tTrain_Accu: 63%  \tValid_Acc:21%  \tVal_kappa : -0.110  \n",
            "Epoch: 98 \tTraining Loss:  0.886 \tTrain_Accu: 62%  \tValid_Acc:26%  \tVal_kappa : 0.009  \n",
            "Epoch: 99 \tTraining Loss:  0.802 \tTrain_Accu: 67%  \tValid_Acc:19%  \tVal_kappa : 0.041  \n",
            "Epoch: 100 \tTraining Loss:  0.848 \tTrain_Accu: 64%  \tValid_Acc:26%  \tVal_kappa : 0.221  \n",
            "Epoch: 101 \tTraining Loss:  0.851 \tTrain_Accu: 62%  \tValid_Acc:34%  \tVal_kappa : -0.138  \n",
            "Epoch: 102 \tTraining Loss:  0.830 \tTrain_Accu: 64%  \tValid_Acc:31%  \tVal_kappa : 0.007  \n",
            "Epoch: 103 \tTraining Loss:  0.814 \tTrain_Accu: 61%  \tValid_Acc:24%  \tVal_kappa : 0.000  \n",
            "Epoch: 104 \tTraining Loss:  0.803 \tTrain_Accu: 65%  \tValid_Acc:29%  \tVal_kappa : -0.236  \n",
            "Epoch: 105 \tTraining Loss:  0.783 \tTrain_Accu: 71%  \tValid_Acc:16%  \tVal_kappa : 0.243  \n",
            "Epoch: 106 \tTraining Loss:  0.797 \tTrain_Accu: 65%  \tValid_Acc:23%  \tVal_kappa : 0.084  \n",
            "Epoch: 107 \tTraining Loss:  0.805 \tTrain_Accu: 67%  \tValid_Acc:20%  \tVal_kappa : -0.113  \n",
            "Epoch: 108 \tTraining Loss:  0.825 \tTrain_Accu: 66%  \tValid_Acc:30%  \tVal_kappa : 0.331  \n",
            "Epoch: 109 \tTraining Loss:  0.729 \tTrain_Accu: 70%  \tValid_Acc:30%  \tVal_kappa : -0.237  \n",
            "Epoch: 110 \tTraining Loss:  0.779 \tTrain_Accu: 68%  \tValid_Acc:31%  \tVal_kappa : -0.221  \n",
            "Epoch: 111 \tTraining Loss:  0.798 \tTrain_Accu: 66%  \tValid_Acc:20%  \tVal_kappa : -0.314  \n",
            "Epoch: 112 \tTraining Loss:  0.740 \tTrain_Accu: 70%  \tValid_Acc:26%  \tVal_kappa : -0.113  \n",
            "Epoch: 113 \tTraining Loss:  0.723 \tTrain_Accu: 68%  \tValid_Acc:19%  \tVal_kappa : -0.224  \n",
            "Epoch: 114 \tTraining Loss:  0.854 \tTrain_Accu: 62%  \tValid_Acc:21%  \tVal_kappa : -0.225  \n",
            "Epoch: 115 \tTraining Loss:  0.814 \tTrain_Accu: 64%  \tValid_Acc:21%  \tVal_kappa : -0.088  \n",
            "Epoch: 116 \tTraining Loss:  0.759 \tTrain_Accu: 68%  \tValid_Acc:26%  \tVal_kappa : -0.043  \n",
            "Epoch: 117 \tTraining Loss:  0.772 \tTrain_Accu: 68%  \tValid_Acc:31%  \tVal_kappa : -0.217  \n",
            "Epoch: 118 \tTraining Loss:  0.757 \tTrain_Accu: 66%  \tValid_Acc:34%  \tVal_kappa : -0.204  \n",
            "Epoch: 119 \tTraining Loss:  0.786 \tTrain_Accu: 66%  \tValid_Acc:23%  \tVal_kappa : 0.274  \n",
            "Epoch: 120 \tTraining Loss:  0.754 \tTrain_Accu: 67%  \tValid_Acc:34%  \tVal_kappa : -0.095  \n",
            "Epoch: 121 \tTraining Loss:  0.813 \tTrain_Accu: 65%  \tValid_Acc:21%  \tVal_kappa : -0.442  \n",
            "Epoch: 122 \tTraining Loss:  0.685 \tTrain_Accu: 69%  \tValid_Acc:19%  \tVal_kappa : -0.279  \n",
            "Epoch: 123 \tTraining Loss:  0.725 \tTrain_Accu: 69%  \tValid_Acc:23%  \tVal_kappa : -0.003  \n",
            "Epoch: 124 \tTraining Loss:  0.741 \tTrain_Accu: 69%  \tValid_Acc:24%  \tVal_kappa : -0.225  \n",
            "Epoch: 125 \tTraining Loss:  0.806 \tTrain_Accu: 66%  \tValid_Acc:29%  \tVal_kappa : 0.381  \n",
            "Epoch: 126 \tTraining Loss:  0.684 \tTrain_Accu: 69%  \tValid_Acc:27%  \tVal_kappa : 0.250  \n",
            "Epoch: 127 \tTraining Loss:  0.772 \tTrain_Accu: 66%  \tValid_Acc:31%  \tVal_kappa : -0.098  \n",
            "Epoch: 128 \tTraining Loss:  0.737 \tTrain_Accu: 67%  \tValid_Acc:21%  \tVal_kappa : -0.277  \n",
            "Epoch: 129 \tTraining Loss:  0.798 \tTrain_Accu: 67%  \tValid_Acc:24%  \tVal_kappa : -0.413  \n",
            "Epoch: 130 \tTraining Loss:  0.708 \tTrain_Accu: 73%  \tValid_Acc:20%  \tVal_kappa : 0.240  \n",
            "Epoch: 131 \tTraining Loss:  0.742 \tTrain_Accu: 67%  \tValid_Acc:41%  \tVal_kappa : 0.074  \n",
            "Epoch: 132 \tTraining Loss:  0.684 \tTrain_Accu: 68%  \tValid_Acc:27%  \tVal_kappa : 0.060  \n",
            "Epoch: 133 \tTraining Loss:  0.726 \tTrain_Accu: 70%  \tValid_Acc:24%  \tVal_kappa : -0.423  \n",
            "Epoch: 134 \tTraining Loss:  0.724 \tTrain_Accu: 71%  \tValid_Acc:24%  \tVal_kappa : -0.291  \n",
            "Epoch: 135 \tTraining Loss:  0.703 \tTrain_Accu: 72%  \tValid_Acc:17%  \tVal_kappa : 0.022  \n",
            "Epoch: 136 \tTraining Loss:  0.680 \tTrain_Accu: 74%  \tValid_Acc:29%  \tVal_kappa : -0.221  \n",
            "Epoch: 137 \tTraining Loss:  0.683 \tTrain_Accu: 74%  \tValid_Acc:27%  \tVal_kappa : -0.361  \n",
            "Epoch: 138 \tTraining Loss:  0.584 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : -0.267  \n",
            "Epoch: 139 \tTraining Loss:  0.745 \tTrain_Accu: 69%  \tValid_Acc:27%  \tVal_kappa : 0.230  \n",
            "Epoch: 140 \tTraining Loss:  0.678 \tTrain_Accu: 74%  \tValid_Acc:29%  \tVal_kappa : -0.245  \n",
            "Epoch: 141 \tTraining Loss:  0.651 \tTrain_Accu: 74%  \tValid_Acc:33%  \tVal_kappa : -0.208  \n",
            "Epoch: 142 \tTraining Loss:  0.689 \tTrain_Accu: 73%  \tValid_Acc:26%  \tVal_kappa : -0.106  \n",
            "Epoch: 143 \tTraining Loss:  0.755 \tTrain_Accu: 65%  \tValid_Acc:24%  \tVal_kappa : -0.058  \n",
            "Epoch: 144 \tTraining Loss:  0.684 \tTrain_Accu: 72%  \tValid_Acc:31%  \tVal_kappa : 0.091  \n",
            "Epoch: 145 \tTraining Loss:  0.704 \tTrain_Accu: 72%  \tValid_Acc:36%  \tVal_kappa : -0.140  \n",
            "Epoch: 146 \tTraining Loss:  0.704 \tTrain_Accu: 74%  \tValid_Acc:29%  \tVal_kappa : -0.240  \n",
            "Epoch: 147 \tTraining Loss:  0.710 \tTrain_Accu: 69%  \tValid_Acc:31%  \tVal_kappa : -0.025  \n",
            "Epoch: 148 \tTraining Loss:  0.744 \tTrain_Accu: 71%  \tValid_Acc:23%  \tVal_kappa : -0.237  \n",
            "Epoch: 149 \tTraining Loss:  0.690 \tTrain_Accu: 72%  \tValid_Acc:26%  \tVal_kappa : -0.291  \n",
            "Epoch: 150 \tTraining Loss:  0.669 \tTrain_Accu: 73%  \tValid_Acc:20%  \tVal_kappa : -0.243  \n",
            "Epoch: 151 \tTraining Loss:  0.695 \tTrain_Accu: 74%  \tValid_Acc:26%  \tVal_kappa : -0.331  \n",
            "Epoch: 152 \tTraining Loss:  0.703 \tTrain_Accu: 69%  \tValid_Acc:27%  \tVal_kappa : 0.167  \n",
            "Epoch: 153 \tTraining Loss:  0.673 \tTrain_Accu: 72%  \tValid_Acc:19%  \tVal_kappa : 0.074  \n",
            "Epoch: 154 \tTraining Loss:  0.694 \tTrain_Accu: 71%  \tValid_Acc:29%  \tVal_kappa : 0.074  \n",
            "Epoch: 155 \tTraining Loss:  0.592 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : -0.347  \n",
            "Epoch: 156 \tTraining Loss:  0.580 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : 0.210  \n",
            "Epoch: 157 \tTraining Loss:  0.643 \tTrain_Accu: 73%  \tValid_Acc:29%  \tVal_kappa : -0.086  \n",
            "Epoch: 158 \tTraining Loss:  0.723 \tTrain_Accu: 68%  \tValid_Acc:21%  \tVal_kappa : -0.056  \n",
            "Epoch: 159 \tTraining Loss:  0.602 \tTrain_Accu: 77%  \tValid_Acc:21%  \tVal_kappa : -0.236  \n",
            "Epoch: 160 \tTraining Loss:  0.708 \tTrain_Accu: 73%  \tValid_Acc:24%  \tVal_kappa : -0.144  \n",
            "Epoch: 161 \tTraining Loss:  0.631 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : -0.187  \n",
            "Epoch: 162 \tTraining Loss:  0.666 \tTrain_Accu: 74%  \tValid_Acc:21%  \tVal_kappa : -0.236  \n",
            "Epoch: 163 \tTraining Loss:  0.715 \tTrain_Accu: 76%  \tValid_Acc:29%  \tVal_kappa : -0.336  \n",
            "Epoch: 164 \tTraining Loss:  0.743 \tTrain_Accu: 70%  \tValid_Acc:27%  \tVal_kappa : -0.043  \n",
            "Epoch: 165 \tTraining Loss:  0.695 \tTrain_Accu: 74%  \tValid_Acc:26%  \tVal_kappa : 0.131  \n",
            "Epoch: 166 \tTraining Loss:  0.605 \tTrain_Accu: 73%  \tValid_Acc:27%  \tVal_kappa : 0.390  \n",
            "Epoch: 167 \tTraining Loss:  0.659 \tTrain_Accu: 72%  \tValid_Acc:27%  \tVal_kappa : -0.438  \n",
            "Epoch: 168 \tTraining Loss:  0.676 \tTrain_Accu: 73%  \tValid_Acc:19%  \tVal_kappa : -0.039  \n",
            "Epoch: 169 \tTraining Loss:  0.709 \tTrain_Accu: 74%  \tValid_Acc:21%  \tVal_kappa : -0.298  \n",
            "Epoch: 170 \tTraining Loss:  0.658 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : -0.204  \n",
            "Epoch: 171 \tTraining Loss:  0.698 \tTrain_Accu: 71%  \tValid_Acc:31%  \tVal_kappa : -0.098  \n",
            "Epoch: 172 \tTraining Loss:  0.610 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : -0.182  \n",
            "Epoch: 173 \tTraining Loss:  0.699 \tTrain_Accu: 71%  \tValid_Acc:30%  \tVal_kappa : 0.049  \n",
            "Epoch: 174 \tTraining Loss:  0.577 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : -0.147  \n",
            "Epoch: 175 \tTraining Loss:  0.632 \tTrain_Accu: 72%  \tValid_Acc:17%  \tVal_kappa : -0.318  \n",
            "Epoch: 176 \tTraining Loss:  0.585 \tTrain_Accu: 78%  \tValid_Acc:27%  \tVal_kappa : -0.247  \n",
            "Epoch: 177 \tTraining Loss:  0.669 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : -0.347  \n",
            "Epoch: 178 \tTraining Loss:  0.624 \tTrain_Accu: 74%  \tValid_Acc:26%  \tVal_kappa : -0.111  \n",
            "Epoch: 179 \tTraining Loss:  0.634 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : -0.587  \n",
            "Epoch: 180 \tTraining Loss:  0.656 \tTrain_Accu: 74%  \tValid_Acc:24%  \tVal_kappa : 0.005  \n",
            "Epoch: 181 \tTraining Loss:  0.642 \tTrain_Accu: 75%  \tValid_Acc:19%  \tVal_kappa : -0.221  \n",
            "Epoch: 182 \tTraining Loss:  0.602 \tTrain_Accu: 74%  \tValid_Acc:24%  \tVal_kappa : -0.364  \n",
            "Epoch: 183 \tTraining Loss:  0.635 \tTrain_Accu: 75%  \tValid_Acc:19%  \tVal_kappa : -0.243  \n",
            "Epoch: 184 \tTraining Loss:  0.643 \tTrain_Accu: 74%  \tValid_Acc:24%  \tVal_kappa : 0.313  \n",
            "Epoch: 185 \tTraining Loss:  0.651 \tTrain_Accu: 74%  \tValid_Acc:29%  \tVal_kappa : -0.020  \n",
            "Epoch: 186 \tTraining Loss:  0.538 \tTrain_Accu: 80%  \tValid_Acc:19%  \tVal_kappa : -0.084  \n",
            "Epoch: 187 \tTraining Loss:  0.627 \tTrain_Accu: 75%  \tValid_Acc:31%  \tVal_kappa : -0.262  \n",
            "Epoch: 188 \tTraining Loss:  0.630 \tTrain_Accu: 76%  \tValid_Acc:27%  \tVal_kappa : -0.047  \n",
            "Epoch: 189 \tTraining Loss:  0.691 \tTrain_Accu: 71%  \tValid_Acc:31%  \tVal_kappa : 0.083  \n",
            "Epoch: 190 \tTraining Loss:  0.623 \tTrain_Accu: 77%  \tValid_Acc:24%  \tVal_kappa : 0.193  \n",
            "Epoch: 191 \tTraining Loss:  0.608 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : -0.118  \n",
            "Epoch: 192 \tTraining Loss:  0.615 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : -0.173  \n",
            "Epoch: 193 \tTraining Loss:  0.657 \tTrain_Accu: 73%  \tValid_Acc:27%  \tVal_kappa : -0.217  \n",
            "Epoch: 194 \tTraining Loss:  0.616 \tTrain_Accu: 75%  \tValid_Acc:36%  \tVal_kappa : -0.449  \n",
            "Epoch: 195 \tTraining Loss:  0.580 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : -0.402  \n",
            "Epoch: 196 \tTraining Loss:  0.675 \tTrain_Accu: 71%  \tValid_Acc:23%  \tVal_kappa : 0.030  \n",
            "Epoch: 197 \tTraining Loss:  0.622 \tTrain_Accu: 75%  \tValid_Acc:20%  \tVal_kappa : -0.131  \n",
            "Epoch: 198 \tTraining Loss:  0.587 \tTrain_Accu: 77%  \tValid_Acc:29%  \tVal_kappa : -0.110  \n",
            "Epoch: 199 \tTraining Loss:  0.640 \tTrain_Accu: 75%  \tValid_Acc:26%  \tVal_kappa : -0.347  \n",
            "Epoch: 200 \tTraining Loss:  0.560 \tTrain_Accu: 77%  \tValid_Acc:26%  \tVal_kappa : 0.000  \n",
            "Epoch: 201 \tTraining Loss:  0.581 \tTrain_Accu: 78%  \tValid_Acc:23%  \tVal_kappa : 0.033  \n",
            "Epoch: 202 \tTraining Loss:  0.608 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : 0.144  \n",
            "Epoch: 203 \tTraining Loss:  0.666 \tTrain_Accu: 75%  \tValid_Acc:23%  \tVal_kappa : -0.098  \n",
            "Epoch: 204 \tTraining Loss:  0.537 \tTrain_Accu: 81%  \tValid_Acc:21%  \tVal_kappa : 0.403  \n",
            "Epoch: 205 \tTraining Loss:  0.642 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : -0.094  \n",
            "Epoch: 206 \tTraining Loss:  0.621 \tTrain_Accu: 79%  \tValid_Acc:34%  \tVal_kappa : -0.217  \n",
            "Epoch: 207 \tTraining Loss:  0.600 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : -0.083  \n",
            "Epoch: 208 \tTraining Loss:  0.571 \tTrain_Accu: 79%  \tValid_Acc:24%  \tVal_kappa : -0.168  \n",
            "Epoch: 209 \tTraining Loss:  0.639 \tTrain_Accu: 72%  \tValid_Acc:29%  \tVal_kappa : -0.098  \n",
            "Epoch: 210 \tTraining Loss:  0.594 \tTrain_Accu: 80%  \tValid_Acc:24%  \tVal_kappa : -0.131  \n",
            "Epoch: 211 \tTraining Loss:  0.529 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : -0.098  \n",
            "Epoch: 212 \tTraining Loss:  0.509 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : -0.171  \n",
            "Epoch: 213 \tTraining Loss:  0.549 \tTrain_Accu: 79%  \tValid_Acc:24%  \tVal_kappa : -0.233  \n",
            "Epoch: 214 \tTraining Loss:  0.576 \tTrain_Accu: 79%  \tValid_Acc:29%  \tVal_kappa : 0.033  \n",
            "Epoch: 215 \tTraining Loss:  0.588 \tTrain_Accu: 78%  \tValid_Acc:30%  \tVal_kappa : -0.098  \n",
            "Epoch: 216 \tTraining Loss:  0.566 \tTrain_Accu: 78%  \tValid_Acc:31%  \tVal_kappa : -0.299  \n",
            "Epoch: 217 \tTraining Loss:  0.585 \tTrain_Accu: 78%  \tValid_Acc:31%  \tVal_kappa : 0.011  \n",
            "Epoch: 218 \tTraining Loss:  0.592 \tTrain_Accu: 78%  \tValid_Acc:26%  \tVal_kappa : -0.402  \n",
            "Epoch: 219 \tTraining Loss:  0.536 \tTrain_Accu: 81%  \tValid_Acc:27%  \tVal_kappa : -0.010  \n",
            "Epoch: 220 \tTraining Loss:  0.569 \tTrain_Accu: 79%  \tValid_Acc:36%  \tVal_kappa : -0.221  \n",
            "Epoch: 221 \tTraining Loss:  0.654 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : -0.336  \n",
            "Epoch: 222 \tTraining Loss:  0.486 \tTrain_Accu: 84%  \tValid_Acc:24%  \tVal_kappa : -0.459  \n",
            "Epoch: 223 \tTraining Loss:  0.532 \tTrain_Accu: 78%  \tValid_Acc:29%  \tVal_kappa : 0.052  \n",
            "Epoch: 224 \tTraining Loss:  0.545 \tTrain_Accu: 78%  \tValid_Acc:31%  \tVal_kappa : 0.030  \n",
            "Epoch: 225 \tTraining Loss:  0.620 \tTrain_Accu: 74%  \tValid_Acc:27%  \tVal_kappa : -0.299  \n",
            "Epoch: 226 \tTraining Loss:  0.554 \tTrain_Accu: 77%  \tValid_Acc:29%  \tVal_kappa : 0.033  \n",
            "Epoch: 227 \tTraining Loss:  0.551 \tTrain_Accu: 79%  \tValid_Acc:29%  \tVal_kappa : -0.550  \n",
            "Epoch: 228 \tTraining Loss:  0.648 \tTrain_Accu: 75%  \tValid_Acc:30%  \tVal_kappa : 0.016  \n",
            "Epoch: 229 \tTraining Loss:  0.527 \tTrain_Accu: 82%  \tValid_Acc:19%  \tVal_kappa : -0.204  \n",
            "Epoch: 230 \tTraining Loss:  0.562 \tTrain_Accu: 79%  \tValid_Acc:31%  \tVal_kappa : -0.327  \n",
            "Epoch: 231 \tTraining Loss:  0.560 \tTrain_Accu: 78%  \tValid_Acc:17%  \tVal_kappa : 0.030  \n",
            "Epoch: 232 \tTraining Loss:  0.526 \tTrain_Accu: 81%  \tValid_Acc:34%  \tVal_kappa : -0.373  \n",
            "Epoch: 233 \tTraining Loss:  0.519 \tTrain_Accu: 79%  \tValid_Acc:17%  \tVal_kappa : -0.339  \n",
            "Epoch: 234 \tTraining Loss:  0.494 \tTrain_Accu: 79%  \tValid_Acc:24%  \tVal_kappa : -0.306  \n",
            "Epoch: 235 \tTraining Loss:  0.502 \tTrain_Accu: 83%  \tValid_Acc:30%  \tVal_kappa : 0.009  \n",
            "Epoch: 236 \tTraining Loss:  0.591 \tTrain_Accu: 78%  \tValid_Acc:23%  \tVal_kappa : -0.299  \n",
            "Epoch: 237 \tTraining Loss:  0.524 \tTrain_Accu: 80%  \tValid_Acc:31%  \tVal_kappa : -0.217  \n",
            "Epoch: 238 \tTraining Loss:  0.577 \tTrain_Accu: 79%  \tValid_Acc:29%  \tVal_kappa : 0.042  \n",
            "Epoch: 239 \tTraining Loss:  0.548 \tTrain_Accu: 81%  \tValid_Acc:34%  \tVal_kappa : -0.176  \n",
            "Epoch: 240 \tTraining Loss:  0.498 \tTrain_Accu: 80%  \tValid_Acc:27%  \tVal_kappa : -0.331  \n",
            "Epoch: 241 \tTraining Loss:  0.538 \tTrain_Accu: 78%  \tValid_Acc:34%  \tVal_kappa : -0.191  \n",
            "Epoch: 242 \tTraining Loss:  0.521 \tTrain_Accu: 80%  \tValid_Acc:31%  \tVal_kappa : 0.030  \n",
            "Epoch: 243 \tTraining Loss:  0.592 \tTrain_Accu: 77%  \tValid_Acc:30%  \tVal_kappa : -0.086  \n",
            "Epoch: 244 \tTraining Loss:  0.581 \tTrain_Accu: 79%  \tValid_Acc:27%  \tVal_kappa : -0.098  \n",
            "Epoch: 245 \tTraining Loss:  0.468 \tTrain_Accu: 81%  \tValid_Acc:29%  \tVal_kappa : -0.347  \n",
            "Epoch: 246 \tTraining Loss:  0.574 \tTrain_Accu: 77%  \tValid_Acc:29%  \tVal_kappa : -0.237  \n",
            "Epoch: 247 \tTraining Loss:  0.550 \tTrain_Accu: 78%  \tValid_Acc:29%  \tVal_kappa : 0.091  \n",
            "Epoch: 248 \tTraining Loss:  0.479 \tTrain_Accu: 80%  \tValid_Acc:30%  \tVal_kappa : 0.395  \n",
            "Epoch: 249 \tTraining Loss:  0.543 \tTrain_Accu: 82%  \tValid_Acc:30%  \tVal_kappa : -0.030  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 03:28:34,847]\u001b[0m Trial 18 finished with value: 30.0 and parameters: {}. Best is trial 8 with value: 32.9.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.549 \tTrain_Accu: 77%  \tValid_Acc:30%  \tVal_kappa : -0.270  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./optuna_valid_NNI_drop.torch']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhh1w0XyFymP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB80qQ4QGDzw"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "checkpoint = torch.load(\"./check_valid_NNI_RMSprops.torch\")\n",
        "train_loss = checkpoint['train_loss']\n",
        "valid_loss = checkpoint['valid_loss']\n",
        "plt.plot(train_loss, label='Training loss')\n",
        "plt.plot(valid_loss, label='Validation loss')\n",
        "#plt.title(\"NNI_Rain_drop(0.7)_input_LR\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(frameon=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYhByirgGErf"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "checkpoint = torch.load(\"./check_valid_NNI_RMSprops.torch\")\n",
        "train_acc = checkpoint['train_acc']\n",
        "valid_acc = checkpoint['valid_acc']\n",
        "plt.plot(train_acc, label='Training acc')\n",
        "plt.plot(valid_acc, label='Validation acc')\n",
        "#plt.title(\"NNI_Rain_drop(0.7)_input_LR\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(frameon=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF_Ndq7GF7os"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "uVjQ2EY9GRPc",
        "outputId": "a2ee935d-d9d1-4873-ed52-1394d6e5b149"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_temp_NNI[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_dropout(0.7)\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_NNI_temp_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3, 4, 3, 2, 4, 1, 1, 3, 2, 4, 3, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0,\n",
            "        0, 0, 3, 3, 4, 4, 4, 4, 4, 3, 4, 3, 4, 2, 2, 2, 0, 1, 0, 1, 1, 3, 2, 3,\n",
            "        3, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 4, 4, 1, 2, 0, 0, 1, 1, 1])\n",
            "labels tensor([1, 3, 3, 4, 4, 4, 3, 3, 2, 2, 3, 3, 4, 3, 3, 3, 2, 3, 1, 2, 2, 3, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 1, 1, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 3, 3, 3, 3, 3, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 3, 4, 4])\n",
            "correct : 14\n",
            "test_Accuracy % : 20.0\n",
            "kappa -0.029188642439130108\n",
            "[[ 0  0  0  0  0]\n",
            " [ 0  0  1  2  1]\n",
            " [ 2  1  3  1  1]\n",
            " [10  4  0  3  2]\n",
            " [ 9 10  7  5  8]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZShuJXx9GKeh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGozaA--tHYQ"
      },
      "source": [
        "## NNI_temp with 350 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_S0kpXctG5T"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_temp_NNI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 1,\n",
        "          'n_epochs' : 350,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           'dropout'       : 0.8,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_NNI_temp(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_NNI[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_NNI[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 1\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_temp_NNI[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_temp_NNI[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_NNI_temp_std_350.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pSqVfMltWsy",
        "outputId": "1d6b1069-77f6-4f8f-f475-96b5e68520bf"
      },
      "source": [
        "import joblib\n",
        "\n",
        "study.optimize(train_temp_NNI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"./optuna_valid_NNI_drop.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.710 \tTrain_Accu: 18%  \tValid_Acc:10%  \tVal_kappa : -0.002  \n",
            "Epoch: 2 \tTraining Loss:  1.609 \tTrain_Accu: 20%  \tValid_Acc:10%  \tVal_kappa : -0.207  \n",
            "Epoch: 3 \tTraining Loss:  1.603 \tTrain_Accu: 21%  \tValid_Acc:7%  \tVal_kappa : -0.054  \n",
            "Epoch: 4 \tTraining Loss:  1.602 \tTrain_Accu: 25%  \tValid_Acc:10%  \tVal_kappa : 0.154  \n",
            "Epoch: 5 \tTraining Loss:  1.603 \tTrain_Accu: 23%  \tValid_Acc:20%  \tVal_kappa : 0.194  \n",
            "Epoch: 6 \tTraining Loss:  1.597 \tTrain_Accu: 23%  \tValid_Acc:20%  \tVal_kappa : 0.223  \n",
            "Epoch: 7 \tTraining Loss:  1.595 \tTrain_Accu: 23%  \tValid_Acc:14%  \tVal_kappa : -0.030  \n",
            "Epoch: 8 \tTraining Loss:  1.557 \tTrain_Accu: 27%  \tValid_Acc:20%  \tVal_kappa : 0.311  \n",
            "Epoch: 9 \tTraining Loss:  1.586 \tTrain_Accu: 24%  \tValid_Acc:11%  \tVal_kappa : 0.125  \n",
            "Epoch: 10 \tTraining Loss:  1.549 \tTrain_Accu: 30%  \tValid_Acc:19%  \tVal_kappa : -0.211  \n",
            "Epoch: 11 \tTraining Loss:  1.538 \tTrain_Accu: 24%  \tValid_Acc:13%  \tVal_kappa : -0.269  \n",
            "Epoch: 12 \tTraining Loss:  1.557 \tTrain_Accu: 27%  \tValid_Acc:7%  \tVal_kappa : -0.220  \n",
            "Epoch: 13 \tTraining Loss:  1.571 \tTrain_Accu: 29%  \tValid_Acc:16%  \tVal_kappa : -0.404  \n",
            "Epoch: 14 \tTraining Loss:  1.560 \tTrain_Accu: 32%  \tValid_Acc:17%  \tVal_kappa : -0.441  \n",
            "Epoch: 15 \tTraining Loss:  1.509 \tTrain_Accu: 29%  \tValid_Acc:16%  \tVal_kappa : -0.087  \n",
            "Epoch: 16 \tTraining Loss:  1.526 \tTrain_Accu: 29%  \tValid_Acc:23%  \tVal_kappa : 0.168  \n",
            "Epoch: 17 \tTraining Loss:  1.512 \tTrain_Accu: 30%  \tValid_Acc:23%  \tVal_kappa : -0.050  \n",
            "Epoch: 18 \tTraining Loss:  1.545 \tTrain_Accu: 27%  \tValid_Acc:29%  \tVal_kappa : 0.008  \n",
            "Epoch: 19 \tTraining Loss:  1.501 \tTrain_Accu: 33%  \tValid_Acc:16%  \tVal_kappa : -0.131  \n",
            "Epoch: 20 \tTraining Loss:  1.465 \tTrain_Accu: 32%  \tValid_Acc:23%  \tVal_kappa : 0.178  \n",
            "Epoch: 21 \tTraining Loss:  1.507 \tTrain_Accu: 31%  \tValid_Acc:16%  \tVal_kappa : -0.299  \n",
            "Epoch: 22 \tTraining Loss:  1.478 \tTrain_Accu: 31%  \tValid_Acc:24%  \tVal_kappa : 0.115  \n",
            "Epoch: 23 \tTraining Loss:  1.492 \tTrain_Accu: 30%  \tValid_Acc:14%  \tVal_kappa : 0.520  \n",
            "Epoch: 24 \tTraining Loss:  1.451 \tTrain_Accu: 33%  \tValid_Acc:11%  \tVal_kappa : 0.098  \n",
            "Epoch: 25 \tTraining Loss:  1.445 \tTrain_Accu: 30%  \tValid_Acc:23%  \tVal_kappa : -0.216  \n",
            "Epoch: 26 \tTraining Loss:  1.408 \tTrain_Accu: 38%  \tValid_Acc:23%  \tVal_kappa : 0.007  \n",
            "Epoch: 27 \tTraining Loss:  1.409 \tTrain_Accu: 36%  \tValid_Acc:24%  \tVal_kappa : 0.444  \n",
            "Epoch: 28 \tTraining Loss:  1.388 \tTrain_Accu: 39%  \tValid_Acc:20%  \tVal_kappa : -0.263  \n",
            "Epoch: 29 \tTraining Loss:  1.380 \tTrain_Accu: 41%  \tValid_Acc:21%  \tVal_kappa : -0.338  \n",
            "Epoch: 30 \tTraining Loss:  1.404 \tTrain_Accu: 36%  \tValid_Acc:20%  \tVal_kappa : -0.186  \n",
            "Epoch: 31 \tTraining Loss:  1.402 \tTrain_Accu: 37%  \tValid_Acc:27%  \tVal_kappa : 0.007  \n",
            "Epoch: 32 \tTraining Loss:  1.304 \tTrain_Accu: 43%  \tValid_Acc:27%  \tVal_kappa : -0.228  \n",
            "Epoch: 33 \tTraining Loss:  1.351 \tTrain_Accu: 41%  \tValid_Acc:29%  \tVal_kappa : 0.021  \n",
            "Epoch: 34 \tTraining Loss:  1.331 \tTrain_Accu: 39%  \tValid_Acc:21%  \tVal_kappa : 0.191  \n",
            "Epoch: 35 \tTraining Loss:  1.313 \tTrain_Accu: 43%  \tValid_Acc:21%  \tVal_kappa : 0.005  \n",
            "Epoch: 36 \tTraining Loss:  1.342 \tTrain_Accu: 42%  \tValid_Acc:30%  \tVal_kappa : 0.194  \n",
            "Epoch: 37 \tTraining Loss:  1.337 \tTrain_Accu: 40%  \tValid_Acc:20%  \tVal_kappa : -0.038  \n",
            "Epoch: 38 \tTraining Loss:  1.317 \tTrain_Accu: 40%  \tValid_Acc:21%  \tVal_kappa : 0.158  \n",
            "Epoch: 39 \tTraining Loss:  1.270 \tTrain_Accu: 42%  \tValid_Acc:13%  \tVal_kappa : 0.305  \n",
            "Epoch: 40 \tTraining Loss:  1.249 \tTrain_Accu: 41%  \tValid_Acc:26%  \tVal_kappa : 0.119  \n",
            "Epoch: 41 \tTraining Loss:  1.294 \tTrain_Accu: 44%  \tValid_Acc:26%  \tVal_kappa : 0.110  \n",
            "Epoch: 42 \tTraining Loss:  1.271 \tTrain_Accu: 44%  \tValid_Acc:17%  \tVal_kappa : 0.324  \n",
            "Epoch: 43 \tTraining Loss:  1.208 \tTrain_Accu: 49%  \tValid_Acc:30%  \tVal_kappa : 0.119  \n",
            "Epoch: 44 \tTraining Loss:  1.297 \tTrain_Accu: 40%  \tValid_Acc:23%  \tVal_kappa : 0.173  \n",
            "Epoch: 45 \tTraining Loss:  1.227 \tTrain_Accu: 44%  \tValid_Acc:24%  \tVal_kappa : 0.493  \n",
            "Epoch: 46 \tTraining Loss:  1.223 \tTrain_Accu: 46%  \tValid_Acc:26%  \tVal_kappa : 0.433  \n",
            "Epoch: 47 \tTraining Loss:  1.225 \tTrain_Accu: 45%  \tValid_Acc:20%  \tVal_kappa : -0.224  \n",
            "Epoch: 48 \tTraining Loss:  1.170 \tTrain_Accu: 48%  \tValid_Acc:17%  \tVal_kappa : -0.266  \n",
            "Epoch: 49 \tTraining Loss:  1.157 \tTrain_Accu: 47%  \tValid_Acc:24%  \tVal_kappa : -0.007  \n",
            "Epoch: 50 \tTraining Loss:  1.125 \tTrain_Accu: 49%  \tValid_Acc:21%  \tVal_kappa : 0.342  \n",
            "Epoch: 51 \tTraining Loss:  1.138 \tTrain_Accu: 46%  \tValid_Acc:20%  \tVal_kappa : -0.284  \n",
            "Epoch: 52 \tTraining Loss:  1.204 \tTrain_Accu: 44%  \tValid_Acc:21%  \tVal_kappa : 0.016  \n",
            "Epoch: 53 \tTraining Loss:  1.189 \tTrain_Accu: 47%  \tValid_Acc:23%  \tVal_kappa : -0.075  \n",
            "Epoch: 54 \tTraining Loss:  1.109 \tTrain_Accu: 49%  \tValid_Acc:27%  \tVal_kappa : -0.420  \n",
            "Epoch: 55 \tTraining Loss:  1.149 \tTrain_Accu: 46%  \tValid_Acc:19%  \tVal_kappa : 0.199  \n",
            "Epoch: 56 \tTraining Loss:  1.083 \tTrain_Accu: 52%  \tValid_Acc:17%  \tVal_kappa : 0.537  \n",
            "Epoch: 57 \tTraining Loss:  1.101 \tTrain_Accu: 53%  \tValid_Acc:20%  \tVal_kappa : 0.101  \n",
            "Epoch: 58 \tTraining Loss:  1.084 \tTrain_Accu: 50%  \tValid_Acc:26%  \tVal_kappa : 0.002  \n",
            "Epoch: 59 \tTraining Loss:  1.019 \tTrain_Accu: 57%  \tValid_Acc:20%  \tVal_kappa : -0.344  \n",
            "Epoch: 60 \tTraining Loss:  1.099 \tTrain_Accu: 53%  \tValid_Acc:24%  \tVal_kappa : 0.227  \n",
            "Epoch: 61 \tTraining Loss:  1.059 \tTrain_Accu: 55%  \tValid_Acc:24%  \tVal_kappa : 0.188  \n",
            "Epoch: 62 \tTraining Loss:  1.094 \tTrain_Accu: 51%  \tValid_Acc:20%  \tVal_kappa : 0.183  \n",
            "Epoch: 63 \tTraining Loss:  1.006 \tTrain_Accu: 55%  \tValid_Acc:23%  \tVal_kappa : 0.024  \n",
            "Epoch: 64 \tTraining Loss:  1.022 \tTrain_Accu: 55%  \tValid_Acc:20%  \tVal_kappa : 0.235  \n",
            "Epoch: 65 \tTraining Loss:  1.039 \tTrain_Accu: 57%  \tValid_Acc:27%  \tVal_kappa : 0.561  \n",
            "Epoch: 66 \tTraining Loss:  1.033 \tTrain_Accu: 55%  \tValid_Acc:21%  \tVal_kappa : -0.360  \n",
            "Epoch: 67 \tTraining Loss:  1.004 \tTrain_Accu: 53%  \tValid_Acc:24%  \tVal_kappa : 0.111  \n",
            "Epoch: 68 \tTraining Loss:  1.050 \tTrain_Accu: 53%  \tValid_Acc:29%  \tVal_kappa : 0.339  \n",
            "Epoch: 69 \tTraining Loss:  1.008 \tTrain_Accu: 54%  \tValid_Acc:23%  \tVal_kappa : -0.224  \n",
            "Epoch: 70 \tTraining Loss:  1.017 \tTrain_Accu: 56%  \tValid_Acc:21%  \tVal_kappa : -0.298  \n",
            "Epoch: 71 \tTraining Loss:  0.968 \tTrain_Accu: 55%  \tValid_Acc:19%  \tVal_kappa : 0.005  \n",
            "Epoch: 72 \tTraining Loss:  1.023 \tTrain_Accu: 53%  \tValid_Acc:30%  \tVal_kappa : 0.128  \n",
            "Epoch: 73 \tTraining Loss:  0.985 \tTrain_Accu: 58%  \tValid_Acc:20%  \tVal_kappa : -0.181  \n",
            "Epoch: 74 \tTraining Loss:  0.894 \tTrain_Accu: 58%  \tValid_Acc:26%  \tVal_kappa : 0.068  \n",
            "Epoch: 75 \tTraining Loss:  0.907 \tTrain_Accu: 58%  \tValid_Acc:26%  \tVal_kappa : 0.308  \n",
            "Epoch: 76 \tTraining Loss:  0.910 \tTrain_Accu: 58%  \tValid_Acc:16%  \tVal_kappa : -0.138  \n",
            "Epoch: 77 \tTraining Loss:  0.965 \tTrain_Accu: 56%  \tValid_Acc:24%  \tVal_kappa : -0.048  \n",
            "Epoch: 78 \tTraining Loss:  0.929 \tTrain_Accu: 57%  \tValid_Acc:33%  \tVal_kappa : -0.224  \n",
            "Epoch: 79 \tTraining Loss:  0.908 \tTrain_Accu: 56%  \tValid_Acc:21%  \tVal_kappa : 0.225  \n",
            "Epoch: 80 \tTraining Loss:  0.941 \tTrain_Accu: 58%  \tValid_Acc:19%  \tVal_kappa : 0.216  \n",
            "Epoch: 81 \tTraining Loss:  0.916 \tTrain_Accu: 59%  \tValid_Acc:31%  \tVal_kappa : -0.086  \n",
            "Epoch: 82 \tTraining Loss:  0.989 \tTrain_Accu: 55%  \tValid_Acc:17%  \tVal_kappa : 0.256  \n",
            "Epoch: 83 \tTraining Loss:  0.962 \tTrain_Accu: 55%  \tValid_Acc:23%  \tVal_kappa : -0.128  \n",
            "Epoch: 84 \tTraining Loss:  0.952 \tTrain_Accu: 57%  \tValid_Acc:20%  \tVal_kappa : 0.451  \n",
            "Epoch: 85 \tTraining Loss:  0.865 \tTrain_Accu: 66%  \tValid_Acc:24%  \tVal_kappa : 0.201  \n",
            "Epoch: 86 \tTraining Loss:  0.916 \tTrain_Accu: 63%  \tValid_Acc:20%  \tVal_kappa : -0.397  \n",
            "Epoch: 87 \tTraining Loss:  0.903 \tTrain_Accu: 62%  \tValid_Acc:20%  \tVal_kappa : -0.546  \n",
            "Epoch: 88 \tTraining Loss:  0.865 \tTrain_Accu: 61%  \tValid_Acc:29%  \tVal_kappa : 0.002  \n",
            "Epoch: 89 \tTraining Loss:  0.846 \tTrain_Accu: 62%  \tValid_Acc:24%  \tVal_kappa : -0.375  \n",
            "Epoch: 90 \tTraining Loss:  0.906 \tTrain_Accu: 61%  \tValid_Acc:24%  \tVal_kappa : -0.111  \n",
            "Epoch: 91 \tTraining Loss:  0.812 \tTrain_Accu: 66%  \tValid_Acc:24%  \tVal_kappa : -0.162  \n",
            "Epoch: 92 \tTraining Loss:  0.901 \tTrain_Accu: 62%  \tValid_Acc:24%  \tVal_kappa : -0.094  \n",
            "Epoch: 93 \tTraining Loss:  0.867 \tTrain_Accu: 63%  \tValid_Acc:24%  \tVal_kappa : 0.074  \n",
            "Epoch: 94 \tTraining Loss:  0.927 \tTrain_Accu: 62%  \tValid_Acc:23%  \tVal_kappa : -0.083  \n",
            "Epoch: 95 \tTraining Loss:  0.837 \tTrain_Accu: 63%  \tValid_Acc:30%  \tVal_kappa : 0.024  \n",
            "Epoch: 96 \tTraining Loss:  0.835 \tTrain_Accu: 62%  \tValid_Acc:31%  \tVal_kappa : 0.128  \n",
            "Epoch: 97 \tTraining Loss:  0.853 \tTrain_Accu: 62%  \tValid_Acc:13%  \tVal_kappa : -0.013  \n",
            "Epoch: 98 \tTraining Loss:  0.798 \tTrain_Accu: 66%  \tValid_Acc:24%  \tVal_kappa : 0.009  \n",
            "Epoch: 99 \tTraining Loss:  0.779 \tTrain_Accu: 64%  \tValid_Acc:14%  \tVal_kappa : -0.058  \n",
            "Epoch: 100 \tTraining Loss:  0.884 \tTrain_Accu: 62%  \tValid_Acc:30%  \tVal_kappa : -0.018  \n",
            "Epoch: 101 \tTraining Loss:  0.780 \tTrain_Accu: 65%  \tValid_Acc:31%  \tVal_kappa : -0.009  \n",
            "Epoch: 102 \tTraining Loss:  0.801 \tTrain_Accu: 64%  \tValid_Acc:20%  \tVal_kappa : 0.005  \n",
            "Epoch: 103 \tTraining Loss:  0.786 \tTrain_Accu: 64%  \tValid_Acc:23%  \tVal_kappa : 0.000  \n",
            "Epoch: 104 \tTraining Loss:  0.749 \tTrain_Accu: 68%  \tValid_Acc:30%  \tVal_kappa : -0.019  \n",
            "Epoch: 105 \tTraining Loss:  0.811 \tTrain_Accu: 66%  \tValid_Acc:20%  \tVal_kappa : 0.141  \n",
            "Epoch: 106 \tTraining Loss:  0.775 \tTrain_Accu: 66%  \tValid_Acc:26%  \tVal_kappa : -0.404  \n",
            "Epoch: 107 \tTraining Loss:  0.750 \tTrain_Accu: 65%  \tValid_Acc:27%  \tVal_kappa : -0.118  \n",
            "Epoch: 108 \tTraining Loss:  0.815 \tTrain_Accu: 66%  \tValid_Acc:30%  \tVal_kappa : 0.049  \n",
            "Epoch: 109 \tTraining Loss:  0.765 \tTrain_Accu: 68%  \tValid_Acc:27%  \tVal_kappa : -0.371  \n",
            "Epoch: 110 \tTraining Loss:  0.757 \tTrain_Accu: 68%  \tValid_Acc:24%  \tVal_kappa : -0.380  \n",
            "Epoch: 111 \tTraining Loss:  0.784 \tTrain_Accu: 70%  \tValid_Acc:24%  \tVal_kappa : -0.429  \n",
            "Epoch: 112 \tTraining Loss:  0.733 \tTrain_Accu: 67%  \tValid_Acc:24%  \tVal_kappa : 0.049  \n",
            "Epoch: 113 \tTraining Loss:  0.757 \tTrain_Accu: 67%  \tValid_Acc:27%  \tVal_kappa : -0.173  \n",
            "Epoch: 114 \tTraining Loss:  0.797 \tTrain_Accu: 66%  \tValid_Acc:26%  \tVal_kappa : -0.225  \n",
            "Epoch: 115 \tTraining Loss:  0.789 \tTrain_Accu: 67%  \tValid_Acc:26%  \tVal_kappa : 0.038  \n",
            "Epoch: 116 \tTraining Loss:  0.765 \tTrain_Accu: 63%  \tValid_Acc:29%  \tVal_kappa : 0.002  \n",
            "Epoch: 117 \tTraining Loss:  0.729 \tTrain_Accu: 69%  \tValid_Acc:26%  \tVal_kappa : 0.153  \n",
            "Epoch: 118 \tTraining Loss:  0.792 \tTrain_Accu: 66%  \tValid_Acc:33%  \tVal_kappa : -0.121  \n",
            "Epoch: 119 \tTraining Loss:  0.759 \tTrain_Accu: 64%  \tValid_Acc:26%  \tVal_kappa : 0.108  \n",
            "Epoch: 120 \tTraining Loss:  0.733 \tTrain_Accu: 70%  \tValid_Acc:21%  \tVal_kappa : -0.259  \n",
            "Epoch: 121 \tTraining Loss:  0.738 \tTrain_Accu: 68%  \tValid_Acc:21%  \tVal_kappa : -0.522  \n",
            "Epoch: 122 \tTraining Loss:  0.703 \tTrain_Accu: 71%  \tValid_Acc:27%  \tVal_kappa : -0.091  \n",
            "Epoch: 123 \tTraining Loss:  0.656 \tTrain_Accu: 72%  \tValid_Acc:30%  \tVal_kappa : -0.134  \n",
            "Epoch: 124 \tTraining Loss:  0.728 \tTrain_Accu: 68%  \tValid_Acc:27%  \tVal_kappa : -0.237  \n",
            "Epoch: 125 \tTraining Loss:  0.810 \tTrain_Accu: 65%  \tValid_Acc:34%  \tVal_kappa : 0.208  \n",
            "Epoch: 126 \tTraining Loss:  0.712 \tTrain_Accu: 70%  \tValid_Acc:27%  \tVal_kappa : 0.218  \n",
            "Epoch: 127 \tTraining Loss:  0.732 \tTrain_Accu: 70%  \tValid_Acc:27%  \tVal_kappa : -0.118  \n",
            "Epoch: 128 \tTraining Loss:  0.690 \tTrain_Accu: 70%  \tValid_Acc:30%  \tVal_kappa : -0.172  \n",
            "Epoch: 129 \tTraining Loss:  0.734 \tTrain_Accu: 67%  \tValid_Acc:24%  \tVal_kappa : -0.413  \n",
            "Epoch: 130 \tTraining Loss:  0.680 \tTrain_Accu: 72%  \tValid_Acc:23%  \tVal_kappa : 0.242  \n",
            "Epoch: 131 \tTraining Loss:  0.729 \tTrain_Accu: 70%  \tValid_Acc:36%  \tVal_kappa : 0.081  \n",
            "Epoch: 132 \tTraining Loss:  0.699 \tTrain_Accu: 68%  \tValid_Acc:29%  \tVal_kappa : 0.390  \n",
            "Epoch: 133 \tTraining Loss:  0.616 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : -0.310  \n",
            "Epoch: 134 \tTraining Loss:  0.688 \tTrain_Accu: 69%  \tValid_Acc:23%  \tVal_kappa : -0.055  \n",
            "Epoch: 135 \tTraining Loss:  0.667 \tTrain_Accu: 74%  \tValid_Acc:20%  \tVal_kappa : 0.014  \n",
            "Epoch: 136 \tTraining Loss:  0.691 \tTrain_Accu: 70%  \tValid_Acc:34%  \tVal_kappa : -0.204  \n",
            "Epoch: 137 \tTraining Loss:  0.660 \tTrain_Accu: 69%  \tValid_Acc:27%  \tVal_kappa : -0.308  \n",
            "Epoch: 138 \tTraining Loss:  0.589 \tTrain_Accu: 74%  \tValid_Acc:29%  \tVal_kappa : -0.039  \n",
            "Epoch: 139 \tTraining Loss:  0.640 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : 0.098  \n",
            "Epoch: 140 \tTraining Loss:  0.630 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : -0.066  \n",
            "Epoch: 141 \tTraining Loss:  0.617 \tTrain_Accu: 74%  \tValid_Acc:29%  \tVal_kappa : 0.161  \n",
            "Epoch: 142 \tTraining Loss:  0.673 \tTrain_Accu: 74%  \tValid_Acc:31%  \tVal_kappa : -0.180  \n",
            "Epoch: 143 \tTraining Loss:  0.649 \tTrain_Accu: 74%  \tValid_Acc:16%  \tVal_kappa : -0.113  \n",
            "Epoch: 144 \tTraining Loss:  0.635 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : 0.221  \n",
            "Epoch: 145 \tTraining Loss:  0.670 \tTrain_Accu: 73%  \tValid_Acc:30%  \tVal_kappa : 0.126  \n",
            "Epoch: 146 \tTraining Loss:  0.649 \tTrain_Accu: 70%  \tValid_Acc:17%  \tVal_kappa : 0.245  \n",
            "Epoch: 147 \tTraining Loss:  0.615 \tTrain_Accu: 72%  \tValid_Acc:37%  \tVal_kappa : 0.032  \n",
            "Epoch: 148 \tTraining Loss:  0.674 \tTrain_Accu: 70%  \tValid_Acc:21%  \tVal_kappa : 0.117  \n",
            "Epoch: 149 \tTraining Loss:  0.688 \tTrain_Accu: 72%  \tValid_Acc:23%  \tVal_kappa : -0.018  \n",
            "Epoch: 150 \tTraining Loss:  0.657 \tTrain_Accu: 76%  \tValid_Acc:31%  \tVal_kappa : -0.217  \n",
            "Epoch: 151 \tTraining Loss:  0.596 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : -0.217  \n",
            "Epoch: 152 \tTraining Loss:  0.649 \tTrain_Accu: 74%  \tValid_Acc:37%  \tVal_kappa : 0.143  \n",
            "Epoch: 153 \tTraining Loss:  0.690 \tTrain_Accu: 72%  \tValid_Acc:19%  \tVal_kappa : 0.147  \n",
            "Epoch: 154 \tTraining Loss:  0.692 \tTrain_Accu: 69%  \tValid_Acc:29%  \tVal_kappa : 0.074  \n",
            "Epoch: 155 \tTraining Loss:  0.604 \tTrain_Accu: 72%  \tValid_Acc:26%  \tVal_kappa : -0.204  \n",
            "Epoch: 156 \tTraining Loss:  0.573 \tTrain_Accu: 78%  \tValid_Acc:36%  \tVal_kappa : -0.026  \n",
            "Epoch: 157 \tTraining Loss:  0.614 \tTrain_Accu: 75%  \tValid_Acc:36%  \tVal_kappa : -0.137  \n",
            "Epoch: 158 \tTraining Loss:  0.690 \tTrain_Accu: 71%  \tValid_Acc:23%  \tVal_kappa : -0.137  \n",
            "Epoch: 159 \tTraining Loss:  0.652 \tTrain_Accu: 73%  \tValid_Acc:16%  \tVal_kappa : -0.404  \n",
            "Epoch: 160 \tTraining Loss:  0.624 \tTrain_Accu: 72%  \tValid_Acc:30%  \tVal_kappa : -0.176  \n",
            "Epoch: 161 \tTraining Loss:  0.625 \tTrain_Accu: 76%  \tValid_Acc:24%  \tVal_kappa : -0.375  \n",
            "Epoch: 162 \tTraining Loss:  0.663 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : 0.020  \n",
            "Epoch: 163 \tTraining Loss:  0.615 \tTrain_Accu: 75%  \tValid_Acc:31%  \tVal_kappa : -0.449  \n",
            "Epoch: 164 \tTraining Loss:  0.663 \tTrain_Accu: 71%  \tValid_Acc:27%  \tVal_kappa : -0.098  \n",
            "Epoch: 165 \tTraining Loss:  0.607 \tTrain_Accu: 76%  \tValid_Acc:27%  \tVal_kappa : 0.049  \n",
            "Epoch: 166 \tTraining Loss:  0.649 \tTrain_Accu: 75%  \tValid_Acc:17%  \tVal_kappa : 0.088  \n",
            "Epoch: 167 \tTraining Loss:  0.694 \tTrain_Accu: 72%  \tValid_Acc:19%  \tVal_kappa : -0.140  \n",
            "Epoch: 168 \tTraining Loss:  0.580 \tTrain_Accu: 78%  \tValid_Acc:20%  \tVal_kappa : 0.220  \n",
            "Epoch: 169 \tTraining Loss:  0.623 \tTrain_Accu: 74%  \tValid_Acc:24%  \tVal_kappa : -0.110  \n",
            "Epoch: 170 \tTraining Loss:  0.647 \tTrain_Accu: 72%  \tValid_Acc:30%  \tVal_kappa : -0.094  \n",
            "Epoch: 171 \tTraining Loss:  0.626 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : 0.070  \n",
            "Epoch: 172 \tTraining Loss:  0.571 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : -0.245  \n",
            "Epoch: 173 \tTraining Loss:  0.648 \tTrain_Accu: 72%  \tValid_Acc:31%  \tVal_kappa : -0.094  \n",
            "Epoch: 174 \tTraining Loss:  0.510 \tTrain_Accu: 80%  \tValid_Acc:26%  \tVal_kappa : 0.049  \n",
            "Epoch: 175 \tTraining Loss:  0.551 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : -0.204  \n",
            "Epoch: 176 \tTraining Loss:  0.536 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : -0.282  \n",
            "Epoch: 177 \tTraining Loss:  0.661 \tTrain_Accu: 75%  \tValid_Acc:26%  \tVal_kappa : -0.336  \n",
            "Epoch: 178 \tTraining Loss:  0.572 \tTrain_Accu: 78%  \tValid_Acc:30%  \tVal_kappa : -0.009  \n",
            "Epoch: 179 \tTraining Loss:  0.598 \tTrain_Accu: 75%  \tValid_Acc:29%  \tVal_kappa : -0.488  \n",
            "Epoch: 180 \tTraining Loss:  0.607 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : 0.313  \n",
            "Epoch: 181 \tTraining Loss:  0.561 \tTrain_Accu: 78%  \tValid_Acc:30%  \tVal_kappa : -0.086  \n",
            "Epoch: 182 \tTraining Loss:  0.601 \tTrain_Accu: 74%  \tValid_Acc:19%  \tVal_kappa : -0.200  \n",
            "Epoch: 183 \tTraining Loss:  0.585 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : -0.266  \n",
            "Epoch: 184 \tTraining Loss:  0.581 \tTrain_Accu: 75%  \tValid_Acc:24%  \tVal_kappa : -0.172  \n",
            "Epoch: 185 \tTraining Loss:  0.620 \tTrain_Accu: 75%  \tValid_Acc:20%  \tVal_kappa : -0.140  \n",
            "Epoch: 186 \tTraining Loss:  0.562 \tTrain_Accu: 76%  \tValid_Acc:27%  \tVal_kappa : -0.237  \n",
            "Epoch: 187 \tTraining Loss:  0.528 \tTrain_Accu: 78%  \tValid_Acc:33%  \tVal_kappa : 0.013  \n",
            "Epoch: 188 \tTraining Loss:  0.595 \tTrain_Accu: 76%  \tValid_Acc:26%  \tVal_kappa : 0.098  \n",
            "Epoch: 189 \tTraining Loss:  0.584 \tTrain_Accu: 76%  \tValid_Acc:23%  \tVal_kappa : -0.217  \n",
            "Epoch: 190 \tTraining Loss:  0.585 \tTrain_Accu: 75%  \tValid_Acc:24%  \tVal_kappa : 0.177  \n",
            "Epoch: 191 \tTraining Loss:  0.593 \tTrain_Accu: 74%  \tValid_Acc:20%  \tVal_kappa : 0.221  \n",
            "Epoch: 192 \tTraining Loss:  0.603 \tTrain_Accu: 77%  \tValid_Acc:14%  \tVal_kappa : -0.173  \n",
            "Epoch: 193 \tTraining Loss:  0.589 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : -0.021  \n",
            "Epoch: 194 \tTraining Loss:  0.661 \tTrain_Accu: 74%  \tValid_Acc:36%  \tVal_kappa : -0.002  \n",
            "Epoch: 195 \tTraining Loss:  0.513 \tTrain_Accu: 81%  \tValid_Acc:20%  \tVal_kappa : -0.346  \n",
            "Epoch: 196 \tTraining Loss:  0.624 \tTrain_Accu: 74%  \tValid_Acc:21%  \tVal_kappa : -0.120  \n",
            "Epoch: 197 \tTraining Loss:  0.561 \tTrain_Accu: 76%  \tValid_Acc:17%  \tVal_kappa : -0.618  \n",
            "Epoch: 198 \tTraining Loss:  0.539 \tTrain_Accu: 78%  \tValid_Acc:40%  \tVal_kappa : 0.157  \n",
            "Epoch: 199 \tTraining Loss:  0.562 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : -0.212  \n",
            "Epoch: 200 \tTraining Loss:  0.587 \tTrain_Accu: 73%  \tValid_Acc:24%  \tVal_kappa : 0.167  \n",
            "Epoch: 201 \tTraining Loss:  0.585 \tTrain_Accu: 76%  \tValid_Acc:27%  \tVal_kappa : 0.264  \n",
            "Epoch: 202 \tTraining Loss:  0.598 \tTrain_Accu: 75%  \tValid_Acc:26%  \tVal_kappa : 0.271  \n",
            "Epoch: 203 \tTraining Loss:  0.613 \tTrain_Accu: 74%  \tValid_Acc:31%  \tVal_kappa : -0.022  \n",
            "Epoch: 204 \tTraining Loss:  0.488 \tTrain_Accu: 81%  \tValid_Acc:23%  \tVal_kappa : 0.190  \n",
            "Epoch: 205 \tTraining Loss:  0.589 \tTrain_Accu: 78%  \tValid_Acc:36%  \tVal_kappa : -0.094  \n",
            "Epoch: 206 \tTraining Loss:  0.571 \tTrain_Accu: 78%  \tValid_Acc:31%  \tVal_kappa : 0.165  \n",
            "Epoch: 207 \tTraining Loss:  0.569 \tTrain_Accu: 78%  \tValid_Acc:26%  \tVal_kappa : 0.141  \n",
            "Epoch: 208 \tTraining Loss:  0.530 \tTrain_Accu: 77%  \tValid_Acc:19%  \tVal_kappa : -0.608  \n",
            "Epoch: 209 \tTraining Loss:  0.530 \tTrain_Accu: 78%  \tValid_Acc:33%  \tVal_kappa : -0.172  \n",
            "Epoch: 210 \tTraining Loss:  0.505 \tTrain_Accu: 79%  \tValid_Acc:31%  \tVal_kappa : 0.419  \n",
            "Epoch: 211 \tTraining Loss:  0.492 \tTrain_Accu: 81%  \tValid_Acc:27%  \tVal_kappa : 0.356  \n",
            "Epoch: 212 \tTraining Loss:  0.519 \tTrain_Accu: 78%  \tValid_Acc:30%  \tVal_kappa : -0.043  \n",
            "Epoch: 213 \tTraining Loss:  0.501 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : -0.339  \n",
            "Epoch: 214 \tTraining Loss:  0.580 \tTrain_Accu: 80%  \tValid_Acc:27%  \tVal_kappa : 0.379  \n",
            "Epoch: 215 \tTraining Loss:  0.531 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : -0.086  \n",
            "Epoch: 216 \tTraining Loss:  0.554 \tTrain_Accu: 77%  \tValid_Acc:31%  \tVal_kappa : -0.504  \n",
            "Epoch: 217 \tTraining Loss:  0.541 \tTrain_Accu: 76%  \tValid_Acc:30%  \tVal_kappa : -0.115  \n",
            "Epoch: 218 \tTraining Loss:  0.527 \tTrain_Accu: 79%  \tValid_Acc:26%  \tVal_kappa : -0.330  \n",
            "Epoch: 219 \tTraining Loss:  0.553 \tTrain_Accu: 77%  \tValid_Acc:29%  \tVal_kappa : -0.258  \n",
            "Epoch: 220 \tTraining Loss:  0.494 \tTrain_Accu: 80%  \tValid_Acc:30%  \tVal_kappa : -0.106  \n",
            "Epoch: 221 \tTraining Loss:  0.569 \tTrain_Accu: 77%  \tValid_Acc:36%  \tVal_kappa : -0.328  \n",
            "Epoch: 222 \tTraining Loss:  0.470 \tTrain_Accu: 81%  \tValid_Acc:23%  \tVal_kappa : 0.161  \n",
            "Epoch: 223 \tTraining Loss:  0.512 \tTrain_Accu: 80%  \tValid_Acc:26%  \tVal_kappa : -0.207  \n",
            "Epoch: 224 \tTraining Loss:  0.496 \tTrain_Accu: 79%  \tValid_Acc:31%  \tVal_kappa : 0.193  \n",
            "Epoch: 225 \tTraining Loss:  0.544 \tTrain_Accu: 79%  \tValid_Acc:27%  \tVal_kappa : -0.016  \n",
            "Epoch: 226 \tTraining Loss:  0.544 \tTrain_Accu: 79%  \tValid_Acc:30%  \tVal_kappa : -0.262  \n",
            "Epoch: 227 \tTraining Loss:  0.500 \tTrain_Accu: 81%  \tValid_Acc:27%  \tVal_kappa : -0.371  \n",
            "Epoch: 228 \tTraining Loss:  0.539 \tTrain_Accu: 77%  \tValid_Acc:29%  \tVal_kappa : 0.047  \n",
            "Epoch: 229 \tTraining Loss:  0.469 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : -0.138  \n",
            "Epoch: 230 \tTraining Loss:  0.583 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : -0.456  \n",
            "Epoch: 231 \tTraining Loss:  0.517 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : 0.045  \n",
            "Epoch: 232 \tTraining Loss:  0.528 \tTrain_Accu: 81%  \tValid_Acc:21%  \tVal_kappa : 0.126  \n",
            "Epoch: 233 \tTraining Loss:  0.523 \tTrain_Accu: 79%  \tValid_Acc:26%  \tVal_kappa : -0.346  \n",
            "Epoch: 234 \tTraining Loss:  0.466 \tTrain_Accu: 82%  \tValid_Acc:24%  \tVal_kappa : -0.145  \n",
            "Epoch: 235 \tTraining Loss:  0.489 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : -0.020  \n",
            "Epoch: 236 \tTraining Loss:  0.580 \tTrain_Accu: 78%  \tValid_Acc:30%  \tVal_kappa : -0.299  \n",
            "Epoch: 237 \tTraining Loss:  0.452 \tTrain_Accu: 82%  \tValid_Acc:26%  \tVal_kappa : -0.225  \n",
            "Epoch: 238 \tTraining Loss:  0.506 \tTrain_Accu: 82%  \tValid_Acc:24%  \tVal_kappa : 0.050  \n",
            "Epoch: 239 \tTraining Loss:  0.548 \tTrain_Accu: 78%  \tValid_Acc:31%  \tVal_kappa : -0.204  \n",
            "Epoch: 240 \tTraining Loss:  0.484 \tTrain_Accu: 81%  \tValid_Acc:27%  \tVal_kappa : -0.028  \n",
            "Epoch: 241 \tTraining Loss:  0.510 \tTrain_Accu: 78%  \tValid_Acc:34%  \tVal_kappa : 0.253  \n",
            "Epoch: 242 \tTraining Loss:  0.528 \tTrain_Accu: 77%  \tValid_Acc:23%  \tVal_kappa : -0.078  \n",
            "Epoch: 243 \tTraining Loss:  0.490 \tTrain_Accu: 77%  \tValid_Acc:29%  \tVal_kappa : -0.039  \n",
            "Epoch: 244 \tTraining Loss:  0.460 \tTrain_Accu: 82%  \tValid_Acc:29%  \tVal_kappa : -0.091  \n",
            "Epoch: 245 \tTraining Loss:  0.515 \tTrain_Accu: 78%  \tValid_Acc:26%  \tVal_kappa : 0.051  \n",
            "Epoch: 246 \tTraining Loss:  0.500 \tTrain_Accu: 80%  \tValid_Acc:34%  \tVal_kappa : -0.237  \n",
            "Epoch: 247 \tTraining Loss:  0.561 \tTrain_Accu: 78%  \tValid_Acc:26%  \tVal_kappa : -0.376  \n",
            "Epoch: 248 \tTraining Loss:  0.448 \tTrain_Accu: 83%  \tValid_Acc:21%  \tVal_kappa : 0.423  \n",
            "Epoch: 249 \tTraining Loss:  0.496 \tTrain_Accu: 78%  \tValid_Acc:30%  \tVal_kappa : -0.098  \n",
            "Epoch: 250 \tTraining Loss:  0.576 \tTrain_Accu: 78%  \tValid_Acc:31%  \tVal_kappa : -0.270  \n",
            "Epoch: 251 \tTraining Loss:  0.573 \tTrain_Accu: 77%  \tValid_Acc:23%  \tVal_kappa : 0.528  \n",
            "Epoch: 252 \tTraining Loss:  0.503 \tTrain_Accu: 78%  \tValid_Acc:29%  \tVal_kappa : -0.287  \n",
            "Epoch: 253 \tTraining Loss:  0.483 \tTrain_Accu: 80%  \tValid_Acc:29%  \tVal_kappa : -0.262  \n",
            "Epoch: 254 \tTraining Loss:  0.413 \tTrain_Accu: 84%  \tValid_Acc:31%  \tVal_kappa : -0.149  \n",
            "Epoch: 255 \tTraining Loss:  0.544 \tTrain_Accu: 79%  \tValid_Acc:37%  \tVal_kappa : -0.387  \n",
            "Epoch: 256 \tTraining Loss:  0.473 \tTrain_Accu: 81%  \tValid_Acc:29%  \tVal_kappa : -0.189  \n",
            "Epoch: 257 \tTraining Loss:  0.495 \tTrain_Accu: 79%  \tValid_Acc:26%  \tVal_kappa : -0.484  \n",
            "Epoch: 258 \tTraining Loss:  0.535 \tTrain_Accu: 76%  \tValid_Acc:30%  \tVal_kappa : -0.184  \n",
            "Epoch: 259 \tTraining Loss:  0.416 \tTrain_Accu: 82%  \tValid_Acc:33%  \tVal_kappa : -0.016  \n",
            "Epoch: 260 \tTraining Loss:  0.495 \tTrain_Accu: 79%  \tValid_Acc:29%  \tVal_kappa : 0.099  \n",
            "Epoch: 261 \tTraining Loss:  0.466 \tTrain_Accu: 83%  \tValid_Acc:27%  \tVal_kappa : -0.158  \n",
            "Epoch: 262 \tTraining Loss:  0.431 \tTrain_Accu: 83%  \tValid_Acc:34%  \tVal_kappa : -0.191  \n",
            "Epoch: 263 \tTraining Loss:  0.486 \tTrain_Accu: 78%  \tValid_Acc:30%  \tVal_kappa : -0.285  \n",
            "Epoch: 264 \tTraining Loss:  0.529 \tTrain_Accu: 78%  \tValid_Acc:17%  \tVal_kappa : 0.559  \n",
            "Epoch: 265 \tTraining Loss:  0.522 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : -0.022  \n",
            "Epoch: 266 \tTraining Loss:  0.438 \tTrain_Accu: 84%  \tValid_Acc:33%  \tVal_kappa : 0.280  \n",
            "Epoch: 267 \tTraining Loss:  0.498 \tTrain_Accu: 79%  \tValid_Acc:27%  \tVal_kappa : -0.236  \n",
            "Epoch: 268 \tTraining Loss:  0.456 \tTrain_Accu: 79%  \tValid_Acc:31%  \tVal_kappa : 0.310  \n",
            "Epoch: 269 \tTraining Loss:  0.485 \tTrain_Accu: 80%  \tValid_Acc:26%  \tVal_kappa : 0.280  \n",
            "Epoch: 270 \tTraining Loss:  0.508 \tTrain_Accu: 80%  \tValid_Acc:30%  \tVal_kappa : -0.116  \n",
            "Epoch: 271 \tTraining Loss:  0.483 \tTrain_Accu: 82%  \tValid_Acc:26%  \tVal_kappa : -0.318  \n",
            "Epoch: 272 \tTraining Loss:  0.411 \tTrain_Accu: 81%  \tValid_Acc:24%  \tVal_kappa : 0.060  \n",
            "Epoch: 273 \tTraining Loss:  0.494 \tTrain_Accu: 82%  \tValid_Acc:24%  \tVal_kappa : -0.355  \n",
            "Epoch: 274 \tTraining Loss:  0.439 \tTrain_Accu: 84%  \tValid_Acc:26%  \tVal_kappa : -0.067  \n",
            "Epoch: 275 \tTraining Loss:  0.539 \tTrain_Accu: 80%  \tValid_Acc:27%  \tVal_kappa : 0.290  \n",
            "Epoch: 276 \tTraining Loss:  0.426 \tTrain_Accu: 85%  \tValid_Acc:30%  \tVal_kappa : -0.330  \n",
            "Epoch: 277 \tTraining Loss:  0.535 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : -0.217  \n",
            "Epoch: 278 \tTraining Loss:  0.540 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : -0.140  \n",
            "Epoch: 279 \tTraining Loss:  0.552 \tTrain_Accu: 77%  \tValid_Acc:30%  \tVal_kappa : -0.120  \n",
            "Epoch: 280 \tTraining Loss:  0.513 \tTrain_Accu: 81%  \tValid_Acc:24%  \tVal_kappa : -0.038  \n",
            "Epoch: 281 \tTraining Loss:  0.423 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : -0.100  \n",
            "Epoch: 282 \tTraining Loss:  0.510 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : 0.138  \n",
            "Epoch: 283 \tTraining Loss:  0.527 \tTrain_Accu: 80%  \tValid_Acc:30%  \tVal_kappa : -0.473  \n",
            "Epoch: 284 \tTraining Loss:  0.507 \tTrain_Accu: 78%  \tValid_Acc:29%  \tVal_kappa : -0.224  \n",
            "Epoch: 285 \tTraining Loss:  0.528 \tTrain_Accu: 76%  \tValid_Acc:30%  \tVal_kappa : 0.310  \n",
            "Epoch: 286 \tTraining Loss:  0.474 \tTrain_Accu: 82%  \tValid_Acc:27%  \tVal_kappa : 0.043  \n",
            "Epoch: 287 \tTraining Loss:  0.516 \tTrain_Accu: 78%  \tValid_Acc:31%  \tVal_kappa : -0.127  \n",
            "Epoch: 288 \tTraining Loss:  0.505 \tTrain_Accu: 81%  \tValid_Acc:23%  \tVal_kappa : -0.562  \n",
            "Epoch: 289 \tTraining Loss:  0.432 \tTrain_Accu: 84%  \tValid_Acc:30%  \tVal_kappa : -0.039  \n",
            "Epoch: 290 \tTraining Loss:  0.474 \tTrain_Accu: 81%  \tValid_Acc:30%  \tVal_kappa : -0.142  \n",
            "Epoch: 291 \tTraining Loss:  0.511 \tTrain_Accu: 82%  \tValid_Acc:26%  \tVal_kappa : -0.417  \n",
            "Epoch: 292 \tTraining Loss:  0.424 \tTrain_Accu: 85%  \tValid_Acc:27%  \tVal_kappa : 0.245  \n",
            "Epoch: 293 \tTraining Loss:  0.504 \tTrain_Accu: 80%  \tValid_Acc:33%  \tVal_kappa : -0.303  \n",
            "Epoch: 294 \tTraining Loss:  0.539 \tTrain_Accu: 81%  \tValid_Acc:21%  \tVal_kappa : -0.171  \n",
            "Epoch: 295 \tTraining Loss:  0.448 \tTrain_Accu: 82%  \tValid_Acc:31%  \tVal_kappa : 0.021  \n",
            "Epoch: 296 \tTraining Loss:  0.562 \tTrain_Accu: 80%  \tValid_Acc:27%  \tVal_kappa : -0.275  \n",
            "Epoch: 297 \tTraining Loss:  0.499 \tTrain_Accu: 81%  \tValid_Acc:23%  \tVal_kappa : 0.182  \n",
            "Epoch: 298 \tTraining Loss:  0.462 \tTrain_Accu: 83%  \tValid_Acc:27%  \tVal_kappa : -0.177  \n",
            "Epoch: 299 \tTraining Loss:  0.450 \tTrain_Accu: 83%  \tValid_Acc:27%  \tVal_kappa : -0.193  \n",
            "Epoch: 300 \tTraining Loss:  0.549 \tTrain_Accu: 79%  \tValid_Acc:29%  \tVal_kappa : -0.193  \n",
            "Epoch: 301 \tTraining Loss:  0.517 \tTrain_Accu: 81%  \tValid_Acc:26%  \tVal_kappa : -0.281  \n",
            "Epoch: 302 \tTraining Loss:  0.430 \tTrain_Accu: 83%  \tValid_Acc:26%  \tVal_kappa : -0.258  \n",
            "Epoch: 303 \tTraining Loss:  0.461 \tTrain_Accu: 80%  \tValid_Acc:27%  \tVal_kappa : 0.323  \n",
            "Epoch: 304 \tTraining Loss:  0.444 \tTrain_Accu: 86%  \tValid_Acc:33%  \tVal_kappa : -0.116  \n",
            "Epoch: 305 \tTraining Loss:  0.429 \tTrain_Accu: 84%  \tValid_Acc:33%  \tVal_kappa : -0.140  \n",
            "Epoch: 306 \tTraining Loss:  0.475 \tTrain_Accu: 82%  \tValid_Acc:26%  \tVal_kappa : 0.008  \n",
            "Epoch: 307 \tTraining Loss:  0.453 \tTrain_Accu: 81%  \tValid_Acc:20%  \tVal_kappa : -0.120  \n",
            "Epoch: 308 \tTraining Loss:  0.495 \tTrain_Accu: 80%  \tValid_Acc:26%  \tVal_kappa : -0.177  \n",
            "Epoch: 309 \tTraining Loss:  0.486 \tTrain_Accu: 79%  \tValid_Acc:26%  \tVal_kappa : -0.464  \n",
            "Epoch: 310 \tTraining Loss:  0.451 \tTrain_Accu: 83%  \tValid_Acc:27%  \tVal_kappa : -0.025  \n",
            "Epoch: 311 \tTraining Loss:  0.421 \tTrain_Accu: 84%  \tValid_Acc:26%  \tVal_kappa : -0.330  \n",
            "Epoch: 312 \tTraining Loss:  0.415 \tTrain_Accu: 84%  \tValid_Acc:37%  \tVal_kappa : 0.254  \n",
            "Epoch: 313 \tTraining Loss:  0.413 \tTrain_Accu: 86%  \tValid_Acc:17%  \tVal_kappa : 0.018  \n",
            "Epoch: 314 \tTraining Loss:  0.481 \tTrain_Accu: 81%  \tValid_Acc:34%  \tVal_kappa : -0.294  \n",
            "Epoch: 315 \tTraining Loss:  0.393 \tTrain_Accu: 86%  \tValid_Acc:29%  \tVal_kappa : 0.167  \n",
            "Epoch: 316 \tTraining Loss:  0.434 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : -0.417  \n",
            "Epoch: 317 \tTraining Loss:  0.421 \tTrain_Accu: 84%  \tValid_Acc:23%  \tVal_kappa : -0.046  \n",
            "Epoch: 318 \tTraining Loss:  0.458 \tTrain_Accu: 82%  \tValid_Acc:29%  \tVal_kappa : -0.156  \n",
            "Epoch: 319 \tTraining Loss:  0.466 \tTrain_Accu: 79%  \tValid_Acc:20%  \tVal_kappa : 0.104  \n",
            "Epoch: 320 \tTraining Loss:  0.464 \tTrain_Accu: 84%  \tValid_Acc:30%  \tVal_kappa : -0.017  \n",
            "Epoch: 321 \tTraining Loss:  0.443 \tTrain_Accu: 80%  \tValid_Acc:30%  \tVal_kappa : 0.014  \n",
            "Epoch: 322 \tTraining Loss:  0.481 \tTrain_Accu: 83%  \tValid_Acc:31%  \tVal_kappa : -0.156  \n",
            "Epoch: 323 \tTraining Loss:  0.477 \tTrain_Accu: 81%  \tValid_Acc:33%  \tVal_kappa : -0.087  \n",
            "Epoch: 324 \tTraining Loss:  0.492 \tTrain_Accu: 82%  \tValid_Acc:30%  \tVal_kappa : -0.346  \n",
            "Epoch: 325 \tTraining Loss:  0.402 \tTrain_Accu: 85%  \tValid_Acc:26%  \tVal_kappa : 0.025  \n",
            "Epoch: 326 \tTraining Loss:  0.460 \tTrain_Accu: 81%  \tValid_Acc:23%  \tVal_kappa : 0.187  \n",
            "Epoch: 327 \tTraining Loss:  0.479 \tTrain_Accu: 81%  \tValid_Acc:29%  \tVal_kappa : -0.182  \n",
            "Epoch: 328 \tTraining Loss:  0.487 \tTrain_Accu: 81%  \tValid_Acc:21%  \tVal_kappa : -0.107  \n",
            "Epoch: 329 \tTraining Loss:  0.515 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : 0.028  \n",
            "Epoch: 330 \tTraining Loss:  0.457 \tTrain_Accu: 79%  \tValid_Acc:33%  \tVal_kappa : -0.444  \n",
            "Epoch: 331 \tTraining Loss:  0.480 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : 0.028  \n",
            "Epoch: 332 \tTraining Loss:  0.456 \tTrain_Accu: 85%  \tValid_Acc:30%  \tVal_kappa : 0.015  \n",
            "Epoch: 333 \tTraining Loss:  0.434 \tTrain_Accu: 83%  \tValid_Acc:29%  \tVal_kappa : -0.006  \n",
            "Epoch: 334 \tTraining Loss:  0.475 \tTrain_Accu: 82%  \tValid_Acc:29%  \tVal_kappa : 0.086  \n",
            "Epoch: 335 \tTraining Loss:  0.434 \tTrain_Accu: 83%  \tValid_Acc:21%  \tVal_kappa : 0.278  \n",
            "Epoch: 336 \tTraining Loss:  0.532 \tTrain_Accu: 78%  \tValid_Acc:29%  \tVal_kappa : -0.281  \n",
            "Epoch: 337 \tTraining Loss:  0.412 \tTrain_Accu: 84%  \tValid_Acc:23%  \tVal_kappa : -0.294  \n",
            "Epoch: 338 \tTraining Loss:  0.428 \tTrain_Accu: 84%  \tValid_Acc:23%  \tVal_kappa : 0.302  \n",
            "Epoch: 339 \tTraining Loss:  0.491 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : -0.429  \n",
            "Epoch: 340 \tTraining Loss:  0.422 \tTrain_Accu: 86%  \tValid_Acc:33%  \tVal_kappa : -0.281  \n",
            "Epoch: 341 \tTraining Loss:  0.467 \tTrain_Accu: 83%  \tValid_Acc:26%  \tVal_kappa : -0.218  \n",
            "Epoch: 342 \tTraining Loss:  0.442 \tTrain_Accu: 82%  \tValid_Acc:31%  \tVal_kappa : 0.141  \n",
            "Epoch: 343 \tTraining Loss:  0.357 \tTrain_Accu: 87%  \tValid_Acc:29%  \tVal_kappa : -0.164  \n",
            "Epoch: 344 \tTraining Loss:  0.452 \tTrain_Accu: 82%  \tValid_Acc:20%  \tVal_kappa : -0.109  \n",
            "Epoch: 345 \tTraining Loss:  0.510 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : -0.168  \n",
            "Epoch: 346 \tTraining Loss:  0.511 \tTrain_Accu: 78%  \tValid_Acc:36%  \tVal_kappa : -0.327  \n",
            "Epoch: 347 \tTraining Loss:  0.432 \tTrain_Accu: 82%  \tValid_Acc:30%  \tVal_kappa : -0.119  \n",
            "Epoch: 348 \tTraining Loss:  0.481 \tTrain_Accu: 84%  \tValid_Acc:33%  \tVal_kappa : -0.296  \n",
            "Epoch: 349 \tTraining Loss:  0.447 \tTrain_Accu: 83%  \tValid_Acc:17%  \tVal_kappa : -0.178  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 03:51:05,357]\u001b[0m Trial 1 finished with value: 35.7 and parameters: {}. Best is trial 1 with value: 35.7.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 350 \tTraining Loss:  0.434 \tTrain_Accu: 84%  \tValid_Acc:36%  \tVal_kappa : 0.009  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./optuna_valid_NNI_drop.torch']"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa2BhZBQtOdJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4Y-qnRstwrw"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "Z0_zFS1dtzAN",
        "outputId": "b98b2119-67f2-4459-d571-5fae03bb8954"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_temp_NNI[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_dropout(0.8)\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_NNI_temp_std_350.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 3, 4, 0, 4, 2, 3, 3, 2, 3, 4, 3, 3, 0, 2, 1, 0, 2, 2, 2, 2, 0, 0, 3,\n",
            "        0, 4, 4, 3, 1, 3, 4, 4, 3, 1, 4, 2, 3, 2, 1, 0, 2, 1, 1, 2, 2, 2, 2, 3,\n",
            "        1, 1, 1, 2, 3, 2, 1, 1, 0, 0, 3, 1, 0, 1, 4, 3, 2, 0, 2, 3, 1, 1])\n",
            "labels tensor([1, 3, 3, 4, 4, 4, 3, 3, 2, 2, 3, 3, 4, 3, 3, 3, 2, 3, 1, 2, 2, 3, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 1, 1, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 3, 3, 3, 3, 3, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 3, 4, 4])\n",
            "correct : 17\n",
            "test_Accuracy % : 24.3\n",
            "kappa -0.02443876101165099\n",
            "[[ 0  0  0  0  0]\n",
            " [ 0  1  2  0  1]\n",
            " [ 2  1  3  2  0]\n",
            " [ 2  3  5  7  2]\n",
            " [ 7 11  8  7  6]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAHECAYAAADh34REAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVxUVf8H8M8MiyDIJqu7ssjiRu6Z9bikRmiaPpYrpmblUpaWpj4ulaY9PdrCT0srRSTLSlHLfQs1E8sFARfcBWQTAdlh5v7+IEliHbx37p2Zz7vXvF7jnXPv/c7RDl/OuecclSAIAoiIiIhIdGq5AyAiIiIyVky0iIiIiCTCRIuIiIhIIky0iIiIiCTCRIuIiIhIIky0iIiIiCRiLncASlBYKncERERE+mOl55/+1oHTRbtWwZlQ0a6lD+zRIiIiIpIIe7SIiIhIWirT7ddhokVERETSUqnkjkA2pptiEhEREUmMPVpEREQkLQ4dEhEREUmEQ4dEREREJDb2aBEREZG0OHRIREREJBEOHRIRERGR2NijRURERNLi0CERERGRRDh0SERERERiY48WERERSYtDh0REREQS4dAhEREREYmNPVpEREQkLQ4dEhEREUmEQ4dEREREJDb2aBEREZG0OHRIREREJBETTrRM95sTERERSYw9WkRERCQttek+DM9Ei4iIiKTFoUMiIiIiEht7tIiIiEhaJryOFhMtA5GXl4uNG9bjwP59SEpMhJmZGi1btsLAoGcxevRYWFhayh2iwWMd6wfrWXqsY+mxjnUk49DhtWvXcPToUZw/fx6xsbG4ceMGBEHAp59+ikGDBtV47s6dO7F582ZcunQJWq0WrVu3xvDhwzFq1Cio1XX7TipBEAQxvoghKyyVO4KaJScnYdKEcUhOSgIAWFlbQ6vRoLi4GADg6+ePdV9vgJ29vZxhGjTWsX6wnqXHOpaeMdSxlZ67Waz7LxftWgUH5upUfunSpdi4cWOl47UlWkuWLMG3336LBg0aoGfPnjA3N8eJEyeQl5eHp59+Gp999lmdki0+o6VwpaWleH3aq0hOSoKLiwu+/Go9Tv5xFif/PIcVH6+CjY0NLl6Ix7y5b8sdqsFiHesH61l6rGPpsY7rSaUS76UjHx8fTJo0CatWrcL+/fvRrVu3Ws/Zu3cvvv32W7i4uGDHjh348ssv8X//93/Yt28fPD09sX//foSHh9fp/ky0FG7H9m1IuHwZAPC/Tz5Hj56PAwDUajUGPROE/yx6DwBwNOpXnPz9hGxxGjLWsX6wnqXHOpYe67ieVGrxXjr697//jXfeeQdBQUFo0aJFnc758ssvAQCzZ89Gq1atyo87Oztj8eLFAIB169ZBq9XWei0mWgq3c3skAKBrt+7o2Cmw0ueDgp5F02bNKpQl3bCO9YP1LD3WsfRYx/UkY4+WrlJSUhAXFwcLC4sqhxa7desGNzc3pKen4+zZs7Vej4mWghUUFODsmdMAgCd6P1llGZVKhV69egMATvx2XG+xGQvWsX6wnqXHOpYe69g0xMfHAwC8vb1hZWVVZZn27dsDAC5cuFDr9TjrUMGuX7ta3i3p5e1dbbkHn2VkpCM7Kwv2Dg56ic8YsI71g/UsPdax9FjHj0DEWYc5OTnIycmpdNzOzg52dnaPfP3ExEQAQJMmTaot4+HhUaFsTZhoKVhaWlr5e1dXt2rLubr9/Vlaehr/p9YB61g/WM/SYx1Lj3X8CEQc8gsLC0NoaGil49OnT8eMGTMe+fr5+fkAAGtr62rL2NjYAADy8vJqvZ7RJFq//vor7t27h6FDh8odimjyH/oLtLKq/i/84c/y6/CXTn9jHesH61l6rGPpsY6VISQkBMOGDat0XIzeLCkYTaK1evVqxMTEGFWiRUREZBREHDoUa4iwOg0bNgRQ9kxedR70ZD3o2aqJ0SRaxqjhQ3+BhYXV/4U//FnDOvyl099Yx/rBepYe61h6rONHYEBb8DRt2hQAkJycXG2ZlJSUCmVrwlmHCubq6lr+Pi0ttdpyaal/f+bq4lptOaqMdawfrGfpsY6lxzo2Df7+/gCAhIQEFBYWVlnm/PnzAAA/P79ar6e4Hq1XX321Xuddv35d5Ejk17qNJ9RqNbRaLa4kJOCJ3k9VWe5KQgIAwNnZhQ9d6oh1rB+sZ+mxjqXHOn4EMu51qCsPDw8EBAQgLi4Oe/bsqfRIUnR0NFJSUuDi4oLAwMprqf2T4r75kSNH8Ouvv+LIkSM6vaqa6mnorK2t0SnwMQDA8WNHqywjCAJ+++0YAKDn4730FpuxYB3rB+tZeqxj6bGOH4GMK8PXx5QpUwAAH3/8MW7evFl+/O7du1iyZAkA4OWXX67TXoeK69GytrZGYWEhlixZAksddj9fvXp1ndazMDSDnxuK03/+gVPRJxETcw4dOnSs8Pm+vbuRePt2eVnSHetYP1jP0mMdS491bHji4uLKkyMAuHLlCgBg1apV+Oabb8qPb9mypfz9oEGDMGrUKGzevBmDBw/G448/Xr6pdG5uLvr374+xY8fW6f4qQRAEkb6LKEaNGoWzZ89iy5Yt5Suv1sULL7yAmJiYOq3S+k+FpTqfojelpaV48d/DkHD5Mlzd3PDBshXo3qMntFotDuzfiyULFyA3NxdP9H4S//fFOrnDNUisY/1gPUuPdSw9Y6ljKz13s1gPWSPatQp2vKZT+ZMnT2L8+PG1lrt06VKlYzt37kRERAQuX74MrVaLNm3aYPjw4Rg1alSderMABSZay5YtQ3h4OBYtWoQXX3yxzucZa6IFAElJiZj80ngkJyUBAKysrSFotSgqKgIA+Pr5Y93XG2Bnby9nmAaNdawfrGfpsY6lZwx1rPdE67kvRbtWwfZXRLuWPihu6LB9+/YQBAGxsbE6nefs7Fy+JL6xadq0GX7ctgNh67/BwQP7kZSYCDNzc3h6eWFQUDBGjx4LCx2GWaky1rF+sJ6lxzqWHuuYdKG4Hq2CggLcvHkTNjY2aN68uV7uqfQeLSIiIjHpvUdr6FrRrlUQOUW0a+mD4nq0rK2t4evrK3cYREREJBYDWt5BbIpLtKojCAKysrKg0Whgb28PCwsLuUMiIiIiqpGiE62srCxERETg0KFDuHTpEjQaDQBArVajTZs26Nu3L8aMGVNhtV4iIiJSGAPagkdsintG64H9+/dj/vz5uH//PqoLUaVSwcrKCgsWLMDw4cPLjwuCgAsXLpQvo18bPqNFRESmRN/PaDUc/k3theoo/6eJol1LHxTZo7V7927MmjULWq0WPj4+GDp0KNq3b4/GjRtDEARkZmYiJiYGkZGRSEhIwIIFC6DRaDBy5EiUlJRg9uzZ8Pb2rnOiRURERCQFxfVoZWZmon///igsLMS7776LcePG1Vg+LCwMK1asgIWFBbZu3Yrly5fj2LFjmD59OqZNm1ane7JHi4iITIm+e7RsRqwX7Vp5P74k2rX0QXE9WuHh4cjPz8esWbNqTbIAICQkBEVFRVi5ciVGjBiBgoICtGzZEiNGjNBDtERERFQr031ES3mbSkdFRcHBwQETJ9Z9DHbixImwt7dHQUEBvL29ERERATc3NwmjJCIiIqqd4hKtxMREdOrUCWZmZnU+x9zcHIGBgVCpVAgPD4ezs7OEERIREZEuVCqVaC9Do7ihw/z8fNjY2Oh8no2NDczMzODg4CBBVERERFRfhpggiUVxPVqOjo5I+mujTl0kJyfDyclJgoiIiIiI6kdxiVZAQADOnz+P5OTkOp+TlJSEmJgYBAQESBgZERER1YcpDx0qLtEKCgqCRqPBvHnzUFxcXGv54uJizJs3D1qtFkFBQXqIkIiIiHTBREtBgoOD4e/vj5MnT2LcuHGIj4+vtmxsbCzGjh2L6Oho+Pn5ITg4WI+REhEREdVMcQuWAkBKSgpGjx6N5ORkqFQqeHl5oUOHDuWzCTMyMnDu3DlcvXoVgiDAw8MDmzdvhru7e73uxwVLiYjIlOh7wVL70eGiXSv729rX2FQSRSZaAJCdnY0lS5Zgz5490Gq1ACrOWhAEAWq1GgMHDsTChQvh6OhY73sx0SIiIlOi70TLYcwm0a6VFTFWtGvpg2ITrQdu376Nw4cPIy4uDpmZmQDKZiYGBASgT58+aNGixSPfg4kWERGZEiZa+qO4dbT+qXnz5hg/frzcYRAREVE9GeJD7GJRfKJFREREhs2UEy3FzTokIiIiMhbs0SIiIiJJmXKPFhMtIiIikpbp5lkcOiQiIiKSCnu0iIiISFIcOiQiIiKSiCknWhw6JCIiIpIIe7SIiIhIUqbco8VEi4iIiKRlunkWhw6JiIiIpMIeLdKLzNxiuUMwepl5rGOpebnZyh2C0WNboR9NHCz1ej8OHRJJiA0nEZFpM+VEi0OHRERERBJhjxYRERFJypR7tJhoERERkaRMOdHi0CERERGRRNijRURERNIy3Q4tJlpEREQkLQ4dEhEREZHo2KNFREREkjLlHi0mWkRERCQpJlpEREREUjHdPIvPaBERERFJhT1aREREJCkOHRIRERFJxJQTLQ4dEhEREUmEPVpEREQkKVPu0WKiRURERJIy5USLQ4dEREREEmGPFhEREUnLdDu0mGgRERGRtEx56JCJFhERERm1lJQUrFu3DseOHcOdO3cgCAI8PDzQo0cPvPzyy2jevLlk9+YzWkRERCQplUol2ktX8fHxGDx4MDZt2oTCwkI88cQT6N27NwoLC/H9999jyJAhOH36tATfugx7tIiIiEhSco4cvvfee8jJycHIkSOxcOFCWFhYAABKSkqwaNEi/PTTT1i8eDF27Nghyf3Zo0VERERGqaioCGfOnAEAzJgxozzJAgALCwvMnDkTAHDp0iUUFBRIEgN7tIiIiEhScj0Mr1arYW5ujtLS0hrLNWzYEFZWVtLEIMlViYiIiP6iUon30oWFhQV69OgBAPj8889RUlJS/llJSQk+/fRTAMDw4cMlSwbZo0VERERGa/HixZg8eTK2bNmCqKgotGvXDgBw/vx55OTkICQkBG+//bZk92eiZSDy8nKxccN6HNi/D0mJiTAzU6Nly1YYGPQsRo8eCwtLS7lDNFiFhQU4d/oPXL4Yj4RLF3D5YjxSU+4AAEImv4YJL0+VOULjcD87C6d+i8L5M9G4lnAR6al3oNFoYGfvCM+2fugzIBjde/eVO0yjwPZCOmwv6kfM3qKcnBzk5ORUOm5nZwc7O7tKx5s3b47Nmzdjzpw5iIqKQkpKSvln7dq1Q5cuXSo8uyU2JloGIDk5CZMmjENyUhIAwMraGsXFxYiLi0VcXCx2/bwT677eADt7e5kjNUwX42Ix9002jlKbNGIANBpN+Z8tLRvA3MwcmRlpyMxIw6njvyKwWy+8vXgFGlhZyxipYWN7IS22F/Uj5qhcWFgYQkNDKx2fPn06ZsyYUen46dOnMWPGDNja2mL16tUIDAwsP75ixQrMmDEDM2bMwPTp08UL8iFMtBSutLQUr097FclJSXBxccEHH36EHj0fh1arxb69e/DeogW4eCEe8+a+jdA1a+UO12A1srODd1s/eLf1h09bP/zfJx8h826G3GEZFY1GA2/fAPxr4GB06toT7k2aAQDSUpLx46avcHDXdpyJPo4vVi7DG/Pelzlaw8T2Qj/YXsgrJCQEw4YNq3S8qt6snJwcTJs2DQUFBfjuu+8qLEzav39/eHt7Y8iQIVizZg2Cg4PRqlUr0eNloqVwO7ZvQ8LlywCA/33yOTp2KsvE1Wo1Bj0TBEGrxdx3ZuFo1K84+fsJdO/RU85wDVL7To9hx/7jFY6tXf2JTNEYr8X/+wLtA7tWOu7q3gRTZy+EmZk59u38CVEHdmHM5GlwdnWXIUrDxvZCemwv6ketFq9Lq7ohwqocOXIEmZmZ6NGjR5Wrv7ds2RIdOnRAdHQ0oqOjJUm0OOtQ4XZujwQAdO3WvbzRfNigoGfRtFmzCmVJN2ZmZnKHYBKqSrIe1u+Z58rfX70UL3U4RonthfTYXtSPXLMO79wpe36uUaNG1ZZ5kLRlZWXV+/vVhImWghUUFODsmbJtAZ7o/WSVZVQqFXr16g0AOPHb8SrLEBmChx/Q1mq1MkZimNheEFXm6uoKAIiLi6uwtMMDJSUliIuLAwA0++uXELEx0VKw69eulv/A8fL2rrbcg88yMtKRLVFGTiS1uLN/lr9v0dpLxkgME9sLUjK59jp88sknYW1tjeTkZHz44YcoLi4u/6y4uBgffPAB7ty5A3t7e/Tu3Vvsrw2Az2gpWlpaWvl7V1e3asu5uv39WVp6GuwdHCSNi0hsebn3sXXzegCAX/tANG3RSt6ADBDbC1IyufY6bNy4MRYtWoT58+cjIiIC+/fvR0BAAAAgNjYW6enpsLS0xLJly2ocXnwUik60SktLkZWVBXt7+1rXuMjKykJ+fj6aNGmip+ikl5+XV/7eqobp7g9/9vA5RIZAq9Xi02X/wb27GbC0bIDJr8+ROySDxPaCqGrDhg2Dj48PwsLC8Mcff+D48bJhczc3N4wYMQIvvfQSvLyk60VXZKKVk5ODDz/8ELt370ZRUREsLCzQp08fvPnmm9XOCFixYgW2b9+O+Hg+REtkSL4J/Rh//n4UADD5jTlo5Vn9sBcRGSa59jp8ICAgAB999JEs91bcM1rFxcWYMGECIiMjUVhYCEEQUFxcjL1792LYsGH4+eefqz1XEAQ9Riq9hjY25e8LC6vfVfzhzx4+h0jpwtaswu7I7wEAL02dVWHmIemG7QUpmVzPaCmB4hKtzZs3Iz4+Hl5eXoiIiMCZM2cQGRmJZ555BgUFBXjnnXcQEREhd5h68WC2BACkpaVWWy4t9e/PXF1cqy1HpCQbv/wUO37YBAAIeXUmgkeMljkiw8b2gkiZFJdo7d69G1ZWVvjyyy/RuXNnWFtbw9fXF6tWrcKyZctgZmaGDz74AOvXr5c7VMm1buMJtbrsr+hKQkK15R585uzswgdbySCEffEJtn+/EQAwbsobGDJynMwRGT62F6Rkcq2jpQSKS7SuXLmCTp06VflQ+/PPP4+1a9fCysoKH330EdauNe4tJKytrdEp8DEAwPFjR6ssIwgCfvvtGACg5+O99BYbUX2FrVmFHVvCAZQlWUNfHC9zRMaB7QUpGYcOFaSwsBCNGzeu9vOePXti3bp1sLa2xqpVq7B69Wo9Rqd/g58bCgA4FX0SMTHnKn2+b+9uJN6+XaEskVKFrVlVYbiQSZa42F4QKY/iEi0HBwekplb/fAEAdOnSBV999RWsra3x+eef4/PPP9dTdPo35Llh8PbxgSAImDVzBk7+fgIA/tokdjfeW/QfAGUrQXPfsvq7n5ON7Kx75S/hr4UfCwsLKxwvyM+XOVLD9fAzWRNee4vDhRJge6EfbC90Z8pDhypBYVP1Jk+ejD/++AMnTpyAtXX1a8EAwNmzZzF58mTk5eXBzs4OOTk5uHDhgs73LCytb7T6kZSUiMkvjUdyUhIAwMraGoJWi6KiIgCAr58/1n29AXb29nKGWa3M3OLaC8nsxaEDkXonudZyA58dgrkLl+ohIt1l5im3ntNT7+DVUcEAyjY4trN3rLH8kJFj8dwLyuvt8nKzlTuEWrG9kJ4xtBdNHCxrLySizu8fFu1af/6nj2jX0gfF9Wg98cQTKCoqwp49e2ot26lTJ3zzzTewtbVFdna2HqKTR9OmzfDjth145bVp8PL2gQoqmJubwz8gAG+9PQebvv1esY0mEVBx6RWtVouse3drfBUWVL88AdWM7QWRsiiuR+v69esICQmBp6dnnWcWnj9/HpMmTcL9+/eNskfL0BnCb6jGQMk9WsbCEHq0DB3bC/3Qd49Wlw/E69H6Y4Fh9WgpbmX41q1bIyoqSqdz2rdvj+joaIkiIiIiokdhiLMFxaK4RKs6giAgKysLGo2mTnsfEhEREclN0YlWVlYWIiIicOjQIVy6dAkajQZA2cO0bdq0Qd++fTFmzJgKKyITERGRsphwh5byHoZ/YP/+/RgwYABCQ0MRFxeH0tJSCIIAQRCg0WiQkJCAtWvXYuDAgfjpp58qnCsIAjeXJiIiUghTXrBUkT1au3fvxqxZs6DVauHj44OhQ4eiffv2aNy4MQRBQGZmJmJiYhAZGYmEhAQsWLAAGo0GI0eORElJCWbPng1vb2/4+/vL/VWIiIjIhCku0crMzMT8+fMBAPPnz8e4cZUXNfT09ETXrl0xadIkhIWFYcWKFVi6dCk6d+6M5cuX49ixY/Dx8dF36ERERFQFA+yIEo3iEq3w8HDk5+dj1qxZVSZZ/xQSEoKioiKsXLkSI0aMQEFBAVq2bIkRI0boIVoiIiKqjSEO+YlFcc9oRUVFwcHBARMnTqzzORMnToS9vT0KCgrg7e2NiIgIuLm5SRglERERUe0Ul2glJiaiU6dOMDMzq/M55ubmCAwMhEqlQnh4OJydnSWMkIiIiHRhynsdKm7oMD8/HzY2NjqfZ2NjAzMzMzg4OEgQFREREdUXhw4VxNHREUl/bYaqi+TkZDg5OUkQEREREVH9KC7RCggIwPnz55GcXPvO6A8kJSUhJiYGAQEBEkZGRERE9WHKQ4eKS7SCgoKg0Wgwb948FBfXvrlocXEx5s2bB61Wi6CgID1ESERERLow5QVLFZdoBQcHw9/fHydPnsS4ceNqXOE9NjYWY8eORXR0NPz8/BAcHKzHSImIiIhqpriH4VUqFVavXo3Ro0fj3LlzGD58OLy8vNChQ4fy2YQZGRk4d+4crl69CkEQ4OHhgdWrVxtkpktERGTsTPnns+ISLQBwd3fHtm3bsGTJEuzZswcJCQlISEio8BclCALUajUGDRqEhQsXwtHRUcaIiYiIqDomnGcpM9ECAHt7e6xcuRJvvvkmDh8+jLi4OGRmZgIom5kYEBCAPn36oEWLFjJHSkRERFQ1xSZaDzRv3hzjx4+XOwwiIiKqJw4dEhEREUnEhPMsJlpEREQkLVPu0VLc8g5ERERExoI9WkRERCQpE+7QYqJFRERE0lKbcKbFoUMiIiIiibBHi4iIiCRlwh1aTLSIiIhIWpx1SERERESiY48WERERSUptuh1aTLSIiIhIWqY8dMhEC8CV1Fy5QzB6TjaWcodg9DJyi+UOwQSwrdAHLzdbuUMgEg0TLZIckywiqismWcbJhDu0mGgRERGRtFQw3UyLsw6JiIiIJMIeLSIiIpIUZx0SERERSYSzDqvg5+cnyg1UKhXi4+NFuRYRERGRIak20RIEQZQbiHUdIiIiMkwm3KFVfaJ18OBBfcZBRERERkptwplWtYlW06ZN9RkHERERkdHhw/BEREQkKRPu0GKiRURERNLirMN6SE5OxpkzZ5CWlob8/PwaH3qfPn16fW9DREREZLB0TrRSU1OxaNEiREVF1TqjUBAEqFQqJlpEREQmzIQ7tHRLtO7fv49x48bh9u3bcHR0RGBgIA4ePAgrKysMGDAAd+/exdmzZ5GXlwdHR0f861//kihsIiIiMhRKmHVYWFiI8PBw7NmzBzdv3kRJSQkaN26Mdu3aISQkBJ07d5bkvjolWhs2bMCtW7fQoUMHfPXVV7Czs4Ovry9sbW3x0UcfAQAKCgqwZs0arF27Fubm5nj//fclCZyIiIioLm7fvo1Jkybh5s2bcHFxQffu3WFmZobk5GQcPHgQvr6+yki0Dh06BJVKhXfeeQd2dnZVlrG2tsZbb72FkpISbNiwAV27dsWQIUNECZaIiIgMj5z9Wfn5+Zg4cSJu376NWbNmYdKkSTAzMyv//N69e8jKypLs/mpdCt+6dQtqtRqBgYEVjpeUlFQq+/LLLwMAfvjhh0cIj4iIiAydSqUS7aWrNWvW4NatWxgzZgymTJlSIckCAEdHR7Ru3Vqsr1qJTomWRqNBo0aNKgRpbW2NvLy8Sg/GOzk5wc7ODpcvXxYnUiIiIiIdFBcXY8uWLQCACRMmyBKDTkOHbm5uuHPnToVj7u7uuHHjBq5duwZPT8/y44WFhcjJyYGFhYU4kRIREZFBUss0dhgXF4esrCy4ubmhefPmiIuLw/79+5GZmYnGjRujV69e6NKli6Qx6NSj1bx5c5SUlODWrVvlxzp16gQA+O677yqU3bhxIwRBQIsWLUQIk4iIiAyVXEOHD0bV3NzcsGLFCjz//PNYs2YNvv/+e6xevRpjxozBtGnTkJ+fL8XXBqBjj1bPnj1x7NgxHD16FGPGjAEAjBo1CpGRkdi0aRNu3rwJPz8/XLp0Cb/++itUKhWGDh0qSeBERERkenJycpCTk1PpuJ2dXaWJetnZ2QCACxcuICYmBiEhIRg7diwcHBxw6tQpLFmyBAcOHMCSJUuwYsUKSeLVKdEKDg7GuXPncPfu3fJjHTp0wOzZs/G///0PUVFROHr0aPnzWgMGDMDEiRPFjZiIiIgMipjLaIWFhSE0NLTS8enTp2PGjBkVjmm1WgBlk/aGDBmCefPmlX/Wr18/uLq64t///je2b9+OadOmSTIKp/MzWp999lml45MmTcJTTz2FvXv3IjU1Fba2tujVqxd69eolWqBERERkmMTc6zAkJATDhg2rdLyqZadsbGzK348cObLS5+3bt0dAQABiY2MRHR0tf6JVEy8vL3h5eYl1OSIiIqJKqhoirE6zZs2qfP/PMrGxscjIyBAlvn/S6WF4IiIiIl2pVeK9dOHv71/+vrpFSe/duwcAaNiwYb2/X02YaBEREZGk5Jp16Obmho4dOwIATpw4Uenz7OxsxMfHAwDatWv36F+0CjoNHY4fP17nG6hUKoSFhel8HhEREdGjevXVV/Haa6/hyy+/RNeuXdG+fXsAQFFRERYvXoz79+8jICCg0q43YtEp0YqOjq5TuQcZpyAIoj4AZ4ruZ2fh1G9ROH8mGtcSLiI99Q40Gg3s7B3h2dYPfQYEo3vvvnKHadAKCwtw7vQfuHwxHgmXLuDyxXikppQtzBsy+TVMeHmqzBEah1tXL+Fc9DHcunoRqUm3kJuThYL8PFg3tIF705Zo1+VxPPXMMNg0spc7VIPF9kJ/8vJysXHDehzYvw9JiYkwM1OjZctWGBj0LDZAgrYAACAASURBVEaPHgsLS0u5Q1QUOTOBvn37YuLEifjmm28watQodOzYEQ4ODoiJiUFaWhrc3NywcuVKyfIVlfDPvXNqsG3btho/v3//Ps6fP499+/bBysoKM2bMgI2NTZWzA5QkNilX7hCqNfLpbtBoNOV/trRsALVajcLCgvJjgd164e3FK9DAylqOEGvlZKPsBufsn6fw5tSqlyExpETrcqpy/x0DwOYvPsaRXT+V/9nC0hJmZuYoLPh7oUBbOwdMXfARPH3byxFirZxtlf1v2RjaCy83W7lDqFVychImTRiH5KQkAICVtTW0Gg2Ki4sBAL5+/lj39QbY2Sv3lwYr0abC1c3k72NFu9ZXL9RviG/fvn3YtGkTLly4gIKCAjRp0gR9+/bFlClT4OTkJFp8/6RTolVXN2/exMSJE2Fvb4/NmzejQYMGYt9CVEpOtIb37Qxv3wD8a+BgdOraE+5NymZNpKUk48dNX+Hgru0AgCf7B+GNee/LGWq1DCHRWjh3Jrzb+sG7rT982vrh/z75CJl3M5hoiejEoV24n30PXn4d4d6sJRraNgIAFBbk48yJI/hpfSjuZ99DI3tHvP/FFljbKO8HrtITLWNoL5SeaJWWluLFfw9DwuXLcHFxwQcffoQePR+HVqvFvr178N6iBcjLy0PvJ59C6Jq1codbLVNMtORitnjx4sViX9TBwQGenp74+uuvoVar0b17d7FvIaq0+8Vyh1At/w6PYczk6fDyDYBto7+ns9rYNkLXx59CVuZdXL18ATevJaDfM8+hoQJ/OFlbmtVeSEYubu4YEzIZA4OGoEv3nmjt6Y1tP2xGXu59dHqsKzp17ip3iHVyN0+5/44BoHlrb3j6dYCjsyssLP/+5cvcwgLNW3ujWWsvnDyyB8VFhWjS0hPNWilvuZiGCv+3bAzthZPCk9nIbT9h648/AAC+WPcNunTtBqDskRkvb280adIUB/bvw62bN/FY5y5o1qy5nOFWy1zPU+F2xqdBpYIoryEBrvoN/hFJVtW9evVCgwYN8Msvv0h1C5PQPrDmH/L9nnmu/P3VS/FSh2OUzMyU/cPTVLRu+/dvqffupskYieFieyG9ndsjAQBdu3VHx06VH54eFPQsmv61XtODsiTfrEMlkDSnVavVSElJkfIWJu/hBy4fbDVAZIiuxJ0tf+/i3lTGSIwX24tHU1BQgLNnTgMAnuj9ZJVlVCoVevXqDQA48dtxvcVGyiXZKO3p06dRUFCAxo0bS3ULAhB39s/y9y1aK2+ohagmJSXFyM68i/OnjmHHt+sAAK4ezdCh2xMyR2ac2F48muvXrpYnqF7e3tWWe/BZRkY6srOyYO/goJf4lMwAO6JEI3qiVVpaisOHD+PDDz+ESqVCz549xb4F/SUv9z62bl4PAPBrH4imLVrJGxBRHU0b/hRKSyo/U+bp1wGTZy+BhYWyn9MxRGwvHl1a2t9D2q6ubtWWc3X7+7O09DQmWgDUJpxp6ZRo9evXr8bPi4qKkJmZCUEQIAgCHB0d8cYbb9Q7uJKSEpiZmUGtrjjCmZ6ejmPHjuHu3bto1aoVevfurfiZjWLTarX4dNl/cO9uBiwtG2Dy63PkDomozuwdnVBSXIyiwgIU/bX0QNv2nfH8hGlwcnGXOTrjw/ZCHPl5eeXvrWpYHuPhzx4+h0yTTolW0l9rhtTG0tIS/fr1w1tvvYXmzXWfcXHt2jUsWrQIf/75J8zMzPDUU09h0aJFcHFxwb59+/Duu+8iP//vtXc8PDwQGhpaYU8jY/dN6Mf48/ejAIDJb8xBK8/qu7GJlGbZV3+vyZeTlYmTh/dg1w8bsHz2JASNnIAhY6bIGJ3xYXtBcjPhDi3dEq2NGzfW+LmZmRns7OzQqlUrWFhY1CugzMxMjBs3Dnfv3gVQ9pvYgQMHkJ6ejv/973945513YG5ujqeeegpOTk74448/cOvWLbzyyivYvXs3bG2VN11ZbGFrVmF35PcAgJemzqowk4jI0Ng5OOHpYaPhFdARK96Zgl++X49WPv7o0JXPaYmB7YV4GtrYlL9/eBHYf3r4s4fPMWWGOFtQLDolWt26dZMqjnLr16/H3bt3ERQUhHfeeQdmZmb45JNPsHXrVixcuBDOzs7YsGEDmv01fVaj0eDdd9/Fzp078d1332Hy5MmSxyinjV9+ih0/bAIAhLw6E8EjRsscEZE4WvsEwMuvAxLizuLo3u1MtETA9kJcrq5/r9+UlpYKn7a+VZZLS039+xwXw1rzicSn0/IOycnJSH3oH1BtUlNTkZycrFNAv/76K+zt7bFs2TK4u7vDxcUFixcvhpOTE06cOIE33nijPMkCynrR5s6diwYNGuDw4cM63cvQhH3xCbZ/X9arOG7KGxgycpzMERGJy6GxCwAg/U6izJEYPrYX4mvdxrP8meErCQnVlnvwmbOzCx+E/4taxJeh0Snmvn37YsSIEXUuP2rUKPTv31+ngG7fvo327dvDysqq/JiFhUX5bttV9ao5OTnB398f165d0+lehiRszSrs2BIOoKzRHPrieJkjIhJfRkrZL2YNrBvKHIlhY3shDWtra3QKfAwAcPzY0SrLCIKA3347BgDo+XgvvcWmdFywVAe6bo2oa/nS0lLYV7ERp6OjIwDAza3qKbXu7u64f/++TvcyFGFrVlXo/mejSYZGq9HU2hZcOHcKNxLKViv3afeYPsIySmwvpDX4uaEAgFPRJxETc67S5/v27kbi7dsVypJpk7QXrrCwUOftTRwcHHDv3r1Kx2trpDUaDRo2NL7fgh9+xmLCa2+x+18i93OykZ11r/wl/LUoYWFhYYXjBQ/NdqW6y8xIwwczQxC1ZxvSU5Iq/P+cmZ6KPT9uxJqlcyAIAmwa2aH/cy/KGK3hYnshvSHPDYO3jw8EQcCsmTNw8vcTAPDXptK78d6i/wAoWzm+ew+uI/mAWiXey9CoBB26nHx9feHs7Ixjx47VWvbmzZsYNGgQ3N3ddXp2auTIkcjMzMSBAwcqXS8jIwOdO3eu8rznn38eBQUF2L17d53v9UBsUq7O5+hDeuodvDoqGEDZdkZ29o41lh8yciyee0F5v7062Sh/8ckXhw5E6p3anycc+OwQzF24VA8R6e5yqjL/HQNARuodzH/5+fI/m5tbwKqhDUqKi8rX0QIAZ7cmeGXuMrTwbCtHmLVyVvCGx8bSXni5KX/meFJSIia/NB7Jfy15ZGVtDUGrRVFREQDA188f677eALsqRmeUwkqyfWGq9taOi6Jda+WQqichKFWNVX3gwAEcPHiwwrHc3Fy8++67NV40JycHf/5ZttVD9+7ddQrIz88PW7ZsQUpKCtzd/164sGXLlmjZsmWV59y7dw+XLl3CwIEDdbqX0j2cA2u1WmTdu1tj+cKC6qcbE8nJwckZU+YsxeXzp3H9cjyyM9ORm5MNlVoNJxd3NGvthY7deqPbUwNg2cCq9gtSJWwv9Kdp02b4cdsOhK3/BgcP7EdSYiLMzM3h6eWFQUHBGD16bIV9JYnLO1Tr4sWL2LZtW4VjhYWFlY5Vp0WLFjqvDD906FA4OjqiQIdG4IcffoBGo0GXLl10upfSubo3wU+H/qy9ID2y7yL3yh2CUTO3sEDnXn3RuVdfuUMxWmwv9MvGxhZTp7+OqdNflzsUUrgahw6jo6MRHR1d/ufQ0FA0bNgQEydOrP6CKhVsbW3h7e2Nbt26wdxcz/2T9aDUoUNjYQhDh8ZAyUOHxkLJQ4fGwhCGDo2BvocO3/75kmjX+m+wMh8tqE6NVd2tW7cKyyk8SLSmT58ueWD/JAgCsrKyoNFoYG9vX++V54mIiEi/THjkULeV4Q8ePKjzLMJHkZWVhYiICBw6dAiXLl2CRqMBUPagZ5s2bdC3b1+MGTOmwmq9REREREqhU6LVtGlTqeKoZP/+/Zg/fz7u379faWkHjUaDhIQEXLlyBRs3bsSCBQswfPjw8s8FQcCFCxdMapNpIiIipVKbcJeWTolWXFwcVqxYgYCAAMyZM6fGsh988AEuX76MefPmwddXt6mYu3fvxqxZs6DVauHj44OhQ4eiffv2aNy4MQRBQGZmJmJiYhAZGYmEhAQsWLAAGo0GI0eORElJCWbPng1vb28mWkRERApgiFvniEWn775t2zacOnUKAQEBtZb18fFBdHQ0IiMjdQooMzMT8+fPBwDMnz8fO3bswMSJE9G1a1e0adMGnp6e6Nq1KyZNmoSdO3fi3XffhUqlwtKlS3H16lVMnToV+/btM+mppERERKQMOiVaJ0+eBAA8+eSTtZZ9sKbV77//rlNA4eHhyM/Px5tvvolx42pf1TgkJAQzZ85EUVERRowYgaNHj6JFixY67clIRERE0lGpxHsZGp0SrZSUFNjZ2cHOzq7Wsvb29rCzs8OdO3d0CigqKgoODg41LiHxTxMnToS9vT0KCgrg7e2NiIiIavdEJCIiIv1Sq1SivQyNTolWSUkJSkpK6ly+tLQUhYWFOgWUmJiITp066TS70dzcHIGBgVCpVAgPD4ezs7NO9yQiIiKSgk6JlpubGwoKCnDt2rVay167dg35+flwcXHRKaD8/HzY2NjodA4A2NjYwMzMDA4ODjqfS0RERNLh0GEdde/eHYIg4PPPP6+17GeffQaVSqXzXoeOjo5I+mujTl0kJyfDyclJ5/OIiIhIWmqVeC9Do1OiFRISAjMzM+zZswdvv/020tLSKpVJS0vD7NmzsWfPHqjVaoSEhOgUUEBAAM6fP4/k5OQ6n5OUlISYmJg6zYYkIiIi0hed1tHy9PTE3LlzsXTpUvz888/YvXs32rZtiyZNmgAoS3guX75cvoL722+/DR8fH50CCgoKwuHDhzFv3jysXbsWlrXsgF5cXIx58+ZBq9UiKChIp3sRERGR9AzxIXax6LyG2Lhx47Bq1Sq4uLigtLQUcXFx2L9/P/bv34/4+HiUlpbC1dUVK1euxIQJE3QOKDg4GP7+/jh58iTGjRuH+Pj4asvGxsZi7NixiI6Ohp+fH4KDg3W+HxEREUnLlJ/RUgn/3N+mjkpLS3HixAmcO3cOGRkZAABnZ2d07NgRPXv2hLl5WWdZbm4ubG112409JSUFo0ePRnJyMlQqFby8vNChQ4fy2YQZGRk4d+4crl69CkEQ4OHhgc2bN8Pd3b0+XwWxSbn1Oo/qxsmm5l5JEsflVP47lpqzLf8tS83LTbefF1Q/VjqNZz269w9cEe1a/+nvJdq19KHeiVZNBEHA0aNHERkZicOHD+PMmTM6XyM7OxtLlizBnj17oNVqy4J9KJUVBAFqtRoDBw7EwoUL4ejoWO94mWhJi4mWfjDRkh4TLekx0dIPfSdaSw+Kl2jN72dYiZaoVZ2QkIBt27Zh586dyMjIgCAI9d4Kx97eHitXrsSbb76Jw4cPIy4uDpmZmQDKZiYGBASgT58+aNGihZhfgYiIiESmggGO+YnkkROte/fu4eeff8a2bdtw4cIFAGW9Tebm5ujRo0f5Vjz11bx5c4wfP/5RwyQiIiLSu3olWqWlpTh8+DC2bduGqKgoaDSa8t6rf/3rXxg0aBD69u2LRo0aiR0vERERGRhDXP9KLDolWufPn0dkZCR++eUXZGdnlydXXbp0walTpwAA//3vf3V++J2IiIiMFxOtGqSlpWH79u2IjIzEtWvX8ODZeR8fHwwePBjBwcHw8PCAr6+v5MESERERGZIaE61Jkybh999/h1arhSAIaNKkCZ599lkMHjxY54VIiYiIyDTVd2KcMagx0Tp+/DhUKhWCg4PxwgsvoEuXLvqKi4iIiIwEhw5rcfDgQQBAfn4+evXqBTMzM0mDIiIiIjIGNW7BExoain79+qG4uBg7d+7EK6+8gieeeALvv/8+Tp8+ra8YiYiIyICZ8hY8NfZo9e/fH/3796+wVlZ8fDwiIiLw7bffokmTJggODuYeg0RERFQtU95UWucteK5cuYKtW7di586dSE9PL3/A7cFSD9u3bze4B+W5BY+0uAWPfnALHulxCx7pcQse/dD3FjyfHL0u2rVm9m4t2rX0od57HWq1Whw/fhxbt27FoUOHUFRUVHZBlQq+vr54+umnMXDgQHh6eooasBSYaEmLiZZ+MNGSHhMt6THR0g99J1qfHRMv0Xr9CRNJtB6Wm5uLX375BZGRkeUbSD/o6WrdujV27dr1qLeQFBMtaTHR0g8mWtJjoiU9Jlr6oe9E6/Pj4iVaM3oZVqJV48PwdWVra4sXXngBmzdvxt69e/Hqq6/Cw8MDgiDg+nXxKpeIiIjIkIie07Zs2RIzZ87EzJkz8fvvv2P79u1i34IMDHta9OPQjbtyh2D0oi6kyx2C0Qv9dwe5QzAJ7Zrqt+dQDdN9GF7SzsMePXqgR48eUt6CiIiIFM6EJx2KM3RIRERERJXp+XE4IiIiMjXcgoeIiIhIIqa8YCmHDomIiIgkwkSLiIiIJKW0vQ5XrlyJtm3bom3btvj666/FuWg1OHRIREREklLS0GFMTAy++uorqFQqiLBme63Yo0VEREQmobi4GHPnzkXjxo3Rr18/vdyTiRYRERFJSilDh59++imuXr2KJUuWoFGjRuJ8uVow0SIiIiJJqUV81de5c+ewfv16BAcHo2/fvo9wJd0w0SIiIiKjVlRUhDlz5sDe3h7z58/X6735MDwRERFJSiXzw/CrVq3C9evXsWrVKjg5Oen13ky0iIiISFJiplk5OTnIycmpdNzOzg52dnaVjp8+fRphYWHo378/goKCRIykbphoERERkcEICwtDaGhopePTp0/HjBkzKhwrLCzEu+++C1tbWyxatEhfIVbARIuIiIgkJeY6WiEhIRg2bFil41X1Zq1cuRI3btzAsmXL4OrqKloMumCiRURERJISc+iwuiHCqhw4cABqtRqRkZGIjIys8Nm1a9cAAJs3b8aRI0fQokULLF26VMRIyzDRIiIiIqOl1WoRHR1d7ee3b9/G7du3q3zuSwxMtIiIiEhSck06PHToULWfzZ07F9u2bcM777yDSZMmSRYDEy0iIiKSlNzLO8iJC5YSERERSYQ9WkRERCQpU+7VYaJFREREklLi0OHy5cuxfPlyye/DRIuIiIgkpbw0S39MuTePiIiISFLs0SIiIiJJKXHoUF+YaBEREZGkTHn4zJS/OxEREZGk2KOlcPezs3DqtyicPxONawkXkZ56BxqNBnb2jvBs64c+A4LRvXdfucM0eLeuXsK56GO4dfUiUpNuITcnCwX5ebBuaAP3pi3RrsvjeOqZYbBpZC93qAbr+skDiI74pNZyT037AO5tO+khIuNyZObjdS575nY23vwpTsJojBfb5Prh0CEp1qQRA6DRaMr/bGnZAOZm5sjMSENmRhpOHf8Vgd164e3FK9DAylrGSA3b8f07cWTXT+V/trC0hKVlA+Tdz8HVi+dx9eJ5HNzxPaYu+Aievu1ljNTwqVRqNLCtfkNYM3M2S/WRmVdc4+dmahXsrS0AABdTc/URklFim1w/pptmMdFSPI1GA2/fAPxr4GB06toT7k2aAQDSUpLx46avcHDXdpyJPo4vVi7DG/Pelzlaw9XKxx/D3Tzg5dcR7s1aoqFtIwBAYUE+zpw4gp/Wh+J+9j2sWToH73+xBdY2tjJHbLisHZ0xePE3codhdJ5f90eNn498rAmmPtkKALArLlUPERkntsmkKyZaCrf4f1+gfWDXSsdd3Ztg6uyFMDMzx76dPyHqwC6MmTwNzq7uMkRp+Hr2DaryuJV1Q/TsGwR7x8b4dNFM3M++h5hTx9H9XwP1HCHRowkKcAUAxCTl4Pa9QpmjMVxsk+vHhEcO+TC80lX1P/TD+j3zXPn7q5fipQ7HZLVu2678/b27aTJGQqS7AI9GaNW4IQDgl1j2Zj0Ktsn1o4ZKtJehYaJl4CwsLcvfa7VaGSMxblfizpa/d3FvKmMkRLp70JuVW1SKIwl3ZY7GuLFNpn8y2KHD27dvIy8vD76+vnKHIqu4s3+Wv2/R2kvGSIxPSUkxsjPv4vypY9jx7ToAgKtHM3To9oTMkRm2otxs7PvoDdxPS4IgaGFl5wjn1n5o03MAXL07yB2e0bG2UKOPjzMA4OClDBSV8oe/lNgmV82Uhw4NNtGaN28e/vzzT8THm27XbF7ufWzdvB4A4Nc+EE1btJI3ICMxbfhTKC2pPIPL068DJs9eAgsLyyrOorrSFBfhXuJVWDa0RWlRIfLupiLvbipu/nEErbv3R5cXZ0BtZiZ3mEajr48zGlqW1SeHDaXFNrl6KgMc8hOLwSZaACAIgtwhyEar1eLTZf/BvbsZsLRsgMmvz5E7JKNh7+iEkuJiFBUWoKiwAADQtn1nPD9hGpxc+GBrfVnbOSFg0Cg06/g4Grk2g5mFBbRaDTJvXEbs7gikXjqL6ycPwKyBFTqPeFXucI3Gs+3cAABX0vNwOS1P5miMF9tkqo7iEq3BgwfXqVxiYmKl8iqVCjt27JAkLqX5JvRj/Pn7UQDA5DfmoJWnt8wRGY9lX20rf5+TlYmTh/dg1w8bsHz2JASNnIAhY6bIGJ3hcvd7DO5+j1U4plabwbmNH5567T0c/3oZks7/jqtHd8HnycFo5Mpn4R5VKydr+HuULVXC3ixpsU2uGYcOFSQhIQEqlarOvVUJCQnl701l5dmwNauwO/J7AMBLU2dVmOVC4rJzcMLTw0bDK6AjVrwzBb98vx6tfPzRoSuf0xKTSq1Gx6ETkXT+dwiCFsmx0Wjbd5jcYRm8B71ZRaUa7L+YLnM0xottcu0McbagWBSXaJmbm0Or1WLMmDEYMGBAteWWLVuGS5cuISwsTI/RyW/jl59ixw+bAAAhr85E8IjRMkdkGlr7BMDLrwMS4s7i6N7tTLQk0MilCRrY2KEoLwe5d1PkDsfgmatVeNrXBQAQlZCJ3CJNLWdQfbBNptooLtHaunUr5s6di4iICKSnp2PRokVwcnKqVK5Ro7Lu8G7duuk7RNmEffEJdmwJBwCMm/IGhowcJ3NEpsWhcdkPrfQ7iTJHQlS7Xp5OcGhYtuXOL1wJXhJsk+vORAacqqS4dbR8fHzwww8/YNq0aTh48CCCgoJM5rmrmoStWVXhf+ihL46XOSLTk5GSDABoYN1Q5kiMU276HRTl5QAAbBq7yRyN4Xu2XdnaWYn3CnA2MUfmaIwP22TdqFTivQyN4hItADAzM8P06dPx448/wt3dHXPmzMGrr76K1FTT/K0sbM2qCl3T/B9aXFqNptZnAi+cO4UbCWVLifi0e6zGslRZbfUrCALObi/b/1ClUqNJgOn0VEvBtZElOjd3AADsiudOBmJjm0y6UGSi9YCvry9+/PFHvPbaazh27BieffZZbNmyRe6w9Orh8f8Jr73FrmkJZGak4YOZIYjasw3pKUkVkoLM9FTs+XEj1iydA0EQYNPIDv2fe1HGaA1TfmYa9n/8Jq4c343cjJTyOha0WmRcv4ioNYuQFHMCANCm1yDYuTWTM1yDFxTgBjO1CqUaLfbEMdESE9vk+lGJ+J+hUdwzWv9kbm6O119/Hf3798ecOXOwaNEi/PLLL8jMzJQ7NMmlp97B9u83AgDUajUivwtD5HfVP/w/ZORYPPcCf7Oqj8TrCYhY/REAwNzcAlYNbVBSXFS+jhYAOLs1wStzl8HesbFcYRq0zFsJyLxVNktYbW4BiwbWKCkqgLa0pLxM6+798djwV+QK0SioAAzyLxs2/P1GFjLzS2o+geqMbXL9qQ0vPxKN4hOtB/z9/bF161aEhobi66+/RmlpqdEv5/Bwz4pWq0XWvZr3KCssKKjxc6qag5MzpsxZisvnT+P65XhkZ6YjNycbKrUaTi7uaNbaCx279Ua3pwbAsoGV3OEapAaNHPDYiFeQcf0ispKuoyg3G8X5uTCzsIRNYzc4t/ZD6x5Pw6WNv9yhGrzOLezhbtcAANfOEhvbZKoPlWCAy6vHxsbiyJEjAIDp06c/+vWSch/5GlS9jNzK29mQ+A7d4GbBUou6wLWopBb6b+53qQ/tmtrq9X6HLorXPvX1NaxRBYPp0RIEAVlZWdBoNGjbti3atWsnd0hERERUB0Y+AFUjRSdaWVlZiIiIwKFDh3Dp0iVoNGUL7qnVarRp0wZ9+/bFmDFj4OrqKnOkRERERJUpdtbh/v37MWDAAISGhiIuLg6lpaUQBAGCIECj0SAhIQFr167FwIED8dNPP1U4VxAExMfHyxQ5ERERPYyzDhVm9+7dmDVrFrRaLXx8fDB06FC0b98ejRs3hiAIyMzMRExMDCIjI5GQkIAFCxZAo9Fg5MiRKCkpwezZs+Ht7Q1/fz5YS0REJDfOOlSQzMxMzJ8/HwAwf/58jBtXeY0ST09PdO3aFZMmTUJYWBhWrFiBpUuXonPnzli+fDmOHTsGHx8ffYdOREREVIHiEq3w8HDk5+dj1qxZVSZZ/xQSEoKioiKsXLkSI0aMQEFBAVq2bIkRI0boIVoiIiKqjSEO+YlFcc9oRUVFwcHBARMnTqzzORMnToS9vT0KCgrg7e2NiIgIuLlxrzQiIiIl4F6HCpKYmIhOnTrBzMyszueYm5sjMDAQKpUK4eHhcHZ2ljBCIiIiorpR3NBhfn4+bGxsdD7PxsYGZmZmcHBwkCAqIiIiqi8D7IgSjeISLUdHRyQlJel8XnJyMpycnCSIiIiIiB6F2hDH/ESiuKHDgIAAnD9/HsnJyXU+JykpCTExMQgICJAwMiIiIiLdKC7RCgoKgkajwbx581BcXPseecXFxZg3bx60Wi2CgoL0ECERERHpQiXiy9AoLtEKDg6Gv78/Tp48iXHjxtW4wntsbCzGjh2L6Oho+Pn5ITg4WI+REhERUZ2YcKaluGe0VCoVVq9ejdGjR+PcuXMYPnw4vLy80KFDh/LZhBkZGTh37hyuXr0KQRDg4eGB5klzcgAAIABJREFU1atXQ2XCY8BERESkPIpLtADA3d0d27Ztw5IlS7Bnzx4kJCQgISGhQiIlCALUajUGDRqEhQsXwtHRUcaIiYiIqDqmvGCpIhMtALC3t8fKlSvx5ptv4vDhw4iLi0NmZiaAspmJAQEB6NOnD1q0aCFzpERERFQTUx5wUmyi9UDz5s0xfvx4ucMgIiIi0pniEy0iIiIybCbcocVEi4iIiCRmwpmW4pZ3ICIiIjIW7NEiIiIiSXHWIREREZFETHnWIYcOiYiIiCTCHi0iIiKSlAl3aDHRIiIiIomZcKbFoUMiIiIiibBHi4iIiCTFWYdEREREEuGsQyIiIiISHXu0AEz/IUbuEIzaybBv5Q7BJLQYMFjuEIyeh0cjuUMweiuOXJU7BJMQPqajXu8nV4dWSUkJ/vjjD/z666+Ijo7GjRs3UFxcDEdHRwQGBmLMmDHo3r27pDEw0SIiIiJpyZRpnTp1Ci+99BIAwMXFBV27doW1tTWuXr2KvXv3Yu/evZg6dSreeOMNyWJgokVERESSkutheJVKhYEDB2L8+PHo0qVLhc927dqF2bNnY/Xq1ejevTt69OghSQx8RouIiIiMUs+ePfHZZ59VSrIAICgoCMOGDQMA7NixQ7IY2KNFREREklLqrEN/f38AQGpqqmT3YKJFREREklJonoUbN24AKHt+SypMtIiIiMhg5OTkICcnp9JxOzs72NnZ1fk66enp2LZtGwBgwIABosX3T0y0iIiISFoidmmFhYUhNDS00vHp06djxowZdbpGaWkp3n77bdy/fx89e/ZE3759xQvwH5hoERERkaTEnHUYEhJS/hD7w3TpzVq0aBFOnDgBDw8P/Pe//xUttqow0SIiIiKDoesQ4T998MEH+PHHH+Hi4oINGzZI+nwWwESLiIiIJKaUWYfLly9HeHg4nJycsGHDBrRq1UryezLRIiIiIkkpIc/66KOPsH79ejg4OGD9+vXw8vLSy325YCkREREZtY8//hhff/017O3tsX79evj6+urt3uzRIiIiImnJ2KW1atUqrFu3DnZ2dvjmm2/KFynVFyZaREREJCm59jo8ePAgvvjiCwBAixYtsGnTpirLtWnTBlOmTJEkBiZaREREZJSys7PL38fGxiI2NrbKct26dWOiRURERIZJrlmHzz//PJ5//nl5bv4XJlpEREQkKSXMOpQLZx0SERERSYQ9WkRERCQtE+7SYqJFREREkpJr1qEScOiQiIiISCLs0SIiIiJJKWWvQzkw0SIiIiJJmXCexaFDIiIiIqmwR4uIiIikZcJdWky0iIiISFKcdUhEREREomOPloIdmfl4ncueuZ2NN3+KkzAaw2VtZYHenb0R6Nccgb7NEejfAi08nAAAH3yxC0u/3FXtufa21ujdxQuBfi3Qybc5Av2aw8PFHgDw8sJwbNp5Ui/fwZg87t0YI7s1Q4fm9nC2tYQAID2nCGdvZeH7k4k4df2e3CEaJLYX+mdlrkY/n8bo3Mwebo0awNpCjftFpUjJKcbFtFzsvZiO/BKt3GEqAmcdkiJl5hXX+LmZWgV7awsAwMXUXH2EZJC6BLTC9tCp9Tp3cJ8OWPfeOJEjMl1LhvnjxR7Ny/9cUKwBADRv3BDNGzfE4MAmWH/0Bpb/fEmuEA0W2wv98nOzwdReLeHwV52WaLQoLtXCqaElnBpawt/dFn8mZuPWvUKZI1UGE86zmGgp2fPr/vj/9u48Lqp6f/z4awaGfV9EQkRRB1cSl8pKr5qVoTctzZsLWKZ2v2SrSy43TW9lpddubrngzSXttple0/Tm9jNvLpEbIihaIoioLIOyL3N+fyCTBLjADDPDvJ89eDzinM85vM/7Acf3fM7n8zm33D+syz3E9GoBwLaEyw0QkfXKzs3nWFIqxxJTOZaUxgcTnzb0TN3Opau5HD+dxrHEVI4mXuCLBeNNHG3j9HS3ewxF1vYTGSzYnkxKVgEALf1cmBSppV+HAJ7v2YK433LYmXDFnOFaHblfNJw2/i5M7B2Ko72any/o2JJwhd+yCwFwsFMR5OlE12BPCkukN0tIoWXVIjs0AeDExWukyqemWv3v6FmCer9ZZdvfX3nyjo7dsPWwPB40ksFdggA4n5nPG5+foFyvGPb9llnAq58d5/tJD9Pc14UnwptKoWVkcr8wDgc7FS/2aI6jvZr/Jl1l3S/pVfaXlCv8ll1oKLzEDTbcpSWD4a1Uh0B3Wvi6ALD1pHw6vRX9Tf+gN+Sxoip/dwcAki5dr1JkVSrTKySmXwfAxcGuQWNr7OR+YTwPtfQmwN0RXWEp/z56ydzhWA2VEf+zNlJoWanKT6d5xWXsTc4yczRC3F7qjU/4bQPdsVNXv1naq1W0u8cdgJMXrzVobI2d3C+M5+HQiok0h1N0lMoHMXEH5NGhFXLWqOmj9QNg1+lMistkHICwfJ8fTOVPbf1p4efKguHh/GN7MhduGqM18QktzX1dSMksYPWP580bbCMi9wvjsVeraOnjDMBv2YX4umgY1DGA8Hvc8XSyJ7+knF+zCtiVnMXxG72zooLMOrQipaWlHD9+nCtXruDi4kLHjh3x8/Mzd1gNqq/Wz/BoRR4DCGuxJ/Eq721JYtITWvqHN6V/eFPDrENnBztyC0rZcOAC/9xxlvzicjNH23jI/cJ4/Fwd0NhVPAhq4uZAdPcwnDV2lJbrKS7T4+msIaKZJxHNPNlzNot/HUozc8SWw4brLMsrtE6cOIG3tzfBwcHV9n399dfMnz+f3NxcwzaVSkVkZCSzZ8/G1dW1IUM1mwEdAwA4ezWfM1fyzRyNEHduzf4Uzmfm897Qjvi5O+J801gsjb0KFwc73J3syS0sNWOUjYvcL4zH9abf10EdA8gvLWfhvvMcSculXAFfFw3Du9zD/SFe9GntS3puEduTMs0YsbAEFjdGa9iwYXzyySfVtn/22We89dZb6HQ6vLy8uPfeewkJCUGv17N161ZefPFFFKXxPy9v4eNM+8CKcSzy6VRYEyeNmo9GhLPi+a5c0hXxfGwcD8zezQOzd/N8bBznLuczuGsQX014gLCmbuYOt1GQ+4Vx3Ty0UK1WsepgKj+nVhRZAFkFpSzZn0LKjfGIT3YIoIbhiDZJpTLel7WxuEILqFYw6XQ6/vGPf6BWq3nrrbf46aef+Pe//8327dvZtGkTwcHB/PLLL2zevNlMETecyk+nxWXl/JB01czRCHHnpkSGEXlvIL9eyWPEssP8lJxFTkEpOQWl/JScxchlh/ntaj4+bg7MHNze3OE2CnK/MK7Cm8a3XbpWzC9p1SdtKMC2xIqlSdyd7Gnp49JQ4Vk4lRG/rItFFlp/tGvXLgoLCxkyZAgjR45EdVNJ27ZtWz744AMAvvvuO3OF2CDs1SoebesPwL7kbPJkHIuwEq4Odgy7vxkA6w+kUlLDgOziMj2f/XQBgG4tvfFxdWjQGBsbuV8YX07B74+0L12rfS2yi7nFhv/3ddWYNCZh+ayi0Dpz5gwqlYoRI0bUuD8iIoKwsDCSkpIaOLKG9VArH7xcKv5ot8rKzsKKtPB3NQwirpxpWJOUzN/3Nbsxu0vUjdwvjC+/pJzsglu/6gis8/GWqcmjQwtXWFjxvDskJKTWNiEhIeh0uoYKySwGdKxYCyctp5BjNXRZC2Gp9DcNBwjyrr2A8nX7vRcrv7jMpDE1dnK/MI34SxXvibzHw6nWNkGev++7mnf7wswW2O6DQysptJo0qbhhVBZcNVGpVDg7N95PwE3cHega7AXAtlPyahJhXX69km9YymFo96AaFyxVq+AvNx4v6gpK+e2qzJCrK7lfmM6+c9kANPVwpGszj2r7VUBku4pHttkFJZyXV/HYPItb3gHgxx9/JDo62vB9VlbFSsbnz5/Hx8enxmPS0tLw9vZukPjMIbJDAHZqFWXlerbLO+Dumpe7M3Z2v3+uUN/of3Zx0uDr9fuyIEXFpeQXVv0EevP+m7m5OFbZV1BUQmGRLEtQk+IyPV/9nEb0QyF0bObJsucimLftDMmXK3oHtAFuTB4QRpcWFX/Da/enIItu153cL0znzNV8DqfouC/EixfuD0alSuNIWi76G8s7PNvlHprf6LX96lgG8mtcwRof+RmLRRZamZmZZGZWX3vkhx9+oEuXLtW263Q6kpKS6NWrV0OE1+BUQP/2Fb16B8/ryC6Qf8zv1sF/TyXkHt9q29947lHeeO5Rw/fr/nOQ8bM+q9Imbc8HNZ7zo6nD+GjqMMP37yzbxrvLtxkp4sZn/rYztPBzoVeYv+GruLSil8tR8/v6RFuOXuKT3efMFabVk/uF6a04kIqHkz1tA9x4tVcLSsr1lJTpcXP8/Z/UjScy2P9bjhmjtCzW+I5CY7G4Qmvt2rW17nN3d69x+5YtW3B2dqZbt26mCsusujb3pKmHIyBr4QjrVVymZ9y/jvB4pwCejAikQ5AHvm6OKIpCuq6QE6m5bIy7yP+TBR7rRe4Xpldcrue9nefo1cqHh1t6E+TlhLO9muyCEk5fyeeH05kkZ9Y+6UPYFpViC6t83kbvf/5k7hAatUNrNpg7BJvQ/LE/mzuERi8wsOYPe8J4gv1t4w0f5rZu5L0N+vMyrhmvZ7Wph3UtmWFxPVq1URQFnU5HeXk5np6eaDTWlWghhBDCVtnug0MLL7R0Oh3r169n9+7dnD59mvLyivEcarWa0NBQ+vbty8iRIw2zEoUQQgghLInFLu/www8/8Nhjj7F48WISEhIoKytDURQURaG8vJzk5GRWrFjB448/zjfffFPlWEVROHXqlJkiF0IIIcTNbHnBUovs0fr++++ZOHEier0erVbL4MGD6dSpE76+viiKQnZ2NidOnGDTpk0kJyfzt7/9jfLycoYNG0ZpaSmTJk2iTZs2tG8v70sTQgghzE1mHVqQ7OxsZsyYAcCMGTOIioqq1qZVq1Z0796dF154gTVr1vDBBx/w7rvv0rVrV95//33279+PVqtt6NCFEEIIIaqwuEJr3bp1FBQUMHHixBqLrD8aPXo0xcXFLFiwgKFDh1JYWEhISAhDhw5tgGiFEEIIcVu226FleWO09u3bh5eXF2PGjLnjY8aMGYOnpyeFhYW0adOG9evXExAQYMIohRBCCHGn5F2HFiQtLY3OnTtjZ2d3+8Y32NvbExERgUqlYt26dfj5+ZkwQiGEEEKIO2Nxjw4LCgpwdb37BetcXV2xs7PDy8vLBFEJIYQQoq6scbagsVhcoeXt7c3Fixfv+rj09PRaXzgthBBCCPOx5VmHFvfosEOHDsTHx5Oenn7Hx1y8eJETJ07QoUMHE0YmhBBCiLqw5XW0LK7QioyMpLy8nOnTp1NSUnLb9iUlJUyfPh29Xk9kZGQDRCiEEEIIcWcsrtAaOHAg7du359ChQ0RFRd1yhfeTJ08yatQoDh8+TLt27Rg4cGADRiqEEEIIcWsWN0ZLpVKxdOlSRowYwfHjxxkyZAitW7cmPDzcMJswMzOT48ePc+7cORRFITAwkKVLl6Kyxj5FIYQQopGz5X+eLa7QAmjatCnffvsts2fPZvv27SQnJ5OcnFylkFIUBbVaTf/+/Zk5cybe3t5mjFgIIYQQojqLLLQAPD09WbBgAa+//jp79uwhISGB7OxsoGJmYocOHejTpw/Nmzc3c6RCCCGEuBVbnnVosYVWpeDgYKKjo80dhhBCCCHqyJYfHVrcYHghhBBCiMbC4nu0hBBCCGHdbLhDSwotIYQQQpiYDVda8uhQCCGEEMJEpEdLCCGEECYlsw6FEEIIIUzEEmYdbtmyhc8//5zTp0+j1+tp2bIlQ4YMYfjw4ajVpnvAJ4WWEEIIIRq12bNns2HDBhwdHenRowf29vYcOHCAOXPmcODAARYuXGiyYksKLSGEEEKYlDk7tHbs2MGGDRvw9/fns88+o0WLFkDF6/yio6P54YcfWLduHaNHjzbJz5fB8EIIIYQwLZURv+7S8uXLAZg0aZKhyALw8/Pj7bffBmDlypXo9fq7P/kdkEJLCCGEEI1SRkYGCQkJaDQa+vfvX23/fffdR0BAAFevXuXYsWMmiUEKLSGEEEKYlMqI/92NU6dOAdCmTRucnJxqbNOpUycAEhMT63eRtZAxWkIIIYQwKWPOOrx27RrXrl2rtt3DwwMPD48q29LS0gC45557aj1fYGBglbbGJoUWsPe1B80dQuMm+RVCCJvmZMRqY+WaNSxevLja9gkTJvDyyy9X2VZQUACAs7NzredzdXUFID8/33hB3kQKLSGEEEJYjdGjR/PUU09V2/7H3ixLIYWWEEIIIaxGTY8Ia+Pi4gJAYWFhrW0qe7Iqe7aMTQbDCyGEEKJRCgoKAiA9Pb3WNhkZGVXaGpsUWkIIIYRolNq3bw9AcnIyRUVFNbaJj48HoF27diaJQQotIYQQQjRKgYGBdOjQgdLSUrZv315t/+HDh8nIyMDf35+IiAiTxCCFlhBCCCEarfHjxwMwf/58UlJSDNuzsrKYPXs2AOPGjTPZuw5ViqIoJjmzEEIIIYQFePvtt/n8889xdHTkwQcfNLxUOi8vj379+rFw4ULs7OxM8rOl0BJCCCFEo7dlyxbWr1/PmTNn0Ov1hIaGMmTIEIYPH26y3iyQQksIIYQQwmRkjJYQQgghhInIgqUWQq/Xs3XrVrZt28bJkyfJycnBxcWFZs2a0atXL6KiovD19a12XEFBATt37iQ+Pp74+HiSkpIoLCykd+/eLF++3AxXYrnqmuNff/2Vffv28eOPP3L69GlycnJwcnKidevWPPHEE4wYMQIHBwczXJFlqmuejxw5wubNmzl16hSXLl1Cp9Oh0Who1qwZf/rTnxgzZgw+Pj5muCLLU9cc1+TMmTM8/fTTlJaW0qZNG7777jsTR28d6prjQ4cOER0dfctzf/HFF3Tu3NlUoQsLI48OLUBGRgYxMTEkJCSgVqsJDw8nKCiI/Px8jh07hk6nw8XFhXfffZfIyMgqxyYmJjJ48OBq55RCq6r65LhXr15cvnwZR0dHOnbsSNOmTcnMzOTYsWMUFxfTvn17Pv30U7y8vMx0dZajPnn+6KOPWLZsGUFBQTRv3hwfHx9yc3OJj48nNzcXX19f1q1bR6tWrcx0dZahPjn+o7KyMoYNG8apU6dQFEUKrRvqk+PKQsvPz4+ePXvWeP6YmBiaN2/eEJciLIEizConJ0fp06ePotVqlVGjRikXLlyosr+kpERZvny50rZtWyUsLEzZvn17lf0pKSnKtGnTlPXr1yvHjx9XPv/8c0Wr1Srjx49vyMuwaPXNcXR0tPLVV18peXl5VbanpqYqAwYMULRarTJlyhSTX4elq2+ez549q1y8eLHaefPz85XXXntN0Wq1ysiRI016DZauvjn+o0WLFilarVaZPXu2otVqlQEDBpgyfKtQ3xwfPHjQcKwQiqIoUmiZ2euvv65otVplyJAhSlFRUa3tVq9erWi1WqVr165KVlZWre2++eYbKbT+wNg5vtnPP/+saLVapVOnTkpxcbGxQrZKpsxzenq6otVqlbCwMJvOszFznJiYqHTo0EGZMGGCoTiQQqv+OZZCS/yRDIY3owsXLvD9998DMGvWLBwdHWttGx0djVar5fr162zYsKGhQrR6ps5x5esdiouL0el09Q/YSpk6z5Xr29jb25t0GrYlM2aOS0tLmTp1Kq6ursyaNctkMVsbuScLU7DNO5aF2LNnD3q9njZt2tCpU6dbtlWpVIaxWLt3726I8BoFU+e4cpVhjUZj02O0TJnnkpISPv74YwB69uyJvb1tzuExZo4/+eQTEhMTmTZtGn5+fiaJ1xoZM8eZmZksXryYt956i/fee4+vv/6anJwck8QtLJtt3rEsREJCAsBt/6ArVbZLSkqivLzcZKvYNiamzvGKFSsA6NOnj03PPDRmns+fP8+yZcsAyMnJIT4+nqysLDp16sTbb79t3MCtiLFyfOrUKZYvX06vXr1qnEhjy4z5e/zrr7+yaNGiKu3feecdJk6cSFRUlJEiFtZACi0zys7OBrjjT5SVU4nLy8vJzc2Vqe53wJQ53rhxI9u2bcPZ2ZnXX3+9/sFaMWPmOTMzk2+//bZK+x49evD3v/+dgIAAI0VsfYyR45KSEt58800cHR2ZM2eOyWK1VsbIsbu7O8899xyPPvooLVq0wNnZmZSUFDZs2MA333zDO++8g5OTE88884zJrkNYFnl0aKXKysrMHUKjd6scHzhwgJkzZ6JSqZg9ezahoaENGFnj8sc8d+vWjdOnT5OYmMjevXv58MMPSU1NZeDAgWzfvt1MUVq3yhwvWbKEM2fOMHnyZAIDA80cVeNSmeP27dszbdo0unXrhp+fH66urrRv35533nmH6dOnAxUvNy4pKTFnuKIBSaFlRt7e3kDFJ/g7kZWVBYBarbbp8UB3wxQ5jouLIyYmhtLSUmbMmMGgQYOME6wVM0We1Wo1gYGBDBo0iNWrV2Nvb8+0adO4fPmycYK2MvXN8cmTJ4mNjeW+++7j2WefNVmc1szU9+SRI0fi7e2NTqfj+PHjdQ9UWBUptMyoQ4cOAHf8B3fixAkAQkNDbXo80N0wdo6PHDnC+PHjKSgoYPLkyTLW4gZT/y4HBwfTvXt3CgoK2L9/f90DtWL1zfGePXsoKysjKyuL6OhooqKiDF/vvfceAGlpaYZtlRM9bImpf4/VajUtWrQAsNkPDLZICi0z6tOnD2q1mnPnzhn+YGujKAqbN28GoG/fvg0RXqNgzBwfO3aMsWPHkp+fz2uvvcbYsWNNErM1aojf5crehspeBFtjrByfO3eOw4cPV/lKSkoCoLCw0LCtoKDANBdiwRri97hy5qGLi0vdAxVWRQotMwoJCeHxxx8HYM6cORQXF9fadu3atZw5cwZnZ2dGjRrVUCFaPWPl+MSJE7zwwgvk5+fz8ssv83//938mjdvamPp3uaysjLi4OABDj4CtqW+OX375ZU6fPl3j19q1awFo06aNYVu7du1Mf1EWxtS/x0lJSZw/fx6VSkXHjh2NErOwfFJomdnMmTMJDAwkPj6ecePGkZaWVmV/aWkpK1as4P333wdgxowZNj3zqi7qm+P4+HjGjBlDXl4eMTExTJgwoUHjtxb1zfOKFSsMs75ulpWVxfTp07lw4QKBgYG1vj/OFsj9wvTqm+O1a9fWuF7W0aNHeeWVVwCIjIykSZMmJrwKYUnkpdIWID09nZiYGBITE7Gzs6vyAtOjR4+i0+lwcHBg+vTpDB8+vNrxL730ElevXgUqpienpqbi4eFBy5YtDW1iYmLo3bt3Q12SxalPju+77z5yc3Px8PDgkUceqfVnTJkyxeaX3KhPnsPCwrCzsyMsLIzg4GDs7OzIyMjg1KlTFBUV4efnx7Jly+54jaPGqr73i5pUvghZXipdoT457tatG4WFhbRt25ZmzZqhKAopKSmcPn0aRVHo0qULK1euxM3NzUxXJxqaFFoWory8nO+++47vv/+ekydPkpOTY5gu7OTkxDfffEPr1q1rPLZv375cvHjxluefO3cuTz/9tNHjtiZ1zXFYWNgdnX/Xrl00a9bMqDFbo7rmef369fz8888kJiaSlZVFYWEhbm5uhIaG0qdPH5599lk8PDwa+nIsUn3uFzWRQqu6uuY4NjaWuLg4zp49S05ODkVFRXh6etKuXTsGDBjAoEGDZLFpGyOFlgXLzs4mOjqa5ORkevbsydKlS2W2oZFJjhuG5Nn0JMemJzkWdSFjtCyYj48Pn376KS1atODHH39k0qRJlJeXmzusRkVy3DAkz6YnOTY9ybGoC7u3bfnlYVbA1dWVfv364e7ujo+PD25ubjKI0sgkxw1D8mx6kmPTkxyLuyWPDoUQQgghTEQeHQohhBBCmIgUWkIIIYQQJiKFlhBCCCGEiUihJYQwmaioKMLCwti4cWOV7YcOHSIsLKxRvbdz48aNhIWFyYvGhRBV2Js7ACHE7U2dOpVvv/222nZXV1eCg4N58MEHGT16NE2bNjVDdOaXmJjIzp07CQoKsvmFeYUQlkV6tISwIhqNBj8/P/z8/PD19aWgoICkpCT+9a9/8ec//9nw4mVL5+zsTMuWLQkODjbK+RITE1m8eHGNxagQQpiT9GgJYUUiIiJYt26d4fvCwkJ27NjBu+++y7Vr13jttdfYuXMnTk5OZozy9sLDw9m+fbu5wxBCCJOTHi0hrJizszODBw9mxowZAFy9epWdO3eaOSohhBCVpEdLiEYgMjKSadOmodfrSUhIYODAgURFRXH48GHmzp1Lv379WL58Obt27eLSpUtoNJoqjxlLSkr48ssv2bZtG2fPnqWgoAB/f38eeOABxo4dS6tWrWr92fv27SM2NpaEhAQURaF169aMGDGCwYMH13pM5UuMg4KC2L17d41tLl26xJo1a9i/f7/hpemBgYF07tyZJ598kgceeACo+tLvw4cPV3sJ+Nq1a7n//vurbIuLi2P9+vX88ssvZGdn4+rqSrt27Rg6dCgDBgxApVLVGNPly5dZvHgxe/fuRafT0aRJE/r168dLL71U67UKIWybFFpCNAIODg54e3uTlZVFXl5elX3Z2dk8/fTTpKam4uDggEajqbL/ypUrjBs3jqSkJADUajXOzs6kp6ezceNGtm7dyvz583nssceq/dzY2FjmzZsHgEqlwt3dnfj4eN58803D+epix44dTJkyhaKiIgAcHR1xcnLi119/5dy5cxw8eNBQoPn5+VFUVEReXh4ajQZPT88q5/rj9c6bN4/Y2FjD925ubuTm5nLgwAEOHDjA7t27mT9/Pmp11Q7/c+fOMWrUKLKzswFwcXEhMzOT1atXs2fPHoYPH17n6xVCNF5SaAnRCBQVFRkKAHd39yr7lixZgqenJytXruThhx9GrVaTkpICQGlpKTExMSQlJdHL7yqtAAAHGElEQVSjRw9effVVOnbsiEaj4cqVK8TGxrJmzRqmTJlC27Ztad68ueG8cXFxzJ8/H4Ann3ySKVOm4O/vz7Vr11i+fDmxsbHVYrkTR44c4Y033qCsrIz777+fSZMm0alTJ1QqFXl5eRw8eJBdu3YZ2v/vf/9j48aNTJs2rdoYtj9as2YNsbGx+Pn58eqrr/LEE0/g7u5OUVERu3fv5r333mPr1q2EhYXx4osvGo4rLS3llVdeITs7m+DgYObOnUv37t3R6/Xs3buXGTNmsGTJkru+ViFE4ydjtIRoBL7++msqX1t67733VtlXWlrKihUr6NWrl6GXJiQkBIBNmzYRHx9Pt27dWLlyJREREYYeoCZNmjB9+nT+8pe/UFhYyOrVq6ucd9GiRSiKwv3338+HH36Iv78/AB4eHkyePJmhQ4dy/fr1u76WuXPnUlZWRvfu3Vm1ahXh4eGGR3lubm7069ePuXPn3vV5r127xj//+U8cHR1ZtWoVw4YNMxSCTk5OREZGsmjRIlQqFatWraKkpMRw7NatWzl79iwajYYVK1bQvXt3oKL3r2/fvixatKhO1yqEaPyk0BLCSimKQlpaGqtWrTI8vgsKCqJPnz5V2vXs2ROtVlvjOSqXQ4iOjq72iK3Sk08+CVT0HFXS6XQcOnQIgHHjxtU4pumvf/3rXV5RxeO5EydOADB58uRaY6qLHTt2UFBQwIMPPkjbtm1rbBMREUGzZs3Izc0lISGhyrEAjz32GKGhodWO69atm6H4EkKIm8mjQyGsSE2DvSv5+/uzZMkSHBwcqmyPiIiosX1ZWZmhqJk5cyZz5sypsV15eTkAGRkZhm2JiYkoioJaraZr1641HhccHExgYCCXLl269UXd5Pjx4wB4eXlV65mrr6NHjwJw8OBBHnrooVrb5ebmAhWD8Stzd+rUKYBbFlPdu3fn559/Nla4QohGQgotIazIzYO9VSoVzs7OhpXhn3nmmWoDwQG8vb1rPFdubi6lpaVARQ/V7VQOTAeqjAdzcXGp9ZiAgIC7KrQyMzOBitmFxnb16lWgYu2xwsLC27av6XqbNGlSa/uAgIB6RiiEaIyk0BLCitxusHdN7Ozsatyu1+sN/79p0ybatWtXr9gsXeX1RkdHG9YdE0IIU5MxWkLYKC8vL0MRlp6eflfH+vj4AHD9+vVb9g5duXLlrs7r5+cHcFe9YA1x7srrvdX13O21CiFsgxRaQtgojUZDx44dgYpFR+9Gu3btUKlU6PV6fvnllxrbpKam3nUBVzkuS6fTcezYsTs+rnI2ZeXMy5p07twZqBjndvNjwTvRvn17gFu+S1LGZwkhaiKFlhA27KmnngIqZh/eboHRykHiUNEbVrkye2xsbI0FzsqVK+86nlatWhEeHg5ULCxaOYbsdtzc3ICKJRxq079/f1xcXMjNzb3tmlc3X2vlsQD//e9/OX/+fLX2R44ckUJLCFEjKbSEsGFDhw6lc+fOFBcXM3r0aL788ssqK8tfvXqV//znP4waNYq1a9dWOXbChAmoVCoOHDjA1KlTDQPZr1+/zoIFC/jiiy/qtGDp1KlTsbOzIy4ujrFjxxIfH2/Yl5eXx9atW5k4cWKVY1q3bg1ULA9ROXPxj7y9vXnjjTcAWLFiBX/729/47bffDPuLioqIi4tj1qxZPPvss1WOjYyMpHXr1pSUlDB+/HhDz1blgqUvv/yyodgTQoibyWB4IWyYRqNh6dKlTJgwgSNHjvDWW28xa9YsPDw8KCkpoaCgwNC2sgerUrdu3Zg0aRLz5s1j06ZNbN68GQ8PD/Ly8igvL+f5558nISGBw4cP31VMXbt2Zd68eUydOpWDBw8ydOhQnJyccHJyIjc3F0VRCAoKqnJMixYtDMsrDBs2DC8vL1xdXQFYsGCB4bFhVFQU169fZ+HChXz11Vd89dVXuLi4oNFouH79umHA/B/Pr9Fo+Pjjj4mKiiIlJYWRI0fi4uKCXq+nqKiIkJAQxo4dy/vvv39X1yqEaPyk0BLCxvn6+vLZZ5+xbds2tmzZQkJCArm5uWg0GkJDQwkPD6d379488sgj1Y4dO3YsWq2W2NhYTp48SVlZGR07djS8VDoqKqpOMQ0YMIDw8HBWr17N/v37ycjIoKysjNDQULp06cKgQYOqHbNo0SIWLlzIvn37uHz5smHJiuLi4irtYmJieOSRR1i/fj2HDh0iIyPD8BLtNm3a0KNHDwYOHFjt/K1bt2bTpk0sWrSIvXv3kpubW+Wl0jt37qzTtQohGjeVcqvRo0IIIYQQos5kjJYQQgghhIlIoSWEEEIIYSJSaAkhhBBCmIgUWkIIIYQQJiKFlhBCCCGEiUihJYQQQghhIlJoCSGEEEKYiBRaQgghhBAmIoWWEEIIIYSJSKElhBBCCGEiUmgJIYQQQpjI/wd0r4Vn7UQV2wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3v7deqRtyqj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogC4A-0byp9T"
      },
      "source": [
        "## NSI_Temp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-IAKLRKyp9T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "033b1c2a-3364-457e-fce1-263c51d0db69"
      },
      "source": [
        "# Reading rainfall file of NNI region \n",
        "Data_temp_NSI = pd.read_csv(\"drive/My Drive/DL_project/Target_TMean_NSI_regional_ave_time_series.csv\")\n",
        "Data_temp_NSI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>Tmean_N</th>\n",
              "      <th>cat_3</th>\n",
              "      <th>cat_5</th>\n",
              "      <th>anomalies</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-04-01</td>\n",
              "      <td>13.529139</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1.130297</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-05-01</td>\n",
              "      <td>10.664010</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.601667</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-06-01</td>\n",
              "      <td>7.765787</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.311765</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-07-01</td>\n",
              "      <td>5.301817</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.244312</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-08-01</td>\n",
              "      <td>4.404314</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.486938</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>2019-08-01</td>\n",
              "      <td>5.154255</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.263003</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>5.721869</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.095062</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>2019-10-01</td>\n",
              "      <td>6.591238</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.577933</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>8.929972</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.018006</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>10.875399</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.005589</td>\n",
              "      <td>NSI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>465 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           time    Tmean_N  cat_3  cat_5  anomalies region\n",
              "0    1981-04-01  13.529139      3      5   1.130297    NSI\n",
              "1    1981-05-01  10.664010      3      5   0.601667    NSI\n",
              "2    1981-06-01   7.765787      3      4   0.311765    NSI\n",
              "3    1981-07-01   5.301817      2      3  -0.244312    NSI\n",
              "4    1981-08-01   4.404314      1      1  -0.486938    NSI\n",
              "..          ...        ...    ...    ...        ...    ...\n",
              "460  2019-08-01   5.154255      2      4   0.263003    NSI\n",
              "461  2019-09-01   5.721869      2      3   0.095062    NSI\n",
              "462  2019-10-01   6.591238      1      1  -0.577933    NSI\n",
              "463  2019-11-01   8.929972      2      3  -0.018006    NSI\n",
              "464  2019-12-01  10.875399      2      3  -0.005589    NSI\n",
              "\n",
              "[465 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylfHlerZyp9T"
      },
      "source": [
        "# Extracting label column\n",
        "labels_temp_NSI = Data_temp_NSI['cat_5'].astype(int) #cat5 column - so 5 prediction classes "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jbxVpWXyp9U"
      },
      "source": [
        "# Function that will convert labels into Pytorch tensors\n",
        "\n",
        "def labels_Tensors(labels):\n",
        "    return (torch.from_numpy(labels.values).type(torch.LongTensor)-1) #cat5 in form 1, 2, 3, 4, 5;\n",
        "\n",
        "# Converting labels of Temp_NSI region into tensors\n",
        "labelsTensors_temp_NSI = labels_Tensors(labels_temp_NSI) # This represents y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAmNg-Smyp9U"
      },
      "source": [
        "# Train lables distribution\n",
        "Train_labels = labels_temp_NSI[:325]\n",
        "Train_labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN-PclYoyp9V"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_valid_loaders_NSI_temp(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_NSI[:325])\n",
        "    validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_NSI[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcNW_kvoIhhD"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_temp_NSI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 1,\n",
        "          'n_epochs' : 350,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           'dropout'       : 0.8,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_NSI_temp(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_NSI[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_NSI[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 10\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_temp_NSI[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_temp_NSI[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_NSI_temp_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BIoA5Yjyp9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e9005d-8af4-455c-d071-35d66a29651d"
      },
      "source": [
        "study = optuna.create_study(sampler=optuna.samplers.TPESampler(), direction='maximize')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 03:55:09,127]\u001b[0m A new study created in memory with name: no-name-3bcbce4e-5b70-4f87-a869-b6eaf1aa0181\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EmpXLvZyp9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15d9411-3c1d-4571-c11f-04d620145bfa"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_temp_NSI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"optimise_valid_NSI_drop(0.5).torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.681 \tTrain_Accu: 21%  \tValid_Acc:10%  \tVal_kappa : 0.000  \n",
            "Epoch: 2 \tTraining Loss:  1.610 \tTrain_Accu: 22%  \tValid_Acc:13%  \tVal_kappa : -0.224  \n",
            "Epoch: 3 \tTraining Loss:  1.600 \tTrain_Accu: 23%  \tValid_Acc:11%  \tVal_kappa : 0.074  \n",
            "Epoch: 4 \tTraining Loss:  1.590 \tTrain_Accu: 23%  \tValid_Acc:13%  \tVal_kappa : 0.245  \n",
            "Epoch: 5 \tTraining Loss:  1.591 \tTrain_Accu: 25%  \tValid_Acc:23%  \tVal_kappa : -0.113  \n",
            "Epoch: 6 \tTraining Loss:  1.599 \tTrain_Accu: 22%  \tValid_Acc:26%  \tVal_kappa : 0.217  \n",
            "Epoch: 7 \tTraining Loss:  1.592 \tTrain_Accu: 25%  \tValid_Acc:14%  \tVal_kappa : -0.081  \n",
            "Epoch: 8 \tTraining Loss:  1.556 \tTrain_Accu: 27%  \tValid_Acc:16%  \tVal_kappa : 0.298  \n",
            "Epoch: 9 \tTraining Loss:  1.589 \tTrain_Accu: 25%  \tValid_Acc:24%  \tVal_kappa : -0.062  \n",
            "Epoch: 10 \tTraining Loss:  1.566 \tTrain_Accu: 24%  \tValid_Acc:20%  \tVal_kappa : -0.612  \n",
            "Epoch: 11 \tTraining Loss:  1.544 \tTrain_Accu: 31%  \tValid_Acc:14%  \tVal_kappa : -0.630  \n",
            "Epoch: 12 \tTraining Loss:  1.531 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : -0.514  \n",
            "Epoch: 13 \tTraining Loss:  1.561 \tTrain_Accu: 29%  \tValid_Acc:20%  \tVal_kappa : -0.198  \n",
            "Epoch: 14 \tTraining Loss:  1.556 \tTrain_Accu: 32%  \tValid_Acc:17%  \tVal_kappa : -0.453  \n",
            "Epoch: 15 \tTraining Loss:  1.508 \tTrain_Accu: 30%  \tValid_Acc:24%  \tVal_kappa : 0.245  \n",
            "Epoch: 16 \tTraining Loss:  1.520 \tTrain_Accu: 28%  \tValid_Acc:16%  \tVal_kappa : 0.251  \n",
            "Epoch: 17 \tTraining Loss:  1.509 \tTrain_Accu: 30%  \tValid_Acc:14%  \tVal_kappa : 0.041  \n",
            "Epoch: 18 \tTraining Loss:  1.501 \tTrain_Accu: 30%  \tValid_Acc:16%  \tVal_kappa : -0.231  \n",
            "Epoch: 19 \tTraining Loss:  1.503 \tTrain_Accu: 33%  \tValid_Acc:17%  \tVal_kappa : -0.102  \n",
            "Epoch: 20 \tTraining Loss:  1.464 \tTrain_Accu: 34%  \tValid_Acc:31%  \tVal_kappa : 0.201  \n",
            "Epoch: 21 \tTraining Loss:  1.458 \tTrain_Accu: 32%  \tValid_Acc:21%  \tVal_kappa : -0.382  \n",
            "Epoch: 22 \tTraining Loss:  1.420 \tTrain_Accu: 35%  \tValid_Acc:26%  \tVal_kappa : -0.141  \n",
            "Epoch: 23 \tTraining Loss:  1.485 \tTrain_Accu: 34%  \tValid_Acc:11%  \tVal_kappa : 0.498  \n",
            "Epoch: 24 \tTraining Loss:  1.384 \tTrain_Accu: 36%  \tValid_Acc:20%  \tVal_kappa : 0.484  \n",
            "Epoch: 25 \tTraining Loss:  1.456 \tTrain_Accu: 37%  \tValid_Acc:26%  \tVal_kappa : -0.195  \n",
            "Epoch: 26 \tTraining Loss:  1.376 \tTrain_Accu: 40%  \tValid_Acc:26%  \tVal_kappa : -0.075  \n",
            "Epoch: 27 \tTraining Loss:  1.401 \tTrain_Accu: 37%  \tValid_Acc:27%  \tVal_kappa : 0.457  \n",
            "Epoch: 28 \tTraining Loss:  1.380 \tTrain_Accu: 40%  \tValid_Acc:29%  \tVal_kappa : 0.031  \n",
            "Epoch: 29 \tTraining Loss:  1.394 \tTrain_Accu: 40%  \tValid_Acc:21%  \tVal_kappa : 0.000  \n",
            "Epoch: 30 \tTraining Loss:  1.386 \tTrain_Accu: 38%  \tValid_Acc:23%  \tVal_kappa : -0.219  \n",
            "Epoch: 31 \tTraining Loss:  1.409 \tTrain_Accu: 40%  \tValid_Acc:20%  \tVal_kappa : -0.011  \n",
            "Epoch: 32 \tTraining Loss:  1.321 \tTrain_Accu: 42%  \tValid_Acc:23%  \tVal_kappa : -0.020  \n",
            "Epoch: 33 \tTraining Loss:  1.291 \tTrain_Accu: 44%  \tValid_Acc:29%  \tVal_kappa : 0.241  \n",
            "Epoch: 34 \tTraining Loss:  1.306 \tTrain_Accu: 43%  \tValid_Acc:24%  \tVal_kappa : 0.201  \n",
            "Epoch: 35 \tTraining Loss:  1.313 \tTrain_Accu: 40%  \tValid_Acc:23%  \tVal_kappa : 0.186  \n",
            "Epoch: 36 \tTraining Loss:  1.309 \tTrain_Accu: 43%  \tValid_Acc:26%  \tVal_kappa : 0.273  \n",
            "Epoch: 37 \tTraining Loss:  1.280 \tTrain_Accu: 42%  \tValid_Acc:17%  \tVal_kappa : -0.222  \n",
            "Epoch: 38 \tTraining Loss:  1.301 \tTrain_Accu: 45%  \tValid_Acc:19%  \tVal_kappa : 0.154  \n",
            "Epoch: 39 \tTraining Loss:  1.267 \tTrain_Accu: 41%  \tValid_Acc:16%  \tVal_kappa : 0.091  \n",
            "Epoch: 40 \tTraining Loss:  1.257 \tTrain_Accu: 44%  \tValid_Acc:17%  \tVal_kappa : -0.249  \n",
            "Epoch: 41 \tTraining Loss:  1.189 \tTrain_Accu: 46%  \tValid_Acc:36%  \tVal_kappa : -0.243  \n",
            "Epoch: 42 \tTraining Loss:  1.223 \tTrain_Accu: 46%  \tValid_Acc:24%  \tVal_kappa : 0.360  \n",
            "Epoch: 43 \tTraining Loss:  1.248 \tTrain_Accu: 50%  \tValid_Acc:21%  \tVal_kappa : 0.209  \n",
            "Epoch: 44 \tTraining Loss:  1.209 \tTrain_Accu: 45%  \tValid_Acc:13%  \tVal_kappa : 0.231  \n",
            "Epoch: 45 \tTraining Loss:  1.183 \tTrain_Accu: 48%  \tValid_Acc:14%  \tVal_kappa : 0.034  \n",
            "Epoch: 46 \tTraining Loss:  1.163 \tTrain_Accu: 48%  \tValid_Acc:16%  \tVal_kappa : 0.480  \n",
            "Epoch: 47 \tTraining Loss:  1.163 \tTrain_Accu: 50%  \tValid_Acc:29%  \tVal_kappa : -0.352  \n",
            "Epoch: 48 \tTraining Loss:  1.173 \tTrain_Accu: 44%  \tValid_Acc:23%  \tVal_kappa : -0.472  \n",
            "Epoch: 49 \tTraining Loss:  1.084 \tTrain_Accu: 53%  \tValid_Acc:24%  \tVal_kappa : -0.161  \n",
            "Epoch: 50 \tTraining Loss:  1.067 \tTrain_Accu: 53%  \tValid_Acc:24%  \tVal_kappa : 0.450  \n",
            "Epoch: 51 \tTraining Loss:  1.077 \tTrain_Accu: 50%  \tValid_Acc:20%  \tVal_kappa : -0.211  \n",
            "Epoch: 52 \tTraining Loss:  1.115 \tTrain_Accu: 50%  \tValid_Acc:26%  \tVal_kappa : -0.021  \n",
            "Epoch: 53 \tTraining Loss:  1.213 \tTrain_Accu: 45%  \tValid_Acc:20%  \tVal_kappa : -0.313  \n",
            "Epoch: 54 \tTraining Loss:  1.102 \tTrain_Accu: 51%  \tValid_Acc:24%  \tVal_kappa : -0.180  \n",
            "Epoch: 55 \tTraining Loss:  1.134 \tTrain_Accu: 48%  \tValid_Acc:21%  \tVal_kappa : 0.049  \n",
            "Epoch: 56 \tTraining Loss:  1.066 \tTrain_Accu: 52%  \tValid_Acc:23%  \tVal_kappa : 0.043  \n",
            "Epoch: 57 \tTraining Loss:  1.114 \tTrain_Accu: 50%  \tValid_Acc:23%  \tVal_kappa : 0.299  \n",
            "Epoch: 58 \tTraining Loss:  1.012 \tTrain_Accu: 54%  \tValid_Acc:23%  \tVal_kappa : -0.037  \n",
            "Epoch: 59 \tTraining Loss:  1.040 \tTrain_Accu: 52%  \tValid_Acc:17%  \tVal_kappa : -0.394  \n",
            "Epoch: 60 \tTraining Loss:  1.077 \tTrain_Accu: 49%  \tValid_Acc:26%  \tVal_kappa : 0.389  \n",
            "Epoch: 61 \tTraining Loss:  1.066 \tTrain_Accu: 54%  \tValid_Acc:14%  \tVal_kappa : 0.103  \n",
            "Epoch: 62 \tTraining Loss:  1.063 \tTrain_Accu: 49%  \tValid_Acc:24%  \tVal_kappa : -0.029  \n",
            "Epoch: 63 \tTraining Loss:  1.027 \tTrain_Accu: 51%  \tValid_Acc:19%  \tVal_kappa : 0.055  \n",
            "Epoch: 64 \tTraining Loss:  1.004 \tTrain_Accu: 58%  \tValid_Acc:13%  \tVal_kappa : 0.133  \n",
            "Epoch: 65 \tTraining Loss:  1.020 \tTrain_Accu: 57%  \tValid_Acc:31%  \tVal_kappa : 0.239  \n",
            "Epoch: 66 \tTraining Loss:  0.991 \tTrain_Accu: 54%  \tValid_Acc:26%  \tVal_kappa : -0.451  \n",
            "Epoch: 67 \tTraining Loss:  1.012 \tTrain_Accu: 56%  \tValid_Acc:23%  \tVal_kappa : -0.167  \n",
            "Epoch: 68 \tTraining Loss:  0.991 \tTrain_Accu: 57%  \tValid_Acc:21%  \tVal_kappa : -0.036  \n",
            "Epoch: 69 \tTraining Loss:  1.034 \tTrain_Accu: 56%  \tValid_Acc:17%  \tVal_kappa : -0.283  \n",
            "Epoch: 70 \tTraining Loss:  1.000 \tTrain_Accu: 55%  \tValid_Acc:31%  \tVal_kappa : 0.303  \n",
            "Epoch: 71 \tTraining Loss:  0.909 \tTrain_Accu: 58%  \tValid_Acc:21%  \tVal_kappa : -0.007  \n",
            "Epoch: 72 \tTraining Loss:  0.991 \tTrain_Accu: 55%  \tValid_Acc:21%  \tVal_kappa : -0.148  \n",
            "Epoch: 73 \tTraining Loss:  0.935 \tTrain_Accu: 58%  \tValid_Acc:23%  \tVal_kappa : 0.372  \n",
            "Epoch: 74 \tTraining Loss:  0.883 \tTrain_Accu: 61%  \tValid_Acc:23%  \tVal_kappa : -0.114  \n",
            "Epoch: 75 \tTraining Loss:  1.071 \tTrain_Accu: 53%  \tValid_Acc:23%  \tVal_kappa : -0.029  \n",
            "Epoch: 76 \tTraining Loss:  0.924 \tTrain_Accu: 62%  \tValid_Acc:16%  \tVal_kappa : 0.071  \n",
            "Epoch: 77 \tTraining Loss:  0.935 \tTrain_Accu: 57%  \tValid_Acc:21%  \tVal_kappa : 0.051  \n",
            "Epoch: 78 \tTraining Loss:  0.954 \tTrain_Accu: 56%  \tValid_Acc:17%  \tVal_kappa : -0.130  \n",
            "Epoch: 79 \tTraining Loss:  0.919 \tTrain_Accu: 59%  \tValid_Acc:21%  \tVal_kappa : 0.392  \n",
            "Epoch: 80 \tTraining Loss:  0.816 \tTrain_Accu: 62%  \tValid_Acc:14%  \tVal_kappa : 0.021  \n",
            "Epoch: 81 \tTraining Loss:  0.877 \tTrain_Accu: 61%  \tValid_Acc:19%  \tVal_kappa : 0.213  \n",
            "Epoch: 82 \tTraining Loss:  0.928 \tTrain_Accu: 58%  \tValid_Acc:19%  \tVal_kappa : 0.174  \n",
            "Epoch: 83 \tTraining Loss:  0.873 \tTrain_Accu: 60%  \tValid_Acc:27%  \tVal_kappa : 0.291  \n",
            "Epoch: 84 \tTraining Loss:  0.917 \tTrain_Accu: 59%  \tValid_Acc:19%  \tVal_kappa : 0.465  \n",
            "Epoch: 85 \tTraining Loss:  0.936 \tTrain_Accu: 58%  \tValid_Acc:13%  \tVal_kappa : 0.023  \n",
            "Epoch: 86 \tTraining Loss:  0.901 \tTrain_Accu: 58%  \tValid_Acc:16%  \tVal_kappa : -0.190  \n",
            "Epoch: 87 \tTraining Loss:  0.822 \tTrain_Accu: 63%  \tValid_Acc:21%  \tVal_kappa : -0.322  \n",
            "Epoch: 88 \tTraining Loss:  0.857 \tTrain_Accu: 63%  \tValid_Acc:24%  \tVal_kappa : -0.082  \n",
            "Epoch: 89 \tTraining Loss:  0.843 \tTrain_Accu: 63%  \tValid_Acc:29%  \tVal_kappa : -0.530  \n",
            "Epoch: 90 \tTraining Loss:  0.889 \tTrain_Accu: 62%  \tValid_Acc:16%  \tVal_kappa : -0.044  \n",
            "Epoch: 91 \tTraining Loss:  0.873 \tTrain_Accu: 59%  \tValid_Acc:19%  \tVal_kappa : 0.148  \n",
            "Epoch: 92 \tTraining Loss:  0.817 \tTrain_Accu: 68%  \tValid_Acc:26%  \tVal_kappa : 0.118  \n",
            "Epoch: 93 \tTraining Loss:  0.834 \tTrain_Accu: 62%  \tValid_Acc:23%  \tVal_kappa : 0.076  \n",
            "Epoch: 94 \tTraining Loss:  0.805 \tTrain_Accu: 66%  \tValid_Acc:21%  \tVal_kappa : 0.122  \n",
            "Epoch: 95 \tTraining Loss:  0.769 \tTrain_Accu: 64%  \tValid_Acc:24%  \tVal_kappa : 0.156  \n",
            "Epoch: 96 \tTraining Loss:  0.851 \tTrain_Accu: 62%  \tValid_Acc:20%  \tVal_kappa : -0.102  \n",
            "Epoch: 97 \tTraining Loss:  0.794 \tTrain_Accu: 66%  \tValid_Acc:20%  \tVal_kappa : 0.186  \n",
            "Epoch: 98 \tTraining Loss:  0.798 \tTrain_Accu: 68%  \tValid_Acc:26%  \tVal_kappa : -0.103  \n",
            "Epoch: 99 \tTraining Loss:  0.754 \tTrain_Accu: 67%  \tValid_Acc:27%  \tVal_kappa : -0.001  \n",
            "Epoch: 100 \tTraining Loss:  0.868 \tTrain_Accu: 61%  \tValid_Acc:27%  \tVal_kappa : -0.076  \n",
            "Epoch: 101 \tTraining Loss:  0.768 \tTrain_Accu: 68%  \tValid_Acc:30%  \tVal_kappa : 0.222  \n",
            "Epoch: 102 \tTraining Loss:  0.769 \tTrain_Accu: 68%  \tValid_Acc:16%  \tVal_kappa : 0.007  \n",
            "Epoch: 103 \tTraining Loss:  0.755 \tTrain_Accu: 66%  \tValid_Acc:21%  \tVal_kappa : 0.043  \n",
            "Epoch: 104 \tTraining Loss:  0.739 \tTrain_Accu: 68%  \tValid_Acc:19%  \tVal_kappa : -0.338  \n",
            "Epoch: 105 \tTraining Loss:  0.820 \tTrain_Accu: 64%  \tValid_Acc:16%  \tVal_kappa : 0.140  \n",
            "Epoch: 106 \tTraining Loss:  0.787 \tTrain_Accu: 66%  \tValid_Acc:23%  \tVal_kappa : -0.306  \n",
            "Epoch: 107 \tTraining Loss:  0.740 \tTrain_Accu: 68%  \tValid_Acc:14%  \tVal_kappa : -0.182  \n",
            "Epoch: 108 \tTraining Loss:  0.771 \tTrain_Accu: 67%  \tValid_Acc:23%  \tVal_kappa : -0.153  \n",
            "Epoch: 109 \tTraining Loss:  0.727 \tTrain_Accu: 70%  \tValid_Acc:26%  \tVal_kappa : -0.167  \n",
            "Epoch: 110 \tTraining Loss:  0.770 \tTrain_Accu: 69%  \tValid_Acc:30%  \tVal_kappa : -0.159  \n",
            "Epoch: 111 \tTraining Loss:  0.794 \tTrain_Accu: 63%  \tValid_Acc:24%  \tVal_kappa : 0.047  \n",
            "Epoch: 112 \tTraining Loss:  0.771 \tTrain_Accu: 67%  \tValid_Acc:23%  \tVal_kappa : 0.413  \n",
            "Epoch: 113 \tTraining Loss:  0.774 \tTrain_Accu: 68%  \tValid_Acc:19%  \tVal_kappa : -0.082  \n",
            "Epoch: 114 \tTraining Loss:  0.772 \tTrain_Accu: 66%  \tValid_Acc:26%  \tVal_kappa : -0.231  \n",
            "Epoch: 115 \tTraining Loss:  0.792 \tTrain_Accu: 62%  \tValid_Acc:16%  \tVal_kappa : 0.167  \n",
            "Epoch: 116 \tTraining Loss:  0.661 \tTrain_Accu: 73%  \tValid_Acc:19%  \tVal_kappa : 0.469  \n",
            "Epoch: 117 \tTraining Loss:  0.702 \tTrain_Accu: 70%  \tValid_Acc:17%  \tVal_kappa : 0.172  \n",
            "Epoch: 118 \tTraining Loss:  0.672 \tTrain_Accu: 72%  \tValid_Acc:24%  \tVal_kappa : -0.007  \n",
            "Epoch: 119 \tTraining Loss:  0.762 \tTrain_Accu: 68%  \tValid_Acc:19%  \tVal_kappa : 0.164  \n",
            "Epoch: 120 \tTraining Loss:  0.752 \tTrain_Accu: 67%  \tValid_Acc:23%  \tVal_kappa : -0.216  \n",
            "Epoch: 121 \tTraining Loss:  0.726 \tTrain_Accu: 69%  \tValid_Acc:17%  \tVal_kappa : -0.259  \n",
            "Epoch: 122 \tTraining Loss:  0.722 \tTrain_Accu: 70%  \tValid_Acc:21%  \tVal_kappa : -0.304  \n",
            "Epoch: 123 \tTraining Loss:  0.695 \tTrain_Accu: 70%  \tValid_Acc:29%  \tVal_kappa : -0.120  \n",
            "Epoch: 124 \tTraining Loss:  0.700 \tTrain_Accu: 70%  \tValid_Acc:19%  \tVal_kappa : 0.171  \n",
            "Epoch: 125 \tTraining Loss:  0.741 \tTrain_Accu: 68%  \tValid_Acc:23%  \tVal_kappa : 0.401  \n",
            "Epoch: 126 \tTraining Loss:  0.713 \tTrain_Accu: 70%  \tValid_Acc:30%  \tVal_kappa : 0.180  \n",
            "Epoch: 127 \tTraining Loss:  0.674 \tTrain_Accu: 68%  \tValid_Acc:19%  \tVal_kappa : -0.173  \n",
            "Epoch: 128 \tTraining Loss:  0.656 \tTrain_Accu: 71%  \tValid_Acc:17%  \tVal_kappa : 0.025  \n",
            "Epoch: 129 \tTraining Loss:  0.696 \tTrain_Accu: 69%  \tValid_Acc:21%  \tVal_kappa : -0.463  \n",
            "Epoch: 130 \tTraining Loss:  0.680 \tTrain_Accu: 69%  \tValid_Acc:20%  \tVal_kappa : 0.308  \n",
            "Epoch: 131 \tTraining Loss:  0.683 \tTrain_Accu: 73%  \tValid_Acc:20%  \tVal_kappa : -0.228  \n",
            "Epoch: 132 \tTraining Loss:  0.727 \tTrain_Accu: 66%  \tValid_Acc:24%  \tVal_kappa : -0.011  \n",
            "Epoch: 133 \tTraining Loss:  0.575 \tTrain_Accu: 77%  \tValid_Acc:21%  \tVal_kappa : 0.197  \n",
            "Epoch: 134 \tTraining Loss:  0.619 \tTrain_Accu: 73%  \tValid_Acc:26%  \tVal_kappa : -0.113  \n",
            "Epoch: 135 \tTraining Loss:  0.718 \tTrain_Accu: 68%  \tValid_Acc:16%  \tVal_kappa : -0.001  \n",
            "Epoch: 136 \tTraining Loss:  0.725 \tTrain_Accu: 70%  \tValid_Acc:24%  \tVal_kappa : -0.162  \n",
            "Epoch: 137 \tTraining Loss:  0.626 \tTrain_Accu: 71%  \tValid_Acc:24%  \tVal_kappa : -0.556  \n",
            "Epoch: 138 \tTraining Loss:  0.632 \tTrain_Accu: 71%  \tValid_Acc:20%  \tVal_kappa : -0.456  \n",
            "Epoch: 139 \tTraining Loss:  0.691 \tTrain_Accu: 69%  \tValid_Acc:21%  \tVal_kappa : 0.093  \n",
            "Epoch: 140 \tTraining Loss:  0.608 \tTrain_Accu: 73%  \tValid_Acc:16%  \tVal_kappa : -0.037  \n",
            "Epoch: 141 \tTraining Loss:  0.630 \tTrain_Accu: 72%  \tValid_Acc:23%  \tVal_kappa : -0.029  \n",
            "Epoch: 142 \tTraining Loss:  0.609 \tTrain_Accu: 74%  \tValid_Acc:20%  \tVal_kappa : -0.007  \n",
            "Epoch: 143 \tTraining Loss:  0.616 \tTrain_Accu: 72%  \tValid_Acc:20%  \tVal_kappa : -0.106  \n",
            "Epoch: 144 \tTraining Loss:  0.696 \tTrain_Accu: 69%  \tValid_Acc:21%  \tVal_kappa : 0.509  \n",
            "Epoch: 145 \tTraining Loss:  0.635 \tTrain_Accu: 73%  \tValid_Acc:21%  \tVal_kappa : 0.201  \n",
            "Epoch: 146 \tTraining Loss:  0.672 \tTrain_Accu: 70%  \tValid_Acc:20%  \tVal_kappa : 0.136  \n",
            "Epoch: 147 \tTraining Loss:  0.598 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : 0.267  \n",
            "Epoch: 148 \tTraining Loss:  0.646 \tTrain_Accu: 71%  \tValid_Acc:23%  \tVal_kappa : 0.235  \n",
            "Epoch: 149 \tTraining Loss:  0.653 \tTrain_Accu: 72%  \tValid_Acc:21%  \tVal_kappa : 0.034  \n",
            "Epoch: 150 \tTraining Loss:  0.634 \tTrain_Accu: 70%  \tValid_Acc:26%  \tVal_kappa : -0.184  \n",
            "Epoch: 151 \tTraining Loss:  0.551 \tTrain_Accu: 75%  \tValid_Acc:20%  \tVal_kappa : -0.092  \n",
            "Epoch: 152 \tTraining Loss:  0.610 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : 0.035  \n",
            "Epoch: 153 \tTraining Loss:  0.715 \tTrain_Accu: 72%  \tValid_Acc:23%  \tVal_kappa : 0.171  \n",
            "Epoch: 154 \tTraining Loss:  0.591 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : -0.233  \n",
            "Epoch: 155 \tTraining Loss:  0.681 \tTrain_Accu: 75%  \tValid_Acc:29%  \tVal_kappa : -0.191  \n",
            "Epoch: 156 \tTraining Loss:  0.599 \tTrain_Accu: 74%  \tValid_Acc:21%  \tVal_kappa : 0.424  \n",
            "Epoch: 157 \tTraining Loss:  0.592 \tTrain_Accu: 75%  \tValid_Acc:24%  \tVal_kappa : -0.209  \n",
            "Epoch: 158 \tTraining Loss:  0.603 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : -0.068  \n",
            "Epoch: 159 \tTraining Loss:  0.555 \tTrain_Accu: 75%  \tValid_Acc:13%  \tVal_kappa : -0.432  \n",
            "Epoch: 160 \tTraining Loss:  0.646 \tTrain_Accu: 72%  \tValid_Acc:20%  \tVal_kappa : -0.417  \n",
            "Epoch: 161 \tTraining Loss:  0.597 \tTrain_Accu: 74%  \tValid_Acc:20%  \tVal_kappa : -0.112  \n",
            "Epoch: 162 \tTraining Loss:  0.654 \tTrain_Accu: 75%  \tValid_Acc:29%  \tVal_kappa : 0.022  \n",
            "Epoch: 163 \tTraining Loss:  0.697 \tTrain_Accu: 71%  \tValid_Acc:11%  \tVal_kappa : -0.599  \n",
            "Epoch: 164 \tTraining Loss:  0.632 \tTrain_Accu: 74%  \tValid_Acc:24%  \tVal_kappa : -0.184  \n",
            "Epoch: 165 \tTraining Loss:  0.532 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : -0.043  \n",
            "Epoch: 166 \tTraining Loss:  0.592 \tTrain_Accu: 74%  \tValid_Acc:17%  \tVal_kappa : -0.153  \n",
            "Epoch: 167 \tTraining Loss:  0.615 \tTrain_Accu: 74%  \tValid_Acc:17%  \tVal_kappa : -0.032  \n",
            "Epoch: 168 \tTraining Loss:  0.529 \tTrain_Accu: 79%  \tValid_Acc:26%  \tVal_kappa : 0.307  \n",
            "Epoch: 169 \tTraining Loss:  0.574 \tTrain_Accu: 75%  \tValid_Acc:17%  \tVal_kappa : -0.263  \n",
            "Epoch: 170 \tTraining Loss:  0.644 \tTrain_Accu: 71%  \tValid_Acc:29%  \tVal_kappa : -0.520  \n",
            "Epoch: 171 \tTraining Loss:  0.539 \tTrain_Accu: 78%  \tValid_Acc:14%  \tVal_kappa : 0.382  \n",
            "Epoch: 172 \tTraining Loss:  0.567 \tTrain_Accu: 74%  \tValid_Acc:24%  \tVal_kappa : 0.281  \n",
            "Epoch: 173 \tTraining Loss:  0.698 \tTrain_Accu: 70%  \tValid_Acc:20%  \tVal_kappa : 0.003  \n",
            "Epoch: 174 \tTraining Loss:  0.523 \tTrain_Accu: 78%  \tValid_Acc:23%  \tVal_kappa : -0.065  \n",
            "Epoch: 175 \tTraining Loss:  0.588 \tTrain_Accu: 76%  \tValid_Acc:19%  \tVal_kappa : 0.227  \n",
            "Epoch: 176 \tTraining Loss:  0.565 \tTrain_Accu: 74%  \tValid_Acc:17%  \tVal_kappa : 0.159  \n",
            "Epoch: 177 \tTraining Loss:  0.597 \tTrain_Accu: 77%  \tValid_Acc:19%  \tVal_kappa : -0.039  \n",
            "Epoch: 178 \tTraining Loss:  0.496 \tTrain_Accu: 79%  \tValid_Acc:30%  \tVal_kappa : 0.002  \n",
            "Epoch: 179 \tTraining Loss:  0.541 \tTrain_Accu: 74%  \tValid_Acc:14%  \tVal_kappa : -0.388  \n",
            "Epoch: 180 \tTraining Loss:  0.531 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : 0.282  \n",
            "Epoch: 181 \tTraining Loss:  0.600 \tTrain_Accu: 76%  \tValid_Acc:14%  \tVal_kappa : -0.072  \n",
            "Epoch: 182 \tTraining Loss:  0.536 \tTrain_Accu: 77%  \tValid_Acc:21%  \tVal_kappa : -0.170  \n",
            "Epoch: 183 \tTraining Loss:  0.582 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : 0.012  \n",
            "Epoch: 184 \tTraining Loss:  0.516 \tTrain_Accu: 77%  \tValid_Acc:16%  \tVal_kappa : 0.539  \n",
            "Epoch: 185 \tTraining Loss:  0.562 \tTrain_Accu: 78%  \tValid_Acc:16%  \tVal_kappa : -0.267  \n",
            "Epoch: 186 \tTraining Loss:  0.543 \tTrain_Accu: 76%  \tValid_Acc:17%  \tVal_kappa : -0.032  \n",
            "Epoch: 187 \tTraining Loss:  0.628 \tTrain_Accu: 76%  \tValid_Acc:26%  \tVal_kappa : 0.039  \n",
            "Epoch: 188 \tTraining Loss:  0.525 \tTrain_Accu: 77%  \tValid_Acc:23%  \tVal_kappa : 0.033  \n",
            "Epoch: 189 \tTraining Loss:  0.592 \tTrain_Accu: 73%  \tValid_Acc:31%  \tVal_kappa : -0.210  \n",
            "Epoch: 190 \tTraining Loss:  0.545 \tTrain_Accu: 78%  \tValid_Acc:26%  \tVal_kappa : -0.134  \n",
            "Epoch: 191 \tTraining Loss:  0.526 \tTrain_Accu: 75%  \tValid_Acc:17%  \tVal_kappa : 0.134  \n",
            "Epoch: 192 \tTraining Loss:  0.566 \tTrain_Accu: 77%  \tValid_Acc:23%  \tVal_kappa : -0.032  \n",
            "Epoch: 193 \tTraining Loss:  0.496 \tTrain_Accu: 78%  \tValid_Acc:27%  \tVal_kappa : 0.172  \n",
            "Epoch: 194 \tTraining Loss:  0.546 \tTrain_Accu: 77%  \tValid_Acc:29%  \tVal_kappa : -0.256  \n",
            "Epoch: 195 \tTraining Loss:  0.575 \tTrain_Accu: 76%  \tValid_Acc:23%  \tVal_kappa : -0.297  \n",
            "Epoch: 196 \tTraining Loss:  0.556 \tTrain_Accu: 77%  \tValid_Acc:21%  \tVal_kappa : 0.312  \n",
            "Epoch: 197 \tTraining Loss:  0.600 \tTrain_Accu: 74%  \tValid_Acc:19%  \tVal_kappa : -0.032  \n",
            "Epoch: 198 \tTraining Loss:  0.528 \tTrain_Accu: 76%  \tValid_Acc:23%  \tVal_kappa : -0.188  \n",
            "Epoch: 199 \tTraining Loss:  0.572 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : 0.617  \n",
            "Epoch: 200 \tTraining Loss:  0.499 \tTrain_Accu: 79%  \tValid_Acc:20%  \tVal_kappa : -0.416  \n",
            "Epoch: 201 \tTraining Loss:  0.485 \tTrain_Accu: 82%  \tValid_Acc:20%  \tVal_kappa : -0.285  \n",
            "Epoch: 202 \tTraining Loss:  0.518 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : -0.103  \n",
            "Epoch: 203 \tTraining Loss:  0.621 \tTrain_Accu: 75%  \tValid_Acc:17%  \tVal_kappa : 0.071  \n",
            "Epoch: 204 \tTraining Loss:  0.529 \tTrain_Accu: 79%  \tValid_Acc:21%  \tVal_kappa : 0.493  \n",
            "Epoch: 205 \tTraining Loss:  0.571 \tTrain_Accu: 76%  \tValid_Acc:19%  \tVal_kappa : 0.053  \n",
            "Epoch: 206 \tTraining Loss:  0.562 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : -0.239  \n",
            "Epoch: 207 \tTraining Loss:  0.564 \tTrain_Accu: 76%  \tValid_Acc:26%  \tVal_kappa : 0.157  \n",
            "Epoch: 208 \tTraining Loss:  0.523 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : 0.291  \n",
            "Epoch: 209 \tTraining Loss:  0.494 \tTrain_Accu: 79%  \tValid_Acc:30%  \tVal_kappa : 0.161  \n",
            "Epoch: 210 \tTraining Loss:  0.531 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : -0.191  \n",
            "Epoch: 211 \tTraining Loss:  0.504 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : 0.227  \n",
            "Epoch: 212 \tTraining Loss:  0.463 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : 0.227  \n",
            "Epoch: 213 \tTraining Loss:  0.556 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : 0.140  \n",
            "Epoch: 214 \tTraining Loss:  0.472 \tTrain_Accu: 81%  \tValid_Acc:20%  \tVal_kappa : 0.388  \n",
            "Epoch: 215 \tTraining Loss:  0.456 \tTrain_Accu: 82%  \tValid_Acc:20%  \tVal_kappa : 0.043  \n",
            "Epoch: 216 \tTraining Loss:  0.548 \tTrain_Accu: 76%  \tValid_Acc:16%  \tVal_kappa : -0.093  \n",
            "Epoch: 217 \tTraining Loss:  0.549 \tTrain_Accu: 78%  \tValid_Acc:27%  \tVal_kappa : 0.000  \n",
            "Epoch: 218 \tTraining Loss:  0.551 \tTrain_Accu: 78%  \tValid_Acc:10%  \tVal_kappa : -0.287  \n",
            "Epoch: 219 \tTraining Loss:  0.464 \tTrain_Accu: 79%  \tValid_Acc:20%  \tVal_kappa : 0.152  \n",
            "Epoch: 220 \tTraining Loss:  0.521 \tTrain_Accu: 78%  \tValid_Acc:14%  \tVal_kappa : 0.159  \n",
            "Epoch: 221 \tTraining Loss:  0.640 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : -0.121  \n",
            "Epoch: 222 \tTraining Loss:  0.600 \tTrain_Accu: 75%  \tValid_Acc:17%  \tVal_kappa : -0.469  \n",
            "Epoch: 223 \tTraining Loss:  0.558 \tTrain_Accu: 77%  \tValid_Acc:14%  \tVal_kappa : 0.045  \n",
            "Epoch: 224 \tTraining Loss:  0.517 \tTrain_Accu: 82%  \tValid_Acc:14%  \tVal_kappa : 0.220  \n",
            "Epoch: 225 \tTraining Loss:  0.460 \tTrain_Accu: 80%  \tValid_Acc:16%  \tVal_kappa : -0.409  \n",
            "Epoch: 226 \tTraining Loss:  0.480 \tTrain_Accu: 78%  \tValid_Acc:17%  \tVal_kappa : 0.069  \n",
            "Epoch: 227 \tTraining Loss:  0.461 \tTrain_Accu: 81%  \tValid_Acc:16%  \tVal_kappa : -0.204  \n",
            "Epoch: 228 \tTraining Loss:  0.592 \tTrain_Accu: 77%  \tValid_Acc:26%  \tVal_kappa : 0.321  \n",
            "Epoch: 229 \tTraining Loss:  0.458 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : 0.106  \n",
            "Epoch: 230 \tTraining Loss:  0.500 \tTrain_Accu: 80%  \tValid_Acc:16%  \tVal_kappa : -0.594  \n",
            "Epoch: 231 \tTraining Loss:  0.516 \tTrain_Accu: 77%  \tValid_Acc:23%  \tVal_kappa : -0.078  \n",
            "Epoch: 232 \tTraining Loss:  0.466 \tTrain_Accu: 79%  \tValid_Acc:20%  \tVal_kappa : -0.061  \n",
            "Epoch: 233 \tTraining Loss:  0.505 \tTrain_Accu: 79%  \tValid_Acc:24%  \tVal_kappa : -0.023  \n",
            "Epoch: 234 \tTraining Loss:  0.522 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : -0.036  \n",
            "Epoch: 235 \tTraining Loss:  0.407 \tTrain_Accu: 82%  \tValid_Acc:20%  \tVal_kappa : -0.047  \n",
            "Epoch: 236 \tTraining Loss:  0.550 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : -0.323  \n",
            "Epoch: 237 \tTraining Loss:  0.522 \tTrain_Accu: 75%  \tValid_Acc:20%  \tVal_kappa : -0.234  \n",
            "Epoch: 238 \tTraining Loss:  0.472 \tTrain_Accu: 80%  \tValid_Acc:19%  \tVal_kappa : 0.090  \n",
            "Epoch: 239 \tTraining Loss:  0.467 \tTrain_Accu: 81%  \tValid_Acc:21%  \tVal_kappa : -0.069  \n",
            "Epoch: 240 \tTraining Loss:  0.508 \tTrain_Accu: 79%  \tValid_Acc:16%  \tVal_kappa : 0.124  \n",
            "Epoch: 241 \tTraining Loss:  0.474 \tTrain_Accu: 82%  \tValid_Acc:20%  \tVal_kappa : 0.161  \n",
            "Epoch: 242 \tTraining Loss:  0.511 \tTrain_Accu: 80%  \tValid_Acc:17%  \tVal_kappa : 0.312  \n",
            "Epoch: 243 \tTraining Loss:  0.508 \tTrain_Accu: 75%  \tValid_Acc:23%  \tVal_kappa : -0.043  \n",
            "Epoch: 244 \tTraining Loss:  0.562 \tTrain_Accu: 78%  \tValid_Acc:17%  \tVal_kappa : 0.172  \n",
            "Epoch: 245 \tTraining Loss:  0.610 \tTrain_Accu: 74%  \tValid_Acc:13%  \tVal_kappa : 0.350  \n",
            "Epoch: 246 \tTraining Loss:  0.530 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : 0.172  \n",
            "Epoch: 247 \tTraining Loss:  0.580 \tTrain_Accu: 80%  \tValid_Acc:16%  \tVal_kappa : -0.009  \n",
            "Epoch: 248 \tTraining Loss:  0.533 \tTrain_Accu: 76%  \tValid_Acc:14%  \tVal_kappa : 0.321  \n",
            "Epoch: 249 \tTraining Loss:  0.473 \tTrain_Accu: 79%  \tValid_Acc:17%  \tVal_kappa : 0.089  \n",
            "Epoch: 250 \tTraining Loss:  0.472 \tTrain_Accu: 81%  \tValid_Acc:20%  \tVal_kappa : -0.323  \n",
            "Epoch: 251 \tTraining Loss:  0.475 \tTrain_Accu: 83%  \tValid_Acc:19%  \tVal_kappa : -0.279  \n",
            "Epoch: 252 \tTraining Loss:  0.553 \tTrain_Accu: 77%  \tValid_Acc:23%  \tVal_kappa : 0.061  \n",
            "Epoch: 253 \tTraining Loss:  0.552 \tTrain_Accu: 76%  \tValid_Acc:19%  \tVal_kappa : -0.129  \n",
            "Epoch: 254 \tTraining Loss:  0.415 \tTrain_Accu: 83%  \tValid_Acc:17%  \tVal_kappa : -0.284  \n",
            "Epoch: 255 \tTraining Loss:  0.524 \tTrain_Accu: 82%  \tValid_Acc:19%  \tVal_kappa : -0.148  \n",
            "Epoch: 256 \tTraining Loss:  0.426 \tTrain_Accu: 81%  \tValid_Acc:14%  \tVal_kappa : -0.102  \n",
            "Epoch: 257 \tTraining Loss:  0.546 \tTrain_Accu: 77%  \tValid_Acc:14%  \tVal_kappa : 0.000  \n",
            "Epoch: 258 \tTraining Loss:  0.516 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : 0.185  \n",
            "Epoch: 259 \tTraining Loss:  0.410 \tTrain_Accu: 83%  \tValid_Acc:14%  \tVal_kappa : 0.043  \n",
            "Epoch: 260 \tTraining Loss:  0.474 \tTrain_Accu: 80%  \tValid_Acc:20%  \tVal_kappa : -0.001  \n",
            "Epoch: 261 \tTraining Loss:  0.510 \tTrain_Accu: 78%  \tValid_Acc:17%  \tVal_kappa : -0.487  \n",
            "Epoch: 262 \tTraining Loss:  0.433 \tTrain_Accu: 82%  \tValid_Acc:17%  \tVal_kappa : 0.026  \n",
            "Epoch: 263 \tTraining Loss:  0.502 \tTrain_Accu: 81%  \tValid_Acc:14%  \tVal_kappa : -0.297  \n",
            "Epoch: 264 \tTraining Loss:  0.513 \tTrain_Accu: 80%  \tValid_Acc:20%  \tVal_kappa : 0.231  \n",
            "Epoch: 265 \tTraining Loss:  0.577 \tTrain_Accu: 77%  \tValid_Acc:19%  \tVal_kappa : 0.000  \n",
            "Epoch: 266 \tTraining Loss:  0.507 \tTrain_Accu: 79%  \tValid_Acc:17%  \tVal_kappa : 0.271  \n",
            "Epoch: 267 \tTraining Loss:  0.494 \tTrain_Accu: 79%  \tValid_Acc:19%  \tVal_kappa : -0.272  \n",
            "Epoch: 268 \tTraining Loss:  0.492 \tTrain_Accu: 78%  \tValid_Acc:16%  \tVal_kappa : 0.340  \n",
            "Epoch: 269 \tTraining Loss:  0.475 \tTrain_Accu: 82%  \tValid_Acc:16%  \tVal_kappa : -0.052  \n",
            "Epoch: 270 \tTraining Loss:  0.539 \tTrain_Accu: 78%  \tValid_Acc:17%  \tVal_kappa : 0.159  \n",
            "Epoch: 271 \tTraining Loss:  0.510 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : -0.263  \n",
            "Epoch: 272 \tTraining Loss:  0.527 \tTrain_Accu: 77%  \tValid_Acc:21%  \tVal_kappa : -0.160  \n",
            "Epoch: 273 \tTraining Loss:  0.445 \tTrain_Accu: 79%  \tValid_Acc:24%  \tVal_kappa : -0.046  \n",
            "Epoch: 274 \tTraining Loss:  0.436 \tTrain_Accu: 81%  \tValid_Acc:21%  \tVal_kappa : -0.365  \n",
            "Epoch: 275 \tTraining Loss:  0.447 \tTrain_Accu: 79%  \tValid_Acc:19%  \tVal_kappa : 0.150  \n",
            "Epoch: 276 \tTraining Loss:  0.384 \tTrain_Accu: 82%  \tValid_Acc:20%  \tVal_kappa : -0.245  \n",
            "Epoch: 277 \tTraining Loss:  0.435 \tTrain_Accu: 82%  \tValid_Acc:20%  \tVal_kappa : 0.141  \n",
            "Epoch: 278 \tTraining Loss:  0.442 \tTrain_Accu: 84%  \tValid_Acc:21%  \tVal_kappa : -0.352  \n",
            "Epoch: 279 \tTraining Loss:  0.490 \tTrain_Accu: 82%  \tValid_Acc:13%  \tVal_kappa : 0.201  \n",
            "Epoch: 280 \tTraining Loss:  0.543 \tTrain_Accu: 81%  \tValid_Acc:19%  \tVal_kappa : 0.159  \n",
            "Epoch: 281 \tTraining Loss:  0.460 \tTrain_Accu: 80%  \tValid_Acc:16%  \tVal_kappa : -0.180  \n",
            "Epoch: 282 \tTraining Loss:  0.451 \tTrain_Accu: 82%  \tValid_Acc:21%  \tVal_kappa : 0.159  \n",
            "Epoch: 283 \tTraining Loss:  0.460 \tTrain_Accu: 80%  \tValid_Acc:19%  \tVal_kappa : -0.244  \n",
            "Epoch: 284 \tTraining Loss:  0.457 \tTrain_Accu: 80%  \tValid_Acc:29%  \tVal_kappa : -0.193  \n",
            "Epoch: 285 \tTraining Loss:  0.498 \tTrain_Accu: 80%  \tValid_Acc:13%  \tVal_kappa : 0.195  \n",
            "Epoch: 286 \tTraining Loss:  0.472 \tTrain_Accu: 79%  \tValid_Acc:17%  \tVal_kappa : -0.124  \n",
            "Epoch: 287 \tTraining Loss:  0.496 \tTrain_Accu: 81%  \tValid_Acc:23%  \tVal_kappa : 0.107  \n",
            "Epoch: 288 \tTraining Loss:  0.400 \tTrain_Accu: 84%  \tValid_Acc:20%  \tVal_kappa : -0.097  \n",
            "Epoch: 289 \tTraining Loss:  0.465 \tTrain_Accu: 80%  \tValid_Acc:11%  \tVal_kappa : 0.159  \n",
            "Epoch: 290 \tTraining Loss:  0.432 \tTrain_Accu: 83%  \tValid_Acc:21%  \tVal_kappa : -0.078  \n",
            "Epoch: 291 \tTraining Loss:  0.475 \tTrain_Accu: 83%  \tValid_Acc:30%  \tVal_kappa : -0.398  \n",
            "Epoch: 292 \tTraining Loss:  0.511 \tTrain_Accu: 81%  \tValid_Acc:17%  \tVal_kappa : -0.025  \n",
            "Epoch: 293 \tTraining Loss:  0.433 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : 0.310  \n",
            "Epoch: 294 \tTraining Loss:  0.508 \tTrain_Accu: 77%  \tValid_Acc:24%  \tVal_kappa : 0.086  \n",
            "Epoch: 295 \tTraining Loss:  0.522 \tTrain_Accu: 78%  \tValid_Acc:17%  \tVal_kappa : -0.144  \n",
            "Epoch: 296 \tTraining Loss:  0.475 \tTrain_Accu: 77%  \tValid_Acc:26%  \tVal_kappa : -0.245  \n",
            "Epoch: 297 \tTraining Loss:  0.495 \tTrain_Accu: 81%  \tValid_Acc:16%  \tVal_kappa : 0.061  \n",
            "Epoch: 298 \tTraining Loss:  0.424 \tTrain_Accu: 82%  \tValid_Acc:19%  \tVal_kappa : 0.026  \n",
            "Epoch: 299 \tTraining Loss:  0.395 \tTrain_Accu: 84%  \tValid_Acc:19%  \tVal_kappa : -0.263  \n",
            "Epoch: 300 \tTraining Loss:  0.473 \tTrain_Accu: 79%  \tValid_Acc:26%  \tVal_kappa : 0.148  \n",
            "Epoch: 301 \tTraining Loss:  0.449 \tTrain_Accu: 79%  \tValid_Acc:24%  \tVal_kappa : 0.067  \n",
            "Epoch: 302 \tTraining Loss:  0.390 \tTrain_Accu: 84%  \tValid_Acc:21%  \tVal_kappa : -0.161  \n",
            "Epoch: 303 \tTraining Loss:  0.452 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : -0.026  \n",
            "Epoch: 304 \tTraining Loss:  0.573 \tTrain_Accu: 77%  \tValid_Acc:19%  \tVal_kappa : -0.080  \n",
            "Epoch: 305 \tTraining Loss:  0.535 \tTrain_Accu: 79%  \tValid_Acc:21%  \tVal_kappa : -0.185  \n",
            "Epoch: 306 \tTraining Loss:  0.478 \tTrain_Accu: 79%  \tValid_Acc:17%  \tVal_kappa : 0.003  \n",
            "Epoch: 307 \tTraining Loss:  0.416 \tTrain_Accu: 82%  \tValid_Acc:24%  \tVal_kappa : -0.258  \n",
            "Epoch: 308 \tTraining Loss:  0.459 \tTrain_Accu: 82%  \tValid_Acc:14%  \tVal_kappa : -0.003  \n",
            "Epoch: 309 \tTraining Loss:  0.410 \tTrain_Accu: 82%  \tValid_Acc:17%  \tVal_kappa : 0.265  \n",
            "Epoch: 310 \tTraining Loss:  0.405 \tTrain_Accu: 85%  \tValid_Acc:21%  \tVal_kappa : -0.061  \n",
            "Epoch: 311 \tTraining Loss:  0.417 \tTrain_Accu: 83%  \tValid_Acc:21%  \tVal_kappa : 0.093  \n",
            "Epoch: 312 \tTraining Loss:  0.397 \tTrain_Accu: 85%  \tValid_Acc:24%  \tVal_kappa : -0.153  \n",
            "Epoch: 313 \tTraining Loss:  0.436 \tTrain_Accu: 83%  \tValid_Acc:19%  \tVal_kappa : 0.222  \n",
            "Epoch: 314 \tTraining Loss:  0.436 \tTrain_Accu: 79%  \tValid_Acc:16%  \tVal_kappa : 0.106  \n",
            "Epoch: 315 \tTraining Loss:  0.420 \tTrain_Accu: 84%  \tValid_Acc:21%  \tVal_kappa : -0.406  \n",
            "Epoch: 316 \tTraining Loss:  0.488 \tTrain_Accu: 82%  \tValid_Acc:16%  \tVal_kappa : -0.003  \n",
            "Epoch: 317 \tTraining Loss:  0.421 \tTrain_Accu: 83%  \tValid_Acc:20%  \tVal_kappa : -0.007  \n",
            "Epoch: 318 \tTraining Loss:  0.425 \tTrain_Accu: 82%  \tValid_Acc:21%  \tVal_kappa : -0.003  \n",
            "Epoch: 319 \tTraining Loss:  0.440 \tTrain_Accu: 82%  \tValid_Acc:21%  \tVal_kappa : 0.175  \n",
            "Epoch: 320 \tTraining Loss:  0.453 \tTrain_Accu: 83%  \tValid_Acc:17%  \tVal_kappa : -0.199  \n",
            "Epoch: 321 \tTraining Loss:  0.432 \tTrain_Accu: 81%  \tValid_Acc:17%  \tVal_kappa : 0.061  \n",
            "Epoch: 322 \tTraining Loss:  0.409 \tTrain_Accu: 83%  \tValid_Acc:29%  \tVal_kappa : 0.033  \n",
            "Epoch: 323 \tTraining Loss:  0.532 \tTrain_Accu: 79%  \tValid_Acc:21%  \tVal_kappa : -0.080  \n",
            "Epoch: 324 \tTraining Loss:  0.493 \tTrain_Accu: 78%  \tValid_Acc:23%  \tVal_kappa : -0.280  \n",
            "Epoch: 325 \tTraining Loss:  0.382 \tTrain_Accu: 84%  \tValid_Acc:20%  \tVal_kappa : -0.026  \n",
            "Epoch: 326 \tTraining Loss:  0.377 \tTrain_Accu: 83%  \tValid_Acc:19%  \tVal_kappa : -0.131  \n",
            "Epoch: 327 \tTraining Loss:  0.410 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : 0.033  \n",
            "Epoch: 328 \tTraining Loss:  0.498 \tTrain_Accu: 77%  \tValid_Acc:23%  \tVal_kappa : -0.069  \n",
            "Epoch: 329 \tTraining Loss:  0.469 \tTrain_Accu: 80%  \tValid_Acc:27%  \tVal_kappa : 0.253  \n",
            "Epoch: 330 \tTraining Loss:  0.437 \tTrain_Accu: 82%  \tValid_Acc:21%  \tVal_kappa : -0.026  \n",
            "Epoch: 331 \tTraining Loss:  0.386 \tTrain_Accu: 84%  \tValid_Acc:20%  \tVal_kappa : 0.222  \n",
            "Epoch: 332 \tTraining Loss:  0.445 \tTrain_Accu: 83%  \tValid_Acc:20%  \tVal_kappa : 0.025  \n",
            "Epoch: 333 \tTraining Loss:  0.427 \tTrain_Accu: 82%  \tValid_Acc:21%  \tVal_kappa : -0.180  \n",
            "Epoch: 334 \tTraining Loss:  0.430 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : 0.111  \n",
            "Epoch: 335 \tTraining Loss:  0.425 \tTrain_Accu: 84%  \tValid_Acc:16%  \tVal_kappa : -0.078  \n",
            "Epoch: 336 \tTraining Loss:  0.478 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : 0.434  \n",
            "Epoch: 337 \tTraining Loss:  0.439 \tTrain_Accu: 85%  \tValid_Acc:20%  \tVal_kappa : -0.402  \n",
            "Epoch: 338 \tTraining Loss:  0.492 \tTrain_Accu: 79%  \tValid_Acc:26%  \tVal_kappa : 0.061  \n",
            "Epoch: 339 \tTraining Loss:  0.464 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : -0.290  \n",
            "Epoch: 340 \tTraining Loss:  0.430 \tTrain_Accu: 84%  \tValid_Acc:21%  \tVal_kappa : 0.307  \n",
            "Epoch: 341 \tTraining Loss:  0.464 \tTrain_Accu: 82%  \tValid_Acc:21%  \tVal_kappa : -0.145  \n",
            "Epoch: 342 \tTraining Loss:  0.570 \tTrain_Accu: 76%  \tValid_Acc:31%  \tVal_kappa : -0.435  \n",
            "Epoch: 343 \tTraining Loss:  0.374 \tTrain_Accu: 84%  \tValid_Acc:19%  \tVal_kappa : -0.449  \n",
            "Epoch: 344 \tTraining Loss:  0.437 \tTrain_Accu: 83%  \tValid_Acc:24%  \tVal_kappa : -0.275  \n",
            "Epoch: 345 \tTraining Loss:  0.440 \tTrain_Accu: 81%  \tValid_Acc:17%  \tVal_kappa : -0.182  \n",
            "Epoch: 346 \tTraining Loss:  0.438 \tTrain_Accu: 80%  \tValid_Acc:19%  \tVal_kappa : 0.043  \n",
            "Epoch: 347 \tTraining Loss:  0.479 \tTrain_Accu: 82%  \tValid_Acc:20%  \tVal_kappa : 0.045  \n",
            "Epoch: 348 \tTraining Loss:  0.400 \tTrain_Accu: 84%  \tValid_Acc:26%  \tVal_kappa : -0.354  \n",
            "Epoch: 349 \tTraining Loss:  0.472 \tTrain_Accu: 82%  \tValid_Acc:24%  \tVal_kappa : 0.000  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 04:01:29,574]\u001b[0m Trial 0 finished with value: 15.7 and parameters: {}. Best is trial 0 with value: 15.7.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 350 \tTraining Loss:  0.323 \tTrain_Accu: 87%  \tValid_Acc:16%  \tVal_kappa : 0.079  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['optimise_valid_NSI_drop(0.5).torch']"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWfvQA_Kyp9W"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "efdLGEtirLUR",
        "outputId": "2b574086-98f0-493b-dfe7-51b7746fac9b"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_temp_NSI[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_dropout(0.8)\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_NSI_temp_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 3, 2, 1, 2, 1, 1, 4, 1, 1, 2, 1, 1, 0, 2, 3, 1, 1, 1, 1, 2, 0, 2, 4,\n",
            "        3, 2, 2, 0, 0, 1, 3, 2, 3, 2, 1, 2, 1, 3, 3, 4, 2, 2, 3, 2, 2, 1, 4, 1,\n",
            "        4, 1, 3, 1, 2, 1, 3, 2, 3, 1, 3, 1, 2, 2, 2, 2, 3, 1, 2, 1, 2, 0])\n",
            "labels tensor([0, 2, 3, 4, 4, 4, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 2, 2, 0, 1, 0, 1, 1, 4,\n",
            "        4, 4, 4, 4, 4, 3, 2, 1, 3, 1, 0, 0, 0, 3, 3, 3, 2, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 3, 3, 2, 3, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 3, 4, 3, 2, 0, 2, 2])\n",
            "correct : 15\n",
            "test_Accuracy % : 21.4\n",
            "kappa 0.20463960231980116\n",
            "[[0 5 2 0 0]\n",
            " [1 2 3 0 0]\n",
            " [1 5 3 2 0]\n",
            " [1 6 7 7 2]\n",
            " [2 6 8 4 3]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyM2IKsM0A4V"
      },
      "source": [
        "## WSI_temp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGiTEos1yp9Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "41f39bcb-1619-4129-b217-89f728db25e5"
      },
      "source": [
        "# Reading rainfall file of NNI region \n",
        "Data_temp_WSI = pd.read_csv(\"drive/My Drive/DL_project/Target_TMean_WSI_regional_ave_time_series.csv\")\n",
        "Data_temp_WSI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>Tmean_N</th>\n",
              "      <th>cat_3</th>\n",
              "      <th>cat_5</th>\n",
              "      <th>anomalies</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-04-01</td>\n",
              "      <td>11.319537</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.627651</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-05-01</td>\n",
              "      <td>8.644334</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.343807</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-06-01</td>\n",
              "      <td>5.656854</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.004109</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-07-01</td>\n",
              "      <td>3.329886</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.359621</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-08-01</td>\n",
              "      <td>2.483252</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.633298</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>2019-08-01</td>\n",
              "      <td>3.831511</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.714960</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>4.440939</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.414789</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>2019-10-01</td>\n",
              "      <td>5.329010</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.413333</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>7.637988</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.054893</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>9.319395</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.121614</td>\n",
              "      <td>WSI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>465 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           time    Tmean_N  cat_3  cat_5  anomalies region\n",
              "0    1981-04-01  11.319537      3      5   0.627651    WSI\n",
              "1    1981-05-01   8.644334      3      4   0.343807    WSI\n",
              "2    1981-06-01   5.656854      2      3  -0.004109    WSI\n",
              "3    1981-07-01   3.329886      1      2  -0.359621    WSI\n",
              "4    1981-08-01   2.483252      1      1  -0.633298    WSI\n",
              "..          ...        ...    ...    ...        ...    ...\n",
              "460  2019-08-01   3.831511      3      5   0.714960    WSI\n",
              "461  2019-09-01   4.440939      3      4   0.414789    WSI\n",
              "462  2019-10-01   5.329010      1      2  -0.413333    WSI\n",
              "463  2019-11-01   7.637988      2      3   0.054893    WSI\n",
              "464  2019-12-01   9.319395      2      3  -0.121614    WSI\n",
              "\n",
              "[465 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhBgp_C8yp9Z"
      },
      "source": [
        "# Extracting label column\n",
        "labels_temp_WSI = Data_temp_WSI['cat_5'].astype(int) #cat5 column - so 5 prediction classes "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubwnJ6qyyp9Z"
      },
      "source": [
        "# Function that will convert labels into Pytorch tensors\n",
        "\n",
        "def labels_Tensors(labels):\n",
        "    return (torch.from_numpy(labels.values).type(torch.LongTensor)-1) #cat5 in form 1, 2, 3, 4, 5;\n",
        "\n",
        "# Converting labels of Temp_WSI region into tensors\n",
        "labelsTensors_temp_WSI = labels_Tensors(labels_temp_WSI) # This represents y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e2YQwWayp9a",
        "outputId": "362ba0f6-d0ff-4109-f83b-e2e10695f8ed"
      },
      "source": [
        "train_lab_WSI = labels_temp_WSI[:325]\n",
        "train_lab_WSI.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    68\n",
              "5    65\n",
              "2    65\n",
              "4    63\n",
              "3    63\n",
              "Name: cat_5, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BTAbCpvyp9a"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_valid_loaders_WSI_temp(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_WSI[:325])\n",
        "    validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_WSI[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "   \n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-P5sUZlJTVv"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_temp_WSI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 1,\n",
        "          'n_epochs' : 350,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           'dropout'       : 0.8,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_WSI_temp(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_WSI[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_WSI[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 10\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_temp_WSI[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_temp_WSI[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_WSI_temp_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnK_aBnFyp9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6abd411f-079f-4450-f674-ebfd2cc64308"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_temp_WSI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"optimise_valid_WSI_temp_drop(0.5).torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.710 \tTrain_Accu: 18%  \tValid_Acc:10%  \tVal_kappa : 0.030  \n",
            "Epoch: 2 \tTraining Loss:  1.610 \tTrain_Accu: 21%  \tValid_Acc:14%  \tVal_kappa : 0.127  \n",
            "Epoch: 3 \tTraining Loss:  1.605 \tTrain_Accu: 21%  \tValid_Acc:17%  \tVal_kappa : 0.119  \n",
            "Epoch: 4 \tTraining Loss:  1.604 \tTrain_Accu: 20%  \tValid_Acc:11%  \tVal_kappa : 0.213  \n",
            "Epoch: 5 \tTraining Loss:  1.595 \tTrain_Accu: 22%  \tValid_Acc:20%  \tVal_kappa : -0.037  \n",
            "Epoch: 6 \tTraining Loss:  1.596 \tTrain_Accu: 22%  \tValid_Acc:21%  \tVal_kappa : 0.178  \n",
            "Epoch: 7 \tTraining Loss:  1.591 \tTrain_Accu: 22%  \tValid_Acc:14%  \tVal_kappa : -0.144  \n",
            "Epoch: 8 \tTraining Loss:  1.592 \tTrain_Accu: 26%  \tValid_Acc:16%  \tVal_kappa : 0.116  \n",
            "Epoch: 9 \tTraining Loss:  1.586 \tTrain_Accu: 23%  \tValid_Acc:21%  \tVal_kappa : -0.327  \n",
            "Epoch: 10 \tTraining Loss:  1.580 \tTrain_Accu: 25%  \tValid_Acc:19%  \tVal_kappa : 0.083  \n",
            "Epoch: 11 \tTraining Loss:  1.554 \tTrain_Accu: 28%  \tValid_Acc:17%  \tVal_kappa : 0.036  \n",
            "Epoch: 12 \tTraining Loss:  1.568 \tTrain_Accu: 22%  \tValid_Acc:19%  \tVal_kappa : 0.116  \n",
            "Epoch: 13 \tTraining Loss:  1.543 \tTrain_Accu: 31%  \tValid_Acc:23%  \tVal_kappa : -0.046  \n",
            "Epoch: 14 \tTraining Loss:  1.552 \tTrain_Accu: 25%  \tValid_Acc:9%  \tVal_kappa : -0.245  \n",
            "Epoch: 15 \tTraining Loss:  1.540 \tTrain_Accu: 28%  \tValid_Acc:20%  \tVal_kappa : -0.094  \n",
            "Epoch: 16 \tTraining Loss:  1.562 \tTrain_Accu: 24%  \tValid_Acc:23%  \tVal_kappa : 0.225  \n",
            "Epoch: 17 \tTraining Loss:  1.559 \tTrain_Accu: 28%  \tValid_Acc:17%  \tVal_kappa : -0.159  \n",
            "Epoch: 18 \tTraining Loss:  1.549 \tTrain_Accu: 27%  \tValid_Acc:16%  \tVal_kappa : -0.280  \n",
            "Epoch: 19 \tTraining Loss:  1.551 \tTrain_Accu: 29%  \tValid_Acc:16%  \tVal_kappa : 0.126  \n",
            "Epoch: 20 \tTraining Loss:  1.507 \tTrain_Accu: 30%  \tValid_Acc:14%  \tVal_kappa : 0.113  \n",
            "Epoch: 21 \tTraining Loss:  1.509 \tTrain_Accu: 30%  \tValid_Acc:23%  \tVal_kappa : -0.422  \n",
            "Epoch: 22 \tTraining Loss:  1.513 \tTrain_Accu: 36%  \tValid_Acc:21%  \tVal_kappa : 0.347  \n",
            "Epoch: 23 \tTraining Loss:  1.490 \tTrain_Accu: 33%  \tValid_Acc:10%  \tVal_kappa : 0.280  \n",
            "Epoch: 24 \tTraining Loss:  1.421 \tTrain_Accu: 34%  \tValid_Acc:24%  \tVal_kappa : 0.055  \n",
            "Epoch: 25 \tTraining Loss:  1.488 \tTrain_Accu: 34%  \tValid_Acc:30%  \tVal_kappa : 0.177  \n",
            "Epoch: 26 \tTraining Loss:  1.447 \tTrain_Accu: 34%  \tValid_Acc:20%  \tVal_kappa : 0.144  \n",
            "Epoch: 27 \tTraining Loss:  1.450 \tTrain_Accu: 35%  \tValid_Acc:19%  \tVal_kappa : 0.326  \n",
            "Epoch: 28 \tTraining Loss:  1.425 \tTrain_Accu: 34%  \tValid_Acc:16%  \tVal_kappa : 0.096  \n",
            "Epoch: 29 \tTraining Loss:  1.439 \tTrain_Accu: 35%  \tValid_Acc:20%  \tVal_kappa : 0.130  \n",
            "Epoch: 30 \tTraining Loss:  1.426 \tTrain_Accu: 35%  \tValid_Acc:23%  \tVal_kappa : 0.256  \n",
            "Epoch: 31 \tTraining Loss:  1.431 \tTrain_Accu: 37%  \tValid_Acc:17%  \tVal_kappa : -0.167  \n",
            "Epoch: 32 \tTraining Loss:  1.345 \tTrain_Accu: 35%  \tValid_Acc:23%  \tVal_kappa : 0.303  \n",
            "Epoch: 33 \tTraining Loss:  1.339 \tTrain_Accu: 40%  \tValid_Acc:24%  \tVal_kappa : -0.106  \n",
            "Epoch: 34 \tTraining Loss:  1.287 \tTrain_Accu: 46%  \tValid_Acc:16%  \tVal_kappa : 0.247  \n",
            "Epoch: 35 \tTraining Loss:  1.364 \tTrain_Accu: 43%  \tValid_Acc:19%  \tVal_kappa : -0.292  \n",
            "Epoch: 36 \tTraining Loss:  1.346 \tTrain_Accu: 39%  \tValid_Acc:21%  \tVal_kappa : 0.262  \n",
            "Epoch: 37 \tTraining Loss:  1.339 \tTrain_Accu: 46%  \tValid_Acc:17%  \tVal_kappa : 0.215  \n",
            "Epoch: 38 \tTraining Loss:  1.294 \tTrain_Accu: 43%  \tValid_Acc:19%  \tVal_kappa : -0.204  \n",
            "Epoch: 39 \tTraining Loss:  1.293 \tTrain_Accu: 39%  \tValid_Acc:20%  \tVal_kappa : 0.256  \n",
            "Epoch: 40 \tTraining Loss:  1.324 \tTrain_Accu: 42%  \tValid_Acc:23%  \tVal_kappa : 0.207  \n",
            "Epoch: 41 \tTraining Loss:  1.244 \tTrain_Accu: 45%  \tValid_Acc:13%  \tVal_kappa : -0.149  \n",
            "Epoch: 42 \tTraining Loss:  1.257 \tTrain_Accu: 48%  \tValid_Acc:20%  \tVal_kappa : -0.111  \n",
            "Epoch: 43 \tTraining Loss:  1.259 \tTrain_Accu: 48%  \tValid_Acc:16%  \tVal_kappa : 0.250  \n",
            "Epoch: 44 \tTraining Loss:  1.227 \tTrain_Accu: 46%  \tValid_Acc:24%  \tVal_kappa : 0.339  \n",
            "Epoch: 45 \tTraining Loss:  1.234 \tTrain_Accu: 47%  \tValid_Acc:14%  \tVal_kappa : 0.097  \n",
            "Epoch: 46 \tTraining Loss:  1.218 \tTrain_Accu: 48%  \tValid_Acc:20%  \tVal_kappa : 0.390  \n",
            "Epoch: 47 \tTraining Loss:  1.236 \tTrain_Accu: 47%  \tValid_Acc:17%  \tVal_kappa : -0.264  \n",
            "Epoch: 48 \tTraining Loss:  1.185 \tTrain_Accu: 49%  \tValid_Acc:16%  \tVal_kappa : -0.226  \n",
            "Epoch: 49 \tTraining Loss:  1.149 \tTrain_Accu: 52%  \tValid_Acc:26%  \tVal_kappa : -0.465  \n",
            "Epoch: 50 \tTraining Loss:  1.120 \tTrain_Accu: 51%  \tValid_Acc:30%  \tVal_kappa : -0.175  \n",
            "Epoch: 51 \tTraining Loss:  1.205 \tTrain_Accu: 48%  \tValid_Acc:24%  \tVal_kappa : 0.062  \n",
            "Epoch: 52 \tTraining Loss:  1.076 \tTrain_Accu: 50%  \tValid_Acc:20%  \tVal_kappa : -0.184  \n",
            "Epoch: 53 \tTraining Loss:  1.164 \tTrain_Accu: 49%  \tValid_Acc:19%  \tVal_kappa : 0.298  \n",
            "Epoch: 54 \tTraining Loss:  1.147 \tTrain_Accu: 48%  \tValid_Acc:21%  \tVal_kappa : -0.263  \n",
            "Epoch: 55 \tTraining Loss:  1.191 \tTrain_Accu: 48%  \tValid_Acc:21%  \tVal_kappa : 0.132  \n",
            "Epoch: 56 \tTraining Loss:  1.115 \tTrain_Accu: 50%  \tValid_Acc:27%  \tVal_kappa : -0.002  \n",
            "Epoch: 57 \tTraining Loss:  1.112 \tTrain_Accu: 48%  \tValid_Acc:21%  \tVal_kappa : 0.202  \n",
            "Epoch: 58 \tTraining Loss:  1.148 \tTrain_Accu: 50%  \tValid_Acc:30%  \tVal_kappa : 0.157  \n",
            "Epoch: 59 \tTraining Loss:  1.049 \tTrain_Accu: 57%  \tValid_Acc:24%  \tVal_kappa : -0.349  \n",
            "Epoch: 60 \tTraining Loss:  1.038 \tTrain_Accu: 57%  \tValid_Acc:23%  \tVal_kappa : 0.350  \n",
            "Epoch: 61 \tTraining Loss:  1.130 \tTrain_Accu: 55%  \tValid_Acc:14%  \tVal_kappa : 0.044  \n",
            "Epoch: 62 \tTraining Loss:  1.064 \tTrain_Accu: 53%  \tValid_Acc:17%  \tVal_kappa : 0.089  \n",
            "Epoch: 63 \tTraining Loss:  1.056 \tTrain_Accu: 54%  \tValid_Acc:27%  \tVal_kappa : 0.213  \n",
            "Epoch: 64 \tTraining Loss:  1.050 \tTrain_Accu: 58%  \tValid_Acc:20%  \tVal_kappa : -0.330  \n",
            "Epoch: 65 \tTraining Loss:  1.026 \tTrain_Accu: 54%  \tValid_Acc:13%  \tVal_kappa : 0.476  \n",
            "Epoch: 66 \tTraining Loss:  0.995 \tTrain_Accu: 56%  \tValid_Acc:20%  \tVal_kappa : -0.541  \n",
            "Epoch: 67 \tTraining Loss:  0.984 \tTrain_Accu: 57%  \tValid_Acc:20%  \tVal_kappa : -0.093  \n",
            "Epoch: 68 \tTraining Loss:  1.052 \tTrain_Accu: 53%  \tValid_Acc:17%  \tVal_kappa : 0.145  \n",
            "Epoch: 69 \tTraining Loss:  1.016 \tTrain_Accu: 57%  \tValid_Acc:21%  \tVal_kappa : -0.278  \n",
            "Epoch: 70 \tTraining Loss:  1.036 \tTrain_Accu: 56%  \tValid_Acc:29%  \tVal_kappa : -0.002  \n",
            "Epoch: 71 \tTraining Loss:  0.977 \tTrain_Accu: 57%  \tValid_Acc:20%  \tVal_kappa : 0.074  \n",
            "Epoch: 72 \tTraining Loss:  1.088 \tTrain_Accu: 54%  \tValid_Acc:30%  \tVal_kappa : 0.096  \n",
            "Epoch: 73 \tTraining Loss:  0.936 \tTrain_Accu: 59%  \tValid_Acc:20%  \tVal_kappa : -0.026  \n",
            "Epoch: 74 \tTraining Loss:  0.898 \tTrain_Accu: 64%  \tValid_Acc:24%  \tVal_kappa : 0.027  \n",
            "Epoch: 75 \tTraining Loss:  0.983 \tTrain_Accu: 57%  \tValid_Acc:27%  \tVal_kappa : -0.358  \n",
            "Epoch: 76 \tTraining Loss:  0.950 \tTrain_Accu: 62%  \tValid_Acc:16%  \tVal_kappa : 0.083  \n",
            "Epoch: 77 \tTraining Loss:  0.996 \tTrain_Accu: 56%  \tValid_Acc:16%  \tVal_kappa : -0.270  \n",
            "Epoch: 78 \tTraining Loss:  0.860 \tTrain_Accu: 63%  \tValid_Acc:17%  \tVal_kappa : 0.015  \n",
            "Epoch: 79 \tTraining Loss:  0.903 \tTrain_Accu: 59%  \tValid_Acc:17%  \tVal_kappa : 0.098  \n",
            "Epoch: 80 \tTraining Loss:  0.917 \tTrain_Accu: 60%  \tValid_Acc:17%  \tVal_kappa : -0.056  \n",
            "Epoch: 81 \tTraining Loss:  0.942 \tTrain_Accu: 60%  \tValid_Acc:19%  \tVal_kappa : 0.145  \n",
            "Epoch: 82 \tTraining Loss:  0.992 \tTrain_Accu: 58%  \tValid_Acc:19%  \tVal_kappa : -0.091  \n",
            "Epoch: 83 \tTraining Loss:  0.947 \tTrain_Accu: 59%  \tValid_Acc:17%  \tVal_kappa : -0.261  \n",
            "Epoch: 84 \tTraining Loss:  0.940 \tTrain_Accu: 62%  \tValid_Acc:17%  \tVal_kappa : 0.529  \n",
            "Epoch: 85 \tTraining Loss:  0.894 \tTrain_Accu: 59%  \tValid_Acc:23%  \tVal_kappa : 0.006  \n",
            "Epoch: 86 \tTraining Loss:  0.851 \tTrain_Accu: 61%  \tValid_Acc:14%  \tVal_kappa : -0.290  \n",
            "Epoch: 87 \tTraining Loss:  0.863 \tTrain_Accu: 60%  \tValid_Acc:26%  \tVal_kappa : -0.213  \n",
            "Epoch: 88 \tTraining Loss:  0.894 \tTrain_Accu: 61%  \tValid_Acc:23%  \tVal_kappa : -0.057  \n",
            "Epoch: 89 \tTraining Loss:  0.848 \tTrain_Accu: 62%  \tValid_Acc:21%  \tVal_kappa : -0.228  \n",
            "Epoch: 90 \tTraining Loss:  0.914 \tTrain_Accu: 62%  \tValid_Acc:17%  \tVal_kappa : -0.093  \n",
            "Epoch: 91 \tTraining Loss:  0.831 \tTrain_Accu: 63%  \tValid_Acc:19%  \tVal_kappa : 0.098  \n",
            "Epoch: 92 \tTraining Loss:  0.767 \tTrain_Accu: 66%  \tValid_Acc:27%  \tVal_kappa : -0.024  \n",
            "Epoch: 93 \tTraining Loss:  0.799 \tTrain_Accu: 64%  \tValid_Acc:17%  \tVal_kappa : -0.224  \n",
            "Epoch: 94 \tTraining Loss:  0.829 \tTrain_Accu: 66%  \tValid_Acc:26%  \tVal_kappa : -0.101  \n",
            "Epoch: 95 \tTraining Loss:  0.814 \tTrain_Accu: 65%  \tValid_Acc:29%  \tVal_kappa : -0.071  \n",
            "Epoch: 96 \tTraining Loss:  0.827 \tTrain_Accu: 68%  \tValid_Acc:19%  \tVal_kappa : -0.118  \n",
            "Epoch: 97 \tTraining Loss:  0.812 \tTrain_Accu: 64%  \tValid_Acc:24%  \tVal_kappa : 0.051  \n",
            "Epoch: 98 \tTraining Loss:  0.803 \tTrain_Accu: 68%  \tValid_Acc:30%  \tVal_kappa : -0.164  \n",
            "Epoch: 99 \tTraining Loss:  0.821 \tTrain_Accu: 66%  \tValid_Acc:26%  \tVal_kappa : -0.143  \n",
            "Epoch: 100 \tTraining Loss:  0.806 \tTrain_Accu: 65%  \tValid_Acc:20%  \tVal_kappa : 0.244  \n",
            "Epoch: 101 \tTraining Loss:  0.740 \tTrain_Accu: 68%  \tValid_Acc:24%  \tVal_kappa : 0.056  \n",
            "Epoch: 102 \tTraining Loss:  0.797 \tTrain_Accu: 66%  \tValid_Acc:19%  \tVal_kappa : 0.029  \n",
            "Epoch: 103 \tTraining Loss:  0.718 \tTrain_Accu: 71%  \tValid_Acc:17%  \tVal_kappa : -0.217  \n",
            "Epoch: 104 \tTraining Loss:  0.725 \tTrain_Accu: 68%  \tValid_Acc:29%  \tVal_kappa : 0.193  \n",
            "Epoch: 105 \tTraining Loss:  0.861 \tTrain_Accu: 67%  \tValid_Acc:17%  \tVal_kappa : 0.234  \n",
            "Epoch: 106 \tTraining Loss:  0.736 \tTrain_Accu: 71%  \tValid_Acc:17%  \tVal_kappa : -0.007  \n",
            "Epoch: 107 \tTraining Loss:  0.815 \tTrain_Accu: 67%  \tValid_Acc:23%  \tVal_kappa : -0.220  \n",
            "Epoch: 108 \tTraining Loss:  0.778 \tTrain_Accu: 65%  \tValid_Acc:31%  \tVal_kappa : 0.091  \n",
            "Epoch: 109 \tTraining Loss:  0.725 \tTrain_Accu: 66%  \tValid_Acc:17%  \tVal_kappa : -0.281  \n",
            "Epoch: 110 \tTraining Loss:  0.701 \tTrain_Accu: 70%  \tValid_Acc:21%  \tVal_kappa : -0.060  \n",
            "Epoch: 111 \tTraining Loss:  0.706 \tTrain_Accu: 71%  \tValid_Acc:26%  \tVal_kappa : -0.113  \n",
            "Epoch: 112 \tTraining Loss:  0.751 \tTrain_Accu: 66%  \tValid_Acc:23%  \tVal_kappa : -0.085  \n",
            "Epoch: 113 \tTraining Loss:  0.699 \tTrain_Accu: 71%  \tValid_Acc:16%  \tVal_kappa : -0.064  \n",
            "Epoch: 114 \tTraining Loss:  0.779 \tTrain_Accu: 68%  \tValid_Acc:19%  \tVal_kappa : 0.055  \n",
            "Epoch: 115 \tTraining Loss:  0.708 \tTrain_Accu: 69%  \tValid_Acc:21%  \tVal_kappa : -0.226  \n",
            "Epoch: 116 \tTraining Loss:  0.702 \tTrain_Accu: 72%  \tValid_Acc:20%  \tVal_kappa : 0.256  \n",
            "Epoch: 117 \tTraining Loss:  0.730 \tTrain_Accu: 71%  \tValid_Acc:21%  \tVal_kappa : 0.091  \n",
            "Epoch: 118 \tTraining Loss:  0.703 \tTrain_Accu: 70%  \tValid_Acc:19%  \tVal_kappa : -0.180  \n",
            "Epoch: 119 \tTraining Loss:  0.646 \tTrain_Accu: 73%  \tValid_Acc:21%  \tVal_kappa : 0.273  \n",
            "Epoch: 120 \tTraining Loss:  0.706 \tTrain_Accu: 70%  \tValid_Acc:14%  \tVal_kappa : -0.099  \n",
            "Epoch: 121 \tTraining Loss:  0.606 \tTrain_Accu: 74%  \tValid_Acc:21%  \tVal_kappa : -0.007  \n",
            "Epoch: 122 \tTraining Loss:  0.707 \tTrain_Accu: 72%  \tValid_Acc:14%  \tVal_kappa : -0.181  \n",
            "Epoch: 123 \tTraining Loss:  0.679 \tTrain_Accu: 72%  \tValid_Acc:17%  \tVal_kappa : -0.238  \n",
            "Epoch: 124 \tTraining Loss:  0.728 \tTrain_Accu: 69%  \tValid_Acc:20%  \tVal_kappa : 0.162  \n",
            "Epoch: 125 \tTraining Loss:  0.694 \tTrain_Accu: 70%  \tValid_Acc:27%  \tVal_kappa : 0.380  \n",
            "Epoch: 126 \tTraining Loss:  0.677 \tTrain_Accu: 71%  \tValid_Acc:10%  \tVal_kappa : -0.091  \n",
            "Epoch: 127 \tTraining Loss:  0.621 \tTrain_Accu: 71%  \tValid_Acc:19%  \tVal_kappa : -0.247  \n",
            "Epoch: 128 \tTraining Loss:  0.621 \tTrain_Accu: 74%  \tValid_Acc:26%  \tVal_kappa : -0.353  \n",
            "Epoch: 129 \tTraining Loss:  0.737 \tTrain_Accu: 69%  \tValid_Acc:16%  \tVal_kappa : 0.019  \n",
            "Epoch: 130 \tTraining Loss:  0.675 \tTrain_Accu: 74%  \tValid_Acc:11%  \tVal_kappa : -0.097  \n",
            "Epoch: 131 \tTraining Loss:  0.619 \tTrain_Accu: 74%  \tValid_Acc:29%  \tVal_kappa : -0.195  \n",
            "Epoch: 132 \tTraining Loss:  0.594 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : -0.259  \n",
            "Epoch: 133 \tTraining Loss:  0.623 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : -0.007  \n",
            "Epoch: 134 \tTraining Loss:  0.537 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : -0.072  \n",
            "Epoch: 135 \tTraining Loss:  0.706 \tTrain_Accu: 69%  \tValid_Acc:20%  \tVal_kappa : -0.142  \n",
            "Epoch: 136 \tTraining Loss:  0.656 \tTrain_Accu: 73%  \tValid_Acc:27%  \tVal_kappa : 0.170  \n",
            "Epoch: 137 \tTraining Loss:  0.606 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : 0.084  \n",
            "Epoch: 138 \tTraining Loss:  0.623 \tTrain_Accu: 74%  \tValid_Acc:21%  \tVal_kappa : -0.349  \n",
            "Epoch: 139 \tTraining Loss:  0.670 \tTrain_Accu: 73%  \tValid_Acc:11%  \tVal_kappa : 0.282  \n",
            "Epoch: 140 \tTraining Loss:  0.639 \tTrain_Accu: 74%  \tValid_Acc:16%  \tVal_kappa : -0.261  \n",
            "Epoch: 141 \tTraining Loss:  0.582 \tTrain_Accu: 76%  \tValid_Acc:24%  \tVal_kappa : -0.067  \n",
            "Epoch: 142 \tTraining Loss:  0.676 \tTrain_Accu: 70%  \tValid_Acc:20%  \tVal_kappa : 0.018  \n",
            "Epoch: 143 \tTraining Loss:  0.614 \tTrain_Accu: 76%  \tValid_Acc:24%  \tVal_kappa : -0.194  \n",
            "Epoch: 144 \tTraining Loss:  0.650 \tTrain_Accu: 72%  \tValid_Acc:19%  \tVal_kappa : -0.023  \n",
            "Epoch: 145 \tTraining Loss:  0.645 \tTrain_Accu: 74%  \tValid_Acc:24%  \tVal_kappa : 0.078  \n",
            "Epoch: 146 \tTraining Loss:  0.597 \tTrain_Accu: 73%  \tValid_Acc:24%  \tVal_kappa : -0.156  \n",
            "Epoch: 147 \tTraining Loss:  0.578 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : 0.015  \n",
            "Epoch: 148 \tTraining Loss:  0.588 \tTrain_Accu: 75%  \tValid_Acc:16%  \tVal_kappa : 0.275  \n",
            "Epoch: 149 \tTraining Loss:  0.590 \tTrain_Accu: 76%  \tValid_Acc:20%  \tVal_kappa : -0.034  \n",
            "Epoch: 150 \tTraining Loss:  0.579 \tTrain_Accu: 76%  \tValid_Acc:16%  \tVal_kappa : -0.125  \n",
            "Epoch: 151 \tTraining Loss:  0.587 \tTrain_Accu: 77%  \tValid_Acc:24%  \tVal_kappa : -0.054  \n",
            "Epoch: 152 \tTraining Loss:  0.563 \tTrain_Accu: 76%  \tValid_Acc:11%  \tVal_kappa : -0.116  \n",
            "Epoch: 153 \tTraining Loss:  0.600 \tTrain_Accu: 75%  \tValid_Acc:24%  \tVal_kappa : 0.028  \n",
            "Epoch: 154 \tTraining Loss:  0.615 \tTrain_Accu: 74%  \tValid_Acc:20%  \tVal_kappa : -0.226  \n",
            "Epoch: 155 \tTraining Loss:  0.583 \tTrain_Accu: 76%  \tValid_Acc:16%  \tVal_kappa : -0.480  \n",
            "Epoch: 156 \tTraining Loss:  0.533 \tTrain_Accu: 78%  \tValid_Acc:27%  \tVal_kappa : 0.205  \n",
            "Epoch: 157 \tTraining Loss:  0.585 \tTrain_Accu: 78%  \tValid_Acc:16%  \tVal_kappa : -0.232  \n",
            "Epoch: 158 \tTraining Loss:  0.612 \tTrain_Accu: 73%  \tValid_Acc:20%  \tVal_kappa : 0.077  \n",
            "Epoch: 159 \tTraining Loss:  0.617 \tTrain_Accu: 74%  \tValid_Acc:17%  \tVal_kappa : -0.288  \n",
            "Epoch: 160 \tTraining Loss:  0.640 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : -0.208  \n",
            "Epoch: 161 \tTraining Loss:  0.527 \tTrain_Accu: 79%  \tValid_Acc:20%  \tVal_kappa : -0.176  \n",
            "Epoch: 162 \tTraining Loss:  0.528 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : 0.289  \n",
            "Epoch: 163 \tTraining Loss:  0.630 \tTrain_Accu: 76%  \tValid_Acc:17%  \tVal_kappa : -0.034  \n",
            "Epoch: 164 \tTraining Loss:  0.658 \tTrain_Accu: 75%  \tValid_Acc:17%  \tVal_kappa : -0.074  \n",
            "Epoch: 165 \tTraining Loss:  0.546 \tTrain_Accu: 79%  \tValid_Acc:27%  \tVal_kappa : 0.123  \n",
            "Epoch: 166 \tTraining Loss:  0.601 \tTrain_Accu: 75%  \tValid_Acc:20%  \tVal_kappa : 0.223  \n",
            "Epoch: 167 \tTraining Loss:  0.566 \tTrain_Accu: 76%  \tValid_Acc:20%  \tVal_kappa : 0.196  \n",
            "Epoch: 168 \tTraining Loss:  0.520 \tTrain_Accu: 79%  \tValid_Acc:21%  \tVal_kappa : -0.231  \n",
            "Epoch: 169 \tTraining Loss:  0.621 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : 0.266  \n",
            "Epoch: 170 \tTraining Loss:  0.590 \tTrain_Accu: 75%  \tValid_Acc:23%  \tVal_kappa : -0.167  \n",
            "Epoch: 171 \tTraining Loss:  0.535 \tTrain_Accu: 81%  \tValid_Acc:14%  \tVal_kappa : 0.222  \n",
            "Epoch: 172 \tTraining Loss:  0.560 \tTrain_Accu: 75%  \tValid_Acc:17%  \tVal_kappa : -0.003  \n",
            "Epoch: 173 \tTraining Loss:  0.583 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : -0.034  \n",
            "Epoch: 174 \tTraining Loss:  0.519 \tTrain_Accu: 78%  \tValid_Acc:14%  \tVal_kappa : 0.308  \n",
            "Epoch: 175 \tTraining Loss:  0.528 \tTrain_Accu: 79%  \tValid_Acc:21%  \tVal_kappa : 0.050  \n",
            "Epoch: 176 \tTraining Loss:  0.525 \tTrain_Accu: 78%  \tValid_Acc:23%  \tVal_kappa : 0.192  \n",
            "Epoch: 177 \tTraining Loss:  0.611 \tTrain_Accu: 75%  \tValid_Acc:24%  \tVal_kappa : -0.034  \n",
            "Epoch: 178 \tTraining Loss:  0.493 \tTrain_Accu: 82%  \tValid_Acc:17%  \tVal_kappa : 0.006  \n",
            "Epoch: 179 \tTraining Loss:  0.517 \tTrain_Accu: 79%  \tValid_Acc:21%  \tVal_kappa : -0.380  \n",
            "Epoch: 180 \tTraining Loss:  0.568 \tTrain_Accu: 78%  \tValid_Acc:26%  \tVal_kappa : 0.316  \n",
            "Epoch: 181 \tTraining Loss:  0.511 \tTrain_Accu: 79%  \tValid_Acc:21%  \tVal_kappa : 0.003  \n",
            "Epoch: 182 \tTraining Loss:  0.544 \tTrain_Accu: 77%  \tValid_Acc:19%  \tVal_kappa : -0.390  \n",
            "Epoch: 183 \tTraining Loss:  0.522 \tTrain_Accu: 80%  \tValid_Acc:19%  \tVal_kappa : -0.206  \n",
            "Epoch: 184 \tTraining Loss:  0.494 \tTrain_Accu: 82%  \tValid_Acc:19%  \tVal_kappa : 0.064  \n",
            "Epoch: 185 \tTraining Loss:  0.490 \tTrain_Accu: 80%  \tValid_Acc:19%  \tVal_kappa : -0.091  \n",
            "Epoch: 186 \tTraining Loss:  0.591 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : -0.102  \n",
            "Epoch: 187 \tTraining Loss:  0.539 \tTrain_Accu: 75%  \tValid_Acc:16%  \tVal_kappa : 0.077  \n",
            "Epoch: 188 \tTraining Loss:  0.534 \tTrain_Accu: 79%  \tValid_Acc:19%  \tVal_kappa : -0.067  \n",
            "Epoch: 189 \tTraining Loss:  0.558 \tTrain_Accu: 79%  \tValid_Acc:11%  \tVal_kappa : 0.087  \n",
            "Epoch: 190 \tTraining Loss:  0.520 \tTrain_Accu: 81%  \tValid_Acc:24%  \tVal_kappa : -0.023  \n",
            "Epoch: 191 \tTraining Loss:  0.481 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : 0.026  \n",
            "Epoch: 192 \tTraining Loss:  0.461 \tTrain_Accu: 83%  \tValid_Acc:16%  \tVal_kappa : -0.227  \n",
            "Epoch: 193 \tTraining Loss:  0.562 \tTrain_Accu: 76%  \tValid_Acc:19%  \tVal_kappa : 0.082  \n",
            "Epoch: 194 \tTraining Loss:  0.514 \tTrain_Accu: 79%  \tValid_Acc:27%  \tVal_kappa : -0.071  \n",
            "Epoch: 195 \tTraining Loss:  0.554 \tTrain_Accu: 78%  \tValid_Acc:16%  \tVal_kappa : 0.033  \n",
            "Epoch: 196 \tTraining Loss:  0.531 \tTrain_Accu: 79%  \tValid_Acc:17%  \tVal_kappa : 0.098  \n",
            "Epoch: 197 \tTraining Loss:  0.559 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : -0.417  \n",
            "Epoch: 198 \tTraining Loss:  0.561 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : 0.079  \n",
            "Epoch: 199 \tTraining Loss:  0.554 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : -0.016  \n",
            "Epoch: 200 \tTraining Loss:  0.547 \tTrain_Accu: 82%  \tValid_Acc:17%  \tVal_kappa : -0.064  \n",
            "Epoch: 201 \tTraining Loss:  0.408 \tTrain_Accu: 86%  \tValid_Acc:19%  \tVal_kappa : 0.227  \n",
            "Epoch: 202 \tTraining Loss:  0.443 \tTrain_Accu: 83%  \tValid_Acc:16%  \tVal_kappa : -0.102  \n",
            "Epoch: 203 \tTraining Loss:  0.472 \tTrain_Accu: 82%  \tValid_Acc:16%  \tVal_kappa : 0.227  \n",
            "Epoch: 204 \tTraining Loss:  0.458 \tTrain_Accu: 82%  \tValid_Acc:13%  \tVal_kappa : 0.387  \n",
            "Epoch: 205 \tTraining Loss:  0.417 \tTrain_Accu: 86%  \tValid_Acc:16%  \tVal_kappa : 0.098  \n",
            "Epoch: 206 \tTraining Loss:  0.459 \tTrain_Accu: 83%  \tValid_Acc:26%  \tVal_kappa : 0.231  \n",
            "Epoch: 207 \tTraining Loss:  0.536 \tTrain_Accu: 78%  \tValid_Acc:13%  \tVal_kappa : 0.315  \n",
            "Epoch: 208 \tTraining Loss:  0.571 \tTrain_Accu: 77%  \tValid_Acc:21%  \tVal_kappa : 0.204  \n",
            "Epoch: 209 \tTraining Loss:  0.521 \tTrain_Accu: 79%  \tValid_Acc:19%  \tVal_kappa : 0.212  \n",
            "Epoch: 210 \tTraining Loss:  0.533 \tTrain_Accu: 79%  \tValid_Acc:17%  \tVal_kappa : -0.130  \n",
            "Epoch: 211 \tTraining Loss:  0.518 \tTrain_Accu: 81%  \tValid_Acc:26%  \tVal_kappa : 0.090  \n",
            "Epoch: 212 \tTraining Loss:  0.519 \tTrain_Accu: 79%  \tValid_Acc:14%  \tVal_kappa : 0.263  \n",
            "Epoch: 213 \tTraining Loss:  0.477 \tTrain_Accu: 80%  \tValid_Acc:9%  \tVal_kappa : -0.121  \n",
            "Epoch: 214 \tTraining Loss:  0.474 \tTrain_Accu: 83%  \tValid_Acc:21%  \tVal_kappa : -0.052  \n",
            "Epoch: 215 \tTraining Loss:  0.577 \tTrain_Accu: 81%  \tValid_Acc:19%  \tVal_kappa : -0.080  \n",
            "Epoch: 216 \tTraining Loss:  0.417 \tTrain_Accu: 85%  \tValid_Acc:20%  \tVal_kappa : -0.348  \n",
            "Epoch: 217 \tTraining Loss:  0.493 \tTrain_Accu: 82%  \tValid_Acc:19%  \tVal_kappa : 0.141  \n",
            "Epoch: 218 \tTraining Loss:  0.505 \tTrain_Accu: 81%  \tValid_Acc:17%  \tVal_kappa : -0.176  \n",
            "Epoch: 219 \tTraining Loss:  0.552 \tTrain_Accu: 79%  \tValid_Acc:11%  \tVal_kappa : -0.027  \n",
            "Epoch: 220 \tTraining Loss:  0.534 \tTrain_Accu: 79%  \tValid_Acc:16%  \tVal_kappa : -0.099  \n",
            "Epoch: 221 \tTraining Loss:  0.513 \tTrain_Accu: 81%  \tValid_Acc:17%  \tVal_kappa : -0.278  \n",
            "Epoch: 222 \tTraining Loss:  0.426 \tTrain_Accu: 85%  \tValid_Acc:27%  \tVal_kappa : 0.416  \n",
            "Epoch: 223 \tTraining Loss:  0.495 \tTrain_Accu: 79%  \tValid_Acc:17%  \tVal_kappa : -0.103  \n",
            "Epoch: 224 \tTraining Loss:  0.557 \tTrain_Accu: 80%  \tValid_Acc:19%  \tVal_kappa : -0.218  \n",
            "Epoch: 225 \tTraining Loss:  0.424 \tTrain_Accu: 83%  \tValid_Acc:17%  \tVal_kappa : -0.418  \n",
            "Epoch: 226 \tTraining Loss:  0.441 \tTrain_Accu: 83%  \tValid_Acc:31%  \tVal_kappa : 0.065  \n",
            "Epoch: 227 \tTraining Loss:  0.512 \tTrain_Accu: 81%  \tValid_Acc:20%  \tVal_kappa : -0.148  \n",
            "Epoch: 228 \tTraining Loss:  0.526 \tTrain_Accu: 83%  \tValid_Acc:23%  \tVal_kappa : 0.277  \n",
            "Epoch: 229 \tTraining Loss:  0.464 \tTrain_Accu: 81%  \tValid_Acc:24%  \tVal_kappa : -0.066  \n",
            "Epoch: 230 \tTraining Loss:  0.570 \tTrain_Accu: 76%  \tValid_Acc:20%  \tVal_kappa : -0.305  \n",
            "Epoch: 231 \tTraining Loss:  0.517 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : -0.133  \n",
            "Epoch: 232 \tTraining Loss:  0.481 \tTrain_Accu: 79%  \tValid_Acc:19%  \tVal_kappa : -0.171  \n",
            "Epoch: 233 \tTraining Loss:  0.492 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : -0.215  \n",
            "Epoch: 234 \tTraining Loss:  0.442 \tTrain_Accu: 85%  \tValid_Acc:14%  \tVal_kappa : 0.077  \n",
            "Epoch: 235 \tTraining Loss:  0.458 \tTrain_Accu: 83%  \tValid_Acc:21%  \tVal_kappa : -0.096  \n",
            "Epoch: 236 \tTraining Loss:  0.570 \tTrain_Accu: 79%  \tValid_Acc:14%  \tVal_kappa : -0.071  \n",
            "Epoch: 237 \tTraining Loss:  0.442 \tTrain_Accu: 83%  \tValid_Acc:14%  \tVal_kappa : -0.088  \n",
            "Epoch: 238 \tTraining Loss:  0.475 \tTrain_Accu: 80%  \tValid_Acc:14%  \tVal_kappa : 0.047  \n",
            "Epoch: 239 \tTraining Loss:  0.538 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : 0.006  \n",
            "Epoch: 240 \tTraining Loss:  0.516 \tTrain_Accu: 82%  \tValid_Acc:14%  \tVal_kappa : -0.039  \n",
            "Epoch: 241 \tTraining Loss:  0.511 \tTrain_Accu: 81%  \tValid_Acc:14%  \tVal_kappa : 0.000  \n",
            "Epoch: 242 \tTraining Loss:  0.500 \tTrain_Accu: 81%  \tValid_Acc:10%  \tVal_kappa : 0.315  \n",
            "Epoch: 243 \tTraining Loss:  0.476 \tTrain_Accu: 82%  \tValid_Acc:17%  \tVal_kappa : -0.012  \n",
            "Epoch: 244 \tTraining Loss:  0.443 \tTrain_Accu: 85%  \tValid_Acc:17%  \tVal_kappa : -0.142  \n",
            "Epoch: 245 \tTraining Loss:  0.556 \tTrain_Accu: 81%  \tValid_Acc:13%  \tVal_kappa : 0.072  \n",
            "Epoch: 246 \tTraining Loss:  0.462 \tTrain_Accu: 83%  \tValid_Acc:16%  \tVal_kappa : 0.091  \n",
            "Epoch: 247 \tTraining Loss:  0.469 \tTrain_Accu: 79%  \tValid_Acc:17%  \tVal_kappa : -0.087  \n",
            "Epoch: 248 \tTraining Loss:  0.512 \tTrain_Accu: 79%  \tValid_Acc:16%  \tVal_kappa : 0.301  \n",
            "Epoch: 249 \tTraining Loss:  0.442 \tTrain_Accu: 81%  \tValid_Acc:21%  \tVal_kappa : -0.067  \n",
            "Epoch: 250 \tTraining Loss:  0.383 \tTrain_Accu: 85%  \tValid_Acc:20%  \tVal_kappa : -0.179  \n",
            "Epoch: 251 \tTraining Loss:  0.459 \tTrain_Accu: 82%  \tValid_Acc:20%  \tVal_kappa : -0.032  \n",
            "Epoch: 252 \tTraining Loss:  0.429 \tTrain_Accu: 84%  \tValid_Acc:26%  \tVal_kappa : -0.078  \n",
            "Epoch: 253 \tTraining Loss:  0.504 \tTrain_Accu: 79%  \tValid_Acc:19%  \tVal_kappa : -0.145  \n",
            "Epoch: 254 \tTraining Loss:  0.490 \tTrain_Accu: 81%  \tValid_Acc:16%  \tVal_kappa : -0.199  \n",
            "Epoch: 255 \tTraining Loss:  0.499 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : -0.173  \n",
            "Epoch: 256 \tTraining Loss:  0.464 \tTrain_Accu: 82%  \tValid_Acc:17%  \tVal_kappa : 0.242  \n",
            "Epoch: 257 \tTraining Loss:  0.435 \tTrain_Accu: 83%  \tValid_Acc:14%  \tVal_kappa : -0.146  \n",
            "Epoch: 258 \tTraining Loss:  0.488 \tTrain_Accu: 82%  \tValid_Acc:11%  \tVal_kappa : -0.025  \n",
            "Epoch: 259 \tTraining Loss:  0.506 \tTrain_Accu: 79%  \tValid_Acc:13%  \tVal_kappa : 0.062  \n",
            "Epoch: 260 \tTraining Loss:  0.481 \tTrain_Accu: 81%  \tValid_Acc:19%  \tVal_kappa : -0.189  \n",
            "Epoch: 261 \tTraining Loss:  0.511 \tTrain_Accu: 80%  \tValid_Acc:16%  \tVal_kappa : -0.299  \n",
            "Epoch: 262 \tTraining Loss:  0.455 \tTrain_Accu: 83%  \tValid_Acc:11%  \tVal_kappa : 0.079  \n",
            "Epoch: 263 \tTraining Loss:  0.478 \tTrain_Accu: 81%  \tValid_Acc:21%  \tVal_kappa : -0.344  \n",
            "Epoch: 264 \tTraining Loss:  0.511 \tTrain_Accu: 80%  \tValid_Acc:16%  \tVal_kappa : 0.295  \n",
            "Epoch: 265 \tTraining Loss:  0.475 \tTrain_Accu: 82%  \tValid_Acc:16%  \tVal_kappa : 0.139  \n",
            "Epoch: 266 \tTraining Loss:  0.433 \tTrain_Accu: 83%  \tValid_Acc:19%  \tVal_kappa : 0.316  \n",
            "Epoch: 267 \tTraining Loss:  0.512 \tTrain_Accu: 81%  \tValid_Acc:17%  \tVal_kappa : -0.056  \n",
            "Epoch: 268 \tTraining Loss:  0.499 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : 0.219  \n",
            "Epoch: 269 \tTraining Loss:  0.471 \tTrain_Accu: 82%  \tValid_Acc:17%  \tVal_kappa : 0.008  \n",
            "Epoch: 270 \tTraining Loss:  0.429 \tTrain_Accu: 82%  \tValid_Acc:16%  \tVal_kappa : 0.006  \n",
            "Epoch: 271 \tTraining Loss:  0.505 \tTrain_Accu: 80%  \tValid_Acc:16%  \tVal_kappa : -0.367  \n",
            "Epoch: 272 \tTraining Loss:  0.450 \tTrain_Accu: 81%  \tValid_Acc:11%  \tVal_kappa : -0.075  \n",
            "Epoch: 273 \tTraining Loss:  0.483 \tTrain_Accu: 82%  \tValid_Acc:13%  \tVal_kappa : -0.190  \n",
            "Epoch: 274 \tTraining Loss:  0.418 \tTrain_Accu: 86%  \tValid_Acc:14%  \tVal_kappa : 0.144  \n",
            "Epoch: 275 \tTraining Loss:  0.468 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : 0.141  \n",
            "Epoch: 276 \tTraining Loss:  0.490 \tTrain_Accu: 81%  \tValid_Acc:11%  \tVal_kappa : -0.053  \n",
            "Epoch: 277 \tTraining Loss:  0.395 \tTrain_Accu: 83%  \tValid_Acc:17%  \tVal_kappa : -0.073  \n",
            "Epoch: 278 \tTraining Loss:  0.409 \tTrain_Accu: 85%  \tValid_Acc:14%  \tVal_kappa : -0.116  \n",
            "Epoch: 279 \tTraining Loss:  0.489 \tTrain_Accu: 85%  \tValid_Acc:13%  \tVal_kappa : 0.119  \n",
            "Epoch: 280 \tTraining Loss:  0.474 \tTrain_Accu: 83%  \tValid_Acc:20%  \tVal_kappa : 0.129  \n",
            "Epoch: 281 \tTraining Loss:  0.483 \tTrain_Accu: 83%  \tValid_Acc:16%  \tVal_kappa : 0.062  \n",
            "Epoch: 282 \tTraining Loss:  0.402 \tTrain_Accu: 84%  \tValid_Acc:11%  \tVal_kappa : 0.242  \n",
            "Epoch: 283 \tTraining Loss:  0.433 \tTrain_Accu: 84%  \tValid_Acc:21%  \tVal_kappa : 0.137  \n",
            "Epoch: 284 \tTraining Loss:  0.471 \tTrain_Accu: 82%  \tValid_Acc:21%  \tVal_kappa : -0.291  \n",
            "Epoch: 285 \tTraining Loss:  0.464 \tTrain_Accu: 81%  \tValid_Acc:10%  \tVal_kappa : -0.195  \n",
            "Epoch: 286 \tTraining Loss:  0.400 \tTrain_Accu: 86%  \tValid_Acc:20%  \tVal_kappa : -0.114  \n",
            "Epoch: 287 \tTraining Loss:  0.424 \tTrain_Accu: 86%  \tValid_Acc:17%  \tVal_kappa : -0.026  \n",
            "Epoch: 288 \tTraining Loss:  0.433 \tTrain_Accu: 86%  \tValid_Acc:16%  \tVal_kappa : 0.156  \n",
            "Epoch: 289 \tTraining Loss:  0.446 \tTrain_Accu: 84%  \tValid_Acc:16%  \tVal_kappa : 0.028  \n",
            "Epoch: 290 \tTraining Loss:  0.461 \tTrain_Accu: 85%  \tValid_Acc:20%  \tVal_kappa : 0.193  \n",
            "Epoch: 291 \tTraining Loss:  0.407 \tTrain_Accu: 84%  \tValid_Acc:23%  \tVal_kappa : -0.177  \n",
            "Epoch: 292 \tTraining Loss:  0.420 \tTrain_Accu: 83%  \tValid_Acc:11%  \tVal_kappa : 0.090  \n",
            "Epoch: 293 \tTraining Loss:  0.494 \tTrain_Accu: 81%  \tValid_Acc:20%  \tVal_kappa : 0.487  \n",
            "Epoch: 294 \tTraining Loss:  0.450 \tTrain_Accu: 83%  \tValid_Acc:19%  \tVal_kappa : 0.029  \n",
            "Epoch: 295 \tTraining Loss:  0.531 \tTrain_Accu: 80%  \tValid_Acc:11%  \tVal_kappa : -0.087  \n",
            "Epoch: 296 \tTraining Loss:  0.438 \tTrain_Accu: 83%  \tValid_Acc:11%  \tVal_kappa : 0.293  \n",
            "Epoch: 297 \tTraining Loss:  0.472 \tTrain_Accu: 82%  \tValid_Acc:19%  \tVal_kappa : 0.041  \n",
            "Epoch: 298 \tTraining Loss:  0.404 \tTrain_Accu: 84%  \tValid_Acc:19%  \tVal_kappa : 0.058  \n",
            "Epoch: 299 \tTraining Loss:  0.423 \tTrain_Accu: 86%  \tValid_Acc:16%  \tVal_kappa : -0.392  \n",
            "Epoch: 300 \tTraining Loss:  0.446 \tTrain_Accu: 83%  \tValid_Acc:24%  \tVal_kappa : -0.095  \n",
            "Epoch: 301 \tTraining Loss:  0.408 \tTrain_Accu: 84%  \tValid_Acc:17%  \tVal_kappa : 0.016  \n",
            "Epoch: 302 \tTraining Loss:  0.420 \tTrain_Accu: 86%  \tValid_Acc:13%  \tVal_kappa : 0.004  \n",
            "Epoch: 303 \tTraining Loss:  0.433 \tTrain_Accu: 85%  \tValid_Acc:17%  \tVal_kappa : 0.307  \n",
            "Epoch: 304 \tTraining Loss:  0.453 \tTrain_Accu: 81%  \tValid_Acc:16%  \tVal_kappa : -0.175  \n",
            "Epoch: 305 \tTraining Loss:  0.401 \tTrain_Accu: 86%  \tValid_Acc:16%  \tVal_kappa : -0.052  \n",
            "Epoch: 306 \tTraining Loss:  0.403 \tTrain_Accu: 85%  \tValid_Acc:16%  \tVal_kappa : -0.234  \n",
            "Epoch: 307 \tTraining Loss:  0.434 \tTrain_Accu: 82%  \tValid_Acc:26%  \tVal_kappa : 0.009  \n",
            "Epoch: 308 \tTraining Loss:  0.424 \tTrain_Accu: 83%  \tValid_Acc:23%  \tVal_kappa : 0.231  \n",
            "Epoch: 309 \tTraining Loss:  0.459 \tTrain_Accu: 82%  \tValid_Acc:11%  \tVal_kappa : 0.027  \n",
            "Epoch: 310 \tTraining Loss:  0.436 \tTrain_Accu: 82%  \tValid_Acc:17%  \tVal_kappa : -0.096  \n",
            "Epoch: 311 \tTraining Loss:  0.453 \tTrain_Accu: 84%  \tValid_Acc:16%  \tVal_kappa : 0.241  \n",
            "Epoch: 312 \tTraining Loss:  0.405 \tTrain_Accu: 84%  \tValid_Acc:17%  \tVal_kappa : -0.188  \n",
            "Epoch: 313 \tTraining Loss:  0.497 \tTrain_Accu: 81%  \tValid_Acc:16%  \tVal_kappa : -0.136  \n",
            "Epoch: 314 \tTraining Loss:  0.450 \tTrain_Accu: 83%  \tValid_Acc:14%  \tVal_kappa : -0.040  \n",
            "Epoch: 315 \tTraining Loss:  0.432 \tTrain_Accu: 84%  \tValid_Acc:19%  \tVal_kappa : -0.113  \n",
            "Epoch: 316 \tTraining Loss:  0.457 \tTrain_Accu: 82%  \tValid_Acc:14%  \tVal_kappa : 0.019  \n",
            "Epoch: 317 \tTraining Loss:  0.490 \tTrain_Accu: 79%  \tValid_Acc:21%  \tVal_kappa : -0.080  \n",
            "Epoch: 318 \tTraining Loss:  0.472 \tTrain_Accu: 83%  \tValid_Acc:21%  \tVal_kappa : 0.279  \n",
            "Epoch: 319 \tTraining Loss:  0.383 \tTrain_Accu: 87%  \tValid_Acc:9%  \tVal_kappa : -0.037  \n",
            "Epoch: 320 \tTraining Loss:  0.424 \tTrain_Accu: 84%  \tValid_Acc:14%  \tVal_kappa : 0.141  \n",
            "Epoch: 321 \tTraining Loss:  0.375 \tTrain_Accu: 86%  \tValid_Acc:17%  \tVal_kappa : -0.188  \n",
            "Epoch: 322 \tTraining Loss:  0.397 \tTrain_Accu: 86%  \tValid_Acc:24%  \tVal_kappa : 0.001  \n",
            "Epoch: 323 \tTraining Loss:  0.469 \tTrain_Accu: 84%  \tValid_Acc:14%  \tVal_kappa : -0.093  \n",
            "Epoch: 324 \tTraining Loss:  0.440 \tTrain_Accu: 83%  \tValid_Acc:9%  \tVal_kappa : -0.096  \n",
            "Epoch: 325 \tTraining Loss:  0.410 \tTrain_Accu: 85%  \tValid_Acc:9%  \tVal_kappa : -0.049  \n",
            "Epoch: 326 \tTraining Loss:  0.438 \tTrain_Accu: 84%  \tValid_Acc:21%  \tVal_kappa : 0.155  \n",
            "Epoch: 327 \tTraining Loss:  0.441 \tTrain_Accu: 83%  \tValid_Acc:9%  \tVal_kappa : 0.002  \n",
            "Epoch: 328 \tTraining Loss:  0.419 \tTrain_Accu: 86%  \tValid_Acc:21%  \tVal_kappa : -0.071  \n",
            "Epoch: 329 \tTraining Loss:  0.474 \tTrain_Accu: 82%  \tValid_Acc:13%  \tVal_kappa : 0.300  \n",
            "Epoch: 330 \tTraining Loss:  0.416 \tTrain_Accu: 83%  \tValid_Acc:13%  \tVal_kappa : -0.136  \n",
            "Epoch: 331 \tTraining Loss:  0.363 \tTrain_Accu: 86%  \tValid_Acc:14%  \tVal_kappa : 0.314  \n",
            "Epoch: 332 \tTraining Loss:  0.348 \tTrain_Accu: 86%  \tValid_Acc:19%  \tVal_kappa : 0.175  \n",
            "Epoch: 333 \tTraining Loss:  0.380 \tTrain_Accu: 87%  \tValid_Acc:19%  \tVal_kappa : -0.194  \n",
            "Epoch: 334 \tTraining Loss:  0.423 \tTrain_Accu: 83%  \tValid_Acc:23%  \tVal_kappa : 0.242  \n",
            "Epoch: 335 \tTraining Loss:  0.350 \tTrain_Accu: 86%  \tValid_Acc:23%  \tVal_kappa : 0.025  \n",
            "Epoch: 336 \tTraining Loss:  0.430 \tTrain_Accu: 84%  \tValid_Acc:14%  \tVal_kappa : 0.182  \n",
            "Epoch: 337 \tTraining Loss:  0.325 \tTrain_Accu: 88%  \tValid_Acc:17%  \tVal_kappa : -0.078  \n",
            "Epoch: 338 \tTraining Loss:  0.477 \tTrain_Accu: 80%  \tValid_Acc:13%  \tVal_kappa : 0.063  \n",
            "Epoch: 339 \tTraining Loss:  0.427 \tTrain_Accu: 84%  \tValid_Acc:14%  \tVal_kappa : 0.281  \n",
            "Epoch: 340 \tTraining Loss:  0.378 \tTrain_Accu: 87%  \tValid_Acc:14%  \tVal_kappa : -0.271  \n",
            "Epoch: 341 \tTraining Loss:  0.376 \tTrain_Accu: 86%  \tValid_Acc:20%  \tVal_kappa : -0.156  \n",
            "Epoch: 342 \tTraining Loss:  0.392 \tTrain_Accu: 85%  \tValid_Acc:17%  \tVal_kappa : -0.134  \n",
            "Epoch: 343 \tTraining Loss:  0.395 \tTrain_Accu: 85%  \tValid_Acc:20%  \tVal_kappa : 0.058  \n",
            "Epoch: 344 \tTraining Loss:  0.414 \tTrain_Accu: 85%  \tValid_Acc:14%  \tVal_kappa : -0.057  \n",
            "Epoch: 345 \tTraining Loss:  0.474 \tTrain_Accu: 83%  \tValid_Acc:17%  \tVal_kappa : -0.030  \n",
            "Epoch: 346 \tTraining Loss:  0.477 \tTrain_Accu: 84%  \tValid_Acc:19%  \tVal_kappa : -0.010  \n",
            "Epoch: 347 \tTraining Loss:  0.336 \tTrain_Accu: 88%  \tValid_Acc:13%  \tVal_kappa : 0.170  \n",
            "Epoch: 348 \tTraining Loss:  0.428 \tTrain_Accu: 85%  \tValid_Acc:24%  \tVal_kappa : -0.294  \n",
            "Epoch: 349 \tTraining Loss:  0.324 \tTrain_Accu: 90%  \tValid_Acc:20%  \tVal_kappa : 0.078  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 04:15:41,664]\u001b[0m Trial 1 finished with value: 11.4 and parameters: {}. Best is trial 0 with value: 15.7.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 350 \tTraining Loss:  0.411 \tTrain_Accu: 83%  \tValid_Acc:11%  \tVal_kappa : -0.158  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['optimise_valid_WSI_temp_drop(0.5).torch']"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9nbaVK0yp9b"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "iqLaF1P5zLL9",
        "outputId": "9bfee08e-b12c-45bd-d95a-7d291a55cc59"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_temp_WSI[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_dropout(0.8)\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_WSI_temp_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2, 1, 1, 2, 2, 0, 0, 4, 4, 2, 0, 4, 2, 0, 3, 1, 2, 2, 4, 0, 0, 1, 2, 2,\n",
            "        4, 4, 4, 0, 2, 1, 2, 3, 3, 3, 4, 4, 0, 2, 3, 2, 1, 3, 1, 0, 1, 1, 1, 4,\n",
            "        1, 4, 4, 4, 1, 1, 3, 3, 0, 1, 1, 2, 2, 4, 4, 4, 2, 1, 2, 1, 2, 0])\n",
            "labels tensor([0, 3, 3, 4, 4, 4, 2, 2, 0, 2, 3, 4, 3, 2, 3, 3, 2, 2, 1, 1, 1, 2, 2, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 0, 0, 0, 2, 3, 3, 2, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 1, 2, 1, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 1, 2, 2])\n",
            "correct : 19\n",
            "test_Accuracy % : 27.1\n",
            "kappa -0.04571753770274101\n",
            "[[ 1  0  1  0  3]\n",
            " [ 2  1  0  0  3]\n",
            " [ 3  2  6  1  2]\n",
            " [ 2  4  3  3  0]\n",
            " [ 3 10  8  4  8]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG8r5TJmyp9b"
      },
      "source": [
        "## WNI_temp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3rOiBJwyp9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "599b65d4-32cb-408d-e8fe-bf1c613e24fd"
      },
      "source": [
        "# Reading rainfall file of NNI region \n",
        "Data_temp_WNI = pd.read_csv(\"drive/My Drive/DL_project/Target_TMean_WNI_regional_ave_time_series.csv\")\n",
        "Data_temp_WNI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>Tmean_N</th>\n",
              "      <th>cat_3</th>\n",
              "      <th>cat_5</th>\n",
              "      <th>anomalies</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-04-01</td>\n",
              "      <td>15.650189</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1.266127</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-05-01</td>\n",
              "      <td>13.055781</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.904891</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-06-01</td>\n",
              "      <td>10.325244</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.491939</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-07-01</td>\n",
              "      <td>8.129155</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.003285</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-08-01</td>\n",
              "      <td>7.293863</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.132038</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>2019-08-01</td>\n",
              "      <td>8.151554</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.725653</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>8.799411</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.831812</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>2019-10-01</td>\n",
              "      <td>9.492618</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.227855</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>11.580670</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.659839</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>13.531856</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.785876</td>\n",
              "      <td>WNI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>465 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           time    Tmean_N  cat_3  cat_5  anomalies region\n",
              "0    1981-04-01  15.650189      3      5   1.266127    WNI\n",
              "1    1981-05-01  13.055781      3      5   0.904891    WNI\n",
              "2    1981-06-01  10.325244      3      4   0.491939    WNI\n",
              "3    1981-07-01   8.129155      2      3   0.003285    WNI\n",
              "4    1981-08-01   7.293863      2      3  -0.132038    WNI\n",
              "..          ...        ...    ...    ...        ...    ...\n",
              "460  2019-08-01   8.151554      3      5   0.725653    WNI\n",
              "461  2019-09-01   8.799411      3      5   0.831812    WNI\n",
              "462  2019-10-01   9.492618      2      4   0.227855    WNI\n",
              "463  2019-11-01  11.580670      3      5   0.659839    WNI\n",
              "464  2019-12-01  13.531856      3      5   0.785876    WNI\n",
              "\n",
              "[465 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVZT8Y-Wyp9c"
      },
      "source": [
        "# Extracting lable coulmn\n",
        "labels_temp_WNI = Data_temp_WNI['cat_5'].astype(int) #cat5 column - so 5 prediction classes "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7BvnnEkyp9c"
      },
      "source": [
        "# Function that will convert labels into Pytorch tensors\n",
        "\n",
        "def labels_Tensors(labels):\n",
        "    return (torch.from_numpy(labels.values).type(torch.LongTensor)-1) #cat5 in form 1, 2, 3, 4, 5;\n",
        "\n",
        "# Converting labels of Temp_WNI region into tensors\n",
        "labelsTensors_temp_WNI = labels_Tensors(labels_temp_WNI) # This represents y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2edrzpMJyp9c",
        "outputId": "cee7e694-75e8-4d05-e48e-6a093ee6765a"
      },
      "source": [
        "train_lab_WNI = labels_temp_WNI[:325]\n",
        "train_lab_WNI.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    68\n",
              "2    68\n",
              "1    67\n",
              "3    65\n",
              "4    56\n",
              "Name: cat_5, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQTvMKvfyp9d"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_valid_loaders_WNI_temp(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_WNI[:325])\n",
        "    validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_WNI[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "   \n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yCkTj3LJoIq"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_temp_WNI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 1,\n",
        "          'n_epochs' : 350,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           'dropout'       : 0.8,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_WNI_temp(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_WNI[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_WNI[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 10\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_temp_WNI[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_temp_WNI[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_WNI_temp_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR7np-Okyp9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9590f060-7e7f-4c6b-9e77-1acd06c59625"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_temp_WNI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"optimise_valid_WNI_temp_drop(0.5).torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.691 \tTrain_Accu: 18%  \tValid_Acc:10%  \tVal_kappa : -0.018  \n",
            "Epoch: 2 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:7%  \tVal_kappa : 0.170  \n",
            "Epoch: 3 \tTraining Loss:  1.605 \tTrain_Accu: 22%  \tValid_Acc:14%  \tVal_kappa : 0.019  \n",
            "Epoch: 4 \tTraining Loss:  1.587 \tTrain_Accu: 26%  \tValid_Acc:16%  \tVal_kappa : 0.140  \n",
            "Epoch: 5 \tTraining Loss:  1.602 \tTrain_Accu: 21%  \tValid_Acc:23%  \tVal_kappa : 0.014  \n",
            "Epoch: 6 \tTraining Loss:  1.605 \tTrain_Accu: 20%  \tValid_Acc:14%  \tVal_kappa : 0.250  \n",
            "Epoch: 7 \tTraining Loss:  1.597 \tTrain_Accu: 19%  \tValid_Acc:20%  \tVal_kappa : 0.597  \n",
            "Epoch: 8 \tTraining Loss:  1.585 \tTrain_Accu: 25%  \tValid_Acc:17%  \tVal_kappa : 0.100  \n",
            "Epoch: 9 \tTraining Loss:  1.585 \tTrain_Accu: 25%  \tValid_Acc:13%  \tVal_kappa : 0.192  \n",
            "Epoch: 10 \tTraining Loss:  1.570 \tTrain_Accu: 26%  \tValid_Acc:11%  \tVal_kappa : -0.186  \n",
            "Epoch: 11 \tTraining Loss:  1.556 \tTrain_Accu: 27%  \tValid_Acc:13%  \tVal_kappa : -0.227  \n",
            "Epoch: 12 \tTraining Loss:  1.579 \tTrain_Accu: 23%  \tValid_Acc:7%  \tVal_kappa : -0.261  \n",
            "Epoch: 13 \tTraining Loss:  1.575 \tTrain_Accu: 25%  \tValid_Acc:20%  \tVal_kappa : -0.200  \n",
            "Epoch: 14 \tTraining Loss:  1.566 \tTrain_Accu: 28%  \tValid_Acc:19%  \tVal_kappa : -0.074  \n",
            "Epoch: 15 \tTraining Loss:  1.548 \tTrain_Accu: 29%  \tValid_Acc:20%  \tVal_kappa : -0.252  \n",
            "Epoch: 16 \tTraining Loss:  1.554 \tTrain_Accu: 24%  \tValid_Acc:19%  \tVal_kappa : 0.269  \n",
            "Epoch: 17 \tTraining Loss:  1.530 \tTrain_Accu: 30%  \tValid_Acc:23%  \tVal_kappa : -0.146  \n",
            "Epoch: 18 \tTraining Loss:  1.527 \tTrain_Accu: 29%  \tValid_Acc:14%  \tVal_kappa : -0.174  \n",
            "Epoch: 19 \tTraining Loss:  1.523 \tTrain_Accu: 31%  \tValid_Acc:17%  \tVal_kappa : -0.173  \n",
            "Epoch: 20 \tTraining Loss:  1.510 \tTrain_Accu: 33%  \tValid_Acc:24%  \tVal_kappa : 0.218  \n",
            "Epoch: 21 \tTraining Loss:  1.533 \tTrain_Accu: 33%  \tValid_Acc:16%  \tVal_kappa : -0.259  \n",
            "Epoch: 22 \tTraining Loss:  1.506 \tTrain_Accu: 32%  \tValid_Acc:21%  \tVal_kappa : 0.292  \n",
            "Epoch: 23 \tTraining Loss:  1.513 \tTrain_Accu: 30%  \tValid_Acc:17%  \tVal_kappa : -0.162  \n",
            "Epoch: 24 \tTraining Loss:  1.485 \tTrain_Accu: 33%  \tValid_Acc:20%  \tVal_kappa : 0.073  \n",
            "Epoch: 25 \tTraining Loss:  1.516 \tTrain_Accu: 28%  \tValid_Acc:27%  \tVal_kappa : 0.012  \n",
            "Epoch: 26 \tTraining Loss:  1.400 \tTrain_Accu: 34%  \tValid_Acc:24%  \tVal_kappa : -0.108  \n",
            "Epoch: 27 \tTraining Loss:  1.447 \tTrain_Accu: 37%  \tValid_Acc:20%  \tVal_kappa : 0.074  \n",
            "Epoch: 28 \tTraining Loss:  1.432 \tTrain_Accu: 36%  \tValid_Acc:21%  \tVal_kappa : 0.460  \n",
            "Epoch: 29 \tTraining Loss:  1.437 \tTrain_Accu: 38%  \tValid_Acc:27%  \tVal_kappa : 0.000  \n",
            "Epoch: 30 \tTraining Loss:  1.430 \tTrain_Accu: 37%  \tValid_Acc:24%  \tVal_kappa : -0.183  \n",
            "Epoch: 31 \tTraining Loss:  1.448 \tTrain_Accu: 32%  \tValid_Acc:20%  \tVal_kappa : 0.199  \n",
            "Epoch: 32 \tTraining Loss:  1.351 \tTrain_Accu: 41%  \tValid_Acc:27%  \tVal_kappa : 0.615  \n",
            "Epoch: 33 \tTraining Loss:  1.358 \tTrain_Accu: 41%  \tValid_Acc:24%  \tVal_kappa : 0.000  \n",
            "Epoch: 34 \tTraining Loss:  1.339 \tTrain_Accu: 42%  \tValid_Acc:24%  \tVal_kappa : 0.562  \n",
            "Epoch: 35 \tTraining Loss:  1.354 \tTrain_Accu: 40%  \tValid_Acc:29%  \tVal_kappa : 0.341  \n",
            "Epoch: 36 \tTraining Loss:  1.334 \tTrain_Accu: 40%  \tValid_Acc:31%  \tVal_kappa : 0.315  \n",
            "Epoch: 37 \tTraining Loss:  1.352 \tTrain_Accu: 37%  \tValid_Acc:24%  \tVal_kappa : -0.252  \n",
            "Epoch: 38 \tTraining Loss:  1.331 \tTrain_Accu: 41%  \tValid_Acc:19%  \tVal_kappa : -0.167  \n",
            "Epoch: 39 \tTraining Loss:  1.307 \tTrain_Accu: 41%  \tValid_Acc:20%  \tVal_kappa : 0.210  \n",
            "Epoch: 40 \tTraining Loss:  1.323 \tTrain_Accu: 41%  \tValid_Acc:24%  \tVal_kappa : -0.243  \n",
            "Epoch: 41 \tTraining Loss:  1.321 \tTrain_Accu: 44%  \tValid_Acc:26%  \tVal_kappa : -0.018  \n",
            "Epoch: 42 \tTraining Loss:  1.274 \tTrain_Accu: 42%  \tValid_Acc:16%  \tVal_kappa : -0.185  \n",
            "Epoch: 43 \tTraining Loss:  1.258 \tTrain_Accu: 43%  \tValid_Acc:23%  \tVal_kappa : 0.068  \n",
            "Epoch: 44 \tTraining Loss:  1.288 \tTrain_Accu: 41%  \tValid_Acc:21%  \tVal_kappa : 0.562  \n",
            "Epoch: 45 \tTraining Loss:  1.253 \tTrain_Accu: 44%  \tValid_Acc:24%  \tVal_kappa : -0.179  \n",
            "Epoch: 46 \tTraining Loss:  1.207 \tTrain_Accu: 46%  \tValid_Acc:27%  \tVal_kappa : -0.006  \n",
            "Epoch: 47 \tTraining Loss:  1.257 \tTrain_Accu: 46%  \tValid_Acc:23%  \tVal_kappa : -0.030  \n",
            "Epoch: 48 \tTraining Loss:  1.225 \tTrain_Accu: 46%  \tValid_Acc:26%  \tVal_kappa : -0.131  \n",
            "Epoch: 49 \tTraining Loss:  1.190 \tTrain_Accu: 44%  \tValid_Acc:24%  \tVal_kappa : -0.420  \n",
            "Epoch: 50 \tTraining Loss:  1.075 \tTrain_Accu: 55%  \tValid_Acc:20%  \tVal_kappa : -0.169  \n",
            "Epoch: 51 \tTraining Loss:  1.141 \tTrain_Accu: 52%  \tValid_Acc:30%  \tVal_kappa : -0.119  \n",
            "Epoch: 52 \tTraining Loss:  1.194 \tTrain_Accu: 46%  \tValid_Acc:31%  \tVal_kappa : -0.018  \n",
            "Epoch: 53 \tTraining Loss:  1.194 \tTrain_Accu: 48%  \tValid_Acc:33%  \tVal_kappa : 0.106  \n",
            "Epoch: 54 \tTraining Loss:  1.081 \tTrain_Accu: 53%  \tValid_Acc:27%  \tVal_kappa : -0.167  \n",
            "Epoch: 55 \tTraining Loss:  1.104 \tTrain_Accu: 48%  \tValid_Acc:21%  \tVal_kappa : 0.147  \n",
            "Epoch: 56 \tTraining Loss:  1.139 \tTrain_Accu: 51%  \tValid_Acc:21%  \tVal_kappa : 0.112  \n",
            "Epoch: 57 \tTraining Loss:  1.209 \tTrain_Accu: 48%  \tValid_Acc:17%  \tVal_kappa : 0.264  \n",
            "Epoch: 58 \tTraining Loss:  1.095 \tTrain_Accu: 48%  \tValid_Acc:26%  \tVal_kappa : -0.011  \n",
            "Epoch: 59 \tTraining Loss:  1.075 \tTrain_Accu: 54%  \tValid_Acc:16%  \tVal_kappa : 0.065  \n",
            "Epoch: 60 \tTraining Loss:  1.063 \tTrain_Accu: 51%  \tValid_Acc:23%  \tVal_kappa : -0.309  \n",
            "Epoch: 61 \tTraining Loss:  1.023 \tTrain_Accu: 55%  \tValid_Acc:34%  \tVal_kappa : 0.348  \n",
            "Epoch: 62 \tTraining Loss:  1.108 \tTrain_Accu: 47%  \tValid_Acc:34%  \tVal_kappa : -0.243  \n",
            "Epoch: 63 \tTraining Loss:  1.027 \tTrain_Accu: 55%  \tValid_Acc:31%  \tVal_kappa : 0.120  \n",
            "Epoch: 64 \tTraining Loss:  1.053 \tTrain_Accu: 52%  \tValid_Acc:23%  \tVal_kappa : -0.162  \n",
            "Epoch: 65 \tTraining Loss:  1.092 \tTrain_Accu: 50%  \tValid_Acc:24%  \tVal_kappa : -0.021  \n",
            "Epoch: 66 \tTraining Loss:  1.061 \tTrain_Accu: 55%  \tValid_Acc:26%  \tVal_kappa : -0.261  \n",
            "Epoch: 67 \tTraining Loss:  1.035 \tTrain_Accu: 54%  \tValid_Acc:27%  \tVal_kappa : -0.541  \n",
            "Epoch: 68 \tTraining Loss:  1.001 \tTrain_Accu: 54%  \tValid_Acc:21%  \tVal_kappa : 0.070  \n",
            "Epoch: 69 \tTraining Loss:  1.020 \tTrain_Accu: 52%  \tValid_Acc:26%  \tVal_kappa : -0.125  \n",
            "Epoch: 70 \tTraining Loss:  1.037 \tTrain_Accu: 52%  \tValid_Acc:23%  \tVal_kappa : 0.295  \n",
            "Epoch: 71 \tTraining Loss:  0.943 \tTrain_Accu: 60%  \tValid_Acc:21%  \tVal_kappa : -0.036  \n",
            "Epoch: 72 \tTraining Loss:  1.024 \tTrain_Accu: 56%  \tValid_Acc:31%  \tVal_kappa : 0.275  \n",
            "Epoch: 73 \tTraining Loss:  1.049 \tTrain_Accu: 55%  \tValid_Acc:16%  \tVal_kappa : -0.229  \n",
            "Epoch: 74 \tTraining Loss:  0.941 \tTrain_Accu: 58%  \tValid_Acc:29%  \tVal_kappa : 0.249  \n",
            "Epoch: 75 \tTraining Loss:  0.992 \tTrain_Accu: 57%  \tValid_Acc:19%  \tVal_kappa : -0.359  \n",
            "Epoch: 76 \tTraining Loss:  0.916 \tTrain_Accu: 58%  \tValid_Acc:21%  \tVal_kappa : 0.083  \n",
            "Epoch: 77 \tTraining Loss:  0.962 \tTrain_Accu: 57%  \tValid_Acc:26%  \tVal_kappa : 0.120  \n",
            "Epoch: 78 \tTraining Loss:  0.975 \tTrain_Accu: 55%  \tValid_Acc:23%  \tVal_kappa : -0.011  \n",
            "Epoch: 79 \tTraining Loss:  0.886 \tTrain_Accu: 58%  \tValid_Acc:27%  \tVal_kappa : 0.118  \n",
            "Epoch: 80 \tTraining Loss:  1.038 \tTrain_Accu: 56%  \tValid_Acc:19%  \tVal_kappa : -0.187  \n",
            "Epoch: 81 \tTraining Loss:  0.878 \tTrain_Accu: 62%  \tValid_Acc:27%  \tVal_kappa : -0.286  \n",
            "Epoch: 82 \tTraining Loss:  0.898 \tTrain_Accu: 61%  \tValid_Acc:21%  \tVal_kappa : -0.403  \n",
            "Epoch: 83 \tTraining Loss:  0.922 \tTrain_Accu: 62%  \tValid_Acc:23%  \tVal_kappa : -0.113  \n",
            "Epoch: 84 \tTraining Loss:  0.828 \tTrain_Accu: 60%  \tValid_Acc:26%  \tVal_kappa : 0.113  \n",
            "Epoch: 85 \tTraining Loss:  0.934 \tTrain_Accu: 58%  \tValid_Acc:26%  \tVal_kappa : 0.104  \n",
            "Epoch: 86 \tTraining Loss:  0.881 \tTrain_Accu: 64%  \tValid_Acc:26%  \tVal_kappa : -0.272  \n",
            "Epoch: 87 \tTraining Loss:  0.847 \tTrain_Accu: 64%  \tValid_Acc:26%  \tVal_kappa : -0.164  \n",
            "Epoch: 88 \tTraining Loss:  0.834 \tTrain_Accu: 62%  \tValid_Acc:26%  \tVal_kappa : -0.134  \n",
            "Epoch: 89 \tTraining Loss:  0.890 \tTrain_Accu: 62%  \tValid_Acc:27%  \tVal_kappa : -0.366  \n",
            "Epoch: 90 \tTraining Loss:  0.895 \tTrain_Accu: 62%  \tValid_Acc:23%  \tVal_kappa : -0.435  \n",
            "Epoch: 91 \tTraining Loss:  0.884 \tTrain_Accu: 62%  \tValid_Acc:21%  \tVal_kappa : 0.195  \n",
            "Epoch: 92 \tTraining Loss:  0.851 \tTrain_Accu: 66%  \tValid_Acc:24%  \tVal_kappa : -0.030  \n",
            "Epoch: 93 \tTraining Loss:  0.911 \tTrain_Accu: 61%  \tValid_Acc:21%  \tVal_kappa : -0.390  \n",
            "Epoch: 94 \tTraining Loss:  0.909 \tTrain_Accu: 61%  \tValid_Acc:26%  \tVal_kappa : -0.141  \n",
            "Epoch: 95 \tTraining Loss:  0.803 \tTrain_Accu: 65%  \tValid_Acc:27%  \tVal_kappa : -0.093  \n",
            "Epoch: 96 \tTraining Loss:  0.831 \tTrain_Accu: 64%  \tValid_Acc:24%  \tVal_kappa : 0.000  \n",
            "Epoch: 97 \tTraining Loss:  0.727 \tTrain_Accu: 68%  \tValid_Acc:20%  \tVal_kappa : -0.041  \n",
            "Epoch: 98 \tTraining Loss:  0.782 \tTrain_Accu: 68%  \tValid_Acc:26%  \tVal_kappa : -0.072  \n",
            "Epoch: 99 \tTraining Loss:  0.758 \tTrain_Accu: 66%  \tValid_Acc:26%  \tVal_kappa : -0.055  \n",
            "Epoch: 100 \tTraining Loss:  0.833 \tTrain_Accu: 63%  \tValid_Acc:37%  \tVal_kappa : 0.378  \n",
            "Epoch: 101 \tTraining Loss:  0.758 \tTrain_Accu: 67%  \tValid_Acc:29%  \tVal_kappa : 0.012  \n",
            "Epoch: 102 \tTraining Loss:  0.865 \tTrain_Accu: 63%  \tValid_Acc:29%  \tVal_kappa : 0.228  \n",
            "Epoch: 103 \tTraining Loss:  0.710 \tTrain_Accu: 69%  \tValid_Acc:31%  \tVal_kappa : 0.000  \n",
            "Epoch: 104 \tTraining Loss:  0.724 \tTrain_Accu: 69%  \tValid_Acc:26%  \tVal_kappa : 0.065  \n",
            "Epoch: 105 \tTraining Loss:  0.801 \tTrain_Accu: 66%  \tValid_Acc:20%  \tVal_kappa : 0.103  \n",
            "Epoch: 106 \tTraining Loss:  0.805 \tTrain_Accu: 62%  \tValid_Acc:23%  \tVal_kappa : 0.000  \n",
            "Epoch: 107 \tTraining Loss:  0.692 \tTrain_Accu: 72%  \tValid_Acc:26%  \tVal_kappa : -0.283  \n",
            "Epoch: 108 \tTraining Loss:  0.826 \tTrain_Accu: 64%  \tValid_Acc:26%  \tVal_kappa : -0.249  \n",
            "Epoch: 109 \tTraining Loss:  0.734 \tTrain_Accu: 68%  \tValid_Acc:30%  \tVal_kappa : 0.125  \n",
            "Epoch: 110 \tTraining Loss:  0.701 \tTrain_Accu: 70%  \tValid_Acc:31%  \tVal_kappa : -0.462  \n",
            "Epoch: 111 \tTraining Loss:  0.726 \tTrain_Accu: 68%  \tValid_Acc:23%  \tVal_kappa : -0.115  \n",
            "Epoch: 112 \tTraining Loss:  0.799 \tTrain_Accu: 66%  \tValid_Acc:24%  \tVal_kappa : 0.034  \n",
            "Epoch: 113 \tTraining Loss:  0.675 \tTrain_Accu: 73%  \tValid_Acc:27%  \tVal_kappa : -0.326  \n",
            "Epoch: 114 \tTraining Loss:  0.776 \tTrain_Accu: 66%  \tValid_Acc:20%  \tVal_kappa : -0.106  \n",
            "Epoch: 115 \tTraining Loss:  0.770 \tTrain_Accu: 67%  \tValid_Acc:33%  \tVal_kappa : -0.351  \n",
            "Epoch: 116 \tTraining Loss:  0.698 \tTrain_Accu: 68%  \tValid_Acc:31%  \tVal_kappa : -0.066  \n",
            "Epoch: 117 \tTraining Loss:  0.646 \tTrain_Accu: 72%  \tValid_Acc:26%  \tVal_kappa : -0.262  \n",
            "Epoch: 118 \tTraining Loss:  0.680 \tTrain_Accu: 70%  \tValid_Acc:29%  \tVal_kappa : -0.121  \n",
            "Epoch: 119 \tTraining Loss:  0.674 \tTrain_Accu: 70%  \tValid_Acc:19%  \tVal_kappa : -0.053  \n",
            "Epoch: 120 \tTraining Loss:  0.670 \tTrain_Accu: 71%  \tValid_Acc:21%  \tVal_kappa : -0.361  \n",
            "Epoch: 121 \tTraining Loss:  0.626 \tTrain_Accu: 72%  \tValid_Acc:26%  \tVal_kappa : 0.088  \n",
            "Epoch: 122 \tTraining Loss:  0.686 \tTrain_Accu: 73%  \tValid_Acc:29%  \tVal_kappa : -0.084  \n",
            "Epoch: 123 \tTraining Loss:  0.629 \tTrain_Accu: 74%  \tValid_Acc:26%  \tVal_kappa : -0.320  \n",
            "Epoch: 124 \tTraining Loss:  0.720 \tTrain_Accu: 69%  \tValid_Acc:27%  \tVal_kappa : -0.274  \n",
            "Epoch: 125 \tTraining Loss:  0.695 \tTrain_Accu: 71%  \tValid_Acc:34%  \tVal_kappa : -0.170  \n",
            "Epoch: 126 \tTraining Loss:  0.693 \tTrain_Accu: 73%  \tValid_Acc:30%  \tVal_kappa : 0.438  \n",
            "Epoch: 127 \tTraining Loss:  0.663 \tTrain_Accu: 72%  \tValid_Acc:29%  \tVal_kappa : -0.215  \n",
            "Epoch: 128 \tTraining Loss:  0.642 \tTrain_Accu: 71%  \tValid_Acc:24%  \tVal_kappa : -0.016  \n",
            "Epoch: 129 \tTraining Loss:  0.731 \tTrain_Accu: 68%  \tValid_Acc:27%  \tVal_kappa : 0.102  \n",
            "Epoch: 130 \tTraining Loss:  0.676 \tTrain_Accu: 71%  \tValid_Acc:27%  \tVal_kappa : -0.250  \n",
            "Epoch: 131 \tTraining Loss:  0.677 \tTrain_Accu: 70%  \tValid_Acc:31%  \tVal_kappa : -0.258  \n",
            "Epoch: 132 \tTraining Loss:  0.668 \tTrain_Accu: 71%  \tValid_Acc:29%  \tVal_kappa : -0.015  \n",
            "Epoch: 133 \tTraining Loss:  0.527 \tTrain_Accu: 78%  \tValid_Acc:27%  \tVal_kappa : -0.181  \n",
            "Epoch: 134 \tTraining Loss:  0.666 \tTrain_Accu: 69%  \tValid_Acc:17%  \tVal_kappa : -0.109  \n",
            "Epoch: 135 \tTraining Loss:  0.657 \tTrain_Accu: 70%  \tValid_Acc:20%  \tVal_kappa : -0.173  \n",
            "Epoch: 136 \tTraining Loss:  0.621 \tTrain_Accu: 76%  \tValid_Acc:31%  \tVal_kappa : -0.261  \n",
            "Epoch: 137 \tTraining Loss:  0.589 \tTrain_Accu: 75%  \tValid_Acc:34%  \tVal_kappa : -0.332  \n",
            "Epoch: 138 \tTraining Loss:  0.574 \tTrain_Accu: 74%  \tValid_Acc:26%  \tVal_kappa : -0.416  \n",
            "Epoch: 139 \tTraining Loss:  0.668 \tTrain_Accu: 72%  \tValid_Acc:30%  \tVal_kappa : -0.078  \n",
            "Epoch: 140 \tTraining Loss:  0.637 \tTrain_Accu: 73%  \tValid_Acc:30%  \tVal_kappa : -0.088  \n",
            "Epoch: 141 \tTraining Loss:  0.552 \tTrain_Accu: 82%  \tValid_Acc:30%  \tVal_kappa : -0.018  \n",
            "Epoch: 142 \tTraining Loss:  0.674 \tTrain_Accu: 74%  \tValid_Acc:31%  \tVal_kappa : 0.086  \n",
            "Epoch: 143 \tTraining Loss:  0.643 \tTrain_Accu: 72%  \tValid_Acc:20%  \tVal_kappa : -0.257  \n",
            "Epoch: 144 \tTraining Loss:  0.625 \tTrain_Accu: 72%  \tValid_Acc:24%  \tVal_kappa : 0.052  \n",
            "Epoch: 145 \tTraining Loss:  0.609 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : -0.462  \n",
            "Epoch: 146 \tTraining Loss:  0.617 \tTrain_Accu: 72%  \tValid_Acc:23%  \tVal_kappa : 0.103  \n",
            "Epoch: 147 \tTraining Loss:  0.637 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : 0.000  \n",
            "Epoch: 148 \tTraining Loss:  0.659 \tTrain_Accu: 67%  \tValid_Acc:26%  \tVal_kappa : -0.062  \n",
            "Epoch: 149 \tTraining Loss:  0.616 \tTrain_Accu: 71%  \tValid_Acc:29%  \tVal_kappa : -0.082  \n",
            "Epoch: 150 \tTraining Loss:  0.577 \tTrain_Accu: 76%  \tValid_Acc:21%  \tVal_kappa : -0.610  \n",
            "Epoch: 151 \tTraining Loss:  0.661 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : -0.441  \n",
            "Epoch: 152 \tTraining Loss:  0.602 \tTrain_Accu: 72%  \tValid_Acc:20%  \tVal_kappa : -0.037  \n",
            "Epoch: 153 \tTraining Loss:  0.585 \tTrain_Accu: 77%  \tValid_Acc:21%  \tVal_kappa : -0.096  \n",
            "Epoch: 154 \tTraining Loss:  0.585 \tTrain_Accu: 77%  \tValid_Acc:31%  \tVal_kappa : 0.035  \n",
            "Epoch: 155 \tTraining Loss:  0.555 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : 0.088  \n",
            "Epoch: 156 \tTraining Loss:  0.575 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : -0.162  \n",
            "Epoch: 157 \tTraining Loss:  0.561 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : 0.183  \n",
            "Epoch: 158 \tTraining Loss:  0.622 \tTrain_Accu: 75%  \tValid_Acc:17%  \tVal_kappa : -0.381  \n",
            "Epoch: 159 \tTraining Loss:  0.535 \tTrain_Accu: 76%  \tValid_Acc:19%  \tVal_kappa : -0.341  \n",
            "Epoch: 160 \tTraining Loss:  0.618 \tTrain_Accu: 72%  \tValid_Acc:30%  \tVal_kappa : -0.315  \n",
            "Epoch: 161 \tTraining Loss:  0.587 \tTrain_Accu: 74%  \tValid_Acc:19%  \tVal_kappa : 0.195  \n",
            "Epoch: 162 \tTraining Loss:  0.542 \tTrain_Accu: 76%  \tValid_Acc:33%  \tVal_kappa : -0.042  \n",
            "Epoch: 163 \tTraining Loss:  0.618 \tTrain_Accu: 77%  \tValid_Acc:19%  \tVal_kappa : -0.441  \n",
            "Epoch: 164 \tTraining Loss:  0.620 \tTrain_Accu: 73%  \tValid_Acc:21%  \tVal_kappa : -0.292  \n",
            "Epoch: 165 \tTraining Loss:  0.531 \tTrain_Accu: 78%  \tValid_Acc:27%  \tVal_kappa : -0.127  \n",
            "Epoch: 166 \tTraining Loss:  0.656 \tTrain_Accu: 75%  \tValid_Acc:24%  \tVal_kappa : -0.065  \n",
            "Epoch: 167 \tTraining Loss:  0.504 \tTrain_Accu: 79%  \tValid_Acc:26%  \tVal_kappa : -0.340  \n",
            "Epoch: 168 \tTraining Loss:  0.567 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : -0.474  \n",
            "Epoch: 169 \tTraining Loss:  0.576 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : -0.222  \n",
            "Epoch: 170 \tTraining Loss:  0.552 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : -0.218  \n",
            "Epoch: 171 \tTraining Loss:  0.573 \tTrain_Accu: 77%  \tValid_Acc:24%  \tVal_kappa : -0.198  \n",
            "Epoch: 172 \tTraining Loss:  0.571 \tTrain_Accu: 75%  \tValid_Acc:31%  \tVal_kappa : 0.099  \n",
            "Epoch: 173 \tTraining Loss:  0.540 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : 0.172  \n",
            "Epoch: 174 \tTraining Loss:  0.568 \tTrain_Accu: 78%  \tValid_Acc:33%  \tVal_kappa : 0.119  \n",
            "Epoch: 175 \tTraining Loss:  0.584 \tTrain_Accu: 75%  \tValid_Acc:23%  \tVal_kappa : 0.107  \n",
            "Epoch: 176 \tTraining Loss:  0.561 \tTrain_Accu: 77%  \tValid_Acc:31%  \tVal_kappa : 0.042  \n",
            "Epoch: 177 \tTraining Loss:  0.532 \tTrain_Accu: 76%  \tValid_Acc:29%  \tVal_kappa : -0.260  \n",
            "Epoch: 178 \tTraining Loss:  0.516 \tTrain_Accu: 78%  \tValid_Acc:27%  \tVal_kappa : -0.012  \n",
            "Epoch: 179 \tTraining Loss:  0.592 \tTrain_Accu: 74%  \tValid_Acc:19%  \tVal_kappa : -0.540  \n",
            "Epoch: 180 \tTraining Loss:  0.607 \tTrain_Accu: 73%  \tValid_Acc:27%  \tVal_kappa : 0.061  \n",
            "Epoch: 181 \tTraining Loss:  0.638 \tTrain_Accu: 73%  \tValid_Acc:20%  \tVal_kappa : -0.359  \n",
            "Epoch: 182 \tTraining Loss:  0.491 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : -0.404  \n",
            "Epoch: 183 \tTraining Loss:  0.561 \tTrain_Accu: 77%  \tValid_Acc:23%  \tVal_kappa : -0.450  \n",
            "Epoch: 184 \tTraining Loss:  0.529 \tTrain_Accu: 78%  \tValid_Acc:31%  \tVal_kappa : 0.009  \n",
            "Epoch: 185 \tTraining Loss:  0.579 \tTrain_Accu: 76%  \tValid_Acc:16%  \tVal_kappa : -0.374  \n",
            "Epoch: 186 \tTraining Loss:  0.559 \tTrain_Accu: 77%  \tValid_Acc:24%  \tVal_kappa : -0.162  \n",
            "Epoch: 187 \tTraining Loss:  0.529 \tTrain_Accu: 78%  \tValid_Acc:26%  \tVal_kappa : -0.167  \n",
            "Epoch: 188 \tTraining Loss:  0.543 \tTrain_Accu: 81%  \tValid_Acc:31%  \tVal_kappa : -0.111  \n",
            "Epoch: 189 \tTraining Loss:  0.552 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : -0.451  \n",
            "Epoch: 190 \tTraining Loss:  0.478 \tTrain_Accu: 79%  \tValid_Acc:31%  \tVal_kappa : 0.133  \n",
            "Epoch: 191 \tTraining Loss:  0.554 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : 0.204  \n",
            "Epoch: 192 \tTraining Loss:  0.594 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : -0.186  \n",
            "Epoch: 193 \tTraining Loss:  0.489 \tTrain_Accu: 81%  \tValid_Acc:20%  \tVal_kappa : -0.069  \n",
            "Epoch: 194 \tTraining Loss:  0.534 \tTrain_Accu: 77%  \tValid_Acc:21%  \tVal_kappa : -0.214  \n",
            "Epoch: 195 \tTraining Loss:  0.560 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : -0.172  \n",
            "Epoch: 196 \tTraining Loss:  0.500 \tTrain_Accu: 81%  \tValid_Acc:29%  \tVal_kappa : -0.051  \n",
            "Epoch: 197 \tTraining Loss:  0.566 \tTrain_Accu: 75%  \tValid_Acc:24%  \tVal_kappa : -0.503  \n",
            "Epoch: 198 \tTraining Loss:  0.502 \tTrain_Accu: 78%  \tValid_Acc:27%  \tVal_kappa : -0.370  \n",
            "Epoch: 199 \tTraining Loss:  0.533 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : -0.191  \n",
            "Epoch: 200 \tTraining Loss:  0.548 \tTrain_Accu: 78%  \tValid_Acc:26%  \tVal_kappa : -0.252  \n",
            "Epoch: 201 \tTraining Loss:  0.491 \tTrain_Accu: 79%  \tValid_Acc:17%  \tVal_kappa : -0.410  \n",
            "Epoch: 202 \tTraining Loss:  0.522 \tTrain_Accu: 78%  \tValid_Acc:23%  \tVal_kappa : -0.437  \n",
            "Epoch: 203 \tTraining Loss:  0.538 \tTrain_Accu: 76%  \tValid_Acc:23%  \tVal_kappa : -0.153  \n",
            "Epoch: 204 \tTraining Loss:  0.475 \tTrain_Accu: 79%  \tValid_Acc:24%  \tVal_kappa : -0.006  \n",
            "Epoch: 205 \tTraining Loss:  0.548 \tTrain_Accu: 78%  \tValid_Acc:27%  \tVal_kappa : -0.072  \n",
            "Epoch: 206 \tTraining Loss:  0.518 \tTrain_Accu: 78%  \tValid_Acc:20%  \tVal_kappa : -0.218  \n",
            "Epoch: 207 \tTraining Loss:  0.531 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : -0.031  \n",
            "Epoch: 208 \tTraining Loss:  0.523 \tTrain_Accu: 76%  \tValid_Acc:26%  \tVal_kappa : -0.280  \n",
            "Epoch: 209 \tTraining Loss:  0.521 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : -0.234  \n",
            "Epoch: 210 \tTraining Loss:  0.540 \tTrain_Accu: 76%  \tValid_Acc:23%  \tVal_kappa : -0.267  \n",
            "Epoch: 211 \tTraining Loss:  0.518 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : -0.330  \n",
            "Epoch: 212 \tTraining Loss:  0.530 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : -0.325  \n",
            "Epoch: 213 \tTraining Loss:  0.460 \tTrain_Accu: 81%  \tValid_Acc:23%  \tVal_kappa : -0.077  \n",
            "Epoch: 214 \tTraining Loss:  0.513 \tTrain_Accu: 78%  \tValid_Acc:29%  \tVal_kappa : -0.109  \n",
            "Epoch: 215 \tTraining Loss:  0.507 \tTrain_Accu: 79%  \tValid_Acc:31%  \tVal_kappa : -0.186  \n",
            "Epoch: 216 \tTraining Loss:  0.484 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : -0.539  \n",
            "Epoch: 217 \tTraining Loss:  0.543 \tTrain_Accu: 75%  \tValid_Acc:29%  \tVal_kappa : -0.157  \n",
            "Epoch: 218 \tTraining Loss:  0.487 \tTrain_Accu: 78%  \tValid_Acc:17%  \tVal_kappa : -0.186  \n",
            "Epoch: 219 \tTraining Loss:  0.497 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : -0.113  \n",
            "Epoch: 220 \tTraining Loss:  0.467 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : -0.206  \n",
            "Epoch: 221 \tTraining Loss:  0.499 \tTrain_Accu: 78%  \tValid_Acc:20%  \tVal_kappa : -0.315  \n",
            "Epoch: 222 \tTraining Loss:  0.413 \tTrain_Accu: 82%  \tValid_Acc:30%  \tVal_kappa : -0.278  \n",
            "Epoch: 223 \tTraining Loss:  0.516 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : -0.381  \n",
            "Epoch: 224 \tTraining Loss:  0.492 \tTrain_Accu: 81%  \tValid_Acc:29%  \tVal_kappa : -0.021  \n",
            "Epoch: 225 \tTraining Loss:  0.474 \tTrain_Accu: 81%  \tValid_Acc:23%  \tVal_kappa : -0.256  \n",
            "Epoch: 226 \tTraining Loss:  0.505 \tTrain_Accu: 82%  \tValid_Acc:21%  \tVal_kappa : -0.165  \n",
            "Epoch: 227 \tTraining Loss:  0.485 \tTrain_Accu: 80%  \tValid_Acc:17%  \tVal_kappa : -0.196  \n",
            "Epoch: 228 \tTraining Loss:  0.577 \tTrain_Accu: 77%  \tValid_Acc:24%  \tVal_kappa : 0.210  \n",
            "Epoch: 229 \tTraining Loss:  0.474 \tTrain_Accu: 79%  \tValid_Acc:29%  \tVal_kappa : -0.290  \n",
            "Epoch: 230 \tTraining Loss:  0.575 \tTrain_Accu: 79%  \tValid_Acc:31%  \tVal_kappa : -0.218  \n",
            "Epoch: 231 \tTraining Loss:  0.556 \tTrain_Accu: 77%  \tValid_Acc:23%  \tVal_kappa : -0.400  \n",
            "Epoch: 232 \tTraining Loss:  0.492 \tTrain_Accu: 80%  \tValid_Acc:24%  \tVal_kappa : -0.601  \n",
            "Epoch: 233 \tTraining Loss:  0.506 \tTrain_Accu: 78%  \tValid_Acc:23%  \tVal_kappa : -0.024  \n",
            "Epoch: 234 \tTraining Loss:  0.532 \tTrain_Accu: 78%  \tValid_Acc:30%  \tVal_kappa : -0.245  \n",
            "Epoch: 235 \tTraining Loss:  0.497 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : -0.193  \n",
            "Epoch: 236 \tTraining Loss:  0.625 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : -0.094  \n",
            "Epoch: 237 \tTraining Loss:  0.482 \tTrain_Accu: 80%  \tValid_Acc:29%  \tVal_kappa : -0.498  \n",
            "Epoch: 238 \tTraining Loss:  0.601 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : 0.047  \n",
            "Epoch: 239 \tTraining Loss:  0.443 \tTrain_Accu: 82%  \tValid_Acc:16%  \tVal_kappa : -0.098  \n",
            "Epoch: 240 \tTraining Loss:  0.404 \tTrain_Accu: 83%  \tValid_Acc:24%  \tVal_kappa : -0.410  \n",
            "Epoch: 241 \tTraining Loss:  0.556 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : 0.051  \n",
            "Epoch: 242 \tTraining Loss:  0.476 \tTrain_Accu: 81%  \tValid_Acc:24%  \tVal_kappa : -0.168  \n",
            "Epoch: 243 \tTraining Loss:  0.454 \tTrain_Accu: 81%  \tValid_Acc:36%  \tVal_kappa : -0.244  \n",
            "Epoch: 244 \tTraining Loss:  0.394 \tTrain_Accu: 85%  \tValid_Acc:19%  \tVal_kappa : -0.191  \n",
            "Epoch: 245 \tTraining Loss:  0.461 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : 0.227  \n",
            "Epoch: 246 \tTraining Loss:  0.489 \tTrain_Accu: 81%  \tValid_Acc:31%  \tVal_kappa : -0.017  \n",
            "Epoch: 247 \tTraining Loss:  0.486 \tTrain_Accu: 79%  \tValid_Acc:20%  \tVal_kappa : -0.249  \n",
            "Epoch: 248 \tTraining Loss:  0.503 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : 0.396  \n",
            "Epoch: 249 \tTraining Loss:  0.508 \tTrain_Accu: 81%  \tValid_Acc:19%  \tVal_kappa : -0.041  \n",
            "Epoch: 250 \tTraining Loss:  0.483 \tTrain_Accu: 81%  \tValid_Acc:30%  \tVal_kappa : -0.488  \n",
            "Epoch: 251 \tTraining Loss:  0.497 \tTrain_Accu: 79%  \tValid_Acc:31%  \tVal_kappa : -0.462  \n",
            "Epoch: 252 \tTraining Loss:  0.495 \tTrain_Accu: 81%  \tValid_Acc:23%  \tVal_kappa : -0.480  \n",
            "Epoch: 253 \tTraining Loss:  0.483 \tTrain_Accu: 82%  \tValid_Acc:26%  \tVal_kappa : -0.272  \n",
            "Epoch: 254 \tTraining Loss:  0.388 \tTrain_Accu: 84%  \tValid_Acc:23%  \tVal_kappa : -0.355  \n",
            "Epoch: 255 \tTraining Loss:  0.495 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : -0.297  \n",
            "Epoch: 256 \tTraining Loss:  0.491 \tTrain_Accu: 78%  \tValid_Acc:24%  \tVal_kappa : -0.551  \n",
            "Epoch: 257 \tTraining Loss:  0.529 \tTrain_Accu: 79%  \tValid_Acc:26%  \tVal_kappa : -0.059  \n",
            "Epoch: 258 \tTraining Loss:  0.466 \tTrain_Accu: 80%  \tValid_Acc:14%  \tVal_kappa : -0.378  \n",
            "Epoch: 259 \tTraining Loss:  0.501 \tTrain_Accu: 78%  \tValid_Acc:14%  \tVal_kappa : 0.002  \n",
            "Epoch: 260 \tTraining Loss:  0.501 \tTrain_Accu: 82%  \tValid_Acc:19%  \tVal_kappa : -0.072  \n",
            "Epoch: 261 \tTraining Loss:  0.461 \tTrain_Accu: 81%  \tValid_Acc:24%  \tVal_kappa : -0.423  \n",
            "Epoch: 262 \tTraining Loss:  0.523 \tTrain_Accu: 79%  \tValid_Acc:26%  \tVal_kappa : -0.335  \n",
            "Epoch: 263 \tTraining Loss:  0.486 \tTrain_Accu: 79%  \tValid_Acc:27%  \tVal_kappa : -0.308  \n",
            "Epoch: 264 \tTraining Loss:  0.517 \tTrain_Accu: 79%  \tValid_Acc:27%  \tVal_kappa : -0.217  \n",
            "Epoch: 265 \tTraining Loss:  0.536 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : 0.000  \n",
            "Epoch: 266 \tTraining Loss:  0.446 \tTrain_Accu: 82%  \tValid_Acc:20%  \tVal_kappa : 0.188  \n",
            "Epoch: 267 \tTraining Loss:  0.527 \tTrain_Accu: 78%  \tValid_Acc:26%  \tVal_kappa : -0.439  \n",
            "Epoch: 268 \tTraining Loss:  0.498 \tTrain_Accu: 82%  \tValid_Acc:26%  \tVal_kappa : 0.359  \n",
            "Epoch: 269 \tTraining Loss:  0.479 \tTrain_Accu: 80%  \tValid_Acc:31%  \tVal_kappa : -0.152  \n",
            "Epoch: 270 \tTraining Loss:  0.448 \tTrain_Accu: 82%  \tValid_Acc:24%  \tVal_kappa : -0.107  \n",
            "Epoch: 271 \tTraining Loss:  0.523 \tTrain_Accu: 79%  \tValid_Acc:29%  \tVal_kappa : -0.326  \n",
            "Epoch: 272 \tTraining Loss:  0.394 \tTrain_Accu: 86%  \tValid_Acc:21%  \tVal_kappa : -0.312  \n",
            "Epoch: 273 \tTraining Loss:  0.501 \tTrain_Accu: 79%  \tValid_Acc:27%  \tVal_kappa : -0.400  \n",
            "Epoch: 274 \tTraining Loss:  0.406 \tTrain_Accu: 81%  \tValid_Acc:21%  \tVal_kappa : -0.052  \n",
            "Epoch: 275 \tTraining Loss:  0.468 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : 0.120  \n",
            "Epoch: 276 \tTraining Loss:  0.480 \tTrain_Accu: 81%  \tValid_Acc:31%  \tVal_kappa : -0.486  \n",
            "Epoch: 277 \tTraining Loss:  0.490 \tTrain_Accu: 81%  \tValid_Acc:24%  \tVal_kappa : -0.243  \n",
            "Epoch: 278 \tTraining Loss:  0.489 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : -0.167  \n",
            "Epoch: 279 \tTraining Loss:  0.496 \tTrain_Accu: 82%  \tValid_Acc:24%  \tVal_kappa : -0.485  \n",
            "Epoch: 280 \tTraining Loss:  0.497 \tTrain_Accu: 81%  \tValid_Acc:33%  \tVal_kappa : -0.183  \n",
            "Epoch: 281 \tTraining Loss:  0.406 \tTrain_Accu: 83%  \tValid_Acc:17%  \tVal_kappa : -0.030  \n",
            "Epoch: 282 \tTraining Loss:  0.498 \tTrain_Accu: 82%  \tValid_Acc:16%  \tVal_kappa : 0.259  \n",
            "Epoch: 283 \tTraining Loss:  0.563 \tTrain_Accu: 77%  \tValid_Acc:23%  \tVal_kappa : -0.250  \n",
            "Epoch: 284 \tTraining Loss:  0.463 \tTrain_Accu: 83%  \tValid_Acc:26%  \tVal_kappa : -0.414  \n",
            "Epoch: 285 \tTraining Loss:  0.422 \tTrain_Accu: 82%  \tValid_Acc:24%  \tVal_kappa : 0.345  \n",
            "Epoch: 286 \tTraining Loss:  0.425 \tTrain_Accu: 85%  \tValid_Acc:21%  \tVal_kappa : -0.356  \n",
            "Epoch: 287 \tTraining Loss:  0.566 \tTrain_Accu: 75%  \tValid_Acc:29%  \tVal_kappa : -0.468  \n",
            "Epoch: 288 \tTraining Loss:  0.504 \tTrain_Accu: 78%  \tValid_Acc:26%  \tVal_kappa : -0.482  \n",
            "Epoch: 289 \tTraining Loss:  0.467 \tTrain_Accu: 82%  \tValid_Acc:16%  \tVal_kappa : 0.065  \n",
            "Epoch: 290 \tTraining Loss:  0.474 \tTrain_Accu: 81%  \tValid_Acc:26%  \tVal_kappa : -0.297  \n",
            "Epoch: 291 \tTraining Loss:  0.489 \tTrain_Accu: 81%  \tValid_Acc:31%  \tVal_kappa : -0.286  \n",
            "Epoch: 292 \tTraining Loss:  0.396 \tTrain_Accu: 84%  \tValid_Acc:19%  \tVal_kappa : 0.442  \n",
            "Epoch: 293 \tTraining Loss:  0.454 \tTrain_Accu: 80%  \tValid_Acc:26%  \tVal_kappa : -0.293  \n",
            "Epoch: 294 \tTraining Loss:  0.460 \tTrain_Accu: 82%  \tValid_Acc:26%  \tVal_kappa : -0.415  \n",
            "Epoch: 295 \tTraining Loss:  0.397 \tTrain_Accu: 86%  \tValid_Acc:21%  \tVal_kappa : -0.203  \n",
            "Epoch: 296 \tTraining Loss:  0.483 \tTrain_Accu: 80%  \tValid_Acc:19%  \tVal_kappa : -0.234  \n",
            "Epoch: 297 \tTraining Loss:  0.523 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : -0.330  \n",
            "Epoch: 298 \tTraining Loss:  0.443 \tTrain_Accu: 81%  \tValid_Acc:21%  \tVal_kappa : -0.315  \n",
            "Epoch: 299 \tTraining Loss:  0.439 \tTrain_Accu: 85%  \tValid_Acc:23%  \tVal_kappa : -0.506  \n",
            "Epoch: 300 \tTraining Loss:  0.580 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : 0.089  \n",
            "Epoch: 301 \tTraining Loss:  0.455 \tTrain_Accu: 82%  \tValid_Acc:16%  \tVal_kappa : -0.068  \n",
            "Epoch: 302 \tTraining Loss:  0.484 \tTrain_Accu: 82%  \tValid_Acc:19%  \tVal_kappa : -0.240  \n",
            "Epoch: 303 \tTraining Loss:  0.435 \tTrain_Accu: 83%  \tValid_Acc:19%  \tVal_kappa : -0.359  \n",
            "Epoch: 304 \tTraining Loss:  0.507 \tTrain_Accu: 81%  \tValid_Acc:23%  \tVal_kappa : -0.518  \n",
            "Epoch: 305 \tTraining Loss:  0.375 \tTrain_Accu: 85%  \tValid_Acc:30%  \tVal_kappa : -0.350  \n",
            "Epoch: 306 \tTraining Loss:  0.461 \tTrain_Accu: 82%  \tValid_Acc:24%  \tVal_kappa : -0.226  \n",
            "Epoch: 307 \tTraining Loss:  0.423 \tTrain_Accu: 85%  \tValid_Acc:20%  \tVal_kappa : -0.511  \n",
            "Epoch: 308 \tTraining Loss:  0.461 \tTrain_Accu: 81%  \tValid_Acc:20%  \tVal_kappa : -0.268  \n",
            "Epoch: 309 \tTraining Loss:  0.437 \tTrain_Accu: 82%  \tValid_Acc:23%  \tVal_kappa : 0.209  \n",
            "Epoch: 310 \tTraining Loss:  0.450 \tTrain_Accu: 82%  \tValid_Acc:26%  \tVal_kappa : -0.078  \n",
            "Epoch: 311 \tTraining Loss:  0.423 \tTrain_Accu: 85%  \tValid_Acc:23%  \tVal_kappa : 0.565  \n",
            "Epoch: 312 \tTraining Loss:  0.372 \tTrain_Accu: 83%  \tValid_Acc:21%  \tVal_kappa : -0.430  \n",
            "Epoch: 313 \tTraining Loss:  0.448 \tTrain_Accu: 85%  \tValid_Acc:21%  \tVal_kappa : 0.012  \n",
            "Epoch: 314 \tTraining Loss:  0.508 \tTrain_Accu: 82%  \tValid_Acc:29%  \tVal_kappa : -0.027  \n",
            "Epoch: 315 \tTraining Loss:  0.421 \tTrain_Accu: 82%  \tValid_Acc:26%  \tVal_kappa : -0.380  \n",
            "Epoch: 316 \tTraining Loss:  0.491 \tTrain_Accu: 82%  \tValid_Acc:17%  \tVal_kappa : -0.143  \n",
            "Epoch: 317 \tTraining Loss:  0.459 \tTrain_Accu: 81%  \tValid_Acc:34%  \tVal_kappa : -0.512  \n",
            "Epoch: 318 \tTraining Loss:  0.447 \tTrain_Accu: 82%  \tValid_Acc:24%  \tVal_kappa : -0.278  \n",
            "Epoch: 319 \tTraining Loss:  0.498 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : -0.148  \n",
            "Epoch: 320 \tTraining Loss:  0.450 \tTrain_Accu: 83%  \tValid_Acc:23%  \tVal_kappa : -0.075  \n",
            "Epoch: 321 \tTraining Loss:  0.436 \tTrain_Accu: 82%  \tValid_Acc:16%  \tVal_kappa : -0.009  \n",
            "Epoch: 322 \tTraining Loss:  0.439 \tTrain_Accu: 83%  \tValid_Acc:26%  \tVal_kappa : -0.366  \n",
            "Epoch: 323 \tTraining Loss:  0.417 \tTrain_Accu: 81%  \tValid_Acc:24%  \tVal_kappa : 0.042  \n",
            "Epoch: 324 \tTraining Loss:  0.454 \tTrain_Accu: 81%  \tValid_Acc:21%  \tVal_kappa : -0.497  \n",
            "Epoch: 325 \tTraining Loss:  0.491 \tTrain_Accu: 79%  \tValid_Acc:11%  \tVal_kappa : -0.466  \n",
            "Epoch: 326 \tTraining Loss:  0.480 \tTrain_Accu: 83%  \tValid_Acc:27%  \tVal_kappa : 0.086  \n",
            "Epoch: 327 \tTraining Loss:  0.449 \tTrain_Accu: 82%  \tValid_Acc:27%  \tVal_kappa : -0.052  \n",
            "Epoch: 328 \tTraining Loss:  0.468 \tTrain_Accu: 81%  \tValid_Acc:24%  \tVal_kappa : 0.454  \n",
            "Epoch: 329 \tTraining Loss:  0.497 \tTrain_Accu: 81%  \tValid_Acc:23%  \tVal_kappa : -0.057  \n",
            "Epoch: 330 \tTraining Loss:  0.419 \tTrain_Accu: 83%  \tValid_Acc:21%  \tVal_kappa : 0.210  \n",
            "Epoch: 331 \tTraining Loss:  0.505 \tTrain_Accu: 84%  \tValid_Acc:27%  \tVal_kappa : -0.198  \n",
            "Epoch: 332 \tTraining Loss:  0.364 \tTrain_Accu: 85%  \tValid_Acc:17%  \tVal_kappa : -0.611  \n",
            "Epoch: 333 \tTraining Loss:  0.452 \tTrain_Accu: 81%  \tValid_Acc:23%  \tVal_kappa : -0.113  \n",
            "Epoch: 334 \tTraining Loss:  0.486 \tTrain_Accu: 82%  \tValid_Acc:21%  \tVal_kappa : 0.044  \n",
            "Epoch: 335 \tTraining Loss:  0.403 \tTrain_Accu: 83%  \tValid_Acc:20%  \tVal_kappa : 0.293  \n",
            "Epoch: 336 \tTraining Loss:  0.491 \tTrain_Accu: 81%  \tValid_Acc:16%  \tVal_kappa : -0.326  \n",
            "Epoch: 337 \tTraining Loss:  0.417 \tTrain_Accu: 80%  \tValid_Acc:19%  \tVal_kappa : -0.503  \n",
            "Epoch: 338 \tTraining Loss:  0.442 \tTrain_Accu: 81%  \tValid_Acc:30%  \tVal_kappa : -0.289  \n",
            "Epoch: 339 \tTraining Loss:  0.475 \tTrain_Accu: 81%  \tValid_Acc:24%  \tVal_kappa : -0.246  \n",
            "Epoch: 340 \tTraining Loss:  0.449 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : -0.519  \n",
            "Epoch: 341 \tTraining Loss:  0.425 \tTrain_Accu: 83%  \tValid_Acc:24%  \tVal_kappa : -0.486  \n",
            "Epoch: 342 \tTraining Loss:  0.467 \tTrain_Accu: 83%  \tValid_Acc:33%  \tVal_kappa : -0.490  \n",
            "Epoch: 343 \tTraining Loss:  0.465 \tTrain_Accu: 83%  \tValid_Acc:29%  \tVal_kappa : -0.041  \n",
            "Epoch: 344 \tTraining Loss:  0.470 \tTrain_Accu: 84%  \tValid_Acc:26%  \tVal_kappa : -0.399  \n",
            "Epoch: 345 \tTraining Loss:  0.414 \tTrain_Accu: 82%  \tValid_Acc:29%  \tVal_kappa : -0.222  \n",
            "Epoch: 346 \tTraining Loss:  0.502 \tTrain_Accu: 81%  \tValid_Acc:29%  \tVal_kappa : 0.284  \n",
            "Epoch: 347 \tTraining Loss:  0.494 \tTrain_Accu: 82%  \tValid_Acc:24%  \tVal_kappa : -0.195  \n",
            "Epoch: 348 \tTraining Loss:  0.429 \tTrain_Accu: 84%  \tValid_Acc:17%  \tVal_kappa : -0.583  \n",
            "Epoch: 349 \tTraining Loss:  0.535 \tTrain_Accu: 79%  \tValid_Acc:29%  \tVal_kappa : -0.194  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 04:21:59,879]\u001b[0m Trial 2 finished with value: 20.0 and parameters: {}. Best is trial 2 with value: 20.0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 350 \tTraining Loss:  0.425 \tTrain_Accu: 85%  \tValid_Acc:20%  \tVal_kappa : -0.113  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['optimise_valid_WNI_temp_drop(0.5).torch']"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iN-8q8Uyp9d"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "fK6xC3p3LTp6",
        "outputId": "d3a7e9f9-dd22-4360-863a-10d7046da007"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_temp_WNI[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_dropout(0.8)\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_WNI_temp_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 1, 2, 0, 2, 1, 0, 1, 1, 3, 1, 1, 1, 4, 0, 0, 2, 1, 0, 1, 4, 3, 0,\n",
            "        0, 0, 0, 0, 4, 2, 4, 4, 4, 1, 3, 3, 4, 2, 4, 2, 4, 0, 1, 0, 1, 2, 4, 4,\n",
            "        2, 4, 4, 2, 2, 0, 2, 2, 1, 0, 1, 3, 4, 1, 3, 1, 4, 0, 1, 1, 2, 1])\n",
            "labels tensor([1, 3, 4, 4, 4, 4, 2, 3, 2, 2, 3, 3, 4, 3, 4, 3, 2, 2, 1, 1, 2, 2, 3, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 1, 1, 3, 4, 4, 3, 2, 3, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 2, 3, 3, 4, 3, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 3, 4, 4])\n",
            "correct : 18\n",
            "test_Accuracy % : 25.7\n",
            "kappa 0.06610911987256074\n",
            "[[ 0  0  0  0  0]\n",
            " [ 1  2  0  2  0]\n",
            " [ 1  5  2  0  2]\n",
            " [ 4  7  3  2  1]\n",
            " [ 9  7  8  2 12]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr1Rrwddyp9e"
      },
      "source": [
        "## ESI_temp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0dWWRnFyp9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "b7290969-50fa-48b3-f50c-86f2dddd4444"
      },
      "source": [
        "# Reading rainfall file of NNI region \n",
        "Data_temp_ESI = pd.read_csv(\"drive/My Drive/DL_project/Target_TMean_ESI_regional_ave_time_series.csv\")\n",
        "Data_temp_ESI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>Tmean_N</th>\n",
              "      <th>cat_3</th>\n",
              "      <th>cat_5</th>\n",
              "      <th>anomalies</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-04-01</td>\n",
              "      <td>13.040097</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.742062</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-05-01</td>\n",
              "      <td>10.122859</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.356213</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-06-01</td>\n",
              "      <td>7.250265</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.288826</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-07-01</td>\n",
              "      <td>4.874913</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.008318</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-08-01</td>\n",
              "      <td>3.946161</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.369332</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>2019-08-01</td>\n",
              "      <td>5.151355</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.835862</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>6.052051</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.675340</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>2019-10-01</td>\n",
              "      <td>7.021530</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.274495</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>9.717596</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.406646</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>11.803418</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.542710</td>\n",
              "      <td>ESI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>465 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           time    Tmean_N  cat_3  cat_5  anomalies region\n",
              "0    1981-04-01  13.040097      3      5   0.742062    ESI\n",
              "1    1981-05-01  10.122859      3      4   0.356213    ESI\n",
              "2    1981-06-01   7.250265      2      4   0.288826    ESI\n",
              "3    1981-07-01   4.874913      2      3  -0.008318    ESI\n",
              "4    1981-08-01   3.946161      1      2  -0.369332    ESI\n",
              "..          ...        ...    ...    ...        ...    ...\n",
              "460  2019-08-01   5.151355      3      5   0.835862    ESI\n",
              "461  2019-09-01   6.052051      3      5   0.675340    ESI\n",
              "462  2019-10-01   7.021530      1      2  -0.274495    ESI\n",
              "463  2019-11-01   9.717596      3      4   0.406646    ESI\n",
              "464  2019-12-01  11.803418      3      5   0.542710    ESI\n",
              "\n",
              "[465 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGcP5Rcfyp9e"
      },
      "source": [
        "# Extracting label column\n",
        "labels_temp_ESI = Data_temp_ESI['cat_5'].astype(int) #cat5 column - so 5 prediction classes "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVA7Bb6syp9e"
      },
      "source": [
        "# Function that will convert labels into Pytorch tensors\n",
        "\n",
        "def labels_Tensors(labels):\n",
        "    return (torch.from_numpy(labels.values).type(torch.LongTensor)-1) #cat5 in form 1, 2, 3, 4, 5;\n",
        "\n",
        "# Converting labels of Temp_ESI region into tensors\n",
        "labelsTensors_temp_ESI = labels_Tensors(labels_temp_ESI) # This represents y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D45wkx6syp9f",
        "outputId": "e1bc0de5-9ba0-44ee-f3a5-95196799e6e4"
      },
      "source": [
        "train_lab_ESI = labels_temp_ESI[:324]\n",
        "train_lab_ESI.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    67\n",
              "2    66\n",
              "5    65\n",
              "4    64\n",
              "3    62\n",
              "Name: cat_5, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C49yLwulyp9f"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_valid_loaders_ESI_temp(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_ESI[:325])\n",
        "    validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_ESI[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyme6ElI6RgX"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_temp_ESI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 1,\n",
        "          'n_epochs' : 350,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           'dropout'       : 0.8,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_ESI_temp(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_WNI[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_WNI[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 1\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_temp_ESI[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_temp_ESI[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_ESI_temp_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQgNjDzryp9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e586154-aa9e-4688-bdde-e444789325ef"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_temp_ESI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"optimise_valid_ESI_temp_drop(0.5).torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.676 \tTrain_Accu: 24%  \tValid_Acc:10%  \tVal_kappa : 0.042  \n",
            "Epoch: 2 \tTraining Loss:  1.613 \tTrain_Accu: 18%  \tValid_Acc:17%  \tVal_kappa : 0.086  \n",
            "Epoch: 3 \tTraining Loss:  1.614 \tTrain_Accu: 19%  \tValid_Acc:16%  \tVal_kappa : -0.052  \n",
            "Epoch: 4 \tTraining Loss:  1.607 \tTrain_Accu: 21%  \tValid_Acc:17%  \tVal_kappa : 0.045  \n",
            "Epoch: 5 \tTraining Loss:  1.607 \tTrain_Accu: 23%  \tValid_Acc:16%  \tVal_kappa : -0.071  \n",
            "Epoch: 6 \tTraining Loss:  1.611 \tTrain_Accu: 19%  \tValid_Acc:17%  \tVal_kappa : -0.024  \n",
            "Epoch: 7 \tTraining Loss:  1.612 \tTrain_Accu: 21%  \tValid_Acc:20%  \tVal_kappa : 0.010  \n",
            "Epoch: 8 \tTraining Loss:  1.605 \tTrain_Accu: 23%  \tValid_Acc:17%  \tVal_kappa : 0.102  \n",
            "Epoch: 9 \tTraining Loss:  1.606 \tTrain_Accu: 26%  \tValid_Acc:20%  \tVal_kappa : -0.049  \n",
            "Epoch: 10 \tTraining Loss:  1.598 \tTrain_Accu: 24%  \tValid_Acc:14%  \tVal_kappa : -0.043  \n",
            "Epoch: 11 \tTraining Loss:  1.590 \tTrain_Accu: 25%  \tValid_Acc:13%  \tVal_kappa : -0.021  \n",
            "Epoch: 12 \tTraining Loss:  1.589 \tTrain_Accu: 24%  \tValid_Acc:17%  \tVal_kappa : -0.072  \n",
            "Epoch: 13 \tTraining Loss:  1.605 \tTrain_Accu: 20%  \tValid_Acc:23%  \tVal_kappa : 0.058  \n",
            "Epoch: 14 \tTraining Loss:  1.592 \tTrain_Accu: 25%  \tValid_Acc:13%  \tVal_kappa : 0.037  \n",
            "Epoch: 15 \tTraining Loss:  1.589 \tTrain_Accu: 22%  \tValid_Acc:13%  \tVal_kappa : -0.144  \n",
            "Epoch: 16 \tTraining Loss:  1.577 \tTrain_Accu: 26%  \tValid_Acc:19%  \tVal_kappa : -0.072  \n",
            "Epoch: 17 \tTraining Loss:  1.582 \tTrain_Accu: 25%  \tValid_Acc:13%  \tVal_kappa : -0.092  \n",
            "Epoch: 18 \tTraining Loss:  1.585 \tTrain_Accu: 22%  \tValid_Acc:13%  \tVal_kappa : -0.097  \n",
            "Epoch: 19 \tTraining Loss:  1.572 \tTrain_Accu: 26%  \tValid_Acc:17%  \tVal_kappa : 0.050  \n",
            "Epoch: 20 \tTraining Loss:  1.557 \tTrain_Accu: 26%  \tValid_Acc:24%  \tVal_kappa : 0.168  \n",
            "Epoch: 21 \tTraining Loss:  1.549 \tTrain_Accu: 26%  \tValid_Acc:24%  \tVal_kappa : 0.057  \n",
            "Epoch: 22 \tTraining Loss:  1.532 \tTrain_Accu: 29%  \tValid_Acc:19%  \tVal_kappa : -0.196  \n",
            "Epoch: 23 \tTraining Loss:  1.551 \tTrain_Accu: 26%  \tValid_Acc:13%  \tVal_kappa : -0.024  \n",
            "Epoch: 24 \tTraining Loss:  1.531 \tTrain_Accu: 28%  \tValid_Acc:21%  \tVal_kappa : 0.037  \n",
            "Epoch: 25 \tTraining Loss:  1.553 \tTrain_Accu: 26%  \tValid_Acc:20%  \tVal_kappa : 0.034  \n",
            "Epoch: 26 \tTraining Loss:  1.524 \tTrain_Accu: 35%  \tValid_Acc:14%  \tVal_kappa : -0.218  \n",
            "Epoch: 27 \tTraining Loss:  1.519 \tTrain_Accu: 31%  \tValid_Acc:20%  \tVal_kappa : -0.095  \n",
            "Epoch: 28 \tTraining Loss:  1.476 \tTrain_Accu: 32%  \tValid_Acc:14%  \tVal_kappa : -0.252  \n",
            "Epoch: 29 \tTraining Loss:  1.521 \tTrain_Accu: 27%  \tValid_Acc:17%  \tVal_kappa : -0.035  \n",
            "Epoch: 30 \tTraining Loss:  1.486 \tTrain_Accu: 32%  \tValid_Acc:23%  \tVal_kappa : 0.093  \n",
            "Epoch: 31 \tTraining Loss:  1.516 \tTrain_Accu: 30%  \tValid_Acc:14%  \tVal_kappa : -0.047  \n",
            "Epoch: 32 \tTraining Loss:  1.448 \tTrain_Accu: 36%  \tValid_Acc:20%  \tVal_kappa : 0.126  \n",
            "Epoch: 33 \tTraining Loss:  1.449 \tTrain_Accu: 39%  \tValid_Acc:23%  \tVal_kappa : 0.056  \n",
            "Epoch: 34 \tTraining Loss:  1.415 \tTrain_Accu: 36%  \tValid_Acc:21%  \tVal_kappa : 0.143  \n",
            "Epoch: 35 \tTraining Loss:  1.488 \tTrain_Accu: 31%  \tValid_Acc:26%  \tVal_kappa : 0.000  \n",
            "Epoch: 36 \tTraining Loss:  1.428 \tTrain_Accu: 33%  \tValid_Acc:19%  \tVal_kappa : -0.015  \n",
            "Epoch: 37 \tTraining Loss:  1.420 \tTrain_Accu: 38%  \tValid_Acc:20%  \tVal_kappa : 0.021  \n",
            "Epoch: 38 \tTraining Loss:  1.429 \tTrain_Accu: 37%  \tValid_Acc:23%  \tVal_kappa : -0.103  \n",
            "Epoch: 39 \tTraining Loss:  1.441 \tTrain_Accu: 36%  \tValid_Acc:13%  \tVal_kappa : 0.044  \n",
            "Epoch: 40 \tTraining Loss:  1.379 \tTrain_Accu: 38%  \tValid_Acc:20%  \tVal_kappa : -0.277  \n",
            "Epoch: 41 \tTraining Loss:  1.374 \tTrain_Accu: 43%  \tValid_Acc:24%  \tVal_kappa : 0.085  \n",
            "Epoch: 42 \tTraining Loss:  1.413 \tTrain_Accu: 35%  \tValid_Acc:16%  \tVal_kappa : -0.151  \n",
            "Epoch: 43 \tTraining Loss:  1.345 \tTrain_Accu: 43%  \tValid_Acc:19%  \tVal_kappa : -0.094  \n",
            "Epoch: 44 \tTraining Loss:  1.319 \tTrain_Accu: 42%  \tValid_Acc:21%  \tVal_kappa : 0.025  \n",
            "Epoch: 45 \tTraining Loss:  1.348 \tTrain_Accu: 42%  \tValid_Acc:17%  \tVal_kappa : 0.028  \n",
            "Epoch: 46 \tTraining Loss:  1.330 \tTrain_Accu: 45%  \tValid_Acc:23%  \tVal_kappa : 0.067  \n",
            "Epoch: 47 \tTraining Loss:  1.372 \tTrain_Accu: 35%  \tValid_Acc:19%  \tVal_kappa : -0.126  \n",
            "Epoch: 48 \tTraining Loss:  1.310 \tTrain_Accu: 42%  \tValid_Acc:21%  \tVal_kappa : 0.015  \n",
            "Epoch: 49 \tTraining Loss:  1.267 \tTrain_Accu: 44%  \tValid_Acc:26%  \tVal_kappa : 0.049  \n",
            "Epoch: 50 \tTraining Loss:  1.296 \tTrain_Accu: 42%  \tValid_Acc:10%  \tVal_kappa : -0.087  \n",
            "Epoch: 51 \tTraining Loss:  1.289 \tTrain_Accu: 42%  \tValid_Acc:20%  \tVal_kappa : 0.029  \n",
            "Epoch: 52 \tTraining Loss:  1.242 \tTrain_Accu: 46%  \tValid_Acc:17%  \tVal_kappa : -0.098  \n",
            "Epoch: 53 \tTraining Loss:  1.293 \tTrain_Accu: 42%  \tValid_Acc:19%  \tVal_kappa : -0.051  \n",
            "Epoch: 54 \tTraining Loss:  1.256 \tTrain_Accu: 45%  \tValid_Acc:16%  \tVal_kappa : -0.125  \n",
            "Epoch: 55 \tTraining Loss:  1.181 \tTrain_Accu: 46%  \tValid_Acc:20%  \tVal_kappa : -0.118  \n",
            "Epoch: 56 \tTraining Loss:  1.242 \tTrain_Accu: 42%  \tValid_Acc:21%  \tVal_kappa : 0.043  \n",
            "Epoch: 57 \tTraining Loss:  1.168 \tTrain_Accu: 52%  \tValid_Acc:16%  \tVal_kappa : -0.032  \n",
            "Epoch: 58 \tTraining Loss:  1.229 \tTrain_Accu: 45%  \tValid_Acc:20%  \tVal_kappa : -0.246  \n",
            "Epoch: 59 \tTraining Loss:  1.171 \tTrain_Accu: 49%  \tValid_Acc:23%  \tVal_kappa : -0.154  \n",
            "Epoch: 60 \tTraining Loss:  1.204 \tTrain_Accu: 48%  \tValid_Acc:21%  \tVal_kappa : 0.018  \n",
            "Epoch: 61 \tTraining Loss:  1.150 \tTrain_Accu: 52%  \tValid_Acc:19%  \tVal_kappa : -0.048  \n",
            "Epoch: 62 \tTraining Loss:  1.148 \tTrain_Accu: 49%  \tValid_Acc:24%  \tVal_kappa : 0.056  \n",
            "Epoch: 63 \tTraining Loss:  1.165 \tTrain_Accu: 50%  \tValid_Acc:17%  \tVal_kappa : -0.074  \n",
            "Epoch: 64 \tTraining Loss:  1.178 \tTrain_Accu: 51%  \tValid_Acc:30%  \tVal_kappa : -0.013  \n",
            "Epoch: 65 \tTraining Loss:  1.157 \tTrain_Accu: 46%  \tValid_Acc:29%  \tVal_kappa : -0.039  \n",
            "Epoch: 66 \tTraining Loss:  1.131 \tTrain_Accu: 53%  \tValid_Acc:21%  \tVal_kappa : 0.021  \n",
            "Epoch: 67 \tTraining Loss:  1.145 \tTrain_Accu: 52%  \tValid_Acc:30%  \tVal_kappa : 0.243  \n",
            "Epoch: 68 \tTraining Loss:  1.105 \tTrain_Accu: 51%  \tValid_Acc:9%  \tVal_kappa : -0.282  \n",
            "Epoch: 69 \tTraining Loss:  1.088 \tTrain_Accu: 54%  \tValid_Acc:19%  \tVal_kappa : -0.021  \n",
            "Epoch: 70 \tTraining Loss:  1.115 \tTrain_Accu: 51%  \tValid_Acc:19%  \tVal_kappa : -0.119  \n",
            "Epoch: 71 \tTraining Loss:  1.129 \tTrain_Accu: 49%  \tValid_Acc:17%  \tVal_kappa : -0.121  \n",
            "Epoch: 72 \tTraining Loss:  1.070 \tTrain_Accu: 53%  \tValid_Acc:20%  \tVal_kappa : -0.021  \n",
            "Epoch: 73 \tTraining Loss:  1.017 \tTrain_Accu: 58%  \tValid_Acc:20%  \tVal_kappa : -0.081  \n",
            "Epoch: 74 \tTraining Loss:  1.048 \tTrain_Accu: 55%  \tValid_Acc:24%  \tVal_kappa : 0.084  \n",
            "Epoch: 75 \tTraining Loss:  1.043 \tTrain_Accu: 52%  \tValid_Acc:19%  \tVal_kappa : 0.039  \n",
            "Epoch: 76 \tTraining Loss:  1.003 \tTrain_Accu: 59%  \tValid_Acc:16%  \tVal_kappa : -0.094  \n",
            "Epoch: 77 \tTraining Loss:  1.066 \tTrain_Accu: 54%  \tValid_Acc:26%  \tVal_kappa : 0.082  \n",
            "Epoch: 78 \tTraining Loss:  1.071 \tTrain_Accu: 54%  \tValid_Acc:24%  \tVal_kappa : -0.026  \n",
            "Epoch: 79 \tTraining Loss:  1.053 \tTrain_Accu: 53%  \tValid_Acc:21%  \tVal_kappa : -0.210  \n",
            "Epoch: 80 \tTraining Loss:  1.067 \tTrain_Accu: 56%  \tValid_Acc:17%  \tVal_kappa : -0.248  \n",
            "Epoch: 81 \tTraining Loss:  0.999 \tTrain_Accu: 59%  \tValid_Acc:17%  \tVal_kappa : 0.007  \n",
            "Epoch: 82 \tTraining Loss:  0.960 \tTrain_Accu: 60%  \tValid_Acc:14%  \tVal_kappa : -0.014  \n",
            "Epoch: 83 \tTraining Loss:  1.007 \tTrain_Accu: 56%  \tValid_Acc:21%  \tVal_kappa : 0.071  \n",
            "Epoch: 84 \tTraining Loss:  1.126 \tTrain_Accu: 51%  \tValid_Acc:19%  \tVal_kappa : -0.076  \n",
            "Epoch: 85 \tTraining Loss:  0.937 \tTrain_Accu: 61%  \tValid_Acc:17%  \tVal_kappa : -0.066  \n",
            "Epoch: 86 \tTraining Loss:  0.978 \tTrain_Accu: 59%  \tValid_Acc:20%  \tVal_kappa : -0.213  \n",
            "Epoch: 87 \tTraining Loss:  0.940 \tTrain_Accu: 61%  \tValid_Acc:29%  \tVal_kappa : 0.320  \n",
            "Epoch: 88 \tTraining Loss:  0.940 \tTrain_Accu: 59%  \tValid_Acc:20%  \tVal_kappa : 0.029  \n",
            "Epoch: 89 \tTraining Loss:  0.931 \tTrain_Accu: 60%  \tValid_Acc:27%  \tVal_kappa : -0.045  \n",
            "Epoch: 90 \tTraining Loss:  0.909 \tTrain_Accu: 61%  \tValid_Acc:16%  \tVal_kappa : 0.122  \n",
            "Epoch: 91 \tTraining Loss:  0.891 \tTrain_Accu: 62%  \tValid_Acc:20%  \tVal_kappa : 0.082  \n",
            "Epoch: 92 \tTraining Loss:  0.941 \tTrain_Accu: 60%  \tValid_Acc:21%  \tVal_kappa : 0.036  \n",
            "Epoch: 93 \tTraining Loss:  0.965 \tTrain_Accu: 61%  \tValid_Acc:16%  \tVal_kappa : -0.169  \n",
            "Epoch: 94 \tTraining Loss:  0.960 \tTrain_Accu: 59%  \tValid_Acc:21%  \tVal_kappa : 0.038  \n",
            "Epoch: 95 \tTraining Loss:  0.910 \tTrain_Accu: 63%  \tValid_Acc:23%  \tVal_kappa : 0.112  \n",
            "Epoch: 96 \tTraining Loss:  0.944 \tTrain_Accu: 61%  \tValid_Acc:26%  \tVal_kappa : 0.143  \n",
            "Epoch: 97 \tTraining Loss:  0.876 \tTrain_Accu: 63%  \tValid_Acc:27%  \tVal_kappa : 0.001  \n",
            "Epoch: 98 \tTraining Loss:  0.842 \tTrain_Accu: 65%  \tValid_Acc:17%  \tVal_kappa : 0.068  \n",
            "Epoch: 99 \tTraining Loss:  0.962 \tTrain_Accu: 58%  \tValid_Acc:13%  \tVal_kappa : 0.000  \n",
            "Epoch: 100 \tTraining Loss:  0.917 \tTrain_Accu: 59%  \tValid_Acc:21%  \tVal_kappa : 0.071  \n",
            "Epoch: 101 \tTraining Loss:  0.897 \tTrain_Accu: 68%  \tValid_Acc:20%  \tVal_kappa : 0.000  \n",
            "Epoch: 102 \tTraining Loss:  0.879 \tTrain_Accu: 63%  \tValid_Acc:19%  \tVal_kappa : -0.009  \n",
            "Epoch: 103 \tTraining Loss:  0.825 \tTrain_Accu: 65%  \tValid_Acc:23%  \tVal_kappa : -0.110  \n",
            "Epoch: 104 \tTraining Loss:  0.851 \tTrain_Accu: 65%  \tValid_Acc:23%  \tVal_kappa : 0.163  \n",
            "Epoch: 105 \tTraining Loss:  0.859 \tTrain_Accu: 66%  \tValid_Acc:27%  \tVal_kappa : 0.045  \n",
            "Epoch: 106 \tTraining Loss:  0.801 \tTrain_Accu: 65%  \tValid_Acc:23%  \tVal_kappa : -0.002  \n",
            "Epoch: 107 \tTraining Loss:  0.864 \tTrain_Accu: 62%  \tValid_Acc:20%  \tVal_kappa : 0.074  \n",
            "Epoch: 108 \tTraining Loss:  0.850 \tTrain_Accu: 62%  \tValid_Acc:27%  \tVal_kappa : 0.031  \n",
            "Epoch: 109 \tTraining Loss:  0.778 \tTrain_Accu: 67%  \tValid_Acc:17%  \tVal_kappa : -0.124  \n",
            "Epoch: 110 \tTraining Loss:  0.805 \tTrain_Accu: 67%  \tValid_Acc:21%  \tVal_kappa : 0.180  \n",
            "Epoch: 111 \tTraining Loss:  0.826 \tTrain_Accu: 65%  \tValid_Acc:26%  \tVal_kappa : 0.213  \n",
            "Epoch: 112 \tTraining Loss:  0.818 \tTrain_Accu: 67%  \tValid_Acc:19%  \tVal_kappa : 0.023  \n",
            "Epoch: 113 \tTraining Loss:  0.782 \tTrain_Accu: 66%  \tValid_Acc:24%  \tVal_kappa : 0.098  \n",
            "Epoch: 114 \tTraining Loss:  0.888 \tTrain_Accu: 61%  \tValid_Acc:23%  \tVal_kappa : -0.054  \n",
            "Epoch: 115 \tTraining Loss:  0.781 \tTrain_Accu: 66%  \tValid_Acc:29%  \tVal_kappa : -0.068  \n",
            "Epoch: 116 \tTraining Loss:  0.868 \tTrain_Accu: 64%  \tValid_Acc:21%  \tVal_kappa : -0.094  \n",
            "Epoch: 117 \tTraining Loss:  0.856 \tTrain_Accu: 66%  \tValid_Acc:13%  \tVal_kappa : 0.051  \n",
            "Epoch: 118 \tTraining Loss:  0.748 \tTrain_Accu: 68%  \tValid_Acc:29%  \tVal_kappa : 0.274  \n",
            "Epoch: 119 \tTraining Loss:  0.760 \tTrain_Accu: 70%  \tValid_Acc:23%  \tVal_kappa : 0.049  \n",
            "Epoch: 120 \tTraining Loss:  0.887 \tTrain_Accu: 64%  \tValid_Acc:23%  \tVal_kappa : 0.057  \n",
            "Epoch: 121 \tTraining Loss:  0.735 \tTrain_Accu: 70%  \tValid_Acc:20%  \tVal_kappa : -0.050  \n",
            "Epoch: 122 \tTraining Loss:  0.858 \tTrain_Accu: 63%  \tValid_Acc:29%  \tVal_kappa : 0.082  \n",
            "Epoch: 123 \tTraining Loss:  0.800 \tTrain_Accu: 67%  \tValid_Acc:26%  \tVal_kappa : -0.003  \n",
            "Epoch: 124 \tTraining Loss:  0.781 \tTrain_Accu: 66%  \tValid_Acc:20%  \tVal_kappa : -0.038  \n",
            "Epoch: 125 \tTraining Loss:  0.836 \tTrain_Accu: 67%  \tValid_Acc:17%  \tVal_kappa : -0.018  \n",
            "Epoch: 126 \tTraining Loss:  0.770 \tTrain_Accu: 67%  \tValid_Acc:24%  \tVal_kappa : 0.073  \n",
            "Epoch: 127 \tTraining Loss:  0.806 \tTrain_Accu: 66%  \tValid_Acc:16%  \tVal_kappa : 0.032  \n",
            "Epoch: 128 \tTraining Loss:  0.799 \tTrain_Accu: 68%  \tValid_Acc:16%  \tVal_kappa : 0.157  \n",
            "Epoch: 129 \tTraining Loss:  0.858 \tTrain_Accu: 63%  \tValid_Acc:20%  \tVal_kappa : -0.096  \n",
            "Epoch: 130 \tTraining Loss:  0.741 \tTrain_Accu: 70%  \tValid_Acc:16%  \tVal_kappa : 0.012  \n",
            "Epoch: 131 \tTraining Loss:  0.730 \tTrain_Accu: 71%  \tValid_Acc:14%  \tVal_kappa : 0.057  \n",
            "Epoch: 132 \tTraining Loss:  0.787 \tTrain_Accu: 66%  \tValid_Acc:16%  \tVal_kappa : 0.169  \n",
            "Epoch: 133 \tTraining Loss:  0.677 \tTrain_Accu: 72%  \tValid_Acc:16%  \tVal_kappa : -0.076  \n",
            "Epoch: 134 \tTraining Loss:  0.765 \tTrain_Accu: 69%  \tValid_Acc:23%  \tVal_kappa : 0.050  \n",
            "Epoch: 135 \tTraining Loss:  0.803 \tTrain_Accu: 66%  \tValid_Acc:16%  \tVal_kappa : -0.035  \n",
            "Epoch: 136 \tTraining Loss:  0.787 \tTrain_Accu: 65%  \tValid_Acc:16%  \tVal_kappa : 0.119  \n",
            "Epoch: 137 \tTraining Loss:  0.736 \tTrain_Accu: 67%  \tValid_Acc:24%  \tVal_kappa : 0.078  \n",
            "Epoch: 138 \tTraining Loss:  0.685 \tTrain_Accu: 71%  \tValid_Acc:21%  \tVal_kappa : -0.045  \n",
            "Epoch: 139 \tTraining Loss:  0.701 \tTrain_Accu: 70%  \tValid_Acc:23%  \tVal_kappa : 0.029  \n",
            "Epoch: 140 \tTraining Loss:  0.701 \tTrain_Accu: 69%  \tValid_Acc:17%  \tVal_kappa : -0.140  \n",
            "Epoch: 141 \tTraining Loss:  0.654 \tTrain_Accu: 74%  \tValid_Acc:16%  \tVal_kappa : 0.008  \n",
            "Epoch: 142 \tTraining Loss:  0.694 \tTrain_Accu: 73%  \tValid_Acc:33%  \tVal_kappa : 0.124  \n",
            "Epoch: 143 \tTraining Loss:  0.647 \tTrain_Accu: 73%  \tValid_Acc:17%  \tVal_kappa : -0.018  \n",
            "Epoch: 144 \tTraining Loss:  0.728 \tTrain_Accu: 70%  \tValid_Acc:19%  \tVal_kappa : 0.025  \n",
            "Epoch: 145 \tTraining Loss:  0.688 \tTrain_Accu: 71%  \tValid_Acc:21%  \tVal_kappa : -0.105  \n",
            "Epoch: 146 \tTraining Loss:  0.765 \tTrain_Accu: 68%  \tValid_Acc:23%  \tVal_kappa : 0.037  \n",
            "Epoch: 147 \tTraining Loss:  0.680 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : 0.282  \n",
            "Epoch: 148 \tTraining Loss:  0.632 \tTrain_Accu: 72%  \tValid_Acc:13%  \tVal_kappa : -0.105  \n",
            "Epoch: 149 \tTraining Loss:  0.683 \tTrain_Accu: 73%  \tValid_Acc:34%  \tVal_kappa : 0.101  \n",
            "Epoch: 150 \tTraining Loss:  0.687 \tTrain_Accu: 73%  \tValid_Acc:29%  \tVal_kappa : 0.155  \n",
            "Epoch: 151 \tTraining Loss:  0.769 \tTrain_Accu: 66%  \tValid_Acc:24%  \tVal_kappa : 0.099  \n",
            "Epoch: 152 \tTraining Loss:  0.697 \tTrain_Accu: 72%  \tValid_Acc:17%  \tVal_kappa : -0.125  \n",
            "Epoch: 153 \tTraining Loss:  0.681 \tTrain_Accu: 70%  \tValid_Acc:29%  \tVal_kappa : 0.046  \n",
            "Epoch: 154 \tTraining Loss:  0.716 \tTrain_Accu: 74%  \tValid_Acc:27%  \tVal_kappa : 0.210  \n",
            "Epoch: 155 \tTraining Loss:  0.674 \tTrain_Accu: 71%  \tValid_Acc:23%  \tVal_kappa : 0.104  \n",
            "Epoch: 156 \tTraining Loss:  0.709 \tTrain_Accu: 72%  \tValid_Acc:26%  \tVal_kappa : 0.086  \n",
            "Epoch: 157 \tTraining Loss:  0.728 \tTrain_Accu: 70%  \tValid_Acc:16%  \tVal_kappa : -0.068  \n",
            "Epoch: 158 \tTraining Loss:  0.777 \tTrain_Accu: 70%  \tValid_Acc:21%  \tVal_kappa : -0.018  \n",
            "Epoch: 159 \tTraining Loss:  0.734 \tTrain_Accu: 70%  \tValid_Acc:23%  \tVal_kappa : 0.009  \n",
            "Epoch: 160 \tTraining Loss:  0.732 \tTrain_Accu: 70%  \tValid_Acc:21%  \tVal_kappa : -0.027  \n",
            "Epoch: 161 \tTraining Loss:  0.636 \tTrain_Accu: 72%  \tValid_Acc:23%  \tVal_kappa : 0.073  \n",
            "Epoch: 162 \tTraining Loss:  0.804 \tTrain_Accu: 63%  \tValid_Acc:20%  \tVal_kappa : 0.051  \n",
            "Epoch: 163 \tTraining Loss:  0.794 \tTrain_Accu: 69%  \tValid_Acc:24%  \tVal_kappa : 0.061  \n",
            "Epoch: 164 \tTraining Loss:  0.786 \tTrain_Accu: 68%  \tValid_Acc:23%  \tVal_kappa : 0.064  \n",
            "Epoch: 165 \tTraining Loss:  0.628 \tTrain_Accu: 78%  \tValid_Acc:14%  \tVal_kappa : 0.140  \n",
            "Epoch: 166 \tTraining Loss:  0.668 \tTrain_Accu: 73%  \tValid_Acc:14%  \tVal_kappa : 0.007  \n",
            "Epoch: 167 \tTraining Loss:  0.701 \tTrain_Accu: 73%  \tValid_Acc:16%  \tVal_kappa : 0.031  \n",
            "Epoch: 168 \tTraining Loss:  0.661 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : 0.221  \n",
            "Epoch: 169 \tTraining Loss:  0.620 \tTrain_Accu: 73%  \tValid_Acc:14%  \tVal_kappa : -0.029  \n",
            "Epoch: 170 \tTraining Loss:  0.640 \tTrain_Accu: 72%  \tValid_Acc:29%  \tVal_kappa : 0.299  \n",
            "Epoch: 171 \tTraining Loss:  0.679 \tTrain_Accu: 73%  \tValid_Acc:17%  \tVal_kappa : -0.091  \n",
            "Epoch: 172 \tTraining Loss:  0.672 \tTrain_Accu: 70%  \tValid_Acc:19%  \tVal_kappa : -0.015  \n",
            "Epoch: 173 \tTraining Loss:  0.718 \tTrain_Accu: 73%  \tValid_Acc:16%  \tVal_kappa : 0.152  \n",
            "Epoch: 174 \tTraining Loss:  0.733 \tTrain_Accu: 70%  \tValid_Acc:21%  \tVal_kappa : -0.006  \n",
            "Epoch: 175 \tTraining Loss:  0.720 \tTrain_Accu: 73%  \tValid_Acc:24%  \tVal_kappa : -0.021  \n",
            "Epoch: 176 \tTraining Loss:  0.670 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : 0.032  \n",
            "Epoch: 177 \tTraining Loss:  0.644 \tTrain_Accu: 75%  \tValid_Acc:17%  \tVal_kappa : 0.186  \n",
            "Epoch: 178 \tTraining Loss:  0.734 \tTrain_Accu: 70%  \tValid_Acc:19%  \tVal_kappa : -0.023  \n",
            "Epoch: 179 \tTraining Loss:  0.675 \tTrain_Accu: 72%  \tValid_Acc:20%  \tVal_kappa : -0.058  \n",
            "Epoch: 180 \tTraining Loss:  0.740 \tTrain_Accu: 68%  \tValid_Acc:20%  \tVal_kappa : 0.002  \n",
            "Epoch: 181 \tTraining Loss:  0.741 \tTrain_Accu: 70%  \tValid_Acc:23%  \tVal_kappa : -0.028  \n",
            "Epoch: 182 \tTraining Loss:  0.615 \tTrain_Accu: 74%  \tValid_Acc:14%  \tVal_kappa : -0.033  \n",
            "Epoch: 183 \tTraining Loss:  0.643 \tTrain_Accu: 75%  \tValid_Acc:16%  \tVal_kappa : 0.204  \n",
            "Epoch: 184 \tTraining Loss:  0.662 \tTrain_Accu: 71%  \tValid_Acc:24%  \tVal_kappa : 0.113  \n",
            "Epoch: 185 \tTraining Loss:  0.709 \tTrain_Accu: 67%  \tValid_Acc:17%  \tVal_kappa : 0.125  \n",
            "Epoch: 186 \tTraining Loss:  0.604 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : 0.157  \n",
            "Epoch: 187 \tTraining Loss:  0.683 \tTrain_Accu: 72%  \tValid_Acc:19%  \tVal_kappa : 0.015  \n",
            "Epoch: 188 \tTraining Loss:  0.699 \tTrain_Accu: 71%  \tValid_Acc:14%  \tVal_kappa : -0.032  \n",
            "Epoch: 189 \tTraining Loss:  0.652 \tTrain_Accu: 72%  \tValid_Acc:11%  \tVal_kappa : 0.013  \n",
            "Epoch: 190 \tTraining Loss:  0.640 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : 0.185  \n",
            "Epoch: 191 \tTraining Loss:  0.679 \tTrain_Accu: 73%  \tValid_Acc:16%  \tVal_kappa : 0.092  \n",
            "Epoch: 192 \tTraining Loss:  0.654 \tTrain_Accu: 73%  \tValid_Acc:20%  \tVal_kappa : 0.023  \n",
            "Epoch: 193 \tTraining Loss:  0.645 \tTrain_Accu: 74%  \tValid_Acc:13%  \tVal_kappa : -0.029  \n",
            "Epoch: 194 \tTraining Loss:  0.639 \tTrain_Accu: 77%  \tValid_Acc:16%  \tVal_kappa : 0.060  \n",
            "Epoch: 195 \tTraining Loss:  0.649 \tTrain_Accu: 73%  \tValid_Acc:17%  \tVal_kappa : 0.088  \n",
            "Epoch: 196 \tTraining Loss:  0.676 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : 0.194  \n",
            "Epoch: 197 \tTraining Loss:  0.639 \tTrain_Accu: 74%  \tValid_Acc:21%  \tVal_kappa : -0.050  \n",
            "Epoch: 198 \tTraining Loss:  0.663 \tTrain_Accu: 74%  \tValid_Acc:20%  \tVal_kappa : 0.125  \n",
            "Epoch: 199 \tTraining Loss:  0.732 \tTrain_Accu: 71%  \tValid_Acc:17%  \tVal_kappa : 0.058  \n",
            "Epoch: 200 \tTraining Loss:  0.611 \tTrain_Accu: 77%  \tValid_Acc:19%  \tVal_kappa : -0.018  \n",
            "Epoch: 201 \tTraining Loss:  0.657 \tTrain_Accu: 74%  \tValid_Acc:19%  \tVal_kappa : 0.009  \n",
            "Epoch: 202 \tTraining Loss:  0.626 \tTrain_Accu: 74%  \tValid_Acc:13%  \tVal_kappa : -0.146  \n",
            "Epoch: 203 \tTraining Loss:  0.688 \tTrain_Accu: 73%  \tValid_Acc:17%  \tVal_kappa : 0.046  \n",
            "Epoch: 204 \tTraining Loss:  0.598 \tTrain_Accu: 76%  \tValid_Acc:20%  \tVal_kappa : 0.016  \n",
            "Epoch: 205 \tTraining Loss:  0.599 \tTrain_Accu: 75%  \tValid_Acc:26%  \tVal_kappa : 0.163  \n",
            "Epoch: 206 \tTraining Loss:  0.643 \tTrain_Accu: 75%  \tValid_Acc:24%  \tVal_kappa : 0.041  \n",
            "Epoch: 207 \tTraining Loss:  0.676 \tTrain_Accu: 72%  \tValid_Acc:21%  \tVal_kappa : 0.198  \n",
            "Epoch: 208 \tTraining Loss:  0.648 \tTrain_Accu: 74%  \tValid_Acc:20%  \tVal_kappa : 0.212  \n",
            "Epoch: 209 \tTraining Loss:  0.688 \tTrain_Accu: 75%  \tValid_Acc:23%  \tVal_kappa : 0.179  \n",
            "Epoch: 210 \tTraining Loss:  0.730 \tTrain_Accu: 72%  \tValid_Acc:21%  \tVal_kappa : 0.154  \n",
            "Epoch: 211 \tTraining Loss:  0.614 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : 0.100  \n",
            "Epoch: 212 \tTraining Loss:  0.611 \tTrain_Accu: 77%  \tValid_Acc:24%  \tVal_kappa : 0.058  \n",
            "Epoch: 213 \tTraining Loss:  0.599 \tTrain_Accu: 73%  \tValid_Acc:17%  \tVal_kappa : 0.048  \n",
            "Epoch: 214 \tTraining Loss:  0.638 \tTrain_Accu: 76%  \tValid_Acc:14%  \tVal_kappa : -0.052  \n",
            "Epoch: 215 \tTraining Loss:  0.664 \tTrain_Accu: 76%  \tValid_Acc:23%  \tVal_kappa : 0.106  \n",
            "Epoch: 216 \tTraining Loss:  0.650 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : -0.028  \n",
            "Epoch: 217 \tTraining Loss:  0.717 \tTrain_Accu: 73%  \tValid_Acc:19%  \tVal_kappa : 0.259  \n",
            "Epoch: 218 \tTraining Loss:  0.712 \tTrain_Accu: 68%  \tValid_Acc:27%  \tVal_kappa : 0.230  \n",
            "Epoch: 219 \tTraining Loss:  0.629 \tTrain_Accu: 75%  \tValid_Acc:13%  \tVal_kappa : 0.060  \n",
            "Epoch: 220 \tTraining Loss:  0.626 \tTrain_Accu: 75%  \tValid_Acc:10%  \tVal_kappa : 0.046  \n",
            "Epoch: 221 \tTraining Loss:  0.695 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : 0.016  \n",
            "Epoch: 222 \tTraining Loss:  0.623 \tTrain_Accu: 75%  \tValid_Acc:20%  \tVal_kappa : 0.073  \n",
            "Epoch: 223 \tTraining Loss:  0.678 \tTrain_Accu: 73%  \tValid_Acc:17%  \tVal_kappa : -0.045  \n",
            "Epoch: 224 \tTraining Loss:  0.605 \tTrain_Accu: 76%  \tValid_Acc:23%  \tVal_kappa : 0.175  \n",
            "Epoch: 225 \tTraining Loss:  0.654 \tTrain_Accu: 71%  \tValid_Acc:24%  \tVal_kappa : 0.043  \n",
            "Epoch: 226 \tTraining Loss:  0.566 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : 0.132  \n",
            "Epoch: 227 \tTraining Loss:  0.673 \tTrain_Accu: 74%  \tValid_Acc:19%  \tVal_kappa : 0.080  \n",
            "Epoch: 228 \tTraining Loss:  0.677 \tTrain_Accu: 72%  \tValid_Acc:29%  \tVal_kappa : 0.158  \n",
            "Epoch: 229 \tTraining Loss:  0.607 \tTrain_Accu: 75%  \tValid_Acc:23%  \tVal_kappa : 0.167  \n",
            "Epoch: 230 \tTraining Loss:  0.645 \tTrain_Accu: 73%  \tValid_Acc:16%  \tVal_kappa : 0.118  \n",
            "Epoch: 231 \tTraining Loss:  0.644 \tTrain_Accu: 74%  \tValid_Acc:21%  \tVal_kappa : 0.096  \n",
            "Epoch: 232 \tTraining Loss:  0.597 \tTrain_Accu: 76%  \tValid_Acc:27%  \tVal_kappa : 0.107  \n",
            "Epoch: 233 \tTraining Loss:  0.699 \tTrain_Accu: 72%  \tValid_Acc:16%  \tVal_kappa : 0.248  \n",
            "Epoch: 234 \tTraining Loss:  0.601 \tTrain_Accu: 76%  \tValid_Acc:26%  \tVal_kappa : 0.337  \n",
            "Epoch: 235 \tTraining Loss:  0.569 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : -0.002  \n",
            "Epoch: 236 \tTraining Loss:  0.759 \tTrain_Accu: 68%  \tValid_Acc:16%  \tVal_kappa : 0.045  \n",
            "Epoch: 237 \tTraining Loss:  0.591 \tTrain_Accu: 75%  \tValid_Acc:20%  \tVal_kappa : -0.018  \n",
            "Epoch: 238 \tTraining Loss:  0.573 \tTrain_Accu: 79%  \tValid_Acc:20%  \tVal_kappa : 0.002  \n",
            "Epoch: 239 \tTraining Loss:  0.604 \tTrain_Accu: 75%  \tValid_Acc:9%  \tVal_kappa : 0.038  \n",
            "Epoch: 240 \tTraining Loss:  0.583 \tTrain_Accu: 80%  \tValid_Acc:16%  \tVal_kappa : -0.079  \n",
            "Epoch: 241 \tTraining Loss:  0.652 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : 0.037  \n",
            "Epoch: 242 \tTraining Loss:  0.559 \tTrain_Accu: 79%  \tValid_Acc:11%  \tVal_kappa : -0.064  \n",
            "Epoch: 243 \tTraining Loss:  0.693 \tTrain_Accu: 72%  \tValid_Acc:19%  \tVal_kappa : -0.006  \n",
            "Epoch: 244 \tTraining Loss:  0.659 \tTrain_Accu: 73%  \tValid_Acc:13%  \tVal_kappa : 0.007  \n",
            "Epoch: 245 \tTraining Loss:  0.612 \tTrain_Accu: 75%  \tValid_Acc:14%  \tVal_kappa : -0.153  \n",
            "Epoch: 246 \tTraining Loss:  0.672 \tTrain_Accu: 76%  \tValid_Acc:21%  \tVal_kappa : 0.112  \n",
            "Epoch: 247 \tTraining Loss:  0.617 \tTrain_Accu: 74%  \tValid_Acc:17%  \tVal_kappa : 0.120  \n",
            "Epoch: 248 \tTraining Loss:  0.599 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : 0.147  \n",
            "Epoch: 249 \tTraining Loss:  0.635 \tTrain_Accu: 75%  \tValid_Acc:20%  \tVal_kappa : 0.048  \n",
            "Epoch: 250 \tTraining Loss:  0.496 \tTrain_Accu: 79%  \tValid_Acc:24%  \tVal_kappa : 0.118  \n",
            "Epoch: 251 \tTraining Loss:  0.593 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : -0.016  \n",
            "Epoch: 252 \tTraining Loss:  0.570 \tTrain_Accu: 75%  \tValid_Acc:17%  \tVal_kappa : -0.035  \n",
            "Epoch: 253 \tTraining Loss:  0.606 \tTrain_Accu: 76%  \tValid_Acc:16%  \tVal_kappa : -0.029  \n",
            "Epoch: 254 \tTraining Loss:  0.550 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : 0.093  \n",
            "Epoch: 255 \tTraining Loss:  0.583 \tTrain_Accu: 78%  \tValid_Acc:29%  \tVal_kappa : -0.183  \n",
            "Epoch: 256 \tTraining Loss:  0.610 \tTrain_Accu: 76%  \tValid_Acc:21%  \tVal_kappa : -0.048  \n",
            "Epoch: 257 \tTraining Loss:  0.664 \tTrain_Accu: 74%  \tValid_Acc:14%  \tVal_kappa : 0.056  \n",
            "Epoch: 258 \tTraining Loss:  0.613 \tTrain_Accu: 75%  \tValid_Acc:20%  \tVal_kappa : -0.038  \n",
            "Epoch: 259 \tTraining Loss:  0.646 \tTrain_Accu: 76%  \tValid_Acc:26%  \tVal_kappa : 0.179  \n",
            "Epoch: 260 \tTraining Loss:  0.557 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : 0.226  \n",
            "Epoch: 261 \tTraining Loss:  0.630 \tTrain_Accu: 73%  \tValid_Acc:21%  \tVal_kappa : 0.026  \n",
            "Epoch: 262 \tTraining Loss:  0.589 \tTrain_Accu: 76%  \tValid_Acc:17%  \tVal_kappa : -0.112  \n",
            "Epoch: 263 \tTraining Loss:  0.658 \tTrain_Accu: 72%  \tValid_Acc:20%  \tVal_kappa : 0.123  \n",
            "Epoch: 264 \tTraining Loss:  0.678 \tTrain_Accu: 74%  \tValid_Acc:24%  \tVal_kappa : 0.022  \n",
            "Epoch: 265 \tTraining Loss:  0.642 \tTrain_Accu: 75%  \tValid_Acc:23%  \tVal_kappa : -0.007  \n",
            "Epoch: 266 \tTraining Loss:  0.694 \tTrain_Accu: 72%  \tValid_Acc:19%  \tVal_kappa : 0.202  \n",
            "Epoch: 267 \tTraining Loss:  0.562 \tTrain_Accu: 77%  \tValid_Acc:13%  \tVal_kappa : -0.074  \n",
            "Epoch: 268 \tTraining Loss:  0.561 \tTrain_Accu: 77%  \tValid_Acc:24%  \tVal_kappa : 0.157  \n",
            "Epoch: 269 \tTraining Loss:  0.650 \tTrain_Accu: 73%  \tValid_Acc:9%  \tVal_kappa : -0.135  \n",
            "Epoch: 270 \tTraining Loss:  0.660 \tTrain_Accu: 75%  \tValid_Acc:16%  \tVal_kappa : 0.027  \n",
            "Epoch: 271 \tTraining Loss:  0.602 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : 0.146  \n",
            "Epoch: 272 \tTraining Loss:  0.609 \tTrain_Accu: 77%  \tValid_Acc:20%  \tVal_kappa : 0.087  \n",
            "Epoch: 273 \tTraining Loss:  0.651 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : 0.131  \n",
            "Epoch: 274 \tTraining Loss:  0.637 \tTrain_Accu: 75%  \tValid_Acc:10%  \tVal_kappa : 0.009  \n",
            "Epoch: 275 \tTraining Loss:  0.657 \tTrain_Accu: 74%  \tValid_Acc:21%  \tVal_kappa : 0.122  \n",
            "Epoch: 276 \tTraining Loss:  0.566 \tTrain_Accu: 79%  \tValid_Acc:16%  \tVal_kappa : 0.082  \n",
            "Epoch: 277 \tTraining Loss:  0.624 \tTrain_Accu: 75%  \tValid_Acc:24%  \tVal_kappa : 0.128  \n",
            "Epoch: 278 \tTraining Loss:  0.546 \tTrain_Accu: 80%  \tValid_Acc:16%  \tVal_kappa : -0.012  \n",
            "Epoch: 279 \tTraining Loss:  0.595 \tTrain_Accu: 74%  \tValid_Acc:21%  \tVal_kappa : 0.369  \n",
            "Epoch: 280 \tTraining Loss:  0.609 \tTrain_Accu: 76%  \tValid_Acc:13%  \tVal_kappa : 0.170  \n",
            "Epoch: 281 \tTraining Loss:  0.679 \tTrain_Accu: 74%  \tValid_Acc:26%  \tVal_kappa : 0.055  \n",
            "Epoch: 282 \tTraining Loss:  0.595 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : 0.064  \n",
            "Epoch: 283 \tTraining Loss:  0.557 \tTrain_Accu: 80%  \tValid_Acc:17%  \tVal_kappa : -0.060  \n",
            "Epoch: 284 \tTraining Loss:  0.618 \tTrain_Accu: 74%  \tValid_Acc:19%  \tVal_kappa : -0.008  \n",
            "Epoch: 285 \tTraining Loss:  0.600 \tTrain_Accu: 74%  \tValid_Acc:14%  \tVal_kappa : 0.004  \n",
            "Epoch: 286 \tTraining Loss:  0.602 \tTrain_Accu: 75%  \tValid_Acc:24%  \tVal_kappa : 0.099  \n",
            "Epoch: 287 \tTraining Loss:  0.566 \tTrain_Accu: 79%  \tValid_Acc:21%  \tVal_kappa : 0.247  \n",
            "Epoch: 288 \tTraining Loss:  0.521 \tTrain_Accu: 78%  \tValid_Acc:26%  \tVal_kappa : 0.013  \n",
            "Epoch: 289 \tTraining Loss:  0.614 \tTrain_Accu: 75%  \tValid_Acc:17%  \tVal_kappa : 0.064  \n",
            "Epoch: 290 \tTraining Loss:  0.633 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : 0.081  \n",
            "Epoch: 291 \tTraining Loss:  0.551 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : -0.210  \n",
            "Epoch: 292 \tTraining Loss:  0.511 \tTrain_Accu: 80%  \tValid_Acc:23%  \tVal_kappa : -0.001  \n",
            "Epoch: 293 \tTraining Loss:  0.603 \tTrain_Accu: 76%  \tValid_Acc:26%  \tVal_kappa : -0.002  \n",
            "Epoch: 294 \tTraining Loss:  0.625 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : 0.005  \n",
            "Epoch: 295 \tTraining Loss:  0.545 \tTrain_Accu: 76%  \tValid_Acc:19%  \tVal_kappa : 0.112  \n",
            "Epoch: 296 \tTraining Loss:  0.621 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : 0.140  \n",
            "Epoch: 297 \tTraining Loss:  0.587 \tTrain_Accu: 77%  \tValid_Acc:11%  \tVal_kappa : -0.024  \n",
            "Epoch: 298 \tTraining Loss:  0.632 \tTrain_Accu: 73%  \tValid_Acc:19%  \tVal_kappa : 0.066  \n",
            "Epoch: 299 \tTraining Loss:  0.578 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : -0.270  \n",
            "Epoch: 300 \tTraining Loss:  0.626 \tTrain_Accu: 78%  \tValid_Acc:20%  \tVal_kappa : -0.085  \n",
            "Epoch: 301 \tTraining Loss:  0.534 \tTrain_Accu: 78%  \tValid_Acc:13%  \tVal_kappa : 0.030  \n",
            "Epoch: 302 \tTraining Loss:  0.576 \tTrain_Accu: 78%  \tValid_Acc:14%  \tVal_kappa : 0.017  \n",
            "Epoch: 303 \tTraining Loss:  0.666 \tTrain_Accu: 74%  \tValid_Acc:20%  \tVal_kappa : -0.072  \n",
            "Epoch: 304 \tTraining Loss:  0.687 \tTrain_Accu: 74%  \tValid_Acc:26%  \tVal_kappa : 0.066  \n",
            "Epoch: 305 \tTraining Loss:  0.593 \tTrain_Accu: 75%  \tValid_Acc:13%  \tVal_kappa : 0.020  \n",
            "Epoch: 306 \tTraining Loss:  0.611 \tTrain_Accu: 77%  \tValid_Acc:16%  \tVal_kappa : 0.167  \n",
            "Epoch: 307 \tTraining Loss:  0.583 \tTrain_Accu: 77%  \tValid_Acc:29%  \tVal_kappa : 0.193  \n",
            "Epoch: 308 \tTraining Loss:  0.626 \tTrain_Accu: 73%  \tValid_Acc:11%  \tVal_kappa : -0.047  \n",
            "Epoch: 309 \tTraining Loss:  0.616 \tTrain_Accu: 76%  \tValid_Acc:23%  \tVal_kappa : 0.111  \n",
            "Epoch: 310 \tTraining Loss:  0.516 \tTrain_Accu: 79%  \tValid_Acc:14%  \tVal_kappa : 0.178  \n",
            "Epoch: 311 \tTraining Loss:  0.587 \tTrain_Accu: 78%  \tValid_Acc:13%  \tVal_kappa : 0.002  \n",
            "Epoch: 312 \tTraining Loss:  0.544 \tTrain_Accu: 78%  \tValid_Acc:17%  \tVal_kappa : 0.030  \n",
            "Epoch: 313 \tTraining Loss:  0.642 \tTrain_Accu: 73%  \tValid_Acc:17%  \tVal_kappa : 0.051  \n",
            "Epoch: 314 \tTraining Loss:  0.599 \tTrain_Accu: 77%  \tValid_Acc:26%  \tVal_kappa : 0.027  \n",
            "Epoch: 315 \tTraining Loss:  0.579 \tTrain_Accu: 78%  \tValid_Acc:14%  \tVal_kappa : -0.075  \n",
            "Epoch: 316 \tTraining Loss:  0.668 \tTrain_Accu: 71%  \tValid_Acc:21%  \tVal_kappa : -0.120  \n",
            "Epoch: 317 \tTraining Loss:  0.672 \tTrain_Accu: 74%  \tValid_Acc:27%  \tVal_kappa : -0.042  \n",
            "Epoch: 318 \tTraining Loss:  0.603 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : 0.031  \n",
            "Epoch: 319 \tTraining Loss:  0.561 \tTrain_Accu: 82%  \tValid_Acc:20%  \tVal_kappa : 0.113  \n",
            "Epoch: 320 \tTraining Loss:  0.587 \tTrain_Accu: 76%  \tValid_Acc:17%  \tVal_kappa : -0.006  \n",
            "Epoch: 321 \tTraining Loss:  0.608 \tTrain_Accu: 77%  \tValid_Acc:21%  \tVal_kappa : 0.078  \n",
            "Epoch: 322 \tTraining Loss:  0.551 \tTrain_Accu: 77%  \tValid_Acc:14%  \tVal_kappa : 0.025  \n",
            "Epoch: 323 \tTraining Loss:  0.615 \tTrain_Accu: 73%  \tValid_Acc:16%  \tVal_kappa : 0.031  \n",
            "Epoch: 324 \tTraining Loss:  0.658 \tTrain_Accu: 72%  \tValid_Acc:21%  \tVal_kappa : 0.124  \n",
            "Epoch: 325 \tTraining Loss:  0.513 \tTrain_Accu: 78%  \tValid_Acc:19%  \tVal_kappa : -0.152  \n",
            "Epoch: 326 \tTraining Loss:  0.571 \tTrain_Accu: 80%  \tValid_Acc:16%  \tVal_kappa : -0.044  \n",
            "Epoch: 327 \tTraining Loss:  0.590 \tTrain_Accu: 77%  \tValid_Acc:19%  \tVal_kappa : -0.095  \n",
            "Epoch: 328 \tTraining Loss:  0.579 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : 0.093  \n",
            "Epoch: 329 \tTraining Loss:  0.699 \tTrain_Accu: 74%  \tValid_Acc:17%  \tVal_kappa : 0.042  \n",
            "Epoch: 330 \tTraining Loss:  0.590 \tTrain_Accu: 76%  \tValid_Acc:17%  \tVal_kappa : 0.155  \n",
            "Epoch: 331 \tTraining Loss:  0.639 \tTrain_Accu: 76%  \tValid_Acc:19%  \tVal_kappa : 0.122  \n",
            "Epoch: 332 \tTraining Loss:  0.595 \tTrain_Accu: 78%  \tValid_Acc:17%  \tVal_kappa : -0.020  \n",
            "Epoch: 333 \tTraining Loss:  0.619 \tTrain_Accu: 76%  \tValid_Acc:17%  \tVal_kappa : 0.020  \n",
            "Epoch: 334 \tTraining Loss:  0.617 \tTrain_Accu: 76%  \tValid_Acc:24%  \tVal_kappa : 0.134  \n",
            "Epoch: 335 \tTraining Loss:  0.589 \tTrain_Accu: 78%  \tValid_Acc:14%  \tVal_kappa : -0.005  \n",
            "Epoch: 336 \tTraining Loss:  0.617 \tTrain_Accu: 78%  \tValid_Acc:16%  \tVal_kappa : -0.053  \n",
            "Epoch: 337 \tTraining Loss:  0.491 \tTrain_Accu: 80%  \tValid_Acc:20%  \tVal_kappa : 0.036  \n",
            "Epoch: 338 \tTraining Loss:  0.601 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : -0.047  \n",
            "Epoch: 339 \tTraining Loss:  0.634 \tTrain_Accu: 76%  \tValid_Acc:17%  \tVal_kappa : -0.035  \n",
            "Epoch: 340 \tTraining Loss:  0.577 \tTrain_Accu: 79%  \tValid_Acc:26%  \tVal_kappa : 0.114  \n",
            "Epoch: 341 \tTraining Loss:  0.765 \tTrain_Accu: 73%  \tValid_Acc:14%  \tVal_kappa : -0.088  \n",
            "Epoch: 342 \tTraining Loss:  0.648 \tTrain_Accu: 74%  \tValid_Acc:13%  \tVal_kappa : -0.073  \n",
            "Epoch: 343 \tTraining Loss:  0.519 \tTrain_Accu: 79%  \tValid_Acc:11%  \tVal_kappa : -0.056  \n",
            "Epoch: 344 \tTraining Loss:  0.589 \tTrain_Accu: 79%  \tValid_Acc:24%  \tVal_kappa : 0.160  \n",
            "Epoch: 345 \tTraining Loss:  0.519 \tTrain_Accu: 78%  \tValid_Acc:16%  \tVal_kappa : -0.010  \n",
            "Epoch: 346 \tTraining Loss:  0.682 \tTrain_Accu: 74%  \tValid_Acc:14%  \tVal_kappa : -0.137  \n",
            "Epoch: 347 \tTraining Loss:  0.613 \tTrain_Accu: 78%  \tValid_Acc:29%  \tVal_kappa : 0.099  \n",
            "Epoch: 348 \tTraining Loss:  0.531 \tTrain_Accu: 79%  \tValid_Acc:23%  \tVal_kappa : 0.187  \n",
            "Epoch: 349 \tTraining Loss:  0.660 \tTrain_Accu: 73%  \tValid_Acc:29%  \tVal_kappa : 0.164  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 04:50:58,528]\u001b[0m Trial 6 finished with value: 18.6 and parameters: {}. Best is trial 2 with value: 20.0.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 350 \tTraining Loss:  0.539 \tTrain_Accu: 79%  \tValid_Acc:19%  \tVal_kappa : 0.021  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['optimise_valid_ESI_temp_drop(0.5).torch']"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYcbCWkNyp9g"
      },
      "source": [
        "### Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "00v-p4sL-gHR",
        "outputId": "7dd37a06-d6cc-4e64-eef8-8606c6a6b440"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_temp_ESI[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_dropout(0.8)\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_ESI_temp_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3, 3, 3, 1, 3, 1, 0, 3, 3, 2, 1, 2, 1, 3, 3, 0, 2, 0, 0, 1, 0, 2, 4, 0,\n",
            "        0, 0, 4, 3, 1, 0, 0, 0, 3, 3, 1, 4, 2, 4, 3, 3, 0, 1, 4, 0, 0, 4, 4, 4,\n",
            "        4, 2, 2, 4, 4, 2, 4, 0, 0, 2, 3, 0, 3, 3, 0, 0, 2, 0, 4, 0, 2, 0])\n",
            "labels tensor([1, 2, 2, 4, 4, 4, 3, 2, 2, 2, 3, 4, 4, 3, 4, 4, 3, 2, 1, 1, 2, 3, 2, 4,\n",
            "        4, 4, 4, 4, 4, 4, 3, 2, 4, 3, 1, 1, 1, 2, 2, 1, 1, 3, 4, 4, 4, 4, 4, 4,\n",
            "        4, 2, 2, 1, 3, 4, 4, 2, 2, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 1, 3, 4])\n",
            "correct : 15\n",
            "test_Accuracy % : 21.4\n",
            "kappa 0.0101608806096527\n",
            "[[ 0  0  0  0  0]\n",
            " [ 3  2  1  2  2]\n",
            " [ 5  0  3  5  2]\n",
            " [ 3  2  4  2  1]\n",
            " [11  4  3  7  8]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "068Amke5yp9g"
      },
      "source": [
        "## ENI_temp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9nCPH2oyp9h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "10055c5d-f07c-4480-b4a3-715e663ede47"
      },
      "source": [
        "# Reading rainfall file of NNI region \n",
        "Data_temp_ENI = pd.read_csv(\"drive/My Drive/DL_project/Target_TMean_ENI_regional_ave_time_series.csv\")\n",
        "Data_temp_ENI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>Tmean_N</th>\n",
              "      <th>cat_3</th>\n",
              "      <th>cat_5</th>\n",
              "      <th>anomalies</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-04-01</td>\n",
              "      <td>16.006345</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1.307379</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-05-01</td>\n",
              "      <td>13.409171</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.959782</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-06-01</td>\n",
              "      <td>10.818665</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.773066</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-07-01</td>\n",
              "      <td>8.664255</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.340433</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-08-01</td>\n",
              "      <td>7.825879</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.221965</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>2019-08-01</td>\n",
              "      <td>8.084237</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.480323</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>8.767038</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.584472</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>2019-10-01</td>\n",
              "      <td>9.567420</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.019324</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>11.961591</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.654974</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>14.048849</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.799999</td>\n",
              "      <td>ENI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>465 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           time    Tmean_N  cat_3  cat_5  anomalies region\n",
              "0    1981-04-01  16.006345      3      5   1.307379    ENI\n",
              "1    1981-05-01  13.409171      3      5   0.959782    ENI\n",
              "2    1981-06-01  10.818665      3      5   0.773066    ENI\n",
              "3    1981-07-01   8.664255      3      4   0.340433    ENI\n",
              "4    1981-08-01   7.825879      2      4   0.221965    ENI\n",
              "..          ...        ...    ...    ...        ...    ...\n",
              "460  2019-08-01   8.084237      3      5   0.480323    ENI\n",
              "461  2019-09-01   8.767038      3      5   0.584472    ENI\n",
              "462  2019-10-01   9.567420      2      3   0.019324    ENI\n",
              "463  2019-11-01  11.961591      3      5   0.654974    ENI\n",
              "464  2019-12-01  14.048849      3      5   0.799999    ENI\n",
              "\n",
              "[465 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB1iBAI3yp9h"
      },
      "source": [
        "# Extracting label column\n",
        "labels_temp_ENI = Data_temp_ENI['cat_5'].astype(int) #cat5 column - so 5 prediction classes "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHrBi43Iyp9h"
      },
      "source": [
        "# Function that will convert labels into Pytorch tensors\n",
        "\n",
        "def labels_Tensors(labels):\n",
        "    return (torch.from_numpy(labels.values).type(torch.LongTensor)-1) #cat5 in form 1, 2, 3, 4, 5;\n",
        "\n",
        "# Converting labels of Temp_ENI region into tensors\n",
        "labelsTensors_temp_ENI = labels_Tensors(labels_temp_ENI) # This represents y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8Vf9zoCyp9h",
        "outputId": "38666877-4f72-4558-db69-95763d1bd774"
      },
      "source": [
        "train_lab_ENI = labels_temp_ENI[:324]\n",
        "train_lab_ENI.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    71\n",
              "1    65\n",
              "4    64\n",
              "2    63\n",
              "3    61\n",
              "Name: cat_5, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yknwAE8dyp9i"
      },
      "source": [
        "# Function to get data loader functions\n",
        "\n",
        "def get_valid_loaders_ENI_temp(Batch_size):\n",
        "    \"\"\"Get data loaders\"\"\"\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_ENI[:325])\n",
        "    validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_ENI[325:395])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=Batch_size, shuffle=False )\n",
        "\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YQnFWHBJ61f"
      },
      "source": [
        "# Main function to run\n",
        "\n",
        "def train_temp_ENI(trial):\n",
        "  \n",
        "  cfg = { \n",
        "          'Batch_size' : 1,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr'       : 0.0001,          \n",
        "          'optimizer':  optim.RMSprop,\n",
        "           'dropout'       : 0.8,\n",
        "          'activation': F.relu}\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_ENI_temp(cfg['Batch_size'])\n",
        "  model = Network_dropout(cfg['dropout']).to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_temp_ENI[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_temp_ENI[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 1\n",
        "\n",
        "  \n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  criterion(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = criterion(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              #print(y_pred)\n",
        "              \n",
        "              \n",
        "             \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "       \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_temp_ENI[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_temp_ENI[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "\n",
        "      \n",
        "       \n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f}  '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_ENI_temp_std.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_acc, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-ze1Mscyp9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f4168e-7f27-4dba-a93b-c13f7f2fbaeb"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_temp_ENI, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"optimise_valid_ENI_temp_drop(0.5).torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss:  1.687 \tTrain_Accu: 19%  \tValid_Acc:17%  \tVal_kappa : -0.027  \n",
            "Epoch: 2 \tTraining Loss:  1.611 \tTrain_Accu: 22%  \tValid_Acc:29%  \tVal_kappa : 0.089  \n",
            "Epoch: 3 \tTraining Loss:  1.610 \tTrain_Accu: 20%  \tValid_Acc:16%  \tVal_kappa : -0.123  \n",
            "Epoch: 4 \tTraining Loss:  1.596 \tTrain_Accu: 24%  \tValid_Acc:20%  \tVal_kappa : 0.002  \n",
            "Epoch: 5 \tTraining Loss:  1.584 \tTrain_Accu: 21%  \tValid_Acc:21%  \tVal_kappa : 0.208  \n",
            "Epoch: 6 \tTraining Loss:  1.625 \tTrain_Accu: 20%  \tValid_Acc:16%  \tVal_kappa : -0.160  \n",
            "Epoch: 7 \tTraining Loss:  1.604 \tTrain_Accu: 19%  \tValid_Acc:20%  \tVal_kappa : -0.022  \n",
            "Epoch: 8 \tTraining Loss:  1.582 \tTrain_Accu: 23%  \tValid_Acc:24%  \tVal_kappa : 0.043  \n",
            "Epoch: 9 \tTraining Loss:  1.592 \tTrain_Accu: 23%  \tValid_Acc:19%  \tVal_kappa : 0.046  \n",
            "Epoch: 10 \tTraining Loss:  1.583 \tTrain_Accu: 25%  \tValid_Acc:19%  \tVal_kappa : 0.149  \n",
            "Epoch: 11 \tTraining Loss:  1.598 \tTrain_Accu: 23%  \tValid_Acc:21%  \tVal_kappa : 0.110  \n",
            "Epoch: 12 \tTraining Loss:  1.579 \tTrain_Accu: 25%  \tValid_Acc:14%  \tVal_kappa : -0.044  \n",
            "Epoch: 13 \tTraining Loss:  1.571 \tTrain_Accu: 29%  \tValid_Acc:23%  \tVal_kappa : 0.060  \n",
            "Epoch: 14 \tTraining Loss:  1.565 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.090  \n",
            "Epoch: 15 \tTraining Loss:  1.571 \tTrain_Accu: 24%  \tValid_Acc:21%  \tVal_kappa : 0.031  \n",
            "Epoch: 16 \tTraining Loss:  1.570 \tTrain_Accu: 25%  \tValid_Acc:16%  \tVal_kappa : 0.070  \n",
            "Epoch: 17 \tTraining Loss:  1.552 \tTrain_Accu: 26%  \tValid_Acc:20%  \tVal_kappa : 0.050  \n",
            "Epoch: 18 \tTraining Loss:  1.565 \tTrain_Accu: 27%  \tValid_Acc:17%  \tVal_kappa : -0.130  \n",
            "Epoch: 19 \tTraining Loss:  1.523 \tTrain_Accu: 33%  \tValid_Acc:21%  \tVal_kappa : -0.076  \n",
            "Epoch: 20 \tTraining Loss:  1.554 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.090  \n",
            "Epoch: 21 \tTraining Loss:  1.513 \tTrain_Accu: 33%  \tValid_Acc:23%  \tVal_kappa : 0.240  \n",
            "Epoch: 22 \tTraining Loss:  1.546 \tTrain_Accu: 31%  \tValid_Acc:13%  \tVal_kappa : -0.086  \n",
            "Epoch: 23 \tTraining Loss:  1.531 \tTrain_Accu: 30%  \tValid_Acc:16%  \tVal_kappa : -0.083  \n",
            "Epoch: 24 \tTraining Loss:  1.519 \tTrain_Accu: 31%  \tValid_Acc:16%  \tVal_kappa : -0.045  \n",
            "Epoch: 25 \tTraining Loss:  1.519 \tTrain_Accu: 30%  \tValid_Acc:29%  \tVal_kappa : 0.140  \n",
            "Epoch: 26 \tTraining Loss:  1.482 \tTrain_Accu: 30%  \tValid_Acc:23%  \tVal_kappa : 0.037  \n",
            "Epoch: 27 \tTraining Loss:  1.467 \tTrain_Accu: 36%  \tValid_Acc:20%  \tVal_kappa : 0.228  \n",
            "Epoch: 28 \tTraining Loss:  1.489 \tTrain_Accu: 32%  \tValid_Acc:21%  \tVal_kappa : -0.019  \n",
            "Epoch: 29 \tTraining Loss:  1.478 \tTrain_Accu: 36%  \tValid_Acc:26%  \tVal_kappa : 0.185  \n",
            "Epoch: 30 \tTraining Loss:  1.458 \tTrain_Accu: 34%  \tValid_Acc:23%  \tVal_kappa : 0.095  \n",
            "Epoch: 31 \tTraining Loss:  1.422 \tTrain_Accu: 37%  \tValid_Acc:23%  \tVal_kappa : 0.090  \n",
            "Epoch: 32 \tTraining Loss:  1.424 \tTrain_Accu: 38%  \tValid_Acc:17%  \tVal_kappa : 0.016  \n",
            "Epoch: 33 \tTraining Loss:  1.389 \tTrain_Accu: 41%  \tValid_Acc:23%  \tVal_kappa : 0.029  \n",
            "Epoch: 34 \tTraining Loss:  1.390 \tTrain_Accu: 39%  \tValid_Acc:19%  \tVal_kappa : -0.187  \n",
            "Epoch: 35 \tTraining Loss:  1.392 \tTrain_Accu: 40%  \tValid_Acc:31%  \tVal_kappa : 0.078  \n",
            "Epoch: 36 \tTraining Loss:  1.406 \tTrain_Accu: 38%  \tValid_Acc:24%  \tVal_kappa : 0.117  \n",
            "Epoch: 37 \tTraining Loss:  1.362 \tTrain_Accu: 34%  \tValid_Acc:19%  \tVal_kappa : 0.047  \n",
            "Epoch: 38 \tTraining Loss:  1.355 \tTrain_Accu: 38%  \tValid_Acc:20%  \tVal_kappa : 0.041  \n",
            "Epoch: 39 \tTraining Loss:  1.354 \tTrain_Accu: 39%  \tValid_Acc:20%  \tVal_kappa : 0.023  \n",
            "Epoch: 40 \tTraining Loss:  1.337 \tTrain_Accu: 40%  \tValid_Acc:21%  \tVal_kappa : -0.051  \n",
            "Epoch: 41 \tTraining Loss:  1.345 \tTrain_Accu: 43%  \tValid_Acc:20%  \tVal_kappa : 0.109  \n",
            "Epoch: 42 \tTraining Loss:  1.336 \tTrain_Accu: 41%  \tValid_Acc:20%  \tVal_kappa : 0.012  \n",
            "Epoch: 43 \tTraining Loss:  1.328 \tTrain_Accu: 39%  \tValid_Acc:17%  \tVal_kappa : -0.003  \n",
            "Epoch: 44 \tTraining Loss:  1.329 \tTrain_Accu: 40%  \tValid_Acc:24%  \tVal_kappa : -0.013  \n",
            "Epoch: 45 \tTraining Loss:  1.343 \tTrain_Accu: 38%  \tValid_Acc:23%  \tVal_kappa : -0.001  \n",
            "Epoch: 46 \tTraining Loss:  1.268 \tTrain_Accu: 43%  \tValid_Acc:20%  \tVal_kappa : 0.105  \n",
            "Epoch: 47 \tTraining Loss:  1.307 \tTrain_Accu: 42%  \tValid_Acc:17%  \tVal_kappa : -0.102  \n",
            "Epoch: 48 \tTraining Loss:  1.258 \tTrain_Accu: 44%  \tValid_Acc:21%  \tVal_kappa : 0.112  \n",
            "Epoch: 49 \tTraining Loss:  1.219 \tTrain_Accu: 46%  \tValid_Acc:20%  \tVal_kappa : 0.082  \n",
            "Epoch: 50 \tTraining Loss:  1.256 \tTrain_Accu: 44%  \tValid_Acc:13%  \tVal_kappa : 0.060  \n",
            "Epoch: 51 \tTraining Loss:  1.190 \tTrain_Accu: 47%  \tValid_Acc:20%  \tVal_kappa : 0.097  \n",
            "Epoch: 52 \tTraining Loss:  1.240 \tTrain_Accu: 46%  \tValid_Acc:14%  \tVal_kappa : 0.105  \n",
            "Epoch: 53 \tTraining Loss:  1.277 \tTrain_Accu: 45%  \tValid_Acc:14%  \tVal_kappa : -0.012  \n",
            "Epoch: 54 \tTraining Loss:  1.190 \tTrain_Accu: 45%  \tValid_Acc:19%  \tVal_kappa : -0.021  \n",
            "Epoch: 55 \tTraining Loss:  1.146 \tTrain_Accu: 51%  \tValid_Acc:19%  \tVal_kappa : 0.086  \n",
            "Epoch: 56 \tTraining Loss:  1.218 \tTrain_Accu: 47%  \tValid_Acc:13%  \tVal_kappa : -0.036  \n",
            "Epoch: 57 \tTraining Loss:  1.252 \tTrain_Accu: 41%  \tValid_Acc:13%  \tVal_kappa : -0.061  \n",
            "Epoch: 58 \tTraining Loss:  1.129 \tTrain_Accu: 47%  \tValid_Acc:29%  \tVal_kappa : 0.190  \n",
            "Epoch: 59 \tTraining Loss:  1.144 \tTrain_Accu: 50%  \tValid_Acc:16%  \tVal_kappa : -0.049  \n",
            "Epoch: 60 \tTraining Loss:  1.096 \tTrain_Accu: 52%  \tValid_Acc:31%  \tVal_kappa : 0.064  \n",
            "Epoch: 61 \tTraining Loss:  1.161 \tTrain_Accu: 50%  \tValid_Acc:20%  \tVal_kappa : 0.102  \n",
            "Epoch: 62 \tTraining Loss:  1.142 \tTrain_Accu: 50%  \tValid_Acc:16%  \tVal_kappa : -0.043  \n",
            "Epoch: 63 \tTraining Loss:  1.099 \tTrain_Accu: 54%  \tValid_Acc:21%  \tVal_kappa : 0.201  \n",
            "Epoch: 64 \tTraining Loss:  1.181 \tTrain_Accu: 46%  \tValid_Acc:27%  \tVal_kappa : 0.120  \n",
            "Epoch: 65 \tTraining Loss:  1.191 \tTrain_Accu: 50%  \tValid_Acc:17%  \tVal_kappa : 0.136  \n",
            "Epoch: 66 \tTraining Loss:  1.100 \tTrain_Accu: 53%  \tValid_Acc:16%  \tVal_kappa : 0.135  \n",
            "Epoch: 67 \tTraining Loss:  1.050 \tTrain_Accu: 57%  \tValid_Acc:24%  \tVal_kappa : 0.239  \n",
            "Epoch: 68 \tTraining Loss:  1.065 \tTrain_Accu: 48%  \tValid_Acc:20%  \tVal_kappa : 0.063  \n",
            "Epoch: 69 \tTraining Loss:  1.046 \tTrain_Accu: 54%  \tValid_Acc:19%  \tVal_kappa : -0.031  \n",
            "Epoch: 70 \tTraining Loss:  1.096 \tTrain_Accu: 51%  \tValid_Acc:20%  \tVal_kappa : 0.047  \n",
            "Epoch: 71 \tTraining Loss:  1.101 \tTrain_Accu: 52%  \tValid_Acc:14%  \tVal_kappa : 0.039  \n",
            "Epoch: 72 \tTraining Loss:  1.060 \tTrain_Accu: 54%  \tValid_Acc:17%  \tVal_kappa : 0.019  \n",
            "Epoch: 73 \tTraining Loss:  1.084 \tTrain_Accu: 52%  \tValid_Acc:17%  \tVal_kappa : 0.020  \n",
            "Epoch: 74 \tTraining Loss:  1.039 \tTrain_Accu: 53%  \tValid_Acc:20%  \tVal_kappa : 0.013  \n",
            "Epoch: 75 \tTraining Loss:  1.008 \tTrain_Accu: 54%  \tValid_Acc:30%  \tVal_kappa : 0.193  \n",
            "Epoch: 76 \tTraining Loss:  1.029 \tTrain_Accu: 56%  \tValid_Acc:19%  \tVal_kappa : -0.030  \n",
            "Epoch: 77 \tTraining Loss:  1.031 \tTrain_Accu: 54%  \tValid_Acc:21%  \tVal_kappa : -0.068  \n",
            "Epoch: 78 \tTraining Loss:  1.029 \tTrain_Accu: 57%  \tValid_Acc:17%  \tVal_kappa : -0.069  \n",
            "Epoch: 79 \tTraining Loss:  1.039 \tTrain_Accu: 53%  \tValid_Acc:19%  \tVal_kappa : 0.011  \n",
            "Epoch: 80 \tTraining Loss:  1.064 \tTrain_Accu: 55%  \tValid_Acc:17%  \tVal_kappa : 0.019  \n",
            "Epoch: 81 \tTraining Loss:  0.919 \tTrain_Accu: 60%  \tValid_Acc:21%  \tVal_kappa : 0.011  \n",
            "Epoch: 82 \tTraining Loss:  1.019 \tTrain_Accu: 55%  \tValid_Acc:20%  \tVal_kappa : 0.122  \n",
            "Epoch: 83 \tTraining Loss:  1.039 \tTrain_Accu: 52%  \tValid_Acc:16%  \tVal_kappa : 0.063  \n",
            "Epoch: 84 \tTraining Loss:  1.017 \tTrain_Accu: 54%  \tValid_Acc:20%  \tVal_kappa : 0.111  \n",
            "Epoch: 85 \tTraining Loss:  0.966 \tTrain_Accu: 58%  \tValid_Acc:24%  \tVal_kappa : 0.040  \n",
            "Epoch: 86 \tTraining Loss:  0.942 \tTrain_Accu: 58%  \tValid_Acc:16%  \tVal_kappa : 0.156  \n",
            "Epoch: 87 \tTraining Loss:  0.969 \tTrain_Accu: 55%  \tValid_Acc:20%  \tVal_kappa : -0.001  \n",
            "Epoch: 88 \tTraining Loss:  0.936 \tTrain_Accu: 59%  \tValid_Acc:16%  \tVal_kappa : 0.271  \n",
            "Epoch: 89 \tTraining Loss:  0.952 \tTrain_Accu: 55%  \tValid_Acc:24%  \tVal_kappa : 0.196  \n",
            "Epoch: 90 \tTraining Loss:  1.004 \tTrain_Accu: 58%  \tValid_Acc:24%  \tVal_kappa : -0.009  \n",
            "Epoch: 91 \tTraining Loss:  0.946 \tTrain_Accu: 57%  \tValid_Acc:17%  \tVal_kappa : -0.036  \n",
            "Epoch: 92 \tTraining Loss:  0.952 \tTrain_Accu: 57%  \tValid_Acc:20%  \tVal_kappa : 0.032  \n",
            "Epoch: 93 \tTraining Loss:  0.955 \tTrain_Accu: 59%  \tValid_Acc:20%  \tVal_kappa : 0.117  \n",
            "Epoch: 94 \tTraining Loss:  0.917 \tTrain_Accu: 59%  \tValid_Acc:21%  \tVal_kappa : 0.094  \n",
            "Epoch: 95 \tTraining Loss:  0.973 \tTrain_Accu: 58%  \tValid_Acc:21%  \tVal_kappa : 0.210  \n",
            "Epoch: 96 \tTraining Loss:  0.933 \tTrain_Accu: 62%  \tValid_Acc:21%  \tVal_kappa : 0.031  \n",
            "Epoch: 97 \tTraining Loss:  0.916 \tTrain_Accu: 60%  \tValid_Acc:10%  \tVal_kappa : 0.012  \n",
            "Epoch: 98 \tTraining Loss:  0.849 \tTrain_Accu: 61%  \tValid_Acc:26%  \tVal_kappa : 0.286  \n",
            "Epoch: 99 \tTraining Loss:  0.861 \tTrain_Accu: 66%  \tValid_Acc:19%  \tVal_kappa : 0.102  \n",
            "Epoch: 100 \tTraining Loss:  0.920 \tTrain_Accu: 58%  \tValid_Acc:27%  \tVal_kappa : 0.078  \n",
            "Epoch: 101 \tTraining Loss:  0.821 \tTrain_Accu: 64%  \tValid_Acc:21%  \tVal_kappa : 0.199  \n",
            "Epoch: 102 \tTraining Loss:  0.887 \tTrain_Accu: 59%  \tValid_Acc:19%  \tVal_kappa : 0.091  \n",
            "Epoch: 103 \tTraining Loss:  0.863 \tTrain_Accu: 61%  \tValid_Acc:20%  \tVal_kappa : 0.172  \n",
            "Epoch: 104 \tTraining Loss:  0.893 \tTrain_Accu: 61%  \tValid_Acc:14%  \tVal_kappa : 0.117  \n",
            "Epoch: 105 \tTraining Loss:  0.866 \tTrain_Accu: 65%  \tValid_Acc:13%  \tVal_kappa : 0.102  \n",
            "Epoch: 106 \tTraining Loss:  0.864 \tTrain_Accu: 61%  \tValid_Acc:20%  \tVal_kappa : 0.027  \n",
            "Epoch: 107 \tTraining Loss:  0.818 \tTrain_Accu: 63%  \tValid_Acc:17%  \tVal_kappa : 0.095  \n",
            "Epoch: 108 \tTraining Loss:  0.841 \tTrain_Accu: 65%  \tValid_Acc:21%  \tVal_kappa : 0.129  \n",
            "Epoch: 109 \tTraining Loss:  0.792 \tTrain_Accu: 66%  \tValid_Acc:20%  \tVal_kappa : 0.005  \n",
            "Epoch: 110 \tTraining Loss:  0.846 \tTrain_Accu: 65%  \tValid_Acc:10%  \tVal_kappa : 0.097  \n",
            "Epoch: 111 \tTraining Loss:  0.835 \tTrain_Accu: 64%  \tValid_Acc:9%  \tVal_kappa : -0.048  \n",
            "Epoch: 112 \tTraining Loss:  0.831 \tTrain_Accu: 64%  \tValid_Acc:30%  \tVal_kappa : 0.229  \n",
            "Epoch: 113 \tTraining Loss:  0.838 \tTrain_Accu: 63%  \tValid_Acc:20%  \tVal_kappa : 0.130  \n",
            "Epoch: 114 \tTraining Loss:  0.817 \tTrain_Accu: 66%  \tValid_Acc:13%  \tVal_kappa : 0.054  \n",
            "Epoch: 115 \tTraining Loss:  0.833 \tTrain_Accu: 65%  \tValid_Acc:23%  \tVal_kappa : 0.047  \n",
            "Epoch: 116 \tTraining Loss:  0.834 \tTrain_Accu: 63%  \tValid_Acc:16%  \tVal_kappa : -0.040  \n",
            "Epoch: 117 \tTraining Loss:  0.778 \tTrain_Accu: 67%  \tValid_Acc:16%  \tVal_kappa : 0.158  \n",
            "Epoch: 118 \tTraining Loss:  0.787 \tTrain_Accu: 66%  \tValid_Acc:24%  \tVal_kappa : 0.162  \n",
            "Epoch: 119 \tTraining Loss:  0.795 \tTrain_Accu: 66%  \tValid_Acc:17%  \tVal_kappa : 0.167  \n",
            "Epoch: 120 \tTraining Loss:  0.792 \tTrain_Accu: 66%  \tValid_Acc:26%  \tVal_kappa : 0.062  \n",
            "Epoch: 121 \tTraining Loss:  0.724 \tTrain_Accu: 69%  \tValid_Acc:19%  \tVal_kappa : 0.087  \n",
            "Epoch: 122 \tTraining Loss:  0.683 \tTrain_Accu: 69%  \tValid_Acc:23%  \tVal_kappa : 0.070  \n",
            "Epoch: 123 \tTraining Loss:  0.735 \tTrain_Accu: 70%  \tValid_Acc:27%  \tVal_kappa : 0.099  \n",
            "Epoch: 124 \tTraining Loss:  0.781 \tTrain_Accu: 65%  \tValid_Acc:20%  \tVal_kappa : -0.021  \n",
            "Epoch: 125 \tTraining Loss:  0.751 \tTrain_Accu: 68%  \tValid_Acc:16%  \tVal_kappa : 0.192  \n",
            "Epoch: 126 \tTraining Loss:  0.792 \tTrain_Accu: 68%  \tValid_Acc:20%  \tVal_kappa : 0.208  \n",
            "Epoch: 127 \tTraining Loss:  0.780 \tTrain_Accu: 63%  \tValid_Acc:19%  \tVal_kappa : 0.247  \n",
            "Epoch: 128 \tTraining Loss:  0.746 \tTrain_Accu: 70%  \tValid_Acc:20%  \tVal_kappa : 0.210  \n",
            "Epoch: 129 \tTraining Loss:  0.763 \tTrain_Accu: 69%  \tValid_Acc:20%  \tVal_kappa : 0.121  \n",
            "Epoch: 130 \tTraining Loss:  0.760 \tTrain_Accu: 66%  \tValid_Acc:26%  \tVal_kappa : 0.150  \n",
            "Epoch: 131 \tTraining Loss:  0.764 \tTrain_Accu: 67%  \tValid_Acc:19%  \tVal_kappa : -0.002  \n",
            "Epoch: 132 \tTraining Loss:  0.712 \tTrain_Accu: 69%  \tValid_Acc:14%  \tVal_kappa : 0.146  \n",
            "Epoch: 133 \tTraining Loss:  0.705 \tTrain_Accu: 70%  \tValid_Acc:17%  \tVal_kappa : -0.050  \n",
            "Epoch: 134 \tTraining Loss:  0.776 \tTrain_Accu: 64%  \tValid_Acc:16%  \tVal_kappa : 0.067  \n",
            "Epoch: 135 \tTraining Loss:  0.728 \tTrain_Accu: 67%  \tValid_Acc:21%  \tVal_kappa : 0.093  \n",
            "Epoch: 136 \tTraining Loss:  0.700 \tTrain_Accu: 71%  \tValid_Acc:21%  \tVal_kappa : 0.088  \n",
            "Epoch: 137 \tTraining Loss:  0.710 \tTrain_Accu: 69%  \tValid_Acc:14%  \tVal_kappa : 0.096  \n",
            "Epoch: 138 \tTraining Loss:  0.658 \tTrain_Accu: 72%  \tValid_Acc:17%  \tVal_kappa : -0.095  \n",
            "Epoch: 139 \tTraining Loss:  0.654 \tTrain_Accu: 70%  \tValid_Acc:13%  \tVal_kappa : 0.044  \n",
            "Epoch: 140 \tTraining Loss:  0.713 \tTrain_Accu: 71%  \tValid_Acc:23%  \tVal_kappa : 0.155  \n",
            "Epoch: 141 \tTraining Loss:  0.741 \tTrain_Accu: 68%  \tValid_Acc:20%  \tVal_kappa : 0.035  \n",
            "Epoch: 142 \tTraining Loss:  0.762 \tTrain_Accu: 66%  \tValid_Acc:20%  \tVal_kappa : -0.002  \n",
            "Epoch: 143 \tTraining Loss:  0.747 \tTrain_Accu: 67%  \tValid_Acc:21%  \tVal_kappa : 0.188  \n",
            "Epoch: 144 \tTraining Loss:  0.687 \tTrain_Accu: 71%  \tValid_Acc:24%  \tVal_kappa : 0.081  \n",
            "Epoch: 145 \tTraining Loss:  0.652 \tTrain_Accu: 72%  \tValid_Acc:24%  \tVal_kappa : 0.057  \n",
            "Epoch: 146 \tTraining Loss:  0.762 \tTrain_Accu: 69%  \tValid_Acc:14%  \tVal_kappa : 0.084  \n",
            "Epoch: 147 \tTraining Loss:  0.728 \tTrain_Accu: 69%  \tValid_Acc:19%  \tVal_kappa : -0.009  \n",
            "Epoch: 148 \tTraining Loss:  0.718 \tTrain_Accu: 70%  \tValid_Acc:10%  \tVal_kappa : 0.052  \n",
            "Epoch: 149 \tTraining Loss:  0.728 \tTrain_Accu: 69%  \tValid_Acc:19%  \tVal_kappa : -0.019  \n",
            "Epoch: 150 \tTraining Loss:  0.752 \tTrain_Accu: 66%  \tValid_Acc:13%  \tVal_kappa : -0.004  \n",
            "Epoch: 151 \tTraining Loss:  0.696 \tTrain_Accu: 71%  \tValid_Acc:19%  \tVal_kappa : 0.113  \n",
            "Epoch: 152 \tTraining Loss:  0.712 \tTrain_Accu: 69%  \tValid_Acc:10%  \tVal_kappa : -0.048  \n",
            "Epoch: 153 \tTraining Loss:  0.656 \tTrain_Accu: 70%  \tValid_Acc:21%  \tVal_kappa : 0.161  \n",
            "Epoch: 154 \tTraining Loss:  0.663 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : 0.254  \n",
            "Epoch: 155 \tTraining Loss:  0.730 \tTrain_Accu: 68%  \tValid_Acc:23%  \tVal_kappa : 0.184  \n",
            "Epoch: 156 \tTraining Loss:  0.662 \tTrain_Accu: 73%  \tValid_Acc:17%  \tVal_kappa : -0.017  \n",
            "Epoch: 157 \tTraining Loss:  0.693 \tTrain_Accu: 69%  \tValid_Acc:16%  \tVal_kappa : -0.028  \n",
            "Epoch: 158 \tTraining Loss:  0.651 \tTrain_Accu: 72%  \tValid_Acc:17%  \tVal_kappa : -0.010  \n",
            "Epoch: 159 \tTraining Loss:  0.612 \tTrain_Accu: 73%  \tValid_Acc:16%  \tVal_kappa : 0.177  \n",
            "Epoch: 160 \tTraining Loss:  0.708 \tTrain_Accu: 69%  \tValid_Acc:17%  \tVal_kappa : -0.072  \n",
            "Epoch: 161 \tTraining Loss:  0.669 \tTrain_Accu: 73%  \tValid_Acc:17%  \tVal_kappa : 0.061  \n",
            "Epoch: 162 \tTraining Loss:  0.679 \tTrain_Accu: 70%  \tValid_Acc:11%  \tVal_kappa : -0.111  \n",
            "Epoch: 163 \tTraining Loss:  0.657 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : -0.067  \n",
            "Epoch: 164 \tTraining Loss:  0.632 \tTrain_Accu: 76%  \tValid_Acc:17%  \tVal_kappa : 0.035  \n",
            "Epoch: 165 \tTraining Loss:  0.607 \tTrain_Accu: 75%  \tValid_Acc:19%  \tVal_kappa : 0.132  \n",
            "Epoch: 166 \tTraining Loss:  0.580 \tTrain_Accu: 73%  \tValid_Acc:17%  \tVal_kappa : -0.091  \n",
            "Epoch: 167 \tTraining Loss:  0.618 \tTrain_Accu: 71%  \tValid_Acc:20%  \tVal_kappa : -0.067  \n",
            "Epoch: 168 \tTraining Loss:  0.652 \tTrain_Accu: 72%  \tValid_Acc:17%  \tVal_kappa : 0.190  \n",
            "Epoch: 169 \tTraining Loss:  0.683 \tTrain_Accu: 72%  \tValid_Acc:17%  \tVal_kappa : 0.045  \n",
            "Epoch: 170 \tTraining Loss:  0.600 \tTrain_Accu: 73%  \tValid_Acc:21%  \tVal_kappa : 0.058  \n",
            "Epoch: 171 \tTraining Loss:  0.718 \tTrain_Accu: 72%  \tValid_Acc:13%  \tVal_kappa : -0.133  \n",
            "Epoch: 172 \tTraining Loss:  0.579 \tTrain_Accu: 74%  \tValid_Acc:21%  \tVal_kappa : -0.074  \n",
            "Epoch: 173 \tTraining Loss:  0.632 \tTrain_Accu: 75%  \tValid_Acc:17%  \tVal_kappa : 0.004  \n",
            "Epoch: 174 \tTraining Loss:  0.674 \tTrain_Accu: 69%  \tValid_Acc:21%  \tVal_kappa : 0.140  \n",
            "Epoch: 175 \tTraining Loss:  0.637 \tTrain_Accu: 74%  \tValid_Acc:13%  \tVal_kappa : -0.175  \n",
            "Epoch: 176 \tTraining Loss:  0.584 \tTrain_Accu: 74%  \tValid_Acc:23%  \tVal_kappa : -0.118  \n",
            "Epoch: 177 \tTraining Loss:  0.626 \tTrain_Accu: 73%  \tValid_Acc:20%  \tVal_kappa : 0.097  \n",
            "Epoch: 178 \tTraining Loss:  0.672 \tTrain_Accu: 72%  \tValid_Acc:14%  \tVal_kappa : 0.005  \n",
            "Epoch: 179 \tTraining Loss:  0.676 \tTrain_Accu: 73%  \tValid_Acc:16%  \tVal_kappa : 0.038  \n",
            "Epoch: 180 \tTraining Loss:  0.622 \tTrain_Accu: 73%  \tValid_Acc:20%  \tVal_kappa : 0.112  \n",
            "Epoch: 181 \tTraining Loss:  0.683 \tTrain_Accu: 74%  \tValid_Acc:20%  \tVal_kappa : 0.026  \n",
            "Epoch: 182 \tTraining Loss:  0.651 \tTrain_Accu: 71%  \tValid_Acc:10%  \tVal_kappa : -0.032  \n",
            "Epoch: 183 \tTraining Loss:  0.642 \tTrain_Accu: 72%  \tValid_Acc:16%  \tVal_kappa : 0.025  \n",
            "Epoch: 184 \tTraining Loss:  0.595 \tTrain_Accu: 74%  \tValid_Acc:14%  \tVal_kappa : 0.059  \n",
            "Epoch: 185 \tTraining Loss:  0.610 \tTrain_Accu: 76%  \tValid_Acc:19%  \tVal_kappa : 0.032  \n",
            "Epoch: 186 \tTraining Loss:  0.668 \tTrain_Accu: 73%  \tValid_Acc:19%  \tVal_kappa : 0.038  \n",
            "Epoch: 187 \tTraining Loss:  0.606 \tTrain_Accu: 74%  \tValid_Acc:17%  \tVal_kappa : 0.150  \n",
            "Epoch: 188 \tTraining Loss:  0.554 \tTrain_Accu: 77%  \tValid_Acc:19%  \tVal_kappa : 0.043  \n",
            "Epoch: 189 \tTraining Loss:  0.647 \tTrain_Accu: 71%  \tValid_Acc:19%  \tVal_kappa : 0.189  \n",
            "Epoch: 190 \tTraining Loss:  0.610 \tTrain_Accu: 73%  \tValid_Acc:14%  \tVal_kappa : 0.118  \n",
            "Epoch: 191 \tTraining Loss:  0.631 \tTrain_Accu: 74%  \tValid_Acc:14%  \tVal_kappa : -0.121  \n",
            "Epoch: 192 \tTraining Loss:  0.639 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : 0.127  \n",
            "Epoch: 193 \tTraining Loss:  0.604 \tTrain_Accu: 73%  \tValid_Acc:21%  \tVal_kappa : 0.041  \n",
            "Epoch: 194 \tTraining Loss:  0.636 \tTrain_Accu: 72%  \tValid_Acc:16%  \tVal_kappa : -0.085  \n",
            "Epoch: 195 \tTraining Loss:  0.600 \tTrain_Accu: 74%  \tValid_Acc:14%  \tVal_kappa : 0.135  \n",
            "Epoch: 196 \tTraining Loss:  0.694 \tTrain_Accu: 72%  \tValid_Acc:20%  \tVal_kappa : 0.076  \n",
            "Epoch: 197 \tTraining Loss:  0.595 \tTrain_Accu: 73%  \tValid_Acc:23%  \tVal_kappa : 0.192  \n",
            "Epoch: 198 \tTraining Loss:  0.640 \tTrain_Accu: 73%  \tValid_Acc:19%  \tVal_kappa : 0.070  \n",
            "Epoch: 199 \tTraining Loss:  0.566 \tTrain_Accu: 76%  \tValid_Acc:23%  \tVal_kappa : 0.142  \n",
            "Epoch: 200 \tTraining Loss:  0.578 \tTrain_Accu: 74%  \tValid_Acc:27%  \tVal_kappa : 0.103  \n",
            "Epoch: 201 \tTraining Loss:  0.559 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : 0.054  \n",
            "Epoch: 202 \tTraining Loss:  0.565 \tTrain_Accu: 78%  \tValid_Acc:13%  \tVal_kappa : 0.129  \n",
            "Epoch: 203 \tTraining Loss:  0.583 \tTrain_Accu: 76%  \tValid_Acc:23%  \tVal_kappa : 0.049  \n",
            "Epoch: 204 \tTraining Loss:  0.570 \tTrain_Accu: 74%  \tValid_Acc:16%  \tVal_kappa : -0.036  \n",
            "Epoch: 205 \tTraining Loss:  0.618 \tTrain_Accu: 75%  \tValid_Acc:20%  \tVal_kappa : -0.050  \n",
            "Epoch: 206 \tTraining Loss:  0.662 \tTrain_Accu: 75%  \tValid_Acc:20%  \tVal_kappa : 0.120  \n",
            "Epoch: 207 \tTraining Loss:  0.617 \tTrain_Accu: 74%  \tValid_Acc:14%  \tVal_kappa : 0.034  \n",
            "Epoch: 208 \tTraining Loss:  0.550 \tTrain_Accu: 77%  \tValid_Acc:24%  \tVal_kappa : 0.070  \n",
            "Epoch: 209 \tTraining Loss:  0.598 \tTrain_Accu: 74%  \tValid_Acc:20%  \tVal_kappa : 0.086  \n",
            "Epoch: 210 \tTraining Loss:  0.566 \tTrain_Accu: 77%  \tValid_Acc:16%  \tVal_kappa : 0.034  \n",
            "Epoch: 211 \tTraining Loss:  0.630 \tTrain_Accu: 74%  \tValid_Acc:20%  \tVal_kappa : 0.057  \n",
            "Epoch: 212 \tTraining Loss:  0.645 \tTrain_Accu: 75%  \tValid_Acc:20%  \tVal_kappa : 0.074  \n",
            "Epoch: 213 \tTraining Loss:  0.588 \tTrain_Accu: 76%  \tValid_Acc:19%  \tVal_kappa : 0.025  \n",
            "Epoch: 214 \tTraining Loss:  0.552 \tTrain_Accu: 76%  \tValid_Acc:16%  \tVal_kappa : -0.004  \n",
            "Epoch: 215 \tTraining Loss:  0.545 \tTrain_Accu: 80%  \tValid_Acc:21%  \tVal_kappa : 0.161  \n",
            "Epoch: 216 \tTraining Loss:  0.558 \tTrain_Accu: 75%  \tValid_Acc:23%  \tVal_kappa : 0.214  \n",
            "Epoch: 217 \tTraining Loss:  0.611 \tTrain_Accu: 75%  \tValid_Acc:29%  \tVal_kappa : 0.053  \n",
            "Epoch: 218 \tTraining Loss:  0.553 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : 0.045  \n",
            "Epoch: 219 \tTraining Loss:  0.553 \tTrain_Accu: 75%  \tValid_Acc:14%  \tVal_kappa : -0.120  \n",
            "Epoch: 220 \tTraining Loss:  0.552 \tTrain_Accu: 78%  \tValid_Acc:23%  \tVal_kappa : 0.137  \n",
            "Epoch: 221 \tTraining Loss:  0.495 \tTrain_Accu: 80%  \tValid_Acc:29%  \tVal_kappa : 0.165  \n",
            "Epoch: 222 \tTraining Loss:  0.674 \tTrain_Accu: 71%  \tValid_Acc:20%  \tVal_kappa : 0.018  \n",
            "Epoch: 223 \tTraining Loss:  0.583 \tTrain_Accu: 74%  \tValid_Acc:19%  \tVal_kappa : 0.231  \n",
            "Epoch: 224 \tTraining Loss:  0.643 \tTrain_Accu: 74%  \tValid_Acc:16%  \tVal_kappa : 0.033  \n",
            "Epoch: 225 \tTraining Loss:  0.608 \tTrain_Accu: 75%  \tValid_Acc:27%  \tVal_kappa : 0.090  \n",
            "Epoch: 226 \tTraining Loss:  0.592 \tTrain_Accu: 75%  \tValid_Acc:23%  \tVal_kappa : 0.050  \n",
            "Epoch: 227 \tTraining Loss:  0.516 \tTrain_Accu: 74%  \tValid_Acc:19%  \tVal_kappa : 0.033  \n",
            "Epoch: 228 \tTraining Loss:  0.536 \tTrain_Accu: 79%  \tValid_Acc:17%  \tVal_kappa : 0.135  \n",
            "Epoch: 229 \tTraining Loss:  0.456 \tTrain_Accu: 84%  \tValid_Acc:21%  \tVal_kappa : 0.164  \n",
            "Epoch: 230 \tTraining Loss:  0.601 \tTrain_Accu: 77%  \tValid_Acc:17%  \tVal_kappa : 0.015  \n",
            "Epoch: 231 \tTraining Loss:  0.596 \tTrain_Accu: 75%  \tValid_Acc:21%  \tVal_kappa : 0.058  \n",
            "Epoch: 232 \tTraining Loss:  0.558 \tTrain_Accu: 78%  \tValid_Acc:20%  \tVal_kappa : 0.136  \n",
            "Epoch: 233 \tTraining Loss:  0.630 \tTrain_Accu: 72%  \tValid_Acc:24%  \tVal_kappa : 0.189  \n",
            "Epoch: 234 \tTraining Loss:  0.616 \tTrain_Accu: 73%  \tValid_Acc:21%  \tVal_kappa : 0.025  \n",
            "Epoch: 235 \tTraining Loss:  0.572 \tTrain_Accu: 78%  \tValid_Acc:21%  \tVal_kappa : 0.178  \n",
            "Epoch: 236 \tTraining Loss:  0.585 \tTrain_Accu: 76%  \tValid_Acc:17%  \tVal_kappa : 0.213  \n",
            "Epoch: 237 \tTraining Loss:  0.573 \tTrain_Accu: 76%  \tValid_Acc:21%  \tVal_kappa : 0.126  \n",
            "Epoch: 238 \tTraining Loss:  0.564 \tTrain_Accu: 77%  \tValid_Acc:13%  \tVal_kappa : 0.120  \n",
            "Epoch: 239 \tTraining Loss:  0.596 \tTrain_Accu: 74%  \tValid_Acc:14%  \tVal_kappa : 0.040  \n",
            "Epoch: 240 \tTraining Loss:  0.564 \tTrain_Accu: 78%  \tValid_Acc:14%  \tVal_kappa : 0.164  \n",
            "Epoch: 241 \tTraining Loss:  0.587 \tTrain_Accu: 78%  \tValid_Acc:16%  \tVal_kappa : 0.043  \n",
            "Epoch: 242 \tTraining Loss:  0.565 \tTrain_Accu: 77%  \tValid_Acc:26%  \tVal_kappa : 0.122  \n",
            "Epoch: 243 \tTraining Loss:  0.545 \tTrain_Accu: 75%  \tValid_Acc:19%  \tVal_kappa : 0.092  \n",
            "Epoch: 244 \tTraining Loss:  0.540 \tTrain_Accu: 78%  \tValid_Acc:23%  \tVal_kappa : 0.017  \n",
            "Epoch: 245 \tTraining Loss:  0.519 \tTrain_Accu: 78%  \tValid_Acc:20%  \tVal_kappa : -0.117  \n",
            "Epoch: 246 \tTraining Loss:  0.564 \tTrain_Accu: 75%  \tValid_Acc:19%  \tVal_kappa : 0.031  \n",
            "Epoch: 247 \tTraining Loss:  0.552 \tTrain_Accu: 78%  \tValid_Acc:16%  \tVal_kappa : 0.063  \n",
            "Epoch: 248 \tTraining Loss:  0.510 \tTrain_Accu: 78%  \tValid_Acc:27%  \tVal_kappa : 0.187  \n",
            "Epoch: 249 \tTraining Loss:  0.548 \tTrain_Accu: 79%  \tValid_Acc:19%  \tVal_kappa : 0.086  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-27 04:55:27,679]\u001b[0m Trial 7 finished with value: 21.4 and parameters: {}. Best is trial 7 with value: 21.4.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.539 \tTrain_Accu: 76%  \tValid_Acc:21%  \tVal_kappa : 0.108  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['optimise_valid_ENI_temp_drop(0.5).torch']"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOmfVEw2yp9j"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "0OnlZ0aHLfdg",
        "outputId": "f98b4d62-a3c3-47e9-f8ae-56f94f8dd9d4"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_temp_ENI[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_dropout(0.8)\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_ENI_temp_std.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 3, 4, 3, 4, 3, 1, 2, 2, 4, 1, 3, 4, 3, 4, 1, 1, 1, 2, 1, 1, 1, 3, 3,\n",
            "        4, 4, 1, 4, 4, 4, 2, 3, 4, 4, 1, 4, 1, 3, 3, 3, 2, 3, 3, 1, 3, 3, 2, 4,\n",
            "        4, 3, 4, 3, 4, 1, 4, 4, 3, 2, 3, 1, 1, 3, 4, 1, 2, 4, 3, 2, 2, 1])\n",
            "labels tensor([1, 4, 3, 4, 4, 3, 2, 2, 2, 2, 2, 2, 4, 3, 3, 3, 2, 2, 0, 1, 1, 2, 2, 4,\n",
            "        4, 4, 4, 4, 4, 3, 3, 3, 4, 3, 2, 2, 3, 4, 3, 3, 1, 3, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 3, 3, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 2, 4, 4])\n",
            "correct : 27\n",
            "test_Accuracy % : 38.6\n",
            "kappa 0.34600158353127475\n",
            "[[ 0  0  1  0  0]\n",
            " [ 0  3  1  0  0]\n",
            " [ 0  6  3  2  2]\n",
            " [ 0  3  2  8  6]\n",
            " [ 0  6  3 11 13]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0juQjtKILWT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7Z9iu6pyp9j"
      },
      "source": [
        "# Rainfall models results table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "SMubb7AVtV2d",
        "outputId": "00e8c1d6-b2c5-4e98-d557-9151d247d092"
      },
      "source": [
        "# Table of rainfall models results\n",
        "\n",
        "data2 = {'Region':['NNI', 'ENI', 'WNI', 'NSI', 'ESI', 'WSI'], 'Acc_train':['99%', '98%', '98%', '99%', '99%', '99%'], 'Acc_valid':['23%', '21%', '26%', '29%', '20%', '23%'], 'Acc_test':['32%', '35%', '30%', '34%', '25%', '24%'], 'k':[0.19, 0.2, 0.03, 0.2, 0.2, 0.24 ] }\n",
        "Table2 = pd.DataFrame(data2)\n",
        "Table2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Region</th>\n",
              "      <th>Acc_train</th>\n",
              "      <th>Acc_valid</th>\n",
              "      <th>Acc_test</th>\n",
              "      <th>k</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NNI</td>\n",
              "      <td>99%</td>\n",
              "      <td>23%</td>\n",
              "      <td>32%</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENI</td>\n",
              "      <td>98%</td>\n",
              "      <td>21%</td>\n",
              "      <td>35%</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WNI</td>\n",
              "      <td>98%</td>\n",
              "      <td>26%</td>\n",
              "      <td>30%</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NSI</td>\n",
              "      <td>99%</td>\n",
              "      <td>29%</td>\n",
              "      <td>34%</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ESI</td>\n",
              "      <td>99%</td>\n",
              "      <td>20%</td>\n",
              "      <td>25%</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>WSI</td>\n",
              "      <td>99%</td>\n",
              "      <td>23%</td>\n",
              "      <td>24%</td>\n",
              "      <td>0.24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Region Acc_train Acc_valid Acc_test     k\n",
              "0    NNI       99%       23%      32%  0.19\n",
              "1    ENI       98%       21%      35%  0.20\n",
              "2    WNI       98%       26%      30%  0.03\n",
              "3    NSI       99%       29%      34%  0.20\n",
              "4    ESI       99%       20%      25%  0.20\n",
              "5    WSI       99%       23%      24%  0.24"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "xECC9nT7teTo",
        "outputId": "f0b4bc9e-0c47-4217-9a98-69316344280a"
      },
      "source": [
        "# Code to plot the table to save it\n",
        "\n",
        "from pandas.plotting import table \n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 1)) # set size frame\n",
        "ax.xaxis.set_visible(False)  # hide the x axis\n",
        "ax.yaxis.set_visible(False)  # hide the y axis\n",
        "ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
        "tabla = table(ax, Table2, loc='upper right', colWidths=[0.14]*len(Table2.columns))  # where df is your data frame\n",
        "tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
        "tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
        "tabla.scale(1.8, 1.8) # change size table\n",
        "plt.savefig('Rain_table.png', transparent=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x72 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr1Xuf0LvrZw"
      },
      "source": [
        "# Temperature models results table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "MxmKLi0KwCyi",
        "outputId": "39b6c022-0925-4c28-e476-b2a2a9017fed"
      },
      "source": [
        "# Table of temp models results\n",
        "\n",
        "data2 = {'Region':['NNI', 'ENI', 'WNI', 'NSI', 'ESI', 'WSI'], 'Train_Acc':['84%', '76%', '85%', '87%', '79%', '83%'], 'Valid_Acc':['36%', '21%', '20%', '24%', '29%', '20%'], 'Test_Acc':['24%', '38%', '25%', '21%', '21%', '27%'], 'k':[-0.02, 0.34, 0.06, 0.2, 0.01, -0.04 ] }\n",
        "Table2 = pd.DataFrame(data2)\n",
        "Table2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Region</th>\n",
              "      <th>Train_Acc</th>\n",
              "      <th>Valid_Acc</th>\n",
              "      <th>Test_Acc</th>\n",
              "      <th>k</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NNI</td>\n",
              "      <td>84%</td>\n",
              "      <td>36%</td>\n",
              "      <td>24%</td>\n",
              "      <td>-0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENI</td>\n",
              "      <td>76%</td>\n",
              "      <td>21%</td>\n",
              "      <td>38%</td>\n",
              "      <td>0.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WNI</td>\n",
              "      <td>85%</td>\n",
              "      <td>20%</td>\n",
              "      <td>25%</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NSI</td>\n",
              "      <td>87%</td>\n",
              "      <td>24%</td>\n",
              "      <td>21%</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ESI</td>\n",
              "      <td>79%</td>\n",
              "      <td>29%</td>\n",
              "      <td>21%</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>WSI</td>\n",
              "      <td>83%</td>\n",
              "      <td>20%</td>\n",
              "      <td>27%</td>\n",
              "      <td>-0.04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Region Train_Acc Valid_Acc Test_Acc     k\n",
              "0    NNI       84%       36%      24% -0.02\n",
              "1    ENI       76%       21%      38%  0.34\n",
              "2    WNI       85%       20%      25%  0.06\n",
              "3    NSI       87%       24%      21%  0.20\n",
              "4    ESI       79%       29%      21%  0.01\n",
              "5    WSI       83%       20%      27% -0.04"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "7IzL8zpaxB5I",
        "outputId": "980e788c-af5f-465a-a9f8-b7dbd615049e"
      },
      "source": [
        "# Code to plot the table to save it\n",
        "\n",
        "from pandas.plotting import table \n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 1)) # set size frame\n",
        "ax.xaxis.set_visible(False)  # hide the x axis\n",
        "ax.yaxis.set_visible(False)  # hide the y axis\n",
        "ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
        "tabla = table(ax, Table2, loc='upper right', colWidths=[0.14]*len(Table2.columns))  # where df is your data frame\n",
        "tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
        "tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
        "tabla.scale(1.5, 1.5) # change size table\n",
        "plt.savefig('Rain_table.png', transparent=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x72 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQE0nadvXXEI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VSVLMo8MiaB"
      },
      "source": [
        "# Quadratic weighted kappa (QWK) with NNI rainfall region\n",
        "\n",
        "This experiment has been done using continuous quadratic weighted kappa as a loss function. Custom quadratic weighted loss function is defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMaVyGD6B_Y9"
      },
      "source": [
        "# Function to calculte continous quadratic weighted kappa as loss fuction\n",
        "\n",
        "def _one_minus_kappa_cont(prob, target, n_classes=-1):\n",
        "    # All computation is on prob's device.\n",
        "    #  device = prob.device\n",
        "    #  target.to(device)\n",
        "\n",
        "    if n_classes == -1:\n",
        "         n_classes = prob.shape[-1]\n",
        "\n",
        "    n_samples = torch.tensor(target.shape).prod()\n",
        "\n",
        "  \n",
        "    \n",
        "    def weighted(x): return x ** 2\n",
        "\n",
        "\n",
        "\n",
        "    # w_tq: weights centred to the correct classes, 2-dimensional tensor.\n",
        "    # Dimensions of w_tq:\n",
        "    #   0 - instances\n",
        "    #   1 - classes\n",
        "\n",
        "    w_tq = torch.cat([weighted(torch.arange(-t.item(), -t + n_classes))\n",
        "                         .view(1, n_classes) for t in target])\n",
        "   \n",
        "    w_tq = w_tq\n",
        "    numerator = torch.sum(w_tq * prob)\n",
        "\n",
        "    target_histogram = torch.tensor([torch.sum(target == c) for c in range(n_classes)],\n",
        "                                    dtype=torch.float) / n_samples\n",
        "    target_histogram = target_histogram\n",
        "    # w_ij: weights, 3-dimensional tensor sized Qx1xQ.\n",
        "    # Dimensions of w_ij:\n",
        "    #   0 - target classes\n",
        "    #   1 - instances (defined with 1 element, to be broadcast to N)\n",
        "    #   2 - prediction classes\n",
        "  \n",
        "    w_ij = torch.cat([weighted(torch.arange(-i, -i + n_classes))\n",
        "                         .view(1, 1, n_classes)\n",
        "                          for i in range(n_classes)], dim=0)\n",
        "   \n",
        "    w_ij = w_ij\n",
        "\n",
        "    # The NxQ prob is unsqueezed to 1xNxQ, multiplying w_ij in Qx1xQ,\n",
        "    # producing a QxNxQ result. Summing the QxNxQ along all dimensions\n",
        "    # except 0, collapsing all the inner dimensions (d > 0), produces a 1-D\n",
        "    # tensor of shape (Q,), each of whose elements represents the total\n",
        "    # number of weighted predictions for a target class, equivalent to\n",
        "    # \\sum_{j=1}^Q (W_{i,j} E_{i,j}) in the non-continuous form.\n",
        "    pred_per_target = torch.sum(w_ij * prob,\n",
        "                                dim=list(range(1, w_ij.ndim)))\n",
        "    denominator = torch.sum(pred_per_target * target_histogram)\n",
        "\n",
        "    return numerator / denominator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy0V0FcWiv1j"
      },
      "source": [
        "This fucntion provides QWk meritc\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6MKrCtvCHgg"
      },
      "source": [
        "def cohen_kappa_cont(prob, target, n_classes=-1) :\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        prob: Output probabilities.\n",
        "        target: Targets of samples.\n",
        "        n_classes: Number of classes. If not specified, compute from the length\n",
        "                    of prob.\n",
        "        weighting: None for unweighted, 'linear' or 'quadratic' for weighted.\n",
        "\n",
        "    Returns:\n",
        "        A scalar cohen kappa metric with specified weighting.\n",
        "\n",
        "    \"\"\"\n",
        "    return torch.tensor(1.) - _one_minus_kappa_cont(prob, target, n_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVhyulBGiH7s"
      },
      "source": [
        "## Logrithm of qwk loss function\n",
        "\n",
        "This function is used as a loss function while training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2-AkWAICOis"
      },
      "source": [
        "def Kappaloss_log(input, target):\n",
        "     prob = torch.softmax(input, dim=-1)\n",
        "     one_minus_kappa = torch.log(_one_minus_kappa_cont(prob, target))\n",
        "     return one_minus_kappa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKkm8wxaGp4U"
      },
      "source": [
        "## Tuning\n",
        "\n",
        "Training NNI rainfall data with qwk loss function, RMSprop optimizer, CNN with max pooling and batch normalisation. This configuration was obtained from the paper where they introduced qwk as a loss function ( J. de la Torre , D. Puig , A. Valls , Weighted kappa loss function for multi-class classification of ordinal data in deep learning, Pattern Recogni. Lett. (2017)).\n",
        "\n",
        "NNI rainfall model was run with quadratic weighted kappa as a loss function, batch size 10, RMSprop optimiser. Different learning rate were used to see the behaviour of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mRZQRK-A7gy"
      },
      "source": [
        "# Main function to run, nodropout\n",
        "\n",
        "def train_NNI_QWK(trial):\n",
        "  \n",
        "  cfg = { 'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "         #'lr'       : trial.suggest_loguniform('lr', 1e-3, 1e-1),\n",
        "          'lr' : trial.suggest_categorical('lr', [0.1, 0.01, 0.001, 0.0001]),  \n",
        "          'optimizer':  optim.RMSprop,     \n",
        "         # 'dropout'       : trial.suggest_categorical('dropout', [0.5, 0.7,0.9 ]),\n",
        "          'activation': F.relu}\n",
        "\n",
        " \n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_NNI(cfg['Batch_size'])\n",
        "  model = Network_drop_bn().to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_NNI[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_NNI[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 10\n",
        "\n",
        "  # quad = quadratic_kappa_coefficient(output1, target1).to(device)\n",
        "  # quad_metric = Qwk_metric(output1, target1).to(device)\n",
        "\n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  Kappaloss_log(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = Kappaloss_log(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              #print('labels', target)\n",
        "              #print('pred', valid_pred)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              \n",
        "              \n",
        "         \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "     \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_NNI[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_NNI[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "       #valid_qwk = Qwk_metric(fold_preds, labels_actual).item()\n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f} '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"./check_valid_NNI_kappa_loss_Adam.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_kappa_all, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1USkl3S2FH1U",
        "outputId": "efb52380-ce95-45f9-f69f-e4035ab080ad"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_NNI_QWK, n_trials=4)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"drive/My Drive/DL_project/optimise_valid_NNI_temp.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: -0.003 \tTrain_Accu: 21%  \tValid_Acc:20%  \tVal_kappa : -0.006 \n",
            "Epoch: 2 \tTraining Loss:  0.028 \tTrain_Accu: 19%  \tValid_Acc:21%  \tVal_kappa : 0.096 \n",
            "Epoch: 3 \tTraining Loss: -0.101 \tTrain_Accu: 22%  \tValid_Acc:20%  \tVal_kappa : 0.166 \n",
            "Epoch: 4 \tTraining Loss: -0.011 \tTrain_Accu: 21%  \tValid_Acc:13%  \tVal_kappa : 0.007 \n",
            "Epoch: 5 \tTraining Loss:  0.006 \tTrain_Accu: 17%  \tValid_Acc:24%  \tVal_kappa : -0.006 \n",
            "Epoch: 6 \tTraining Loss: -0.038 \tTrain_Accu: 18%  \tValid_Acc:21%  \tVal_kappa : 0.065 \n",
            "Epoch: 7 \tTraining Loss:  0.043 \tTrain_Accu: 22%  \tValid_Acc:19%  \tVal_kappa : 0.017 \n",
            "Epoch: 8 \tTraining Loss:  0.014 \tTrain_Accu: 18%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 9 \tTraining Loss: -0.003 \tTrain_Accu: 20%  \tValid_Acc:33%  \tVal_kappa : 0.057 \n",
            "Epoch: 10 \tTraining Loss: -0.021 \tTrain_Accu: 22%  \tValid_Acc:30%  \tVal_kappa : 0.023 \n",
            "Epoch: 11 \tTraining Loss:  0.020 \tTrain_Accu: 22%  \tValid_Acc:23%  \tVal_kappa : 0.059 \n",
            "Epoch: 12 \tTraining Loss:  0.032 \tTrain_Accu: 21%  \tValid_Acc:21%  \tVal_kappa : -0.010 \n",
            "Epoch: 13 \tTraining Loss: -0.009 \tTrain_Accu: 17%  \tValid_Acc:19%  \tVal_kappa : 0.030 \n",
            "Epoch: 14 \tTraining Loss:  0.007 \tTrain_Accu: 18%  \tValid_Acc:23%  \tVal_kappa : -0.025 \n",
            "Epoch: 15 \tTraining Loss:  0.008 \tTrain_Accu: 22%  \tValid_Acc:24%  \tVal_kappa : 0.030 \n",
            "Epoch: 16 \tTraining Loss: -0.014 \tTrain_Accu: 22%  \tValid_Acc:26%  \tVal_kappa : 0.057 \n",
            "Epoch: 17 \tTraining Loss:  0.010 \tTrain_Accu: 24%  \tValid_Acc:21%  \tVal_kappa : -0.026 \n",
            "Epoch: 18 \tTraining Loss:  0.008 \tTrain_Accu: 20%  \tValid_Acc:20%  \tVal_kappa : -0.041 \n",
            "Epoch: 19 \tTraining Loss: -0.022 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : 0.020 \n",
            "Epoch: 20 \tTraining Loss:  0.013 \tTrain_Accu: 19%  \tValid_Acc:24%  \tVal_kappa : -0.005 \n",
            "Epoch: 21 \tTraining Loss:  0.003 \tTrain_Accu: 21%  \tValid_Acc:17%  \tVal_kappa : -0.026 \n",
            "Epoch: 22 \tTraining Loss: -0.057 \tTrain_Accu: 20%  \tValid_Acc:20%  \tVal_kappa : -0.005 \n",
            "Epoch: 23 \tTraining Loss:  0.022 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.005 \n",
            "Epoch: 24 \tTraining Loss: -0.028 \tTrain_Accu: 18%  \tValid_Acc:19%  \tVal_kappa : 0.005 \n",
            "Epoch: 25 \tTraining Loss: -0.026 \tTrain_Accu: 21%  \tValid_Acc:24%  \tVal_kappa : 0.039 \n",
            "Epoch: 26 \tTraining Loss: -0.014 \tTrain_Accu: 20%  \tValid_Acc:23%  \tVal_kappa : 0.033 \n",
            "Epoch: 27 \tTraining Loss:  0.013 \tTrain_Accu: 19%  \tValid_Acc:29%  \tVal_kappa : -0.034 \n",
            "Epoch: 28 \tTraining Loss: -0.009 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.009 \n",
            "Epoch: 29 \tTraining Loss:  0.056 \tTrain_Accu: 20%  \tValid_Acc:23%  \tVal_kappa : -0.005 \n",
            "Epoch: 30 \tTraining Loss: -0.036 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : 0.005 \n",
            "Epoch: 31 \tTraining Loss: -0.013 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : 0.037 \n",
            "Epoch: 32 \tTraining Loss:  0.034 \tTrain_Accu: 19%  \tValid_Acc:29%  \tVal_kappa : -0.009 \n",
            "Epoch: 33 \tTraining Loss:  0.004 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.037 \n",
            "Epoch: 34 \tTraining Loss: -0.041 \tTrain_Accu: 21%  \tValid_Acc:21%  \tVal_kappa : 0.005 \n",
            "Epoch: 35 \tTraining Loss: -0.041 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : 0.019 \n",
            "Epoch: 36 \tTraining Loss: -0.009 \tTrain_Accu: 19%  \tValid_Acc:26%  \tVal_kappa : -0.014 \n",
            "Epoch: 37 \tTraining Loss: -0.069 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.000 \n",
            "Epoch: 38 \tTraining Loss:  0.038 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.010 \n",
            "Epoch: 39 \tTraining Loss: -0.001 \tTrain_Accu: 18%  \tValid_Acc:23%  \tVal_kappa : -0.067 \n",
            "Epoch: 40 \tTraining Loss:  0.004 \tTrain_Accu: 20%  \tValid_Acc:23%  \tVal_kappa : -0.009 \n",
            "Epoch: 41 \tTraining Loss: -0.058 \tTrain_Accu: 21%  \tValid_Acc:30%  \tVal_kappa : -0.010 \n",
            "Epoch: 42 \tTraining Loss:  0.001 \tTrain_Accu: 21%  \tValid_Acc:21%  \tVal_kappa : -0.010 \n",
            "Epoch: 43 \tTraining Loss:  0.019 \tTrain_Accu: 20%  \tValid_Acc:29%  \tVal_kappa : 0.106 \n",
            "Epoch: 44 \tTraining Loss: -0.027 \tTrain_Accu: 20%  \tValid_Acc:23%  \tVal_kappa : 0.104 \n",
            "Epoch: 45 \tTraining Loss: -0.010 \tTrain_Accu: 18%  \tValid_Acc:21%  \tVal_kappa : 0.020 \n",
            "Epoch: 46 \tTraining Loss:  0.003 \tTrain_Accu: 19%  \tValid_Acc:29%  \tVal_kappa : 0.071 \n",
            "Epoch: 47 \tTraining Loss: -0.014 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : 0.058 \n",
            "Epoch: 48 \tTraining Loss:  0.027 \tTrain_Accu: 19%  \tValid_Acc:24%  \tVal_kappa : -0.059 \n",
            "Epoch: 49 \tTraining Loss:  0.012 \tTrain_Accu: 22%  \tValid_Acc:27%  \tVal_kappa : 0.009 \n",
            "Epoch: 50 \tTraining Loss: -0.037 \tTrain_Accu: 22%  \tValid_Acc:26%  \tVal_kappa : -0.005 \n",
            "Epoch: 51 \tTraining Loss: -0.021 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.014 \n",
            "Epoch: 52 \tTraining Loss: -0.041 \tTrain_Accu: 19%  \tValid_Acc:24%  \tVal_kappa : 0.010 \n",
            "Epoch: 53 \tTraining Loss: -0.007 \tTrain_Accu: 22%  \tValid_Acc:24%  \tVal_kappa : -0.027 \n",
            "Epoch: 54 \tTraining Loss:  0.012 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : 0.019 \n",
            "Epoch: 55 \tTraining Loss: -0.014 \tTrain_Accu: 20%  \tValid_Acc:23%  \tVal_kappa : 0.048 \n",
            "Epoch: 56 \tTraining Loss: -0.001 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 57 \tTraining Loss:  0.031 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : 0.000 \n",
            "Epoch: 58 \tTraining Loss:  0.007 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.018 \n",
            "Epoch: 59 \tTraining Loss:  0.008 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 60 \tTraining Loss:  0.004 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.009 \n",
            "Epoch: 61 \tTraining Loss: -0.047 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : -0.009 \n",
            "Epoch: 62 \tTraining Loss: -0.035 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.018 \n",
            "Epoch: 63 \tTraining Loss: -0.044 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : 0.000 \n",
            "Epoch: 64 \tTraining Loss: -0.044 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 65 \tTraining Loss:  0.047 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 66 \tTraining Loss: -0.027 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : 0.036 \n",
            "Epoch: 67 \tTraining Loss:  0.018 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 68 \tTraining Loss: -0.012 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 69 \tTraining Loss: -0.042 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.018 \n",
            "Epoch: 70 \tTraining Loss: -0.014 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 71 \tTraining Loss: -0.055 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 72 \tTraining Loss: -0.041 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 73 \tTraining Loss: -0.077 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : 0.000 \n",
            "Epoch: 74 \tTraining Loss: -0.021 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 75 \tTraining Loss: -0.040 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 76 \tTraining Loss:  0.011 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 77 \tTraining Loss: -0.048 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 78 \tTraining Loss: -0.032 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.032 \n",
            "Epoch: 79 \tTraining Loss:  0.025 \tTrain_Accu: 21%  \tValid_Acc:21%  \tVal_kappa : -0.037 \n",
            "Epoch: 80 \tTraining Loss: -0.087 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : -0.009 \n",
            "Epoch: 81 \tTraining Loss:  0.008 \tTrain_Accu: 19%  \tValid_Acc:26%  \tVal_kappa : -0.029 \n",
            "Epoch: 82 \tTraining Loss:  0.017 \tTrain_Accu: 19%  \tValid_Acc:24%  \tVal_kappa : 0.037 \n",
            "Epoch: 83 \tTraining Loss:  0.020 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : 0.009 \n",
            "Epoch: 84 \tTraining Loss: -0.006 \tTrain_Accu: 21%  \tValid_Acc:24%  \tVal_kappa : 0.000 \n",
            "Epoch: 85 \tTraining Loss: -0.043 \tTrain_Accu: 19%  \tValid_Acc:23%  \tVal_kappa : 0.000 \n",
            "Epoch: 86 \tTraining Loss: -0.009 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.028 \n",
            "Epoch: 87 \tTraining Loss: -0.010 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : 0.065 \n",
            "Epoch: 88 \tTraining Loss: -0.065 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.018 \n",
            "Epoch: 89 \tTraining Loss: -0.045 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 90 \tTraining Loss: -0.035 \tTrain_Accu: 22%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 91 \tTraining Loss: -0.035 \tTrain_Accu: 21%  \tValid_Acc:21%  \tVal_kappa : -0.037 \n",
            "Epoch: 92 \tTraining Loss: -0.047 \tTrain_Accu: 22%  \tValid_Acc:24%  \tVal_kappa : 0.037 \n",
            "Epoch: 93 \tTraining Loss: -0.053 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 94 \tTraining Loss: -0.001 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 95 \tTraining Loss:  0.001 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.018 \n",
            "Epoch: 96 \tTraining Loss:  0.036 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 97 \tTraining Loss: -0.023 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 98 \tTraining Loss: -0.030 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : -0.041 \n",
            "Epoch: 99 \tTraining Loss: -0.011 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : -0.009 \n",
            "Epoch: 100 \tTraining Loss:  0.060 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : 0.000 \n",
            "Epoch: 101 \tTraining Loss:  0.012 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.037 \n",
            "Epoch: 102 \tTraining Loss:  0.008 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : -0.009 \n",
            "Epoch: 103 \tTraining Loss:  0.007 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.018 \n",
            "Epoch: 104 \tTraining Loss: -0.009 \tTrain_Accu: 21%  \tValid_Acc:29%  \tVal_kappa : -0.028 \n",
            "Epoch: 105 \tTraining Loss:  0.001 \tTrain_Accu: 21%  \tValid_Acc:24%  \tVal_kappa : 0.005 \n",
            "Epoch: 106 \tTraining Loss:  0.002 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.009 \n",
            "Epoch: 107 \tTraining Loss:  0.007 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.014 \n",
            "Epoch: 108 \tTraining Loss:  0.030 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 109 \tTraining Loss: -0.000 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.027 \n",
            "Epoch: 110 \tTraining Loss: -0.014 \tTrain_Accu: 20%  \tValid_Acc:23%  \tVal_kappa : -0.018 \n",
            "Epoch: 111 \tTraining Loss: -0.042 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : -0.009 \n",
            "Epoch: 112 \tTraining Loss:  0.005 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.014 \n",
            "Epoch: 113 \tTraining Loss: -0.012 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : 0.000 \n",
            "Epoch: 114 \tTraining Loss: -0.019 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 115 \tTraining Loss: -0.021 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 116 \tTraining Loss: -0.013 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 117 \tTraining Loss: -0.006 \tTrain_Accu: 19%  \tValid_Acc:26%  \tVal_kappa : -0.009 \n",
            "Epoch: 118 \tTraining Loss: -0.001 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 119 \tTraining Loss: -0.020 \tTrain_Accu: 19%  \tValid_Acc:21%  \tVal_kappa : -0.037 \n",
            "Epoch: 120 \tTraining Loss:  0.001 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 121 \tTraining Loss:  0.017 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 122 \tTraining Loss:  0.005 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 123 \tTraining Loss:  0.039 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 124 \tTraining Loss: -0.067 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : -0.009 \n",
            "Epoch: 125 \tTraining Loss: -0.017 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 126 \tTraining Loss:  0.041 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 127 \tTraining Loss:  0.008 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.027 \n",
            "Epoch: 128 \tTraining Loss:  0.009 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : -0.018 \n",
            "Epoch: 129 \tTraining Loss: -0.001 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 130 \tTraining Loss: -0.021 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 131 \tTraining Loss: -0.015 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 132 \tTraining Loss: -0.021 \tTrain_Accu: 21%  \tValid_Acc:24%  \tVal_kappa : -0.009 \n",
            "Epoch: 133 \tTraining Loss: -0.016 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 134 \tTraining Loss:  0.026 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 135 \tTraining Loss:  0.018 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 136 \tTraining Loss: -0.019 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 137 \tTraining Loss:  0.011 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 138 \tTraining Loss: -0.010 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 139 \tTraining Loss: -0.015 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 140 \tTraining Loss:  0.024 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.005 \n",
            "Epoch: 141 \tTraining Loss: -0.054 \tTrain_Accu: 22%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 142 \tTraining Loss:  0.011 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.009 \n",
            "Epoch: 143 \tTraining Loss: -0.074 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.009 \n",
            "Epoch: 144 \tTraining Loss:  0.007 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 145 \tTraining Loss: -0.038 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 146 \tTraining Loss: -0.031 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 147 \tTraining Loss:  0.027 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : 0.005 \n",
            "Epoch: 148 \tTraining Loss:  0.005 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 149 \tTraining Loss:  0.010 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 150 \tTraining Loss: -0.033 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : 0.018 \n",
            "Epoch: 151 \tTraining Loss:  0.042 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 152 \tTraining Loss: -0.003 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 153 \tTraining Loss:  0.018 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 154 \tTraining Loss: -0.049 \tTrain_Accu: 19%  \tValid_Acc:26%  \tVal_kappa : -0.009 \n",
            "Epoch: 155 \tTraining Loss: -0.021 \tTrain_Accu: 21%  \tValid_Acc:24%  \tVal_kappa : -0.009 \n",
            "Epoch: 156 \tTraining Loss: -0.078 \tTrain_Accu: 22%  \tValid_Acc:23%  \tVal_kappa : -0.018 \n",
            "Epoch: 157 \tTraining Loss: -0.024 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 158 \tTraining Loss: -0.024 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 159 \tTraining Loss: -0.054 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 160 \tTraining Loss: -0.034 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 161 \tTraining Loss: -0.013 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 162 \tTraining Loss: -0.013 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.009 \n",
            "Epoch: 163 \tTraining Loss: -0.004 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 164 \tTraining Loss: -0.002 \tTrain_Accu: 20%  \tValid_Acc:23%  \tVal_kappa : -0.009 \n",
            "Epoch: 165 \tTraining Loss: -0.025 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : -0.014 \n",
            "Epoch: 166 \tTraining Loss: -0.025 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 167 \tTraining Loss: -0.005 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 168 \tTraining Loss:  0.020 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 169 \tTraining Loss: -0.012 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.004 \n",
            "Epoch: 170 \tTraining Loss:  0.007 \tTrain_Accu: 21%  \tValid_Acc:24%  \tVal_kappa : 0.000 \n",
            "Epoch: 171 \tTraining Loss:  0.042 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : -0.014 \n",
            "Epoch: 172 \tTraining Loss:  0.004 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 173 \tTraining Loss: -0.002 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : 0.009 \n",
            "Epoch: 174 \tTraining Loss: -0.003 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 175 \tTraining Loss: -0.072 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.009 \n",
            "Epoch: 176 \tTraining Loss: -0.033 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.018 \n",
            "Epoch: 177 \tTraining Loss: -0.019 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.018 \n",
            "Epoch: 178 \tTraining Loss:  0.029 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.014 \n",
            "Epoch: 179 \tTraining Loss: -0.007 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : 0.009 \n",
            "Epoch: 180 \tTraining Loss: -0.022 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 181 \tTraining Loss: -0.029 \tTrain_Accu: 21%  \tValid_Acc:24%  \tVal_kappa : -0.027 \n",
            "Epoch: 182 \tTraining Loss:  0.011 \tTrain_Accu: 21%  \tValid_Acc:20%  \tVal_kappa : -0.092 \n",
            "Epoch: 183 \tTraining Loss: -0.066 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : -0.009 \n",
            "Epoch: 184 \tTraining Loss: -0.016 \tTrain_Accu: 20%  \tValid_Acc:29%  \tVal_kappa : 0.073 \n",
            "Epoch: 185 \tTraining Loss: -0.022 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.018 \n",
            "Epoch: 186 \tTraining Loss: -0.001 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.037 \n",
            "Epoch: 187 \tTraining Loss: -0.012 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.018 \n",
            "Epoch: 188 \tTraining Loss: -0.058 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.056 \n",
            "Epoch: 189 \tTraining Loss: -0.043 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.027 \n",
            "Epoch: 190 \tTraining Loss:  0.020 \tTrain_Accu: 22%  \tValid_Acc:30%  \tVal_kappa : 0.010 \n",
            "Epoch: 191 \tTraining Loss: -0.016 \tTrain_Accu: 22%  \tValid_Acc:24%  \tVal_kappa : -0.046 \n",
            "Epoch: 192 \tTraining Loss: -0.025 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 193 \tTraining Loss: -0.016 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : -0.018 \n",
            "Epoch: 194 \tTraining Loss: -0.013 \tTrain_Accu: 22%  \tValid_Acc:26%  \tVal_kappa : 0.028 \n",
            "Epoch: 195 \tTraining Loss: -0.050 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : -0.018 \n",
            "Epoch: 196 \tTraining Loss: -0.075 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.009 \n",
            "Epoch: 197 \tTraining Loss: -0.020 \tTrain_Accu: 20%  \tValid_Acc:23%  \tVal_kappa : 0.000 \n",
            "Epoch: 198 \tTraining Loss: -0.016 \tTrain_Accu: 19%  \tValid_Acc:27%  \tVal_kappa : 0.033 \n",
            "Epoch: 199 \tTraining Loss: -0.034 \tTrain_Accu: 19%  \tValid_Acc:27%  \tVal_kappa : 0.000 \n",
            "Epoch: 200 \tTraining Loss: -0.047 \tTrain_Accu: 19%  \tValid_Acc:26%  \tVal_kappa : 0.027 \n",
            "Epoch: 201 \tTraining Loss: -0.027 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : 0.019 \n",
            "Epoch: 202 \tTraining Loss: -0.071 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.037 \n",
            "Epoch: 203 \tTraining Loss:  0.039 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : -0.009 \n",
            "Epoch: 204 \tTraining Loss:  0.003 \tTrain_Accu: 21%  \tValid_Acc:23%  \tVal_kappa : -0.019 \n",
            "Epoch: 205 \tTraining Loss:  0.017 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.009 \n",
            "Epoch: 206 \tTraining Loss: -0.067 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : -0.009 \n",
            "Epoch: 207 \tTraining Loss:  0.023 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : 0.018 \n",
            "Epoch: 208 \tTraining Loss: -0.048 \tTrain_Accu: 22%  \tValid_Acc:24%  \tVal_kappa : -0.018 \n",
            "Epoch: 209 \tTraining Loss: -0.008 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 210 \tTraining Loss: -0.027 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : 0.018 \n",
            "Epoch: 211 \tTraining Loss: -0.061 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.018 \n",
            "Epoch: 212 \tTraining Loss: -0.021 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.066 \n",
            "Epoch: 213 \tTraining Loss: -0.002 \tTrain_Accu: 19%  \tValid_Acc:27%  \tVal_kappa : 0.027 \n",
            "Epoch: 214 \tTraining Loss: -0.030 \tTrain_Accu: 20%  \tValid_Acc:23%  \tVal_kappa : -0.064 \n",
            "Epoch: 215 \tTraining Loss: -0.039 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : -0.055 \n",
            "Epoch: 216 \tTraining Loss: -0.036 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : -0.009 \n",
            "Epoch: 217 \tTraining Loss: -0.040 \tTrain_Accu: 21%  \tValid_Acc:29%  \tVal_kappa : 0.014 \n",
            "Epoch: 218 \tTraining Loss: -0.051 \tTrain_Accu: 22%  \tValid_Acc:27%  \tVal_kappa : 0.056 \n",
            "Epoch: 219 \tTraining Loss: -0.046 \tTrain_Accu: 19%  \tValid_Acc:24%  \tVal_kappa : -0.032 \n",
            "Epoch: 220 \tTraining Loss:  0.004 \tTrain_Accu: 19%  \tValid_Acc:27%  \tVal_kappa : 0.009 \n",
            "Epoch: 221 \tTraining Loss: -0.031 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : -0.009 \n",
            "Epoch: 222 \tTraining Loss:  0.029 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.028 \n",
            "Epoch: 223 \tTraining Loss:  0.017 \tTrain_Accu: 19%  \tValid_Acc:24%  \tVal_kappa : -0.045 \n",
            "Epoch: 224 \tTraining Loss: -0.012 \tTrain_Accu: 22%  \tValid_Acc:29%  \tVal_kappa : 0.072 \n",
            "Epoch: 225 \tTraining Loss: -0.028 \tTrain_Accu: 21%  \tValid_Acc:24%  \tVal_kappa : 0.000 \n",
            "Epoch: 226 \tTraining Loss:  0.007 \tTrain_Accu: 20%  \tValid_Acc:23%  \tVal_kappa : -0.018 \n",
            "Epoch: 227 \tTraining Loss: -0.031 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : -0.018 \n",
            "Epoch: 228 \tTraining Loss:  0.019 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 229 \tTraining Loss:  0.016 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.009 \n",
            "Epoch: 230 \tTraining Loss:  0.008 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 231 \tTraining Loss:  0.027 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 232 \tTraining Loss: -0.046 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 233 \tTraining Loss: -0.040 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : -0.009 \n",
            "Epoch: 234 \tTraining Loss:  0.015 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.009 \n",
            "Epoch: 235 \tTraining Loss:  0.016 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : -0.018 \n",
            "Epoch: 236 \tTraining Loss:  0.025 \tTrain_Accu: 19%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 237 \tTraining Loss: -0.027 \tTrain_Accu: 20%  \tValid_Acc:23%  \tVal_kappa : -0.046 \n",
            "Epoch: 238 \tTraining Loss: -0.066 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : -0.018 \n",
            "Epoch: 239 \tTraining Loss: -0.037 \tTrain_Accu: 21%  \tValid_Acc:23%  \tVal_kappa : -0.046 \n",
            "Epoch: 240 \tTraining Loss: -0.043 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 241 \tTraining Loss: -0.034 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 242 \tTraining Loss: -0.090 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.009 \n",
            "Epoch: 243 \tTraining Loss: -0.016 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : 0.046 \n",
            "Epoch: 244 \tTraining Loss: -0.042 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 245 \tTraining Loss: -0.028 \tTrain_Accu: 22%  \tValid_Acc:27%  \tVal_kappa : 0.018 \n",
            "Epoch: 246 \tTraining Loss: -0.065 \tTrain_Accu: 20%  \tValid_Acc:21%  \tVal_kappa : -0.065 \n",
            "Epoch: 247 \tTraining Loss: -0.022 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : 0.028 \n",
            "Epoch: 248 \tTraining Loss:  0.003 \tTrain_Accu: 20%  \tValid_Acc:24%  \tVal_kappa : 0.000 \n",
            "Epoch: 249 \tTraining Loss: -0.039 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : -0.009 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-28 00:05:57,017]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'lr': 0.1}. Best is trial 0 with value: 0.0.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss:  0.010 \tTrain_Accu: 21%  \tValid_Acc:27%  \tVal_kappa : 0.018 \n",
            "Epoch: 1 \tTraining Loss: -0.037 \tTrain_Accu: 20%  \tValid_Acc:33%  \tVal_kappa : 0.164 \n",
            "Epoch: 2 \tTraining Loss: -0.155 \tTrain_Accu: 25%  \tValid_Acc:23%  \tVal_kappa : -0.084 \n",
            "Epoch: 3 \tTraining Loss: -0.109 \tTrain_Accu: 22%  \tValid_Acc:19%  \tVal_kappa : 0.326 \n",
            "Epoch: 4 \tTraining Loss: -0.120 \tTrain_Accu: 21%  \tValid_Acc:29%  \tVal_kappa : 0.256 \n",
            "Epoch: 5 \tTraining Loss: -0.087 \tTrain_Accu: 22%  \tValid_Acc:30%  \tVal_kappa : 0.189 \n",
            "Epoch: 6 \tTraining Loss: -0.170 \tTrain_Accu: 27%  \tValid_Acc:31%  \tVal_kappa : 0.258 \n",
            "Epoch: 7 \tTraining Loss: -0.254 \tTrain_Accu: 25%  \tValid_Acc:26%  \tVal_kappa : 0.206 \n",
            "Epoch: 8 \tTraining Loss: -0.219 \tTrain_Accu: 21%  \tValid_Acc:31%  \tVal_kappa : 0.131 \n",
            "Epoch: 9 \tTraining Loss: -0.263 \tTrain_Accu: 22%  \tValid_Acc:31%  \tVal_kappa : 0.252 \n",
            "Epoch: 10 \tTraining Loss: -0.360 \tTrain_Accu: 22%  \tValid_Acc:36%  \tVal_kappa : 0.196 \n",
            "Epoch: 11 \tTraining Loss: -0.280 \tTrain_Accu: 22%  \tValid_Acc:30%  \tVal_kappa : 0.146 \n",
            "Epoch: 12 \tTraining Loss: -0.188 \tTrain_Accu: 25%  \tValid_Acc:24%  \tVal_kappa : 0.197 \n",
            "Epoch: 13 \tTraining Loss: -0.209 \tTrain_Accu: 17%  \tValid_Acc:21%  \tVal_kappa : 0.111 \n",
            "Epoch: 14 \tTraining Loss: -0.219 \tTrain_Accu: 23%  \tValid_Acc:27%  \tVal_kappa : 0.165 \n",
            "Epoch: 15 \tTraining Loss: -0.352 \tTrain_Accu: 26%  \tValid_Acc:36%  \tVal_kappa : 0.174 \n",
            "Epoch: 16 \tTraining Loss: -0.330 \tTrain_Accu: 23%  \tValid_Acc:24%  \tVal_kappa : 0.005 \n",
            "Epoch: 17 \tTraining Loss: -0.328 \tTrain_Accu: 29%  \tValid_Acc:17%  \tVal_kappa : 0.202 \n",
            "Epoch: 18 \tTraining Loss: -0.260 \tTrain_Accu: 24%  \tValid_Acc:24%  \tVal_kappa : 0.196 \n",
            "Epoch: 19 \tTraining Loss: -0.224 \tTrain_Accu: 24%  \tValid_Acc:30%  \tVal_kappa : 0.166 \n",
            "Epoch: 20 \tTraining Loss: -0.375 \tTrain_Accu: 27%  \tValid_Acc:31%  \tVal_kappa : 0.304 \n",
            "Epoch: 21 \tTraining Loss: -0.276 \tTrain_Accu: 30%  \tValid_Acc:29%  \tVal_kappa : 0.397 \n",
            "Epoch: 22 \tTraining Loss: -0.393 \tTrain_Accu: 31%  \tValid_Acc:27%  \tVal_kappa : 0.183 \n",
            "Epoch: 23 \tTraining Loss: -0.338 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : 0.249 \n",
            "Epoch: 24 \tTraining Loss: -0.327 \tTrain_Accu: 22%  \tValid_Acc:26%  \tVal_kappa : 0.010 \n",
            "Epoch: 25 \tTraining Loss: -0.238 \tTrain_Accu: 27%  \tValid_Acc:24%  \tVal_kappa : 0.109 \n",
            "Epoch: 26 \tTraining Loss: -0.303 \tTrain_Accu: 26%  \tValid_Acc:24%  \tVal_kappa : 0.093 \n",
            "Epoch: 27 \tTraining Loss: -0.353 \tTrain_Accu: 24%  \tValid_Acc:31%  \tVal_kappa : 0.340 \n",
            "Epoch: 28 \tTraining Loss: -0.309 \tTrain_Accu: 24%  \tValid_Acc:30%  \tVal_kappa : 0.194 \n",
            "Epoch: 29 \tTraining Loss: -0.337 \tTrain_Accu: 22%  \tValid_Acc:16%  \tVal_kappa : -0.035 \n",
            "Epoch: 30 \tTraining Loss: -0.359 \tTrain_Accu: 30%  \tValid_Acc:26%  \tVal_kappa : 0.122 \n",
            "Epoch: 31 \tTraining Loss: -0.314 \tTrain_Accu: 27%  \tValid_Acc:17%  \tVal_kappa : -0.017 \n",
            "Epoch: 32 \tTraining Loss: -0.261 \tTrain_Accu: 26%  \tValid_Acc:23%  \tVal_kappa : -0.013 \n",
            "Epoch: 33 \tTraining Loss: -0.353 \tTrain_Accu: 24%  \tValid_Acc:20%  \tVal_kappa : 0.082 \n",
            "Epoch: 34 \tTraining Loss: -0.347 \tTrain_Accu: 24%  \tValid_Acc:21%  \tVal_kappa : 0.183 \n",
            "Epoch: 35 \tTraining Loss: -0.331 \tTrain_Accu: 28%  \tValid_Acc:20%  \tVal_kappa : 0.000 \n",
            "Epoch: 36 \tTraining Loss: -0.261 \tTrain_Accu: 26%  \tValid_Acc:27%  \tVal_kappa : 0.161 \n",
            "Epoch: 37 \tTraining Loss: -0.419 \tTrain_Accu: 23%  \tValid_Acc:20%  \tVal_kappa : 0.157 \n",
            "Epoch: 38 \tTraining Loss: -0.311 \tTrain_Accu: 22%  \tValid_Acc:20%  \tVal_kappa : 0.265 \n",
            "Epoch: 39 \tTraining Loss: -0.357 \tTrain_Accu: 27%  \tValid_Acc:20%  \tVal_kappa : 0.066 \n",
            "Epoch: 40 \tTraining Loss: -0.291 \tTrain_Accu: 24%  \tValid_Acc:26%  \tVal_kappa : 0.127 \n",
            "Epoch: 41 \tTraining Loss: -0.387 \tTrain_Accu: 27%  \tValid_Acc:23%  \tVal_kappa : 0.113 \n",
            "Epoch: 42 \tTraining Loss: -0.358 \tTrain_Accu: 25%  \tValid_Acc:29%  \tVal_kappa : 0.097 \n",
            "Epoch: 43 \tTraining Loss: -0.371 \tTrain_Accu: 23%  \tValid_Acc:13%  \tVal_kappa : 0.017 \n",
            "Epoch: 44 \tTraining Loss: -0.343 \tTrain_Accu: 24%  \tValid_Acc:26%  \tVal_kappa : 0.177 \n",
            "Epoch: 45 \tTraining Loss: -0.354 \tTrain_Accu: 27%  \tValid_Acc:20%  \tVal_kappa : 0.098 \n",
            "Epoch: 46 \tTraining Loss: -0.481 \tTrain_Accu: 30%  \tValid_Acc:24%  \tVal_kappa : 0.287 \n",
            "Epoch: 47 \tTraining Loss: -0.433 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.155 \n",
            "Epoch: 48 \tTraining Loss: -0.340 \tTrain_Accu: 27%  \tValid_Acc:19%  \tVal_kappa : -0.034 \n",
            "Epoch: 49 \tTraining Loss: -0.321 \tTrain_Accu: 26%  \tValid_Acc:27%  \tVal_kappa : 0.187 \n",
            "Epoch: 50 \tTraining Loss: -0.346 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.150 \n",
            "Epoch: 51 \tTraining Loss: -0.343 \tTrain_Accu: 25%  \tValid_Acc:24%  \tVal_kappa : 0.011 \n",
            "Epoch: 52 \tTraining Loss: -0.359 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.006 \n",
            "Epoch: 53 \tTraining Loss: -0.249 \tTrain_Accu: 22%  \tValid_Acc:24%  \tVal_kappa : 0.011 \n",
            "Epoch: 54 \tTraining Loss: -0.301 \tTrain_Accu: 26%  \tValid_Acc:20%  \tVal_kappa : 0.073 \n",
            "Epoch: 55 \tTraining Loss: -0.336 \tTrain_Accu: 25%  \tValid_Acc:23%  \tVal_kappa : 0.179 \n",
            "Epoch: 56 \tTraining Loss: -0.406 \tTrain_Accu: 28%  \tValid_Acc:29%  \tVal_kappa : 0.129 \n",
            "Epoch: 57 \tTraining Loss: -0.282 \tTrain_Accu: 28%  \tValid_Acc:13%  \tVal_kappa : -0.149 \n",
            "Epoch: 58 \tTraining Loss: -0.268 \tTrain_Accu: 28%  \tValid_Acc:29%  \tVal_kappa : 0.177 \n",
            "Epoch: 59 \tTraining Loss: -0.341 \tTrain_Accu: 24%  \tValid_Acc:13%  \tVal_kappa : 0.280 \n",
            "Epoch: 60 \tTraining Loss: -0.295 \tTrain_Accu: 26%  \tValid_Acc:23%  \tVal_kappa : 0.156 \n",
            "Epoch: 61 \tTraining Loss: -0.377 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : 0.182 \n",
            "Epoch: 62 \tTraining Loss: -0.373 \tTrain_Accu: 27%  \tValid_Acc:21%  \tVal_kappa : 0.265 \n",
            "Epoch: 63 \tTraining Loss: -0.439 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.073 \n",
            "Epoch: 64 \tTraining Loss: -0.353 \tTrain_Accu: 23%  \tValid_Acc:14%  \tVal_kappa : 0.006 \n",
            "Epoch: 65 \tTraining Loss: -0.394 \tTrain_Accu: 27%  \tValid_Acc:20%  \tVal_kappa : 0.157 \n",
            "Epoch: 66 \tTraining Loss: -0.414 \tTrain_Accu: 29%  \tValid_Acc:16%  \tVal_kappa : 0.100 \n",
            "Epoch: 67 \tTraining Loss: -0.351 \tTrain_Accu: 29%  \tValid_Acc:23%  \tVal_kappa : 0.198 \n",
            "Epoch: 68 \tTraining Loss: -0.521 \tTrain_Accu: 26%  \tValid_Acc:26%  \tVal_kappa : 0.194 \n",
            "Epoch: 69 \tTraining Loss: -0.284 \tTrain_Accu: 26%  \tValid_Acc:13%  \tVal_kappa : 0.013 \n",
            "Epoch: 70 \tTraining Loss: -0.385 \tTrain_Accu: 28%  \tValid_Acc:20%  \tVal_kappa : 0.083 \n",
            "Epoch: 71 \tTraining Loss: -0.367 \tTrain_Accu: 27%  \tValid_Acc:23%  \tVal_kappa : 0.144 \n",
            "Epoch: 72 \tTraining Loss: -0.351 \tTrain_Accu: 27%  \tValid_Acc:16%  \tVal_kappa : 0.012 \n",
            "Epoch: 73 \tTraining Loss: -0.369 \tTrain_Accu: 23%  \tValid_Acc:31%  \tVal_kappa : 0.120 \n",
            "Epoch: 74 \tTraining Loss: -0.433 \tTrain_Accu: 29%  \tValid_Acc:31%  \tVal_kappa : 0.139 \n",
            "Epoch: 75 \tTraining Loss: -0.392 \tTrain_Accu: 24%  \tValid_Acc:21%  \tVal_kappa : 0.037 \n",
            "Epoch: 76 \tTraining Loss: -0.374 \tTrain_Accu: 28%  \tValid_Acc:29%  \tVal_kappa : 0.119 \n",
            "Epoch: 77 \tTraining Loss: -0.399 \tTrain_Accu: 26%  \tValid_Acc:30%  \tVal_kappa : 0.106 \n",
            "Epoch: 78 \tTraining Loss: -0.279 \tTrain_Accu: 26%  \tValid_Acc:27%  \tVal_kappa : 0.176 \n",
            "Epoch: 79 \tTraining Loss: -0.466 \tTrain_Accu: 29%  \tValid_Acc:27%  \tVal_kappa : 0.165 \n",
            "Epoch: 80 \tTraining Loss: -0.325 \tTrain_Accu: 24%  \tValid_Acc:20%  \tVal_kappa : 0.196 \n",
            "Epoch: 81 \tTraining Loss: -0.367 \tTrain_Accu: 23%  \tValid_Acc:20%  \tVal_kappa : 0.208 \n",
            "Epoch: 82 \tTraining Loss: -0.323 \tTrain_Accu: 28%  \tValid_Acc:26%  \tVal_kappa : 0.044 \n",
            "Epoch: 83 \tTraining Loss: -0.411 \tTrain_Accu: 26%  \tValid_Acc:19%  \tVal_kappa : -0.067 \n",
            "Epoch: 84 \tTraining Loss: -0.278 \tTrain_Accu: 26%  \tValid_Acc:10%  \tVal_kappa : -0.094 \n",
            "Epoch: 85 \tTraining Loss: -0.343 \tTrain_Accu: 28%  \tValid_Acc:21%  \tVal_kappa : 0.047 \n",
            "Epoch: 86 \tTraining Loss: -0.376 \tTrain_Accu: 26%  \tValid_Acc:20%  \tVal_kappa : -0.017 \n",
            "Epoch: 87 \tTraining Loss: -0.398 \tTrain_Accu: 26%  \tValid_Acc:19%  \tVal_kappa : 0.000 \n",
            "Epoch: 88 \tTraining Loss: -0.432 \tTrain_Accu: 26%  \tValid_Acc:30%  \tVal_kappa : 0.132 \n",
            "Epoch: 89 \tTraining Loss: -0.490 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : -0.006 \n",
            "Epoch: 90 \tTraining Loss: -0.481 \tTrain_Accu: 26%  \tValid_Acc:24%  \tVal_kappa : 0.064 \n",
            "Epoch: 91 \tTraining Loss: -0.379 \tTrain_Accu: 27%  \tValid_Acc:26%  \tVal_kappa : 0.024 \n",
            "Epoch: 92 \tTraining Loss: -0.475 \tTrain_Accu: 28%  \tValid_Acc:20%  \tVal_kappa : 0.166 \n",
            "Epoch: 93 \tTraining Loss: -0.440 \tTrain_Accu: 31%  \tValid_Acc:37%  \tVal_kappa : 0.242 \n",
            "Epoch: 94 \tTraining Loss: -0.429 \tTrain_Accu: 25%  \tValid_Acc:16%  \tVal_kappa : 0.025 \n",
            "Epoch: 95 \tTraining Loss: -0.521 \tTrain_Accu: 28%  \tValid_Acc:21%  \tVal_kappa : 0.053 \n",
            "Epoch: 96 \tTraining Loss: -0.345 \tTrain_Accu: 24%  \tValid_Acc:24%  \tVal_kappa : 0.146 \n",
            "Epoch: 97 \tTraining Loss: -0.421 \tTrain_Accu: 23%  \tValid_Acc:14%  \tVal_kappa : 0.046 \n",
            "Epoch: 98 \tTraining Loss: -0.475 \tTrain_Accu: 27%  \tValid_Acc:23%  \tVal_kappa : 0.116 \n",
            "Epoch: 99 \tTraining Loss: -0.392 \tTrain_Accu: 31%  \tValid_Acc:24%  \tVal_kappa : 0.101 \n",
            "Epoch: 100 \tTraining Loss: -0.337 \tTrain_Accu: 25%  \tValid_Acc:29%  \tVal_kappa : 0.200 \n",
            "Epoch: 101 \tTraining Loss: -0.425 \tTrain_Accu: 26%  \tValid_Acc:29%  \tVal_kappa : 0.069 \n",
            "Epoch: 102 \tTraining Loss: -0.417 \tTrain_Accu: 23%  \tValid_Acc:19%  \tVal_kappa : -0.006 \n",
            "Epoch: 103 \tTraining Loss: -0.473 \tTrain_Accu: 30%  \tValid_Acc:29%  \tVal_kappa : 0.140 \n",
            "Epoch: 104 \tTraining Loss: -0.456 \tTrain_Accu: 31%  \tValid_Acc:27%  \tVal_kappa : 0.067 \n",
            "Epoch: 105 \tTraining Loss: -0.514 \tTrain_Accu: 30%  \tValid_Acc:27%  \tVal_kappa : 0.279 \n",
            "Epoch: 106 \tTraining Loss: -0.261 \tTrain_Accu: 21%  \tValid_Acc:20%  \tVal_kappa : -0.042 \n",
            "Epoch: 107 \tTraining Loss: -0.409 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : 0.138 \n",
            "Epoch: 108 \tTraining Loss: -0.420 \tTrain_Accu: 24%  \tValid_Acc:26%  \tVal_kappa : 0.078 \n",
            "Epoch: 109 \tTraining Loss: -0.391 \tTrain_Accu: 27%  \tValid_Acc:20%  \tVal_kappa : 0.045 \n",
            "Epoch: 110 \tTraining Loss: -0.474 \tTrain_Accu: 30%  \tValid_Acc:36%  \tVal_kappa : 0.380 \n",
            "Epoch: 111 \tTraining Loss: -0.376 \tTrain_Accu: 26%  \tValid_Acc:23%  \tVal_kappa : 0.131 \n",
            "Epoch: 112 \tTraining Loss: -0.363 \tTrain_Accu: 26%  \tValid_Acc:24%  \tVal_kappa : 0.107 \n",
            "Epoch: 113 \tTraining Loss: -0.529 \tTrain_Accu: 28%  \tValid_Acc:29%  \tVal_kappa : 0.295 \n",
            "Epoch: 114 \tTraining Loss: -0.412 \tTrain_Accu: 27%  \tValid_Acc:27%  \tVal_kappa : 0.247 \n",
            "Epoch: 115 \tTraining Loss: -0.397 \tTrain_Accu: 23%  \tValid_Acc:29%  \tVal_kappa : 0.316 \n",
            "Epoch: 116 \tTraining Loss: -0.411 \tTrain_Accu: 29%  \tValid_Acc:24%  \tVal_kappa : 0.172 \n",
            "Epoch: 117 \tTraining Loss: -0.357 \tTrain_Accu: 26%  \tValid_Acc:19%  \tVal_kappa : 0.051 \n",
            "Epoch: 118 \tTraining Loss: -0.380 \tTrain_Accu: 23%  \tValid_Acc:26%  \tVal_kappa : 0.203 \n",
            "Epoch: 119 \tTraining Loss: -0.408 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.159 \n",
            "Epoch: 120 \tTraining Loss: -0.474 \tTrain_Accu: 30%  \tValid_Acc:24%  \tVal_kappa : 0.089 \n",
            "Epoch: 121 \tTraining Loss: -0.408 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.122 \n",
            "Epoch: 122 \tTraining Loss: -0.436 \tTrain_Accu: 25%  \tValid_Acc:16%  \tVal_kappa : 0.124 \n",
            "Epoch: 123 \tTraining Loss: -0.449 \tTrain_Accu: 26%  \tValid_Acc:20%  \tVal_kappa : 0.203 \n",
            "Epoch: 124 \tTraining Loss: -0.473 \tTrain_Accu: 28%  \tValid_Acc:33%  \tVal_kappa : 0.199 \n",
            "Epoch: 125 \tTraining Loss: -0.423 \tTrain_Accu: 29%  \tValid_Acc:26%  \tVal_kappa : 0.240 \n",
            "Epoch: 126 \tTraining Loss: -0.450 \tTrain_Accu: 27%  \tValid_Acc:24%  \tVal_kappa : 0.050 \n",
            "Epoch: 127 \tTraining Loss: -0.489 \tTrain_Accu: 26%  \tValid_Acc:23%  \tVal_kappa : 0.095 \n",
            "Epoch: 128 \tTraining Loss: -0.463 \tTrain_Accu: 29%  \tValid_Acc:19%  \tVal_kappa : 0.138 \n",
            "Epoch: 129 \tTraining Loss: -0.434 \tTrain_Accu: 25%  \tValid_Acc:20%  \tVal_kappa : 0.139 \n",
            "Epoch: 130 \tTraining Loss: -0.351 \tTrain_Accu: 25%  \tValid_Acc:27%  \tVal_kappa : 0.145 \n",
            "Epoch: 131 \tTraining Loss: -0.435 \tTrain_Accu: 26%  \tValid_Acc:20%  \tVal_kappa : 0.053 \n",
            "Epoch: 132 \tTraining Loss: -0.489 \tTrain_Accu: 28%  \tValid_Acc:26%  \tVal_kappa : 0.184 \n",
            "Epoch: 133 \tTraining Loss: -0.486 \tTrain_Accu: 30%  \tValid_Acc:29%  \tVal_kappa : -0.025 \n",
            "Epoch: 134 \tTraining Loss: -0.416 \tTrain_Accu: 26%  \tValid_Acc:19%  \tVal_kappa : 0.039 \n",
            "Epoch: 135 \tTraining Loss: -0.399 \tTrain_Accu: 27%  \tValid_Acc:30%  \tVal_kappa : 0.149 \n",
            "Epoch: 136 \tTraining Loss: -0.382 \tTrain_Accu: 26%  \tValid_Acc:24%  \tVal_kappa : 0.000 \n",
            "Epoch: 137 \tTraining Loss: -0.516 \tTrain_Accu: 28%  \tValid_Acc:16%  \tVal_kappa : -0.040 \n",
            "Epoch: 138 \tTraining Loss: -0.375 \tTrain_Accu: 24%  \tValid_Acc:24%  \tVal_kappa : 0.100 \n",
            "Epoch: 139 \tTraining Loss: -0.517 \tTrain_Accu: 29%  \tValid_Acc:21%  \tVal_kappa : -0.026 \n",
            "Epoch: 140 \tTraining Loss: -0.448 \tTrain_Accu: 26%  \tValid_Acc:27%  \tVal_kappa : 0.150 \n",
            "Epoch: 141 \tTraining Loss: -0.384 \tTrain_Accu: 25%  \tValid_Acc:16%  \tVal_kappa : -0.039 \n",
            "Epoch: 142 \tTraining Loss: -0.347 \tTrain_Accu: 24%  \tValid_Acc:16%  \tVal_kappa : -0.203 \n",
            "Epoch: 143 \tTraining Loss: -0.305 \tTrain_Accu: 24%  \tValid_Acc:21%  \tVal_kappa : 0.000 \n",
            "Epoch: 144 \tTraining Loss: -0.324 \tTrain_Accu: 26%  \tValid_Acc:23%  \tVal_kappa : 0.035 \n",
            "Epoch: 145 \tTraining Loss: -0.250 \tTrain_Accu: 22%  \tValid_Acc:14%  \tVal_kappa : -0.190 \n",
            "Epoch: 146 \tTraining Loss: -0.288 \tTrain_Accu: 21%  \tValid_Acc:23%  \tVal_kappa : 0.095 \n",
            "Epoch: 147 \tTraining Loss: -0.384 \tTrain_Accu: 26%  \tValid_Acc:16%  \tVal_kappa : 0.077 \n",
            "Epoch: 148 \tTraining Loss: -0.449 \tTrain_Accu: 29%  \tValid_Acc:29%  \tVal_kappa : 0.177 \n",
            "Epoch: 149 \tTraining Loss: -0.500 \tTrain_Accu: 31%  \tValid_Acc:24%  \tVal_kappa : 0.214 \n",
            "Epoch: 150 \tTraining Loss: -0.558 \tTrain_Accu: 27%  \tValid_Acc:24%  \tVal_kappa : 0.141 \n",
            "Epoch: 151 \tTraining Loss: -0.465 \tTrain_Accu: 30%  \tValid_Acc:27%  \tVal_kappa : 0.237 \n",
            "Epoch: 152 \tTraining Loss: -0.482 \tTrain_Accu: 28%  \tValid_Acc:13%  \tVal_kappa : -0.082 \n",
            "Epoch: 153 \tTraining Loss: -0.411 \tTrain_Accu: 27%  \tValid_Acc:26%  \tVal_kappa : 0.233 \n",
            "Epoch: 154 \tTraining Loss: -0.611 \tTrain_Accu: 32%  \tValid_Acc:23%  \tVal_kappa : 0.325 \n",
            "Epoch: 155 \tTraining Loss: -0.417 \tTrain_Accu: 28%  \tValid_Acc:26%  \tVal_kappa : 0.148 \n",
            "Epoch: 156 \tTraining Loss: -0.530 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.113 \n",
            "Epoch: 157 \tTraining Loss: -0.530 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.146 \n",
            "Epoch: 158 \tTraining Loss: -0.507 \tTrain_Accu: 25%  \tValid_Acc:30%  \tVal_kappa : 0.172 \n",
            "Epoch: 159 \tTraining Loss: -0.591 \tTrain_Accu: 29%  \tValid_Acc:27%  \tVal_kappa : 0.236 \n",
            "Epoch: 160 \tTraining Loss: -0.470 \tTrain_Accu: 29%  \tValid_Acc:34%  \tVal_kappa : 0.377 \n",
            "Epoch: 161 \tTraining Loss: -0.524 \tTrain_Accu: 27%  \tValid_Acc:20%  \tVal_kappa : 0.141 \n",
            "Epoch: 162 \tTraining Loss: -0.488 \tTrain_Accu: 30%  \tValid_Acc:26%  \tVal_kappa : 0.283 \n",
            "Epoch: 163 \tTraining Loss: -0.541 \tTrain_Accu: 27%  \tValid_Acc:19%  \tVal_kappa : 0.109 \n",
            "Epoch: 164 \tTraining Loss: -0.420 \tTrain_Accu: 32%  \tValid_Acc:13%  \tVal_kappa : 0.014 \n",
            "Epoch: 165 \tTraining Loss: -0.446 \tTrain_Accu: 27%  \tValid_Acc:19%  \tVal_kappa : 0.083 \n",
            "Epoch: 166 \tTraining Loss: -0.488 \tTrain_Accu: 25%  \tValid_Acc:17%  \tVal_kappa : 0.013 \n",
            "Epoch: 167 \tTraining Loss: -0.420 \tTrain_Accu: 26%  \tValid_Acc:17%  \tVal_kappa : 0.185 \n",
            "Epoch: 168 \tTraining Loss: -0.552 \tTrain_Accu: 29%  \tValid_Acc:23%  \tVal_kappa : 0.082 \n",
            "Epoch: 169 \tTraining Loss: -0.416 \tTrain_Accu: 29%  \tValid_Acc:29%  \tVal_kappa : 0.120 \n",
            "Epoch: 170 \tTraining Loss: -0.592 \tTrain_Accu: 28%  \tValid_Acc:16%  \tVal_kappa : 0.101 \n",
            "Epoch: 171 \tTraining Loss: -0.434 \tTrain_Accu: 29%  \tValid_Acc:19%  \tVal_kappa : 0.068 \n",
            "Epoch: 172 \tTraining Loss: -0.450 \tTrain_Accu: 29%  \tValid_Acc:20%  \tVal_kappa : -0.059 \n",
            "Epoch: 173 \tTraining Loss: -0.433 \tTrain_Accu: 27%  \tValid_Acc:31%  \tVal_kappa : 0.197 \n",
            "Epoch: 174 \tTraining Loss: -0.441 \tTrain_Accu: 27%  \tValid_Acc:24%  \tVal_kappa : 0.243 \n",
            "Epoch: 175 \tTraining Loss: -0.479 \tTrain_Accu: 28%  \tValid_Acc:26%  \tVal_kappa : 0.069 \n",
            "Epoch: 176 \tTraining Loss: -0.358 \tTrain_Accu: 29%  \tValid_Acc:17%  \tVal_kappa : 0.074 \n",
            "Epoch: 177 \tTraining Loss: -0.495 \tTrain_Accu: 29%  \tValid_Acc:29%  \tVal_kappa : 0.241 \n",
            "Epoch: 178 \tTraining Loss: -0.450 \tTrain_Accu: 28%  \tValid_Acc:24%  \tVal_kappa : 0.155 \n",
            "Epoch: 179 \tTraining Loss: -0.656 \tTrain_Accu: 32%  \tValid_Acc:26%  \tVal_kappa : 0.126 \n",
            "Epoch: 180 \tTraining Loss: -0.552 \tTrain_Accu: 28%  \tValid_Acc:26%  \tVal_kappa : 0.205 \n",
            "Epoch: 181 \tTraining Loss: -0.680 \tTrain_Accu: 29%  \tValid_Acc:26%  \tVal_kappa : 0.219 \n",
            "Epoch: 182 \tTraining Loss: -0.454 \tTrain_Accu: 25%  \tValid_Acc:24%  \tVal_kappa : 0.095 \n",
            "Epoch: 183 \tTraining Loss: -0.501 \tTrain_Accu: 25%  \tValid_Acc:24%  \tVal_kappa : 0.034 \n",
            "Epoch: 184 \tTraining Loss: -0.394 \tTrain_Accu: 27%  \tValid_Acc:24%  \tVal_kappa : 0.295 \n",
            "Epoch: 185 \tTraining Loss: -0.581 \tTrain_Accu: 29%  \tValid_Acc:21%  \tVal_kappa : 0.163 \n",
            "Epoch: 186 \tTraining Loss: -0.555 \tTrain_Accu: 30%  \tValid_Acc:17%  \tVal_kappa : -0.025 \n",
            "Epoch: 187 \tTraining Loss: -0.493 \tTrain_Accu: 24%  \tValid_Acc:26%  \tVal_kappa : 0.013 \n",
            "Epoch: 188 \tTraining Loss: -0.575 \tTrain_Accu: 29%  \tValid_Acc:23%  \tVal_kappa : 0.187 \n",
            "Epoch: 189 \tTraining Loss: -0.567 \tTrain_Accu: 28%  \tValid_Acc:20%  \tVal_kappa : 0.123 \n",
            "Epoch: 190 \tTraining Loss: -0.552 \tTrain_Accu: 30%  \tValid_Acc:16%  \tVal_kappa : -0.087 \n",
            "Epoch: 191 \tTraining Loss: -0.558 \tTrain_Accu: 29%  \tValid_Acc:21%  \tVal_kappa : -0.020 \n",
            "Epoch: 192 \tTraining Loss: -0.623 \tTrain_Accu: 28%  \tValid_Acc:26%  \tVal_kappa : 0.053 \n",
            "Epoch: 193 \tTraining Loss: -0.604 \tTrain_Accu: 28%  \tValid_Acc:21%  \tVal_kappa : -0.020 \n",
            "Epoch: 194 \tTraining Loss: -0.556 \tTrain_Accu: 26%  \tValid_Acc:37%  \tVal_kappa : 0.157 \n",
            "Epoch: 195 \tTraining Loss: -0.646 \tTrain_Accu: 31%  \tValid_Acc:34%  \tVal_kappa : 0.134 \n",
            "Epoch: 196 \tTraining Loss: -0.511 \tTrain_Accu: 26%  \tValid_Acc:16%  \tVal_kappa : 0.077 \n",
            "Epoch: 197 \tTraining Loss: -0.544 \tTrain_Accu: 27%  \tValid_Acc:23%  \tVal_kappa : 0.339 \n",
            "Epoch: 198 \tTraining Loss: -0.498 \tTrain_Accu: 27%  \tValid_Acc:20%  \tVal_kappa : 0.058 \n",
            "Epoch: 199 \tTraining Loss: -0.509 \tTrain_Accu: 29%  \tValid_Acc:29%  \tVal_kappa : 0.134 \n",
            "Epoch: 200 \tTraining Loss: -0.555 \tTrain_Accu: 31%  \tValid_Acc:33%  \tVal_kappa : 0.252 \n",
            "Epoch: 201 \tTraining Loss: -0.612 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : 0.097 \n",
            "Epoch: 202 \tTraining Loss: -0.484 \tTrain_Accu: 30%  \tValid_Acc:20%  \tVal_kappa : 0.161 \n",
            "Epoch: 203 \tTraining Loss: -0.652 \tTrain_Accu: 26%  \tValid_Acc:16%  \tVal_kappa : -0.064 \n",
            "Epoch: 204 \tTraining Loss: -0.414 \tTrain_Accu: 27%  \tValid_Acc:20%  \tVal_kappa : 0.049 \n",
            "Epoch: 205 \tTraining Loss: -0.532 \tTrain_Accu: 28%  \tValid_Acc:24%  \tVal_kappa : 0.147 \n",
            "Epoch: 206 \tTraining Loss: -0.671 \tTrain_Accu: 30%  \tValid_Acc:24%  \tVal_kappa : 0.247 \n",
            "Epoch: 207 \tTraining Loss: -0.465 \tTrain_Accu: 25%  \tValid_Acc:27%  \tVal_kappa : 0.161 \n",
            "Epoch: 208 \tTraining Loss: -0.589 \tTrain_Accu: 31%  \tValid_Acc:19%  \tVal_kappa : 0.132 \n",
            "Epoch: 209 \tTraining Loss: -0.673 \tTrain_Accu: 28%  \tValid_Acc:24%  \tVal_kappa : -0.007 \n",
            "Epoch: 210 \tTraining Loss: -0.553 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : 0.044 \n",
            "Epoch: 211 \tTraining Loss: -0.520 \tTrain_Accu: 27%  \tValid_Acc:24%  \tVal_kappa : 0.094 \n",
            "Epoch: 212 \tTraining Loss: -0.573 \tTrain_Accu: 33%  \tValid_Acc:17%  \tVal_kappa : -0.076 \n",
            "Epoch: 213 \tTraining Loss: -0.447 \tTrain_Accu: 27%  \tValid_Acc:26%  \tVal_kappa : -0.129 \n",
            "Epoch: 214 \tTraining Loss: -0.372 \tTrain_Accu: 25%  \tValid_Acc:24%  \tVal_kappa : 0.022 \n",
            "Epoch: 215 \tTraining Loss: -0.548 \tTrain_Accu: 28%  \tValid_Acc:20%  \tVal_kappa : -0.034 \n",
            "Epoch: 216 \tTraining Loss: -0.384 \tTrain_Accu: 27%  \tValid_Acc:17%  \tVal_kappa : 0.104 \n",
            "Epoch: 217 \tTraining Loss: -0.586 \tTrain_Accu: 26%  \tValid_Acc:31%  \tVal_kappa : 0.124 \n",
            "Epoch: 218 \tTraining Loss: -0.580 \tTrain_Accu: 29%  \tValid_Acc:19%  \tVal_kappa : 0.021 \n",
            "Epoch: 219 \tTraining Loss: -0.557 \tTrain_Accu: 28%  \tValid_Acc:19%  \tVal_kappa : 0.026 \n",
            "Epoch: 220 \tTraining Loss: -0.479 \tTrain_Accu: 26%  \tValid_Acc:26%  \tVal_kappa : 0.052 \n",
            "Epoch: 221 \tTraining Loss: -0.601 \tTrain_Accu: 29%  \tValid_Acc:24%  \tVal_kappa : 0.045 \n",
            "Epoch: 222 \tTraining Loss: -0.639 \tTrain_Accu: 31%  \tValid_Acc:21%  \tVal_kappa : 0.075 \n",
            "Epoch: 223 \tTraining Loss: -0.523 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.031 \n",
            "Epoch: 224 \tTraining Loss: -0.515 \tTrain_Accu: 31%  \tValid_Acc:26%  \tVal_kappa : 0.119 \n",
            "Epoch: 225 \tTraining Loss: -0.398 \tTrain_Accu: 25%  \tValid_Acc:23%  \tVal_kappa : 0.173 \n",
            "Epoch: 226 \tTraining Loss: -0.600 \tTrain_Accu: 29%  \tValid_Acc:23%  \tVal_kappa : 0.215 \n",
            "Epoch: 227 \tTraining Loss: -0.441 \tTrain_Accu: 24%  \tValid_Acc:21%  \tVal_kappa : 0.048 \n",
            "Epoch: 228 \tTraining Loss: -0.467 \tTrain_Accu: 27%  \tValid_Acc:19%  \tVal_kappa : 0.032 \n",
            "Epoch: 229 \tTraining Loss: -0.467 \tTrain_Accu: 26%  \tValid_Acc:26%  \tVal_kappa : 0.245 \n",
            "Epoch: 230 \tTraining Loss: -0.421 \tTrain_Accu: 27%  \tValid_Acc:26%  \tVal_kappa : 0.128 \n",
            "Epoch: 231 \tTraining Loss: -0.598 \tTrain_Accu: 32%  \tValid_Acc:19%  \tVal_kappa : 0.184 \n",
            "Epoch: 232 \tTraining Loss: -0.666 \tTrain_Accu: 31%  \tValid_Acc:27%  \tVal_kappa : 0.140 \n",
            "Epoch: 233 \tTraining Loss: -0.536 \tTrain_Accu: 31%  \tValid_Acc:21%  \tVal_kappa : 0.025 \n",
            "Epoch: 234 \tTraining Loss: -0.544 \tTrain_Accu: 32%  \tValid_Acc:19%  \tVal_kappa : -0.006 \n",
            "Epoch: 235 \tTraining Loss: -0.603 \tTrain_Accu: 31%  \tValid_Acc:27%  \tVal_kappa : -0.007 \n",
            "Epoch: 236 \tTraining Loss: -0.533 \tTrain_Accu: 24%  \tValid_Acc:23%  \tVal_kappa : 0.073 \n",
            "Epoch: 237 \tTraining Loss: -0.578 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.100 \n",
            "Epoch: 238 \tTraining Loss: -0.534 \tTrain_Accu: 30%  \tValid_Acc:30%  \tVal_kappa : 0.146 \n",
            "Epoch: 239 \tTraining Loss: -0.679 \tTrain_Accu: 30%  \tValid_Acc:29%  \tVal_kappa : 0.088 \n",
            "Epoch: 240 \tTraining Loss: -0.565 \tTrain_Accu: 28%  \tValid_Acc:26%  \tVal_kappa : 0.191 \n",
            "Epoch: 241 \tTraining Loss: -0.697 \tTrain_Accu: 33%  \tValid_Acc:30%  \tVal_kappa : 0.111 \n",
            "Epoch: 242 \tTraining Loss: -0.608 \tTrain_Accu: 30%  \tValid_Acc:27%  \tVal_kappa : 0.207 \n",
            "Epoch: 243 \tTraining Loss: -0.686 \tTrain_Accu: 30%  \tValid_Acc:17%  \tVal_kappa : 0.102 \n",
            "Epoch: 244 \tTraining Loss: -0.578 \tTrain_Accu: 29%  \tValid_Acc:21%  \tVal_kappa : 0.122 \n",
            "Epoch: 245 \tTraining Loss: -0.699 \tTrain_Accu: 29%  \tValid_Acc:24%  \tVal_kappa : 0.036 \n",
            "Epoch: 246 \tTraining Loss: -0.768 \tTrain_Accu: 33%  \tValid_Acc:20%  \tVal_kappa : 0.081 \n",
            "Epoch: 247 \tTraining Loss: -0.546 \tTrain_Accu: 26%  \tValid_Acc:24%  \tVal_kappa : 0.393 \n",
            "Epoch: 248 \tTraining Loss: -0.670 \tTrain_Accu: 28%  \tValid_Acc:20%  \tVal_kappa : 0.221 \n",
            "Epoch: 249 \tTraining Loss: -0.721 \tTrain_Accu: 29%  \tValid_Acc:19%  \tVal_kappa : 0.066 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-28 00:07:40,938]\u001b[0m Trial 1 finished with value: -0.0 and parameters: {'lr': 0.01}. Best is trial 0 with value: 0.0.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss: -0.583 \tTrain_Accu: 32%  \tValid_Acc:7%  \tVal_kappa : -0.046 \n",
            "Epoch: 1 \tTraining Loss: -0.032 \tTrain_Accu: 22%  \tValid_Acc:19%  \tVal_kappa : -0.030 \n",
            "Epoch: 2 \tTraining Loss: -0.034 \tTrain_Accu: 21%  \tValid_Acc:19%  \tVal_kappa : 0.168 \n",
            "Epoch: 3 \tTraining Loss: -0.125 \tTrain_Accu: 26%  \tValid_Acc:26%  \tVal_kappa : 0.162 \n",
            "Epoch: 4 \tTraining Loss: -0.118 \tTrain_Accu: 25%  \tValid_Acc:24%  \tVal_kappa : 0.107 \n",
            "Epoch: 5 \tTraining Loss: -0.135 \tTrain_Accu: 23%  \tValid_Acc:19%  \tVal_kappa : 0.006 \n",
            "Epoch: 6 \tTraining Loss: -0.186 \tTrain_Accu: 26%  \tValid_Acc:23%  \tVal_kappa : 0.142 \n",
            "Epoch: 7 \tTraining Loss: -0.189 \tTrain_Accu: 26%  \tValid_Acc:17%  \tVal_kappa : 0.215 \n",
            "Epoch: 8 \tTraining Loss: -0.257 \tTrain_Accu: 27%  \tValid_Acc:19%  \tVal_kappa : 0.085 \n",
            "Epoch: 9 \tTraining Loss: -0.263 \tTrain_Accu: 28%  \tValid_Acc:24%  \tVal_kappa : 0.179 \n",
            "Epoch: 10 \tTraining Loss: -0.338 \tTrain_Accu: 30%  \tValid_Acc:29%  \tVal_kappa : 0.104 \n",
            "Epoch: 11 \tTraining Loss: -0.372 \tTrain_Accu: 31%  \tValid_Acc:19%  \tVal_kappa : 0.048 \n",
            "Epoch: 12 \tTraining Loss: -0.330 \tTrain_Accu: 31%  \tValid_Acc:29%  \tVal_kappa : 0.161 \n",
            "Epoch: 13 \tTraining Loss: -0.408 \tTrain_Accu: 28%  \tValid_Acc:20%  \tVal_kappa : 0.343 \n",
            "Epoch: 14 \tTraining Loss: -0.455 \tTrain_Accu: 29%  \tValid_Acc:23%  \tVal_kappa : 0.259 \n",
            "Epoch: 15 \tTraining Loss: -0.485 \tTrain_Accu: 34%  \tValid_Acc:19%  \tVal_kappa : 0.125 \n",
            "Epoch: 16 \tTraining Loss: -0.547 \tTrain_Accu: 31%  \tValid_Acc:24%  \tVal_kappa : 0.211 \n",
            "Epoch: 17 \tTraining Loss: -0.524 \tTrain_Accu: 34%  \tValid_Acc:19%  \tVal_kappa : 0.065 \n",
            "Epoch: 18 \tTraining Loss: -0.568 \tTrain_Accu: 30%  \tValid_Acc:20%  \tVal_kappa : 0.033 \n",
            "Epoch: 19 \tTraining Loss: -0.606 \tTrain_Accu: 33%  \tValid_Acc:24%  \tVal_kappa : 0.112 \n",
            "Epoch: 20 \tTraining Loss: -0.643 \tTrain_Accu: 33%  \tValid_Acc:26%  \tVal_kappa : 0.093 \n",
            "Epoch: 21 \tTraining Loss: -0.757 \tTrain_Accu: 38%  \tValid_Acc:20%  \tVal_kappa : 0.122 \n",
            "Epoch: 22 \tTraining Loss: -0.772 \tTrain_Accu: 39%  \tValid_Acc:14%  \tVal_kappa : 0.125 \n",
            "Epoch: 23 \tTraining Loss: -0.814 \tTrain_Accu: 37%  \tValid_Acc:20%  \tVal_kappa : 0.053 \n",
            "Epoch: 24 \tTraining Loss: -0.816 \tTrain_Accu: 30%  \tValid_Acc:26%  \tVal_kappa : 0.096 \n",
            "Epoch: 25 \tTraining Loss: -0.808 \tTrain_Accu: 40%  \tValid_Acc:26%  \tVal_kappa : 0.118 \n",
            "Epoch: 26 \tTraining Loss: -0.859 \tTrain_Accu: 37%  \tValid_Acc:17%  \tVal_kappa : -0.011 \n",
            "Epoch: 27 \tTraining Loss: -0.884 \tTrain_Accu: 32%  \tValid_Acc:26%  \tVal_kappa : 0.173 \n",
            "Epoch: 28 \tTraining Loss: -0.910 \tTrain_Accu: 34%  \tValid_Acc:34%  \tVal_kappa : 0.386 \n",
            "Epoch: 29 \tTraining Loss: -0.887 \tTrain_Accu: 36%  \tValid_Acc:20%  \tVal_kappa : 0.168 \n",
            "Epoch: 30 \tTraining Loss: -1.011 \tTrain_Accu: 36%  \tValid_Acc:27%  \tVal_kappa : 0.158 \n",
            "Epoch: 31 \tTraining Loss: -0.961 \tTrain_Accu: 37%  \tValid_Acc:19%  \tVal_kappa : -0.040 \n",
            "Epoch: 32 \tTraining Loss: -0.936 \tTrain_Accu: 37%  \tValid_Acc:27%  \tVal_kappa : 0.091 \n",
            "Epoch: 33 \tTraining Loss: -1.022 \tTrain_Accu: 37%  \tValid_Acc:20%  \tVal_kappa : 0.181 \n",
            "Epoch: 34 \tTraining Loss: -1.122 \tTrain_Accu: 40%  \tValid_Acc:19%  \tVal_kappa : 0.070 \n",
            "Epoch: 35 \tTraining Loss: -1.029 \tTrain_Accu: 41%  \tValid_Acc:27%  \tVal_kappa : 0.193 \n",
            "Epoch: 36 \tTraining Loss: -0.901 \tTrain_Accu: 34%  \tValid_Acc:29%  \tVal_kappa : 0.156 \n",
            "Epoch: 37 \tTraining Loss: -1.154 \tTrain_Accu: 36%  \tValid_Acc:26%  \tVal_kappa : 0.106 \n",
            "Epoch: 38 \tTraining Loss: -1.081 \tTrain_Accu: 35%  \tValid_Acc:20%  \tVal_kappa : 0.205 \n",
            "Epoch: 39 \tTraining Loss: -1.133 \tTrain_Accu: 38%  \tValid_Acc:21%  \tVal_kappa : -0.017 \n",
            "Epoch: 40 \tTraining Loss: -1.050 \tTrain_Accu: 31%  \tValid_Acc:23%  \tVal_kappa : 0.011 \n",
            "Epoch: 41 \tTraining Loss: -1.178 \tTrain_Accu: 39%  \tValid_Acc:24%  \tVal_kappa : 0.083 \n",
            "Epoch: 42 \tTraining Loss: -1.087 \tTrain_Accu: 36%  \tValid_Acc:31%  \tVal_kappa : 0.212 \n",
            "Epoch: 43 \tTraining Loss: -1.077 \tTrain_Accu: 32%  \tValid_Acc:20%  \tVal_kappa : 0.088 \n",
            "Epoch: 44 \tTraining Loss: -1.176 \tTrain_Accu: 39%  \tValid_Acc:19%  \tVal_kappa : 0.132 \n",
            "Epoch: 45 \tTraining Loss: -0.976 \tTrain_Accu: 33%  \tValid_Acc:23%  \tVal_kappa : -0.028 \n",
            "Epoch: 46 \tTraining Loss: -1.179 \tTrain_Accu: 38%  \tValid_Acc:19%  \tVal_kappa : 0.194 \n",
            "Epoch: 47 \tTraining Loss: -1.305 \tTrain_Accu: 39%  \tValid_Acc:14%  \tVal_kappa : -0.017 \n",
            "Epoch: 48 \tTraining Loss: -1.127 \tTrain_Accu: 38%  \tValid_Acc:19%  \tVal_kappa : 0.000 \n",
            "Epoch: 49 \tTraining Loss: -1.066 \tTrain_Accu: 36%  \tValid_Acc:19%  \tVal_kappa : -0.006 \n",
            "Epoch: 50 \tTraining Loss: -1.108 \tTrain_Accu: 36%  \tValid_Acc:17%  \tVal_kappa : -0.040 \n",
            "Epoch: 51 \tTraining Loss: -1.077 \tTrain_Accu: 34%  \tValid_Acc:16%  \tVal_kappa : 0.029 \n",
            "Epoch: 52 \tTraining Loss: -1.094 \tTrain_Accu: 39%  \tValid_Acc:23%  \tVal_kappa : 0.078 \n",
            "Epoch: 53 \tTraining Loss: -1.160 \tTrain_Accu: 35%  \tValid_Acc:20%  \tVal_kappa : -0.056 \n",
            "Epoch: 54 \tTraining Loss: -1.160 \tTrain_Accu: 35%  \tValid_Acc:21%  \tVal_kappa : 0.095 \n",
            "Epoch: 55 \tTraining Loss: -1.259 \tTrain_Accu: 37%  \tValid_Acc:13%  \tVal_kappa : 0.075 \n",
            "Epoch: 56 \tTraining Loss: -1.187 \tTrain_Accu: 37%  \tValid_Acc:17%  \tVal_kappa : -0.034 \n",
            "Epoch: 57 \tTraining Loss: -1.186 \tTrain_Accu: 39%  \tValid_Acc:23%  \tVal_kappa : -0.161 \n",
            "Epoch: 58 \tTraining Loss: -1.214 \tTrain_Accu: 45%  \tValid_Acc:19%  \tVal_kappa : 0.072 \n",
            "Epoch: 59 \tTraining Loss: -1.257 \tTrain_Accu: 38%  \tValid_Acc:16%  \tVal_kappa : 0.169 \n",
            "Epoch: 60 \tTraining Loss: -1.106 \tTrain_Accu: 39%  \tValid_Acc:24%  \tVal_kappa : 0.113 \n",
            "Epoch: 61 \tTraining Loss: -1.368 \tTrain_Accu: 45%  \tValid_Acc:24%  \tVal_kappa : 0.243 \n",
            "Epoch: 62 \tTraining Loss: -1.178 \tTrain_Accu: 41%  \tValid_Acc:21%  \tVal_kappa : 0.125 \n",
            "Epoch: 63 \tTraining Loss: -1.214 \tTrain_Accu: 45%  \tValid_Acc:24%  \tVal_kappa : 0.165 \n",
            "Epoch: 64 \tTraining Loss: -1.263 \tTrain_Accu: 34%  \tValid_Acc:17%  \tVal_kappa : 0.018 \n",
            "Epoch: 65 \tTraining Loss: -1.266 \tTrain_Accu: 39%  \tValid_Acc:24%  \tVal_kappa : -0.006 \n",
            "Epoch: 66 \tTraining Loss: -1.265 \tTrain_Accu: 43%  \tValid_Acc:20%  \tVal_kappa : -0.065 \n",
            "Epoch: 67 \tTraining Loss: -1.209 \tTrain_Accu: 41%  \tValid_Acc:19%  \tVal_kappa : 0.105 \n",
            "Epoch: 68 \tTraining Loss: -1.317 \tTrain_Accu: 37%  \tValid_Acc:26%  \tVal_kappa : 0.089 \n",
            "Epoch: 69 \tTraining Loss: -1.257 \tTrain_Accu: 45%  \tValid_Acc:20%  \tVal_kappa : 0.119 \n",
            "Epoch: 70 \tTraining Loss: -1.356 \tTrain_Accu: 43%  \tValid_Acc:19%  \tVal_kappa : 0.176 \n",
            "Epoch: 71 \tTraining Loss: -1.303 \tTrain_Accu: 44%  \tValid_Acc:27%  \tVal_kappa : 0.211 \n",
            "Epoch: 72 \tTraining Loss: -1.174 \tTrain_Accu: 42%  \tValid_Acc:34%  \tVal_kappa : 0.182 \n",
            "Epoch: 73 \tTraining Loss: -1.338 \tTrain_Accu: 35%  \tValid_Acc:30%  \tVal_kappa : 0.135 \n",
            "Epoch: 74 \tTraining Loss: -1.319 \tTrain_Accu: 42%  \tValid_Acc:17%  \tVal_kappa : 0.086 \n",
            "Epoch: 75 \tTraining Loss: -1.345 \tTrain_Accu: 39%  \tValid_Acc:26%  \tVal_kappa : 0.063 \n",
            "Epoch: 76 \tTraining Loss: -1.211 \tTrain_Accu: 43%  \tValid_Acc:27%  \tVal_kappa : 0.187 \n",
            "Epoch: 77 \tTraining Loss: -1.367 \tTrain_Accu: 44%  \tValid_Acc:33%  \tVal_kappa : 0.253 \n",
            "Epoch: 78 \tTraining Loss: -1.179 \tTrain_Accu: 41%  \tValid_Acc:13%  \tVal_kappa : 0.062 \n",
            "Epoch: 79 \tTraining Loss: -1.242 \tTrain_Accu: 41%  \tValid_Acc:23%  \tVal_kappa : 0.050 \n",
            "Epoch: 80 \tTraining Loss: -1.360 \tTrain_Accu: 42%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 81 \tTraining Loss: -1.302 \tTrain_Accu: 42%  \tValid_Acc:26%  \tVal_kappa : 0.193 \n",
            "Epoch: 82 \tTraining Loss: -1.194 \tTrain_Accu: 41%  \tValid_Acc:26%  \tVal_kappa : 0.137 \n",
            "Epoch: 83 \tTraining Loss: -1.258 \tTrain_Accu: 44%  \tValid_Acc:19%  \tVal_kappa : 0.092 \n",
            "Epoch: 84 \tTraining Loss: -1.292 \tTrain_Accu: 44%  \tValid_Acc:20%  \tVal_kappa : 0.071 \n",
            "Epoch: 85 \tTraining Loss: -1.296 \tTrain_Accu: 45%  \tValid_Acc:21%  \tVal_kappa : 0.183 \n",
            "Epoch: 86 \tTraining Loss: -1.389 \tTrain_Accu: 46%  \tValid_Acc:23%  \tVal_kappa : 0.039 \n",
            "Epoch: 87 \tTraining Loss: -1.291 \tTrain_Accu: 40%  \tValid_Acc:17%  \tVal_kappa : 0.117 \n",
            "Epoch: 88 \tTraining Loss: -1.289 \tTrain_Accu: 44%  \tValid_Acc:19%  \tVal_kappa : -0.018 \n",
            "Epoch: 89 \tTraining Loss: -1.350 \tTrain_Accu: 44%  \tValid_Acc:24%  \tVal_kappa : 0.024 \n",
            "Epoch: 90 \tTraining Loss: -1.379 \tTrain_Accu: 44%  \tValid_Acc:24%  \tVal_kappa : 0.012 \n",
            "Epoch: 91 \tTraining Loss: -1.319 \tTrain_Accu: 40%  \tValid_Acc:13%  \tVal_kappa : 0.045 \n",
            "Epoch: 92 \tTraining Loss: -1.409 \tTrain_Accu: 46%  \tValid_Acc:24%  \tVal_kappa : 0.098 \n",
            "Epoch: 93 \tTraining Loss: -1.296 \tTrain_Accu: 46%  \tValid_Acc:31%  \tVal_kappa : 0.167 \n",
            "Epoch: 94 \tTraining Loss: -1.424 \tTrain_Accu: 43%  \tValid_Acc:13%  \tVal_kappa : 0.088 \n",
            "Epoch: 95 \tTraining Loss: -1.309 \tTrain_Accu: 47%  \tValid_Acc:19%  \tVal_kappa : 0.043 \n",
            "Epoch: 96 \tTraining Loss: -1.226 \tTrain_Accu: 41%  \tValid_Acc:24%  \tVal_kappa : 0.149 \n",
            "Epoch: 97 \tTraining Loss: -1.219 \tTrain_Accu: 43%  \tValid_Acc:29%  \tVal_kappa : 0.100 \n",
            "Epoch: 98 \tTraining Loss: -1.376 \tTrain_Accu: 46%  \tValid_Acc:17%  \tVal_kappa : 0.075 \n",
            "Epoch: 99 \tTraining Loss: -1.269 \tTrain_Accu: 46%  \tValid_Acc:24%  \tVal_kappa : 0.100 \n",
            "Epoch: 100 \tTraining Loss: -1.096 \tTrain_Accu: 42%  \tValid_Acc:20%  \tVal_kappa : -0.006 \n",
            "Epoch: 101 \tTraining Loss: -1.328 \tTrain_Accu: 41%  \tValid_Acc:26%  \tVal_kappa : 0.123 \n",
            "Epoch: 102 \tTraining Loss: -1.217 \tTrain_Accu: 41%  \tValid_Acc:20%  \tVal_kappa : 0.065 \n",
            "Epoch: 103 \tTraining Loss: -1.308 \tTrain_Accu: 42%  \tValid_Acc:31%  \tVal_kappa : 0.148 \n",
            "Epoch: 104 \tTraining Loss: -1.366 \tTrain_Accu: 46%  \tValid_Acc:29%  \tVal_kappa : 0.104 \n",
            "Epoch: 105 \tTraining Loss: -1.407 \tTrain_Accu: 47%  \tValid_Acc:20%  \tVal_kappa : 0.144 \n",
            "Epoch: 106 \tTraining Loss: -1.139 \tTrain_Accu: 41%  \tValid_Acc:21%  \tVal_kappa : 0.096 \n",
            "Epoch: 107 \tTraining Loss: -1.239 \tTrain_Accu: 44%  \tValid_Acc:26%  \tVal_kappa : 0.140 \n",
            "Epoch: 108 \tTraining Loss: -1.299 \tTrain_Accu: 42%  \tValid_Acc:23%  \tVal_kappa : 0.019 \n",
            "Epoch: 109 \tTraining Loss: -1.246 \tTrain_Accu: 46%  \tValid_Acc:21%  \tVal_kappa : 0.085 \n",
            "Epoch: 110 \tTraining Loss: -1.418 \tTrain_Accu: 47%  \tValid_Acc:24%  \tVal_kappa : 0.205 \n",
            "Epoch: 111 \tTraining Loss: -1.378 \tTrain_Accu: 47%  \tValid_Acc:21%  \tVal_kappa : -0.006 \n",
            "Epoch: 112 \tTraining Loss: -1.344 \tTrain_Accu: 42%  \tValid_Acc:17%  \tVal_kappa : 0.156 \n",
            "Epoch: 113 \tTraining Loss: -1.351 \tTrain_Accu: 45%  \tValid_Acc:29%  \tVal_kappa : 0.178 \n",
            "Epoch: 114 \tTraining Loss: -1.309 \tTrain_Accu: 43%  \tValid_Acc:23%  \tVal_kappa : 0.274 \n",
            "Epoch: 115 \tTraining Loss: -1.388 \tTrain_Accu: 43%  \tValid_Acc:30%  \tVal_kappa : 0.281 \n",
            "Epoch: 116 \tTraining Loss: -1.344 \tTrain_Accu: 46%  \tValid_Acc:24%  \tVal_kappa : 0.089 \n",
            "Epoch: 117 \tTraining Loss: -1.216 \tTrain_Accu: 43%  \tValid_Acc:23%  \tVal_kappa : 0.179 \n",
            "Epoch: 118 \tTraining Loss: -1.383 \tTrain_Accu: 40%  \tValid_Acc:19%  \tVal_kappa : 0.176 \n",
            "Epoch: 119 \tTraining Loss: -1.468 \tTrain_Accu: 48%  \tValid_Acc:23%  \tVal_kappa : 0.089 \n",
            "Epoch: 120 \tTraining Loss: -1.386 \tTrain_Accu: 47%  \tValid_Acc:27%  \tVal_kappa : 0.071 \n",
            "Epoch: 121 \tTraining Loss: -1.304 \tTrain_Accu: 44%  \tValid_Acc:26%  \tVal_kappa : 0.259 \n",
            "Epoch: 122 \tTraining Loss: -1.259 \tTrain_Accu: 43%  \tValid_Acc:16%  \tVal_kappa : 0.104 \n",
            "Epoch: 123 \tTraining Loss: -1.316 \tTrain_Accu: 40%  \tValid_Acc:23%  \tVal_kappa : 0.206 \n",
            "Epoch: 124 \tTraining Loss: -1.344 \tTrain_Accu: 46%  \tValid_Acc:27%  \tVal_kappa : 0.040 \n",
            "Epoch: 125 \tTraining Loss: -1.277 \tTrain_Accu: 45%  \tValid_Acc:21%  \tVal_kappa : 0.116 \n",
            "Epoch: 126 \tTraining Loss: -1.248 \tTrain_Accu: 43%  \tValid_Acc:21%  \tVal_kappa : 0.047 \n",
            "Epoch: 127 \tTraining Loss: -1.269 \tTrain_Accu: 44%  \tValid_Acc:31%  \tVal_kappa : 0.236 \n",
            "Epoch: 128 \tTraining Loss: -1.371 \tTrain_Accu: 45%  \tValid_Acc:20%  \tVal_kappa : 0.114 \n",
            "Epoch: 129 \tTraining Loss: -1.313 \tTrain_Accu: 42%  \tValid_Acc:23%  \tVal_kappa : 0.243 \n",
            "Epoch: 130 \tTraining Loss: -1.218 \tTrain_Accu: 45%  \tValid_Acc:27%  \tVal_kappa : 0.199 \n",
            "Epoch: 131 \tTraining Loss: -1.217 \tTrain_Accu: 42%  \tValid_Acc:27%  \tVal_kappa : -0.012 \n",
            "Epoch: 132 \tTraining Loss: -1.470 \tTrain_Accu: 46%  \tValid_Acc:21%  \tVal_kappa : 0.193 \n",
            "Epoch: 133 \tTraining Loss: -1.421 \tTrain_Accu: 49%  \tValid_Acc:27%  \tVal_kappa : 0.148 \n",
            "Epoch: 134 \tTraining Loss: -1.277 \tTrain_Accu: 43%  \tValid_Acc:21%  \tVal_kappa : 0.007 \n",
            "Epoch: 135 \tTraining Loss: -1.374 \tTrain_Accu: 45%  \tValid_Acc:30%  \tVal_kappa : 0.188 \n",
            "Epoch: 136 \tTraining Loss: -1.157 \tTrain_Accu: 39%  \tValid_Acc:26%  \tVal_kappa : 0.099 \n",
            "Epoch: 137 \tTraining Loss: -1.370 \tTrain_Accu: 45%  \tValid_Acc:10%  \tVal_kappa : 0.013 \n",
            "Epoch: 138 \tTraining Loss: -1.421 \tTrain_Accu: 46%  \tValid_Acc:17%  \tVal_kappa : 0.089 \n",
            "Epoch: 139 \tTraining Loss: -1.468 \tTrain_Accu: 47%  \tValid_Acc:23%  \tVal_kappa : 0.044 \n",
            "Epoch: 140 \tTraining Loss: -1.297 \tTrain_Accu: 40%  \tValid_Acc:19%  \tVal_kappa : 0.208 \n",
            "Epoch: 141 \tTraining Loss: -1.472 \tTrain_Accu: 47%  \tValid_Acc:23%  \tVal_kappa : 0.099 \n",
            "Epoch: 142 \tTraining Loss: -1.260 \tTrain_Accu: 45%  \tValid_Acc:27%  \tVal_kappa : 0.183 \n",
            "Epoch: 143 \tTraining Loss: -1.407 \tTrain_Accu: 43%  \tValid_Acc:20%  \tVal_kappa : 0.072 \n",
            "Epoch: 144 \tTraining Loss: -1.559 \tTrain_Accu: 48%  \tValid_Acc:20%  \tVal_kappa : 0.179 \n",
            "Epoch: 145 \tTraining Loss: -1.437 \tTrain_Accu: 48%  \tValid_Acc:24%  \tVal_kappa : 0.062 \n",
            "Epoch: 146 \tTraining Loss: -1.367 \tTrain_Accu: 43%  \tValid_Acc:17%  \tVal_kappa : 0.054 \n",
            "Epoch: 147 \tTraining Loss: -1.335 \tTrain_Accu: 44%  \tValid_Acc:17%  \tVal_kappa : -0.019 \n",
            "Epoch: 148 \tTraining Loss: -1.365 \tTrain_Accu: 44%  \tValid_Acc:19%  \tVal_kappa : 0.127 \n",
            "Epoch: 149 \tTraining Loss: -1.490 \tTrain_Accu: 50%  \tValid_Acc:23%  \tVal_kappa : 0.268 \n",
            "Epoch: 150 \tTraining Loss: -1.452 \tTrain_Accu: 46%  \tValid_Acc:26%  \tVal_kappa : 0.230 \n",
            "Epoch: 151 \tTraining Loss: -1.555 \tTrain_Accu: 50%  \tValid_Acc:20%  \tVal_kappa : -0.027 \n",
            "Epoch: 152 \tTraining Loss: -1.474 \tTrain_Accu: 51%  \tValid_Acc:19%  \tVal_kappa : 0.000 \n",
            "Epoch: 153 \tTraining Loss: -1.443 \tTrain_Accu: 49%  \tValid_Acc:19%  \tVal_kappa : 0.052 \n",
            "Epoch: 154 \tTraining Loss: -1.405 \tTrain_Accu: 49%  \tValid_Acc:19%  \tVal_kappa : 0.045 \n",
            "Epoch: 155 \tTraining Loss: -1.241 \tTrain_Accu: 42%  \tValid_Acc:20%  \tVal_kappa : 0.180 \n",
            "Epoch: 156 \tTraining Loss: -1.529 \tTrain_Accu: 48%  \tValid_Acc:23%  \tVal_kappa : 0.088 \n",
            "Epoch: 157 \tTraining Loss: -1.303 \tTrain_Accu: 45%  \tValid_Acc:13%  \tVal_kappa : 0.076 \n",
            "Epoch: 158 \tTraining Loss: -1.346 \tTrain_Accu: 43%  \tValid_Acc:30%  \tVal_kappa : 0.250 \n",
            "Epoch: 159 \tTraining Loss: -1.461 \tTrain_Accu: 47%  \tValid_Acc:30%  \tVal_kappa : 0.235 \n",
            "Epoch: 160 \tTraining Loss: -1.495 \tTrain_Accu: 46%  \tValid_Acc:31%  \tVal_kappa : 0.128 \n",
            "Epoch: 161 \tTraining Loss: -1.445 \tTrain_Accu: 46%  \tValid_Acc:29%  \tVal_kappa : 0.026 \n",
            "Epoch: 162 \tTraining Loss: -1.483 \tTrain_Accu: 50%  \tValid_Acc:23%  \tVal_kappa : 0.253 \n",
            "Epoch: 163 \tTraining Loss: -1.588 \tTrain_Accu: 51%  \tValid_Acc:17%  \tVal_kappa : 0.000 \n",
            "Epoch: 164 \tTraining Loss: -1.417 \tTrain_Accu: 49%  \tValid_Acc:19%  \tVal_kappa : 0.070 \n",
            "Epoch: 165 \tTraining Loss: -1.408 \tTrain_Accu: 47%  \tValid_Acc:17%  \tVal_kappa : 0.132 \n",
            "Epoch: 166 \tTraining Loss: -1.409 \tTrain_Accu: 42%  \tValid_Acc:27%  \tVal_kappa : -0.026 \n",
            "Epoch: 167 \tTraining Loss: -1.445 \tTrain_Accu: 44%  \tValid_Acc:14%  \tVal_kappa : -0.020 \n",
            "Epoch: 168 \tTraining Loss: -1.434 \tTrain_Accu: 52%  \tValid_Acc:31%  \tVal_kappa : 0.132 \n",
            "Epoch: 169 \tTraining Loss: -1.345 \tTrain_Accu: 45%  \tValid_Acc:23%  \tVal_kappa : 0.128 \n",
            "Epoch: 170 \tTraining Loss: -1.313 \tTrain_Accu: 45%  \tValid_Acc:21%  \tVal_kappa : 0.229 \n",
            "Epoch: 171 \tTraining Loss: -1.413 \tTrain_Accu: 49%  \tValid_Acc:14%  \tVal_kappa : -0.119 \n",
            "Epoch: 172 \tTraining Loss: -1.395 \tTrain_Accu: 50%  \tValid_Acc:20%  \tVal_kappa : 0.046 \n",
            "Epoch: 173 \tTraining Loss: -1.446 \tTrain_Accu: 48%  \tValid_Acc:29%  \tVal_kappa : 0.062 \n",
            "Epoch: 174 \tTraining Loss: -1.308 \tTrain_Accu: 45%  \tValid_Acc:16%  \tVal_kappa : 0.098 \n",
            "Epoch: 175 \tTraining Loss: -1.632 \tTrain_Accu: 50%  \tValid_Acc:23%  \tVal_kappa : 0.061 \n",
            "Epoch: 176 \tTraining Loss: -1.424 \tTrain_Accu: 50%  \tValid_Acc:11%  \tVal_kappa : 0.045 \n",
            "Epoch: 177 \tTraining Loss: -1.441 \tTrain_Accu: 51%  \tValid_Acc:17%  \tVal_kappa : 0.219 \n",
            "Epoch: 178 \tTraining Loss: -1.411 \tTrain_Accu: 47%  \tValid_Acc:21%  \tVal_kappa : 0.159 \n",
            "Epoch: 179 \tTraining Loss: -1.576 \tTrain_Accu: 48%  \tValid_Acc:19%  \tVal_kappa : 0.076 \n",
            "Epoch: 180 \tTraining Loss: -1.306 \tTrain_Accu: 41%  \tValid_Acc:17%  \tVal_kappa : 0.036 \n",
            "Epoch: 181 \tTraining Loss: -1.625 \tTrain_Accu: 46%  \tValid_Acc:17%  \tVal_kappa : 0.048 \n",
            "Epoch: 182 \tTraining Loss: -1.225 \tTrain_Accu: 42%  \tValid_Acc:14%  \tVal_kappa : -0.081 \n",
            "Epoch: 183 \tTraining Loss: -1.430 \tTrain_Accu: 45%  \tValid_Acc:17%  \tVal_kappa : 0.076 \n",
            "Epoch: 184 \tTraining Loss: -1.442 \tTrain_Accu: 48%  \tValid_Acc:24%  \tVal_kappa : 0.156 \n",
            "Epoch: 185 \tTraining Loss: -1.500 \tTrain_Accu: 48%  \tValid_Acc:14%  \tVal_kappa : 0.032 \n",
            "Epoch: 186 \tTraining Loss: -1.568 \tTrain_Accu: 48%  \tValid_Acc:17%  \tVal_kappa : 0.071 \n",
            "Epoch: 187 \tTraining Loss: -1.287 \tTrain_Accu: 43%  \tValid_Acc:33%  \tVal_kappa : 0.080 \n",
            "Epoch: 188 \tTraining Loss: -1.354 \tTrain_Accu: 48%  \tValid_Acc:24%  \tVal_kappa : 0.094 \n",
            "Epoch: 189 \tTraining Loss: -1.424 \tTrain_Accu: 48%  \tValid_Acc:19%  \tVal_kappa : 0.073 \n",
            "Epoch: 190 \tTraining Loss: -1.328 \tTrain_Accu: 48%  \tValid_Acc:23%  \tVal_kappa : -0.006 \n",
            "Epoch: 191 \tTraining Loss: -1.527 \tTrain_Accu: 51%  \tValid_Acc:16%  \tVal_kappa : -0.034 \n",
            "Epoch: 192 \tTraining Loss: -1.501 \tTrain_Accu: 45%  \tValid_Acc:20%  \tVal_kappa : -0.061 \n",
            "Epoch: 193 \tTraining Loss: -1.390 \tTrain_Accu: 49%  \tValid_Acc:16%  \tVal_kappa : 0.042 \n",
            "Epoch: 194 \tTraining Loss: -1.496 \tTrain_Accu: 46%  \tValid_Acc:20%  \tVal_kappa : -0.013 \n",
            "Epoch: 195 \tTraining Loss: -1.432 \tTrain_Accu: 48%  \tValid_Acc:30%  \tVal_kappa : 0.102 \n",
            "Epoch: 196 \tTraining Loss: -1.378 \tTrain_Accu: 50%  \tValid_Acc:17%  \tVal_kappa : 0.091 \n",
            "Epoch: 197 \tTraining Loss: -1.445 \tTrain_Accu: 51%  \tValid_Acc:24%  \tVal_kappa : 0.197 \n",
            "Epoch: 198 \tTraining Loss: -1.443 \tTrain_Accu: 50%  \tValid_Acc:13%  \tVal_kappa : 0.045 \n",
            "Epoch: 199 \tTraining Loss: -1.417 \tTrain_Accu: 49%  \tValid_Acc:21%  \tVal_kappa : 0.040 \n",
            "Epoch: 200 \tTraining Loss: -1.515 \tTrain_Accu: 51%  \tValid_Acc:23%  \tVal_kappa : 0.075 \n",
            "Epoch: 201 \tTraining Loss: -1.379 \tTrain_Accu: 48%  \tValid_Acc:20%  \tVal_kappa : 0.163 \n",
            "Epoch: 202 \tTraining Loss: -1.227 \tTrain_Accu: 49%  \tValid_Acc:23%  \tVal_kappa : -0.006 \n",
            "Epoch: 203 \tTraining Loss: -1.326 \tTrain_Accu: 42%  \tValid_Acc:20%  \tVal_kappa : 0.110 \n",
            "Epoch: 204 \tTraining Loss: -1.456 \tTrain_Accu: 47%  \tValid_Acc:27%  \tVal_kappa : 0.051 \n",
            "Epoch: 205 \tTraining Loss: -1.353 \tTrain_Accu: 46%  \tValid_Acc:27%  \tVal_kappa : 0.322 \n",
            "Epoch: 206 \tTraining Loss: -1.436 \tTrain_Accu: 49%  \tValid_Acc:21%  \tVal_kappa : 0.187 \n",
            "Epoch: 207 \tTraining Loss: -1.448 \tTrain_Accu: 49%  \tValid_Acc:26%  \tVal_kappa : 0.148 \n",
            "Epoch: 208 \tTraining Loss: -1.469 \tTrain_Accu: 52%  \tValid_Acc:14%  \tVal_kappa : -0.071 \n",
            "Epoch: 209 \tTraining Loss: -1.511 \tTrain_Accu: 46%  \tValid_Acc:29%  \tVal_kappa : 0.007 \n",
            "Epoch: 210 \tTraining Loss: -1.346 \tTrain_Accu: 48%  \tValid_Acc:23%  \tVal_kappa : 0.112 \n",
            "Epoch: 211 \tTraining Loss: -1.412 \tTrain_Accu: 50%  \tValid_Acc:24%  \tVal_kappa : 0.196 \n",
            "Epoch: 212 \tTraining Loss: -1.584 \tTrain_Accu: 53%  \tValid_Acc:26%  \tVal_kappa : 0.186 \n",
            "Epoch: 213 \tTraining Loss: -1.448 \tTrain_Accu: 50%  \tValid_Acc:26%  \tVal_kappa : 0.107 \n",
            "Epoch: 214 \tTraining Loss: -1.327 \tTrain_Accu: 49%  \tValid_Acc:29%  \tVal_kappa : 0.152 \n",
            "Epoch: 215 \tTraining Loss: -1.406 \tTrain_Accu: 49%  \tValid_Acc:20%  \tVal_kappa : 0.123 \n",
            "Epoch: 216 \tTraining Loss: -1.535 \tTrain_Accu: 46%  \tValid_Acc:21%  \tVal_kappa : 0.241 \n",
            "Epoch: 217 \tTraining Loss: -1.316 \tTrain_Accu: 46%  \tValid_Acc:21%  \tVal_kappa : 0.194 \n",
            "Epoch: 218 \tTraining Loss: -1.456 \tTrain_Accu: 49%  \tValid_Acc:23%  \tVal_kappa : 0.081 \n",
            "Epoch: 219 \tTraining Loss: -1.402 \tTrain_Accu: 50%  \tValid_Acc:21%  \tVal_kappa : 0.232 \n",
            "Epoch: 220 \tTraining Loss: -1.467 \tTrain_Accu: 50%  \tValid_Acc:23%  \tVal_kappa : -0.012 \n",
            "Epoch: 221 \tTraining Loss: -1.505 \tTrain_Accu: 50%  \tValid_Acc:23%  \tVal_kappa : 0.019 \n",
            "Epoch: 222 \tTraining Loss: -1.395 \tTrain_Accu: 50%  \tValid_Acc:26%  \tVal_kappa : 0.079 \n",
            "Epoch: 223 \tTraining Loss: -1.483 \tTrain_Accu: 49%  \tValid_Acc:23%  \tVal_kappa : 0.153 \n",
            "Epoch: 224 \tTraining Loss: -1.355 \tTrain_Accu: 53%  \tValid_Acc:24%  \tVal_kappa : 0.161 \n",
            "Epoch: 225 \tTraining Loss: -1.301 \tTrain_Accu: 45%  \tValid_Acc:24%  \tVal_kappa : 0.288 \n",
            "Epoch: 226 \tTraining Loss: -1.554 \tTrain_Accu: 54%  \tValid_Acc:24%  \tVal_kappa : 0.141 \n",
            "Epoch: 227 \tTraining Loss: -1.239 \tTrain_Accu: 44%  \tValid_Acc:19%  \tVal_kappa : -0.006 \n",
            "Epoch: 228 \tTraining Loss: -1.392 \tTrain_Accu: 50%  \tValid_Acc:11%  \tVal_kappa : -0.013 \n",
            "Epoch: 229 \tTraining Loss: -1.311 \tTrain_Accu: 44%  \tValid_Acc:21%  \tVal_kappa : 0.267 \n",
            "Epoch: 230 \tTraining Loss: -1.427 \tTrain_Accu: 53%  \tValid_Acc:21%  \tVal_kappa : 0.044 \n",
            "Epoch: 231 \tTraining Loss: -1.514 \tTrain_Accu: 50%  \tValid_Acc:13%  \tVal_kappa : 0.040 \n",
            "Epoch: 232 \tTraining Loss: -1.534 \tTrain_Accu: 50%  \tValid_Acc:24%  \tVal_kappa : 0.065 \n",
            "Epoch: 233 \tTraining Loss: -1.379 \tTrain_Accu: 52%  \tValid_Acc:19%  \tVal_kappa : 0.045 \n",
            "Epoch: 234 \tTraining Loss: -1.392 \tTrain_Accu: 50%  \tValid_Acc:27%  \tVal_kappa : 0.054 \n",
            "Epoch: 235 \tTraining Loss: -1.453 \tTrain_Accu: 49%  \tValid_Acc:20%  \tVal_kappa : 0.047 \n",
            "Epoch: 236 \tTraining Loss: -1.440 \tTrain_Accu: 46%  \tValid_Acc:27%  \tVal_kappa : 0.061 \n",
            "Epoch: 237 \tTraining Loss: -1.474 \tTrain_Accu: 52%  \tValid_Acc:21%  \tVal_kappa : 0.162 \n",
            "Epoch: 238 \tTraining Loss: -1.497 \tTrain_Accu: 49%  \tValid_Acc:24%  \tVal_kappa : 0.219 \n",
            "Epoch: 239 \tTraining Loss: -1.537 \tTrain_Accu: 49%  \tValid_Acc:21%  \tVal_kappa : 0.061 \n",
            "Epoch: 240 \tTraining Loss: -1.438 \tTrain_Accu: 48%  \tValid_Acc:26%  \tVal_kappa : -0.048 \n",
            "Epoch: 241 \tTraining Loss: -1.428 \tTrain_Accu: 52%  \tValid_Acc:17%  \tVal_kappa : -0.006 \n",
            "Epoch: 242 \tTraining Loss: -1.466 \tTrain_Accu: 50%  \tValid_Acc:17%  \tVal_kappa : -0.007 \n",
            "Epoch: 243 \tTraining Loss: -1.521 \tTrain_Accu: 51%  \tValid_Acc:13%  \tVal_kappa : 0.058 \n",
            "Epoch: 244 \tTraining Loss: -1.458 \tTrain_Accu: 49%  \tValid_Acc:21%  \tVal_kappa : 0.038 \n",
            "Epoch: 245 \tTraining Loss: -1.491 \tTrain_Accu: 48%  \tValid_Acc:20%  \tVal_kappa : 0.014 \n",
            "Epoch: 246 \tTraining Loss: -1.537 \tTrain_Accu: 47%  \tValid_Acc:16%  \tVal_kappa : 0.071 \n",
            "Epoch: 247 \tTraining Loss: -1.363 \tTrain_Accu: 51%  \tValid_Acc:21%  \tVal_kappa : 0.176 \n",
            "Epoch: 248 \tTraining Loss: -1.517 \tTrain_Accu: 51%  \tValid_Acc:29%  \tVal_kappa : 0.141 \n",
            "Epoch: 249 \tTraining Loss: -1.541 \tTrain_Accu: 52%  \tValid_Acc:21%  \tVal_kappa : 0.007 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-28 00:09:27,204]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'lr': 0.0001}. Best is trial 0 with value: 0.0.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss: -1.547 \tTrain_Accu: 53%  \tValid_Acc:20%  \tVal_kappa : 0.033 \n",
            "Epoch: 1 \tTraining Loss: -0.064 \tTrain_Accu: 21%  \tValid_Acc:24%  \tVal_kappa : -0.133 \n",
            "Epoch: 2 \tTraining Loss:  0.002 \tTrain_Accu: 19%  \tValid_Acc:26%  \tVal_kappa : -0.012 \n",
            "Epoch: 3 \tTraining Loss: -0.128 \tTrain_Accu: 20%  \tValid_Acc:17%  \tVal_kappa : -0.037 \n",
            "Epoch: 4 \tTraining Loss: -0.066 \tTrain_Accu: 18%  \tValid_Acc:20%  \tVal_kappa : -0.030 \n",
            "Epoch: 5 \tTraining Loss: -0.113 \tTrain_Accu: 26%  \tValid_Acc:24%  \tVal_kappa : 0.096 \n",
            "Epoch: 6 \tTraining Loss: -0.109 \tTrain_Accu: 23%  \tValid_Acc:20%  \tVal_kappa : 0.090 \n",
            "Epoch: 7 \tTraining Loss: -0.131 \tTrain_Accu: 22%  \tValid_Acc:24%  \tVal_kappa : 0.082 \n",
            "Epoch: 8 \tTraining Loss: -0.202 \tTrain_Accu: 22%  \tValid_Acc:29%  \tVal_kappa : 0.048 \n",
            "Epoch: 9 \tTraining Loss: -0.160 \tTrain_Accu: 20%  \tValid_Acc:19%  \tVal_kappa : -0.110 \n",
            "Epoch: 10 \tTraining Loss: -0.123 \tTrain_Accu: 21%  \tValid_Acc:20%  \tVal_kappa : 0.056 \n",
            "Epoch: 11 \tTraining Loss: -0.126 \tTrain_Accu: 20%  \tValid_Acc:26%  \tVal_kappa : 0.052 \n",
            "Epoch: 12 \tTraining Loss: -0.135 \tTrain_Accu: 23%  \tValid_Acc:33%  \tVal_kappa : 0.150 \n",
            "Epoch: 13 \tTraining Loss: -0.102 \tTrain_Accu: 20%  \tValid_Acc:17%  \tVal_kappa : 0.020 \n",
            "Epoch: 14 \tTraining Loss: -0.097 \tTrain_Accu: 21%  \tValid_Acc:16%  \tVal_kappa : 0.053 \n",
            "Epoch: 15 \tTraining Loss: -0.163 \tTrain_Accu: 25%  \tValid_Acc:20%  \tVal_kappa : 0.054 \n",
            "Epoch: 16 \tTraining Loss: -0.190 \tTrain_Accu: 27%  \tValid_Acc:23%  \tVal_kappa : 0.034 \n",
            "Epoch: 17 \tTraining Loss: -0.175 \tTrain_Accu: 24%  \tValid_Acc:19%  \tVal_kappa : -0.020 \n",
            "Epoch: 18 \tTraining Loss: -0.143 \tTrain_Accu: 22%  \tValid_Acc:20%  \tVal_kappa : -0.021 \n",
            "Epoch: 19 \tTraining Loss: -0.144 \tTrain_Accu: 22%  \tValid_Acc:20%  \tVal_kappa : 0.120 \n",
            "Epoch: 20 \tTraining Loss: -0.195 \tTrain_Accu: 26%  \tValid_Acc:20%  \tVal_kappa : -0.045 \n",
            "Epoch: 21 \tTraining Loss: -0.165 \tTrain_Accu: 23%  \tValid_Acc:17%  \tVal_kappa : 0.143 \n",
            "Epoch: 22 \tTraining Loss: -0.219 \tTrain_Accu: 22%  \tValid_Acc:17%  \tVal_kappa : -0.060 \n",
            "Epoch: 23 \tTraining Loss: -0.182 \tTrain_Accu: 24%  \tValid_Acc:20%  \tVal_kappa : -0.015 \n",
            "Epoch: 24 \tTraining Loss: -0.255 \tTrain_Accu: 21%  \tValid_Acc:30%  \tVal_kappa : 0.074 \n",
            "Epoch: 25 \tTraining Loss: -0.225 \tTrain_Accu: 23%  \tValid_Acc:16%  \tVal_kappa : -0.081 \n",
            "Epoch: 26 \tTraining Loss: -0.206 \tTrain_Accu: 22%  \tValid_Acc:20%  \tVal_kappa : 0.030 \n",
            "Epoch: 27 \tTraining Loss: -0.228 \tTrain_Accu: 21%  \tValid_Acc:29%  \tVal_kappa : 0.185 \n",
            "Epoch: 28 \tTraining Loss: -0.187 \tTrain_Accu: 23%  \tValid_Acc:23%  \tVal_kappa : 0.091 \n",
            "Epoch: 29 \tTraining Loss: -0.142 \tTrain_Accu: 20%  \tValid_Acc:27%  \tVal_kappa : -0.108 \n",
            "Epoch: 30 \tTraining Loss: -0.170 \tTrain_Accu: 22%  \tValid_Acc:27%  \tVal_kappa : 0.008 \n",
            "Epoch: 31 \tTraining Loss: -0.292 \tTrain_Accu: 20%  \tValid_Acc:21%  \tVal_kappa : 0.008 \n",
            "Epoch: 32 \tTraining Loss: -0.209 \tTrain_Accu: 24%  \tValid_Acc:16%  \tVal_kappa : -0.193 \n",
            "Epoch: 33 \tTraining Loss: -0.285 \tTrain_Accu: 24%  \tValid_Acc:24%  \tVal_kappa : -0.130 \n",
            "Epoch: 34 \tTraining Loss: -0.359 \tTrain_Accu: 23%  \tValid_Acc:24%  \tVal_kappa : 0.258 \n",
            "Epoch: 35 \tTraining Loss: -0.300 \tTrain_Accu: 26%  \tValid_Acc:26%  \tVal_kappa : 0.217 \n",
            "Epoch: 36 \tTraining Loss: -0.305 \tTrain_Accu: 23%  \tValid_Acc:39%  \tVal_kappa : 0.299 \n",
            "Epoch: 37 \tTraining Loss: -0.403 \tTrain_Accu: 26%  \tValid_Acc:23%  \tVal_kappa : 0.116 \n",
            "Epoch: 38 \tTraining Loss: -0.346 \tTrain_Accu: 23%  \tValid_Acc:26%  \tVal_kappa : 0.143 \n",
            "Epoch: 39 \tTraining Loss: -0.422 \tTrain_Accu: 27%  \tValid_Acc:24%  \tVal_kappa : 0.124 \n",
            "Epoch: 40 \tTraining Loss: -0.250 \tTrain_Accu: 21%  \tValid_Acc:26%  \tVal_kappa : 0.053 \n",
            "Epoch: 41 \tTraining Loss: -0.323 \tTrain_Accu: 25%  \tValid_Acc:30%  \tVal_kappa : 0.231 \n",
            "Epoch: 42 \tTraining Loss: -0.389 \tTrain_Accu: 26%  \tValid_Acc:36%  \tVal_kappa : 0.278 \n",
            "Epoch: 43 \tTraining Loss: -0.383 \tTrain_Accu: 22%  \tValid_Acc:14%  \tVal_kappa : 0.038 \n",
            "Epoch: 44 \tTraining Loss: -0.390 \tTrain_Accu: 26%  \tValid_Acc:24%  \tVal_kappa : 0.056 \n",
            "Epoch: 45 \tTraining Loss: -0.333 \tTrain_Accu: 25%  \tValid_Acc:26%  \tVal_kappa : 0.143 \n",
            "Epoch: 46 \tTraining Loss: -0.367 \tTrain_Accu: 28%  \tValid_Acc:27%  \tVal_kappa : 0.352 \n",
            "Epoch: 47 \tTraining Loss: -0.465 \tTrain_Accu: 30%  \tValid_Acc:23%  \tVal_kappa : 0.255 \n",
            "Epoch: 48 \tTraining Loss: -0.382 \tTrain_Accu: 28%  \tValid_Acc:20%  \tVal_kappa : 0.006 \n",
            "Epoch: 49 \tTraining Loss: -0.270 \tTrain_Accu: 26%  \tValid_Acc:23%  \tVal_kappa : -0.026 \n",
            "Epoch: 50 \tTraining Loss: -0.347 \tTrain_Accu: 28%  \tValid_Acc:19%  \tVal_kappa : 0.023 \n",
            "Epoch: 51 \tTraining Loss: -0.273 \tTrain_Accu: 25%  \tValid_Acc:20%  \tVal_kappa : 0.073 \n",
            "Epoch: 52 \tTraining Loss: -0.238 \tTrain_Accu: 26%  \tValid_Acc:31%  \tVal_kappa : 0.145 \n",
            "Epoch: 53 \tTraining Loss: -0.236 \tTrain_Accu: 24%  \tValid_Acc:23%  \tVal_kappa : 0.000 \n",
            "Epoch: 54 \tTraining Loss: -0.300 \tTrain_Accu: 24%  \tValid_Acc:21%  \tVal_kappa : 0.074 \n",
            "Epoch: 55 \tTraining Loss: -0.378 \tTrain_Accu: 25%  \tValid_Acc:27%  \tVal_kappa : 0.179 \n",
            "Epoch: 56 \tTraining Loss: -0.234 \tTrain_Accu: 23%  \tValid_Acc:30%  \tVal_kappa : 0.023 \n",
            "Epoch: 57 \tTraining Loss: -0.259 \tTrain_Accu: 23%  \tValid_Acc:21%  \tVal_kappa : 0.006 \n",
            "Epoch: 58 \tTraining Loss: -0.296 \tTrain_Accu: 26%  \tValid_Acc:34%  \tVal_kappa : 0.203 \n",
            "Epoch: 59 \tTraining Loss: -0.327 \tTrain_Accu: 28%  \tValid_Acc:26%  \tVal_kappa : 0.133 \n",
            "Epoch: 60 \tTraining Loss: -0.301 \tTrain_Accu: 28%  \tValid_Acc:14%  \tVal_kappa : -0.024 \n",
            "Epoch: 61 \tTraining Loss: -0.456 \tTrain_Accu: 29%  \tValid_Acc:27%  \tVal_kappa : 0.123 \n",
            "Epoch: 62 \tTraining Loss: -0.375 \tTrain_Accu: 30%  \tValid_Acc:26%  \tVal_kappa : 0.221 \n",
            "Epoch: 63 \tTraining Loss: -0.418 \tTrain_Accu: 27%  \tValid_Acc:24%  \tVal_kappa : 0.103 \n",
            "Epoch: 64 \tTraining Loss: -0.436 \tTrain_Accu: 26%  \tValid_Acc:23%  \tVal_kappa : 0.060 \n",
            "Epoch: 65 \tTraining Loss: -0.282 \tTrain_Accu: 24%  \tValid_Acc:29%  \tVal_kappa : 0.086 \n",
            "Epoch: 66 \tTraining Loss: -0.350 \tTrain_Accu: 28%  \tValid_Acc:19%  \tVal_kappa : 0.086 \n",
            "Epoch: 67 \tTraining Loss: -0.430 \tTrain_Accu: 29%  \tValid_Acc:24%  \tVal_kappa : 0.184 \n",
            "Epoch: 68 \tTraining Loss: -0.459 \tTrain_Accu: 24%  \tValid_Acc:33%  \tVal_kappa : 0.151 \n",
            "Epoch: 69 \tTraining Loss: -0.450 \tTrain_Accu: 28%  \tValid_Acc:26%  \tVal_kappa : 0.191 \n",
            "Epoch: 70 \tTraining Loss: -0.531 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.124 \n",
            "Epoch: 71 \tTraining Loss: -0.535 \tTrain_Accu: 27%  \tValid_Acc:23%  \tVal_kappa : 0.034 \n",
            "Epoch: 72 \tTraining Loss: -0.465 \tTrain_Accu: 27%  \tValid_Acc:23%  \tVal_kappa : 0.093 \n",
            "Epoch: 73 \tTraining Loss: -0.375 \tTrain_Accu: 22%  \tValid_Acc:31%  \tVal_kappa : 0.128 \n",
            "Epoch: 74 \tTraining Loss: -0.584 \tTrain_Accu: 28%  \tValid_Acc:30%  \tVal_kappa : 0.120 \n",
            "Epoch: 75 \tTraining Loss: -0.463 \tTrain_Accu: 26%  \tValid_Acc:27%  \tVal_kappa : 0.172 \n",
            "Epoch: 76 \tTraining Loss: -0.530 \tTrain_Accu: 29%  \tValid_Acc:33%  \tVal_kappa : 0.255 \n",
            "Epoch: 77 \tTraining Loss: -0.500 \tTrain_Accu: 30%  \tValid_Acc:24%  \tVal_kappa : 0.035 \n",
            "Epoch: 78 \tTraining Loss: -0.270 \tTrain_Accu: 25%  \tValid_Acc:27%  \tVal_kappa : 0.164 \n",
            "Epoch: 79 \tTraining Loss: -0.447 \tTrain_Accu: 27%  \tValid_Acc:23%  \tVal_kappa : 0.148 \n",
            "Epoch: 80 \tTraining Loss: -0.457 \tTrain_Accu: 26%  \tValid_Acc:23%  \tVal_kappa : 0.011 \n",
            "Epoch: 81 \tTraining Loss: -0.231 \tTrain_Accu: 24%  \tValid_Acc:21%  \tVal_kappa : 0.134 \n",
            "Epoch: 82 \tTraining Loss: -0.377 \tTrain_Accu: 24%  \tValid_Acc:27%  \tVal_kappa : -0.006 \n",
            "Epoch: 83 \tTraining Loss: -0.415 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : -0.037 \n",
            "Epoch: 84 \tTraining Loss: -0.406 \tTrain_Accu: 28%  \tValid_Acc:14%  \tVal_kappa : -0.036 \n",
            "Epoch: 85 \tTraining Loss: -0.485 \tTrain_Accu: 30%  \tValid_Acc:27%  \tVal_kappa : 0.132 \n",
            "Epoch: 86 \tTraining Loss: -0.555 \tTrain_Accu: 31%  \tValid_Acc:26%  \tVal_kappa : 0.114 \n",
            "Epoch: 87 \tTraining Loss: -0.462 \tTrain_Accu: 30%  \tValid_Acc:19%  \tVal_kappa : 0.175 \n",
            "Epoch: 88 \tTraining Loss: -0.539 \tTrain_Accu: 26%  \tValid_Acc:33%  \tVal_kappa : 0.163 \n",
            "Epoch: 89 \tTraining Loss: -0.451 \tTrain_Accu: 27%  \tValid_Acc:16%  \tVal_kappa : 0.047 \n",
            "Epoch: 90 \tTraining Loss: -0.525 \tTrain_Accu: 26%  \tValid_Acc:29%  \tVal_kappa : 0.171 \n",
            "Epoch: 91 \tTraining Loss: -0.408 \tTrain_Accu: 25%  \tValid_Acc:16%  \tVal_kappa : 0.000 \n",
            "Epoch: 92 \tTraining Loss: -0.566 \tTrain_Accu: 27%  \tValid_Acc:21%  \tVal_kappa : 0.130 \n",
            "Epoch: 93 \tTraining Loss: -0.509 \tTrain_Accu: 32%  \tValid_Acc:27%  \tVal_kappa : 0.115 \n",
            "Epoch: 94 \tTraining Loss: -0.477 \tTrain_Accu: 27%  \tValid_Acc:16%  \tVal_kappa : -0.032 \n",
            "Epoch: 95 \tTraining Loss: -0.462 \tTrain_Accu: 27%  \tValid_Acc:19%  \tVal_kappa : 0.006 \n",
            "Epoch: 96 \tTraining Loss: -0.449 \tTrain_Accu: 28%  \tValid_Acc:21%  \tVal_kappa : 0.069 \n",
            "Epoch: 97 \tTraining Loss: -0.443 \tTrain_Accu: 29%  \tValid_Acc:24%  \tVal_kappa : 0.158 \n",
            "Epoch: 98 \tTraining Loss: -0.400 \tTrain_Accu: 27%  \tValid_Acc:24%  \tVal_kappa : 0.105 \n",
            "Epoch: 99 \tTraining Loss: -0.467 \tTrain_Accu: 32%  \tValid_Acc:27%  \tVal_kappa : 0.160 \n",
            "Epoch: 100 \tTraining Loss: -0.523 \tTrain_Accu: 29%  \tValid_Acc:27%  \tVal_kappa : 0.059 \n",
            "Epoch: 101 \tTraining Loss: -0.555 \tTrain_Accu: 26%  \tValid_Acc:23%  \tVal_kappa : 0.135 \n",
            "Epoch: 102 \tTraining Loss: -0.517 \tTrain_Accu: 25%  \tValid_Acc:16%  \tVal_kappa : -0.045 \n",
            "Epoch: 103 \tTraining Loss: -0.559 \tTrain_Accu: 30%  \tValid_Acc:26%  \tVal_kappa : 0.097 \n",
            "Epoch: 104 \tTraining Loss: -0.559 \tTrain_Accu: 30%  \tValid_Acc:27%  \tVal_kappa : 0.000 \n",
            "Epoch: 105 \tTraining Loss: -0.533 \tTrain_Accu: 30%  \tValid_Acc:16%  \tVal_kappa : 0.006 \n",
            "Epoch: 106 \tTraining Loss: -0.380 \tTrain_Accu: 27%  \tValid_Acc:23%  \tVal_kappa : 0.012 \n",
            "Epoch: 107 \tTraining Loss: -0.571 \tTrain_Accu: 29%  \tValid_Acc:19%  \tVal_kappa : 0.174 \n",
            "Epoch: 108 \tTraining Loss: -0.565 \tTrain_Accu: 27%  \tValid_Acc:23%  \tVal_kappa : 0.006 \n",
            "Epoch: 109 \tTraining Loss: -0.432 \tTrain_Accu: 26%  \tValid_Acc:29%  \tVal_kappa : 0.018 \n",
            "Epoch: 110 \tTraining Loss: -0.649 \tTrain_Accu: 31%  \tValid_Acc:31%  \tVal_kappa : 0.229 \n",
            "Epoch: 111 \tTraining Loss: -0.523 \tTrain_Accu: 27%  \tValid_Acc:27%  \tVal_kappa : 0.131 \n",
            "Epoch: 112 \tTraining Loss: -0.575 \tTrain_Accu: 30%  \tValid_Acc:26%  \tVal_kappa : 0.201 \n",
            "Epoch: 113 \tTraining Loss: -0.541 \tTrain_Accu: 26%  \tValid_Acc:31%  \tVal_kappa : 0.245 \n",
            "Epoch: 114 \tTraining Loss: -0.494 \tTrain_Accu: 27%  \tValid_Acc:27%  \tVal_kappa : 0.181 \n",
            "Epoch: 115 \tTraining Loss: -0.566 \tTrain_Accu: 26%  \tValid_Acc:30%  \tVal_kappa : 0.289 \n",
            "Epoch: 116 \tTraining Loss: -0.585 \tTrain_Accu: 30%  \tValid_Acc:23%  \tVal_kappa : 0.168 \n",
            "Epoch: 117 \tTraining Loss: -0.444 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : 0.048 \n",
            "Epoch: 118 \tTraining Loss: -0.515 \tTrain_Accu: 22%  \tValid_Acc:17%  \tVal_kappa : 0.018 \n",
            "Epoch: 119 \tTraining Loss: -0.512 \tTrain_Accu: 29%  \tValid_Acc:16%  \tVal_kappa : 0.066 \n",
            "Epoch: 120 \tTraining Loss: -0.559 \tTrain_Accu: 30%  \tValid_Acc:29%  \tVal_kappa : 0.000 \n",
            "Epoch: 121 \tTraining Loss: -0.463 \tTrain_Accu: 25%  \tValid_Acc:26%  \tVal_kappa : 0.124 \n",
            "Epoch: 122 \tTraining Loss: -0.553 \tTrain_Accu: 26%  \tValid_Acc:20%  \tVal_kappa : 0.081 \n",
            "Epoch: 123 \tTraining Loss: -0.593 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.111 \n",
            "Epoch: 124 \tTraining Loss: -0.550 \tTrain_Accu: 29%  \tValid_Acc:30%  \tVal_kappa : 0.059 \n",
            "Epoch: 125 \tTraining Loss: -0.473 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : 0.040 \n",
            "Epoch: 126 \tTraining Loss: -0.562 \tTrain_Accu: 30%  \tValid_Acc:19%  \tVal_kappa : -0.046 \n",
            "Epoch: 127 \tTraining Loss: -0.453 \tTrain_Accu: 26%  \tValid_Acc:27%  \tVal_kappa : 0.143 \n",
            "Epoch: 128 \tTraining Loss: -0.506 \tTrain_Accu: 28%  \tValid_Acc:19%  \tVal_kappa : 0.162 \n",
            "Epoch: 129 \tTraining Loss: -0.402 \tTrain_Accu: 28%  \tValid_Acc:29%  \tVal_kappa : 0.173 \n",
            "Epoch: 130 \tTraining Loss: -0.461 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.059 \n",
            "Epoch: 131 \tTraining Loss: -0.433 \tTrain_Accu: 23%  \tValid_Acc:34%  \tVal_kappa : 0.165 \n",
            "Epoch: 132 \tTraining Loss: -0.483 \tTrain_Accu: 28%  \tValid_Acc:21%  \tVal_kappa : 0.028 \n",
            "Epoch: 133 \tTraining Loss: -0.528 \tTrain_Accu: 31%  \tValid_Acc:24%  \tVal_kappa : 0.000 \n",
            "Epoch: 134 \tTraining Loss: -0.436 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.108 \n",
            "Epoch: 135 \tTraining Loss: -0.393 \tTrain_Accu: 29%  \tValid_Acc:21%  \tVal_kappa : 0.012 \n",
            "Epoch: 136 \tTraining Loss: -0.447 \tTrain_Accu: 24%  \tValid_Acc:21%  \tVal_kappa : 0.164 \n",
            "Epoch: 137 \tTraining Loss: -0.496 \tTrain_Accu: 27%  \tValid_Acc:16%  \tVal_kappa : -0.006 \n",
            "Epoch: 138 \tTraining Loss: -0.422 \tTrain_Accu: 26%  \tValid_Acc:24%  \tVal_kappa : 0.171 \n",
            "Epoch: 139 \tTraining Loss: -0.486 \tTrain_Accu: 29%  \tValid_Acc:29%  \tVal_kappa : 0.107 \n",
            "Epoch: 140 \tTraining Loss: -0.452 \tTrain_Accu: 26%  \tValid_Acc:29%  \tVal_kappa : 0.253 \n",
            "Epoch: 141 \tTraining Loss: -0.588 \tTrain_Accu: 29%  \tValid_Acc:24%  \tVal_kappa : 0.124 \n",
            "Epoch: 142 \tTraining Loss: -0.412 \tTrain_Accu: 27%  \tValid_Acc:21%  \tVal_kappa : 0.115 \n",
            "Epoch: 143 \tTraining Loss: -0.535 \tTrain_Accu: 28%  \tValid_Acc:17%  \tVal_kappa : 0.109 \n",
            "Epoch: 144 \tTraining Loss: -0.546 \tTrain_Accu: 30%  \tValid_Acc:20%  \tVal_kappa : 0.108 \n",
            "Epoch: 145 \tTraining Loss: -0.366 \tTrain_Accu: 25%  \tValid_Acc:14%  \tVal_kappa : 0.012 \n",
            "Epoch: 146 \tTraining Loss: -0.540 \tTrain_Accu: 28%  \tValid_Acc:26%  \tVal_kappa : 0.047 \n",
            "Epoch: 147 \tTraining Loss: -0.614 \tTrain_Accu: 29%  \tValid_Acc:20%  \tVal_kappa : 0.103 \n",
            "Epoch: 148 \tTraining Loss: -0.476 \tTrain_Accu: 30%  \tValid_Acc:24%  \tVal_kappa : 0.146 \n",
            "Epoch: 149 \tTraining Loss: -0.642 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.127 \n",
            "Epoch: 150 \tTraining Loss: -0.444 \tTrain_Accu: 30%  \tValid_Acc:19%  \tVal_kappa : 0.109 \n",
            "Epoch: 151 \tTraining Loss: -0.473 \tTrain_Accu: 30%  \tValid_Acc:19%  \tVal_kappa : 0.179 \n",
            "Epoch: 152 \tTraining Loss: -0.587 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.065 \n",
            "Epoch: 153 \tTraining Loss: -0.621 \tTrain_Accu: 28%  \tValid_Acc:20%  \tVal_kappa : 0.160 \n",
            "Epoch: 154 \tTraining Loss: -0.635 \tTrain_Accu: 32%  \tValid_Acc:23%  \tVal_kappa : 0.263 \n",
            "Epoch: 155 \tTraining Loss: -0.477 \tTrain_Accu: 27%  \tValid_Acc:29%  \tVal_kappa : 0.312 \n",
            "Epoch: 156 \tTraining Loss: -0.552 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : 0.032 \n",
            "Epoch: 157 \tTraining Loss: -0.454 \tTrain_Accu: 25%  \tValid_Acc:11%  \tVal_kappa : -0.007 \n",
            "Epoch: 158 \tTraining Loss: -0.510 \tTrain_Accu: 28%  \tValid_Acc:29%  \tVal_kappa : 0.173 \n",
            "Epoch: 159 \tTraining Loss: -0.559 \tTrain_Accu: 30%  \tValid_Acc:26%  \tVal_kappa : 0.268 \n",
            "Epoch: 160 \tTraining Loss: -0.537 \tTrain_Accu: 29%  \tValid_Acc:30%  \tVal_kappa : 0.254 \n",
            "Epoch: 161 \tTraining Loss: -0.577 \tTrain_Accu: 25%  \tValid_Acc:27%  \tVal_kappa : 0.099 \n",
            "Epoch: 162 \tTraining Loss: -0.570 \tTrain_Accu: 33%  \tValid_Acc:26%  \tVal_kappa : 0.213 \n",
            "Epoch: 163 \tTraining Loss: -0.507 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.111 \n",
            "Epoch: 164 \tTraining Loss: -0.557 \tTrain_Accu: 30%  \tValid_Acc:23%  \tVal_kappa : 0.249 \n",
            "Epoch: 165 \tTraining Loss: -0.552 \tTrain_Accu: 27%  \tValid_Acc:27%  \tVal_kappa : 0.193 \n",
            "Epoch: 166 \tTraining Loss: -0.463 \tTrain_Accu: 22%  \tValid_Acc:26%  \tVal_kappa : -0.027 \n",
            "Epoch: 167 \tTraining Loss: -0.551 \tTrain_Accu: 27%  \tValid_Acc:20%  \tVal_kappa : 0.153 \n",
            "Epoch: 168 \tTraining Loss: -0.475 \tTrain_Accu: 30%  \tValid_Acc:24%  \tVal_kappa : 0.066 \n",
            "Epoch: 169 \tTraining Loss: -0.536 \tTrain_Accu: 28%  \tValid_Acc:20%  \tVal_kappa : 0.146 \n",
            "Epoch: 170 \tTraining Loss: -0.456 \tTrain_Accu: 26%  \tValid_Acc:24%  \tVal_kappa : 0.207 \n",
            "Epoch: 171 \tTraining Loss: -0.549 \tTrain_Accu: 30%  \tValid_Acc:10%  \tVal_kappa : 0.006 \n",
            "Epoch: 172 \tTraining Loss: -0.525 \tTrain_Accu: 29%  \tValid_Acc:16%  \tVal_kappa : 0.014 \n",
            "Epoch: 173 \tTraining Loss: -0.461 \tTrain_Accu: 28%  \tValid_Acc:29%  \tVal_kappa : 0.086 \n",
            "Epoch: 174 \tTraining Loss: -0.459 \tTrain_Accu: 28%  \tValid_Acc:27%  \tVal_kappa : 0.276 \n",
            "Epoch: 175 \tTraining Loss: -0.644 \tTrain_Accu: 27%  \tValid_Acc:29%  \tVal_kappa : 0.205 \n",
            "Epoch: 176 \tTraining Loss: -0.514 \tTrain_Accu: 27%  \tValid_Acc:19%  \tVal_kappa : 0.091 \n",
            "Epoch: 177 \tTraining Loss: -0.633 \tTrain_Accu: 34%  \tValid_Acc:19%  \tVal_kappa : 0.178 \n",
            "Epoch: 178 \tTraining Loss: -0.575 \tTrain_Accu: 28%  \tValid_Acc:24%  \tVal_kappa : 0.134 \n",
            "Epoch: 179 \tTraining Loss: -0.668 \tTrain_Accu: 33%  \tValid_Acc:24%  \tVal_kappa : 0.105 \n",
            "Epoch: 180 \tTraining Loss: -0.515 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : 0.189 \n",
            "Epoch: 181 \tTraining Loss: -0.764 \tTrain_Accu: 29%  \tValid_Acc:21%  \tVal_kappa : 0.214 \n",
            "Epoch: 182 \tTraining Loss: -0.517 \tTrain_Accu: 28%  \tValid_Acc:16%  \tVal_kappa : 0.013 \n",
            "Epoch: 183 \tTraining Loss: -0.535 \tTrain_Accu: 26%  \tValid_Acc:20%  \tVal_kappa : 0.264 \n",
            "Epoch: 184 \tTraining Loss: -0.602 \tTrain_Accu: 28%  \tValid_Acc:23%  \tVal_kappa : 0.177 \n",
            "Epoch: 185 \tTraining Loss: -0.632 \tTrain_Accu: 29%  \tValid_Acc:16%  \tVal_kappa : 0.091 \n",
            "Epoch: 186 \tTraining Loss: -0.612 \tTrain_Accu: 26%  \tValid_Acc:21%  \tVal_kappa : 0.146 \n",
            "Epoch: 187 \tTraining Loss: -0.623 \tTrain_Accu: 27%  \tValid_Acc:29%  \tVal_kappa : 0.145 \n",
            "Epoch: 188 \tTraining Loss: -0.542 \tTrain_Accu: 27%  \tValid_Acc:23%  \tVal_kappa : 0.177 \n",
            "Epoch: 189 \tTraining Loss: -0.701 \tTrain_Accu: 34%  \tValid_Acc:19%  \tVal_kappa : 0.106 \n",
            "Epoch: 190 \tTraining Loss: -0.514 \tTrain_Accu: 29%  \tValid_Acc:14%  \tVal_kappa : -0.071 \n",
            "Epoch: 191 \tTraining Loss: -0.678 \tTrain_Accu: 31%  \tValid_Acc:20%  \tVal_kappa : 0.046 \n",
            "Epoch: 192 \tTraining Loss: -0.596 \tTrain_Accu: 29%  \tValid_Acc:23%  \tVal_kappa : 0.000 \n",
            "Epoch: 193 \tTraining Loss: -0.690 \tTrain_Accu: 31%  \tValid_Acc:21%  \tVal_kappa : 0.026 \n",
            "Epoch: 194 \tTraining Loss: -0.662 \tTrain_Accu: 27%  \tValid_Acc:27%  \tVal_kappa : 0.024 \n",
            "Epoch: 195 \tTraining Loss: -0.515 \tTrain_Accu: 30%  \tValid_Acc:26%  \tVal_kappa : 0.071 \n",
            "Epoch: 196 \tTraining Loss: -0.564 \tTrain_Accu: 28%  \tValid_Acc:27%  \tVal_kappa : 0.203 \n",
            "Epoch: 197 \tTraining Loss: -0.625 \tTrain_Accu: 33%  \tValid_Acc:17%  \tVal_kappa : 0.178 \n",
            "Epoch: 198 \tTraining Loss: -0.663 \tTrain_Accu: 31%  \tValid_Acc:21%  \tVal_kappa : -0.006 \n",
            "Epoch: 199 \tTraining Loss: -0.577 \tTrain_Accu: 28%  \tValid_Acc:26%  \tVal_kappa : 0.084 \n",
            "Epoch: 200 \tTraining Loss: -0.581 \tTrain_Accu: 31%  \tValid_Acc:27%  \tVal_kappa : 0.175 \n",
            "Epoch: 201 \tTraining Loss: -0.474 \tTrain_Accu: 26%  \tValid_Acc:19%  \tVal_kappa : 0.079 \n",
            "Epoch: 202 \tTraining Loss: -0.477 \tTrain_Accu: 28%  \tValid_Acc:24%  \tVal_kappa : 0.198 \n",
            "Epoch: 203 \tTraining Loss: -0.554 \tTrain_Accu: 27%  \tValid_Acc:20%  \tVal_kappa : -0.027 \n",
            "Epoch: 204 \tTraining Loss: -0.455 \tTrain_Accu: 29%  \tValid_Acc:27%  \tVal_kappa : 0.063 \n",
            "Epoch: 205 \tTraining Loss: -0.555 \tTrain_Accu: 28%  \tValid_Acc:20%  \tVal_kappa : 0.023 \n",
            "Epoch: 206 \tTraining Loss: -0.626 \tTrain_Accu: 31%  \tValid_Acc:26%  \tVal_kappa : 0.192 \n",
            "Epoch: 207 \tTraining Loss: -0.640 \tTrain_Accu: 28%  \tValid_Acc:29%  \tVal_kappa : 0.198 \n",
            "Epoch: 208 \tTraining Loss: -0.606 \tTrain_Accu: 30%  \tValid_Acc:31%  \tVal_kappa : 0.195 \n",
            "Epoch: 209 \tTraining Loss: -0.633 \tTrain_Accu: 31%  \tValid_Acc:37%  \tVal_kappa : 0.164 \n",
            "Epoch: 210 \tTraining Loss: -0.584 \tTrain_Accu: 29%  \tValid_Acc:29%  \tVal_kappa : 0.206 \n",
            "Epoch: 211 \tTraining Loss: -0.647 \tTrain_Accu: 29%  \tValid_Acc:26%  \tVal_kappa : 0.099 \n",
            "Epoch: 212 \tTraining Loss: -0.675 \tTrain_Accu: 34%  \tValid_Acc:24%  \tVal_kappa : 0.141 \n",
            "Epoch: 213 \tTraining Loss: -0.570 \tTrain_Accu: 28%  \tValid_Acc:29%  \tVal_kappa : 0.138 \n",
            "Epoch: 214 \tTraining Loss: -0.543 \tTrain_Accu: 29%  \tValid_Acc:30%  \tVal_kappa : 0.092 \n",
            "Epoch: 215 \tTraining Loss: -0.606 \tTrain_Accu: 31%  \tValid_Acc:24%  \tVal_kappa : 0.204 \n",
            "Epoch: 216 \tTraining Loss: -0.653 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.154 \n",
            "Epoch: 217 \tTraining Loss: -0.564 \tTrain_Accu: 27%  \tValid_Acc:33%  \tVal_kappa : 0.169 \n",
            "Epoch: 218 \tTraining Loss: -0.594 \tTrain_Accu: 29%  \tValid_Acc:30%  \tVal_kappa : 0.156 \n",
            "Epoch: 219 \tTraining Loss: -0.745 \tTrain_Accu: 32%  \tValid_Acc:23%  \tVal_kappa : 0.107 \n",
            "Epoch: 220 \tTraining Loss: -0.610 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.086 \n",
            "Epoch: 221 \tTraining Loss: -0.633 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.081 \n",
            "Epoch: 222 \tTraining Loss: -0.506 \tTrain_Accu: 29%  \tValid_Acc:29%  \tVal_kappa : 0.153 \n",
            "Epoch: 223 \tTraining Loss: -0.616 \tTrain_Accu: 26%  \tValid_Acc:23%  \tVal_kappa : 0.082 \n",
            "Epoch: 224 \tTraining Loss: -0.609 \tTrain_Accu: 30%  \tValid_Acc:27%  \tVal_kappa : 0.091 \n",
            "Epoch: 225 \tTraining Loss: -0.538 \tTrain_Accu: 27%  \tValid_Acc:29%  \tVal_kappa : 0.135 \n",
            "Epoch: 226 \tTraining Loss: -0.700 \tTrain_Accu: 32%  \tValid_Acc:29%  \tVal_kappa : 0.247 \n",
            "Epoch: 227 \tTraining Loss: -0.507 \tTrain_Accu: 26%  \tValid_Acc:16%  \tVal_kappa : 0.047 \n",
            "Epoch: 228 \tTraining Loss: -0.578 \tTrain_Accu: 29%  \tValid_Acc:16%  \tVal_kappa : 0.018 \n",
            "Epoch: 229 \tTraining Loss: -0.562 \tTrain_Accu: 29%  \tValid_Acc:27%  \tVal_kappa : 0.228 \n",
            "Epoch: 230 \tTraining Loss: -0.573 \tTrain_Accu: 32%  \tValid_Acc:29%  \tVal_kappa : 0.173 \n",
            "Epoch: 231 \tTraining Loss: -0.598 \tTrain_Accu: 31%  \tValid_Acc:26%  \tVal_kappa : 0.269 \n",
            "Epoch: 232 \tTraining Loss: -0.750 \tTrain_Accu: 31%  \tValid_Acc:24%  \tVal_kappa : -0.038 \n",
            "Epoch: 233 \tTraining Loss: -0.666 \tTrain_Accu: 31%  \tValid_Acc:16%  \tVal_kappa : 0.133 \n",
            "Epoch: 234 \tTraining Loss: -0.733 \tTrain_Accu: 32%  \tValid_Acc:27%  \tVal_kappa : 0.077 \n",
            "Epoch: 235 \tTraining Loss: -0.666 \tTrain_Accu: 31%  \tValid_Acc:21%  \tVal_kappa : -0.052 \n",
            "Epoch: 236 \tTraining Loss: -0.623 \tTrain_Accu: 30%  \tValid_Acc:24%  \tVal_kappa : 0.077 \n",
            "Epoch: 237 \tTraining Loss: -0.722 \tTrain_Accu: 32%  \tValid_Acc:19%  \tVal_kappa : 0.050 \n",
            "Epoch: 238 \tTraining Loss: -0.733 \tTrain_Accu: 32%  \tValid_Acc:26%  \tVal_kappa : 0.124 \n",
            "Epoch: 239 \tTraining Loss: -0.758 \tTrain_Accu: 30%  \tValid_Acc:29%  \tVal_kappa : 0.072 \n",
            "Epoch: 240 \tTraining Loss: -0.670 \tTrain_Accu: 29%  \tValid_Acc:19%  \tVal_kappa : -0.028 \n",
            "Epoch: 241 \tTraining Loss: -0.689 \tTrain_Accu: 30%  \tValid_Acc:23%  \tVal_kappa : 0.076 \n",
            "Epoch: 242 \tTraining Loss: -0.624 \tTrain_Accu: 31%  \tValid_Acc:23%  \tVal_kappa : 0.150 \n",
            "Epoch: 243 \tTraining Loss: -0.526 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.106 \n",
            "Epoch: 244 \tTraining Loss: -0.578 \tTrain_Accu: 31%  \tValid_Acc:26%  \tVal_kappa : 0.129 \n",
            "Epoch: 245 \tTraining Loss: -0.624 \tTrain_Accu: 29%  \tValid_Acc:23%  \tVal_kappa : 0.060 \n",
            "Epoch: 246 \tTraining Loss: -0.710 \tTrain_Accu: 32%  \tValid_Acc:24%  \tVal_kappa : 0.231 \n",
            "Epoch: 247 \tTraining Loss: -0.598 \tTrain_Accu: 30%  \tValid_Acc:21%  \tVal_kappa : 0.314 \n",
            "Epoch: 248 \tTraining Loss: -0.570 \tTrain_Accu: 27%  \tValid_Acc:19%  \tVal_kappa : 0.052 \n",
            "Epoch: 249 \tTraining Loss: -0.611 \tTrain_Accu: 30%  \tValid_Acc:20%  \tVal_kappa : 0.064 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-28 00:11:10,370]\u001b[0m Trial 3 finished with value: -0.1 and parameters: {'lr': 0.01}. Best is trial 0 with value: 0.0.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss: -0.629 \tTrain_Accu: 30%  \tValid_Acc:11%  \tVal_kappa : -0.112 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['drive/My Drive/DL_project/optimise_valid_NNI_temp.torch']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy80avxbgWV9"
      },
      "source": [
        "Training and test accuracy with different learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "0zHv0p4tghB5",
        "outputId": "d5bb152c-7617-47f6-a7b5-a3665b0935c8"
      },
      "source": [
        "data = {  'Learning rate':[0.1, 0.01, 0.0001], 'Training_Acc':['21%', '32%', '53%'], 'Validation_Acc':['27%', '7%', '20%']  }\n",
        "Table = pd.DataFrame(data)\n",
        "Table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Learning rate</th>\n",
              "      <th>Training_Acc</th>\n",
              "      <th>Validation_Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.1000</td>\n",
              "      <td>21%</td>\n",
              "      <td>27%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>32%</td>\n",
              "      <td>7%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>53%</td>\n",
              "      <td>20%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Learning rate Training_Acc Validation_Acc\n",
              "0         0.1000          21%            27%\n",
              "1         0.0100          32%             7%\n",
              "2         0.0001          53%            20%"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD41dlZ-g8LJ"
      },
      "source": [
        "Learnin rate 0.0001 provided the better training and test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRgD3GxEO9oW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivc9hWBkRADN"
      },
      "source": [
        "## NNI QWK\n",
        "\n",
        "The model was run with the best combinations of parameters to save the model parameters and evaluated on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6x6Y3BSH6dV"
      },
      "source": [
        "# Main function to run, nodropout\n",
        "\n",
        "def train_NNI_qwk(trial):\n",
        "  \n",
        "  cfg = { 'Batch_size' : 10,\n",
        "          'n_epochs' : 250,\n",
        "          'seed' : 32,\n",
        "         'save_model' : True,\n",
        "          'lr' : 0.0001,       \n",
        "           'optimizer':  optim.RMSprop,\n",
        "          # 'dropout'       : 0.5,\n",
        "            'activation': F.relu}\n",
        "\n",
        " \n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  torch.manual_seed(cfg['seed'])\n",
        "  train_loader, valid_loader = get_valid_loaders_NNI(cfg['Batch_size'])\n",
        "  model = Network_drop_bn().to(device)\n",
        "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n",
        "  \n",
        "  # placeholders\n",
        "  trainset = torch.utils.data.TensorDataset(dataTensor[:325], labelsTensors_NNI[:325])\n",
        "  validset = torch.utils.data.TensorDataset(dataTensor[325:395], labelsTensors_NNI[325:395])\n",
        "  fold_preds = np.zeros((len(validset), 5))\n",
        "\n",
        "  batch_size = 10\n",
        "\n",
        "  # quad = quadratic_kappa_coefficient(output1, target1).to(device)\n",
        "  # quad_metric = Qwk_metric(output1, target1).to(device)\n",
        "\n",
        "  \n",
        "  train_accuracy = []\n",
        "  valid_accuracy =[]\n",
        "  train_losses =[]\n",
        "  valid_losses = []\n",
        "  val_kappa = []\n",
        "  qwk = []\n",
        "  valid_kappa = []\n",
        "  valid_qwk = []\n",
        "    \n",
        "  for epoch in range(1, cfg['n_epochs'] + 1):\n",
        "      #Valid_accuracy, train_losses, valid_losses = train_valid(cfg['log_interval'], model, train_loader, valid_loader, optimizer, epoch)\n",
        "      #test_accuracy = test(model, test_loader)\n",
        "       model.train()\n",
        "       \n",
        "       train_loss = 0\n",
        "       train_correct = 0\n",
        "       valid_loss = 0\n",
        "       valid_correct = 0\n",
        "       train_acc = 0\n",
        "       valid_acc = 0\n",
        "       valid_kappa_all = 0\n",
        "       \n",
        "    \n",
        "      \n",
        "\n",
        "       for batch_idx, (data, target) in enumerate(train_loader):\n",
        "           data, target = data.to(device), target.to(device)\n",
        "           optimizer.zero_grad()\n",
        "           output = model(data)\n",
        "           output_c = output.cpu()\n",
        "           target_c = target.cpu()\n",
        "           loss =  Kappaloss_log(output_c, target_c)\n",
        "           \n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "           train_loss += loss.item()\n",
        "           train_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "           \n",
        "\n",
        "       with torch.no_grad(): \n",
        "          for batch_i, (data, target) in enumerate(valid_loader): \n",
        "              data, target = data.to(device), target.to(device)         \n",
        "              output = model(data)\n",
        "              output_c = output.cpu()\n",
        "              target_c = target.cpu()\n",
        "              loss = Kappaloss_log(output_c, target_c) \n",
        "              valid_loss += loss.item()\n",
        "              valid_correct += output.argmax(dim=1).eq(target).int().sum().item()\n",
        "              fold_preds[batch_i * batch_size:(batch_i + 1) * batch_size, :] = output.cpu()\n",
        "              valid_pred = output.argmax(dim=1)\n",
        "              #print('labels', target)\n",
        "              #print('pred', valid_pred)\n",
        "              \n",
        "              \n",
        "              y_actual = target.data.cpu().numpy()\n",
        "              y_pred = valid_pred.detach().cpu().numpy()\n",
        "              \n",
        "              \n",
        "         \n",
        "\n",
        "        \n",
        "    \n",
        "       train_loss=train_loss/len(train_loader) \n",
        "       train_acc = train_correct/len(train_loader.dataset) * 100\n",
        "       valid_loss = valid_loss/len(valid_loader)\n",
        "       valid_acc = valid_correct/len(valid_loader.dataset)* 100\n",
        "       train_accuracy.append(train_acc) \n",
        "       valid_accuracy.append(valid_acc)\n",
        "       train_losses.append(train_loss)\n",
        "       valid_losses.append(valid_loss)\n",
        "     \n",
        "        \n",
        "      \n",
        "       fold_preds_round = fold_preds.argmax(axis = 1)\n",
        "       \n",
        "       y_actual_total = labelsTensors_NNI[325:395].data.cpu().numpy()\n",
        "       labels_actual = labelsTensors_NNI[325:395].cpu()\n",
        "      #  print(fold_preds)\n",
        "      #  print(labels_actual)\n",
        "       valid_kappa_all = cohen_kappa_score(y_actual_total, fold_preds_round, weights = 'quadratic')\n",
        "      \n",
        "       #valid_qwk = Qwk_metric(fold_preds, labels_actual).item()\n",
        "\n",
        "   \n",
        "    \n",
        "       print('Epoch: {} \\tTraining Loss: {: .3f} \\tTrain_Accu: {:.0f}%  \\tValid_Acc:{:.0f}%  \\tVal_kappa : {:.3f} '.format(epoch, train_loss, train_acc, valid_acc, valid_kappa_all))  \n",
        "\n",
        "\n",
        "  \n",
        "       torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'train_acc':train_accuracy,\n",
        "              'valid_acc':valid_accuracy,\n",
        "              'train_loss':train_losses,\n",
        "              'valid_loss': valid_losses\n",
        "             },\n",
        "              \"drive/MyDrive/DL_project/check_valid_NNI_kappa_loss.torch\")\n",
        "      \n",
        "   \n",
        "  return  round(valid_kappa_all, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztzlUEoqLCIv",
        "outputId": "ce319af5-f6df-4a43-a8ba-6e2dc0c59dd8"
      },
      "source": [
        "# Code to run for number of trials\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "study.optimize(train_NNI_qwk, n_trials=1)\n",
        "\n",
        "\n",
        "joblib.dump(study, \"drive/My Drive/DL_project/optimise_valid_NNI.torch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: -0.032 \tTrain_Accu: 22%  \tValid_Acc:19%  \tVal_kappa : -0.030 \n",
            "Epoch: 2 \tTraining Loss: -0.033 \tTrain_Accu: 21%  \tValid_Acc:19%  \tVal_kappa : 0.205 \n",
            "Epoch: 3 \tTraining Loss: -0.122 \tTrain_Accu: 26%  \tValid_Acc:26%  \tVal_kappa : 0.211 \n",
            "Epoch: 4 \tTraining Loss: -0.125 \tTrain_Accu: 26%  \tValid_Acc:20%  \tVal_kappa : 0.054 \n",
            "Epoch: 5 \tTraining Loss: -0.130 \tTrain_Accu: 21%  \tValid_Acc:20%  \tVal_kappa : 0.049 \n",
            "Epoch: 6 \tTraining Loss: -0.182 \tTrain_Accu: 25%  \tValid_Acc:23%  \tVal_kappa : 0.183 \n",
            "Epoch: 7 \tTraining Loss: -0.185 \tTrain_Accu: 28%  \tValid_Acc:16%  \tVal_kappa : 0.233 \n",
            "Epoch: 8 \tTraining Loss: -0.266 \tTrain_Accu: 28%  \tValid_Acc:19%  \tVal_kappa : 0.157 \n",
            "Epoch: 9 \tTraining Loss: -0.271 \tTrain_Accu: 28%  \tValid_Acc:24%  \tVal_kappa : 0.171 \n",
            "Epoch: 10 \tTraining Loss: -0.331 \tTrain_Accu: 30%  \tValid_Acc:30%  \tVal_kappa : 0.114 \n",
            "Epoch: 11 \tTraining Loss: -0.363 \tTrain_Accu: 30%  \tValid_Acc:23%  \tVal_kappa : 0.187 \n",
            "Epoch: 12 \tTraining Loss: -0.322 \tTrain_Accu: 32%  \tValid_Acc:27%  \tVal_kappa : 0.056 \n",
            "Epoch: 13 \tTraining Loss: -0.396 \tTrain_Accu: 29%  \tValid_Acc:23%  \tVal_kappa : 0.332 \n",
            "Epoch: 14 \tTraining Loss: -0.471 \tTrain_Accu: 29%  \tValid_Acc:29%  \tVal_kappa : 0.341 \n",
            "Epoch: 15 \tTraining Loss: -0.470 \tTrain_Accu: 35%  \tValid_Acc:21%  \tVal_kappa : 0.081 \n",
            "Epoch: 16 \tTraining Loss: -0.543 \tTrain_Accu: 32%  \tValid_Acc:27%  \tVal_kappa : 0.249 \n",
            "Epoch: 17 \tTraining Loss: -0.519 \tTrain_Accu: 34%  \tValid_Acc:17%  \tVal_kappa : 0.096 \n",
            "Epoch: 18 \tTraining Loss: -0.571 \tTrain_Accu: 30%  \tValid_Acc:20%  \tVal_kappa : 0.039 \n",
            "Epoch: 19 \tTraining Loss: -0.602 \tTrain_Accu: 34%  \tValid_Acc:24%  \tVal_kappa : 0.181 \n",
            "Epoch: 20 \tTraining Loss: -0.631 \tTrain_Accu: 33%  \tValid_Acc:23%  \tVal_kappa : 0.041 \n",
            "Epoch: 21 \tTraining Loss: -0.776 \tTrain_Accu: 38%  \tValid_Acc:20%  \tVal_kappa : 0.046 \n",
            "Epoch: 22 \tTraining Loss: -0.765 \tTrain_Accu: 38%  \tValid_Acc:17%  \tVal_kappa : 0.061 \n",
            "Epoch: 23 \tTraining Loss: -0.797 \tTrain_Accu: 36%  \tValid_Acc:23%  \tVal_kappa : 0.107 \n",
            "Epoch: 24 \tTraining Loss: -0.823 \tTrain_Accu: 32%  \tValid_Acc:20%  \tVal_kappa : 0.040 \n",
            "Epoch: 25 \tTraining Loss: -0.821 \tTrain_Accu: 40%  \tValid_Acc:27%  \tVal_kappa : 0.121 \n",
            "Epoch: 26 \tTraining Loss: -0.851 \tTrain_Accu: 36%  \tValid_Acc:17%  \tVal_kappa : 0.061 \n",
            "Epoch: 27 \tTraining Loss: -0.872 \tTrain_Accu: 31%  \tValid_Acc:19%  \tVal_kappa : 0.091 \n",
            "Epoch: 28 \tTraining Loss: -0.917 \tTrain_Accu: 34%  \tValid_Acc:39%  \tVal_kappa : 0.318 \n",
            "Epoch: 29 \tTraining Loss: -0.891 \tTrain_Accu: 36%  \tValid_Acc:23%  \tVal_kappa : 0.156 \n",
            "Epoch: 30 \tTraining Loss: -0.998 \tTrain_Accu: 37%  \tValid_Acc:30%  \tVal_kappa : 0.206 \n",
            "Epoch: 31 \tTraining Loss: -0.958 \tTrain_Accu: 35%  \tValid_Acc:21%  \tVal_kappa : 0.041 \n",
            "Epoch: 32 \tTraining Loss: -0.916 \tTrain_Accu: 35%  \tValid_Acc:24%  \tVal_kappa : 0.069 \n",
            "Epoch: 33 \tTraining Loss: -1.021 \tTrain_Accu: 35%  \tValid_Acc:21%  \tVal_kappa : 0.211 \n",
            "Epoch: 34 \tTraining Loss: -1.105 \tTrain_Accu: 38%  \tValid_Acc:17%  \tVal_kappa : 0.105 \n",
            "Epoch: 35 \tTraining Loss: -1.040 \tTrain_Accu: 41%  \tValid_Acc:20%  \tVal_kappa : 0.081 \n",
            "Epoch: 36 \tTraining Loss: -0.893 \tTrain_Accu: 36%  \tValid_Acc:34%  \tVal_kappa : 0.241 \n",
            "Epoch: 37 \tTraining Loss: -1.162 \tTrain_Accu: 34%  \tValid_Acc:24%  \tVal_kappa : 0.068 \n",
            "Epoch: 38 \tTraining Loss: -1.065 \tTrain_Accu: 34%  \tValid_Acc:21%  \tVal_kappa : 0.157 \n",
            "Epoch: 39 \tTraining Loss: -1.141 \tTrain_Accu: 38%  \tValid_Acc:19%  \tVal_kappa : -0.103 \n",
            "Epoch: 40 \tTraining Loss: -1.034 \tTrain_Accu: 32%  \tValid_Acc:26%  \tVal_kappa : 0.050 \n",
            "Epoch: 41 \tTraining Loss: -1.162 \tTrain_Accu: 38%  \tValid_Acc:24%  \tVal_kappa : 0.114 \n",
            "Epoch: 42 \tTraining Loss: -1.080 \tTrain_Accu: 36%  \tValid_Acc:31%  \tVal_kappa : 0.145 \n",
            "Epoch: 43 \tTraining Loss: -1.073 \tTrain_Accu: 32%  \tValid_Acc:24%  \tVal_kappa : 0.028 \n",
            "Epoch: 44 \tTraining Loss: -1.179 \tTrain_Accu: 39%  \tValid_Acc:17%  \tVal_kappa : 0.116 \n",
            "Epoch: 45 \tTraining Loss: -0.981 \tTrain_Accu: 34%  \tValid_Acc:26%  \tVal_kappa : 0.079 \n",
            "Epoch: 46 \tTraining Loss: -1.177 \tTrain_Accu: 37%  \tValid_Acc:23%  \tVal_kappa : 0.261 \n",
            "Epoch: 47 \tTraining Loss: -1.304 \tTrain_Accu: 39%  \tValid_Acc:21%  \tVal_kappa : 0.046 \n",
            "Epoch: 48 \tTraining Loss: -1.147 \tTrain_Accu: 37%  \tValid_Acc:21%  \tVal_kappa : -0.030 \n",
            "Epoch: 49 \tTraining Loss: -1.064 \tTrain_Accu: 36%  \tValid_Acc:24%  \tVal_kappa : 0.077 \n",
            "Epoch: 50 \tTraining Loss: -1.094 \tTrain_Accu: 37%  \tValid_Acc:20%  \tVal_kappa : -0.023 \n",
            "Epoch: 51 \tTraining Loss: -1.080 \tTrain_Accu: 34%  \tValid_Acc:20%  \tVal_kappa : 0.059 \n",
            "Epoch: 52 \tTraining Loss: -1.091 \tTrain_Accu: 38%  \tValid_Acc:20%  \tVal_kappa : 0.122 \n",
            "Epoch: 53 \tTraining Loss: -1.160 \tTrain_Accu: 34%  \tValid_Acc:24%  \tVal_kappa : 0.017 \n",
            "Epoch: 54 \tTraining Loss: -1.135 \tTrain_Accu: 36%  \tValid_Acc:19%  \tVal_kappa : 0.063 \n",
            "Epoch: 55 \tTraining Loss: -1.270 \tTrain_Accu: 38%  \tValid_Acc:16%  \tVal_kappa : 0.113 \n",
            "Epoch: 56 \tTraining Loss: -1.195 \tTrain_Accu: 38%  \tValid_Acc:16%  \tVal_kappa : -0.067 \n",
            "Epoch: 57 \tTraining Loss: -1.163 \tTrain_Accu: 39%  \tValid_Acc:17%  \tVal_kappa : -0.210 \n",
            "Epoch: 58 \tTraining Loss: -1.197 \tTrain_Accu: 43%  \tValid_Acc:26%  \tVal_kappa : 0.089 \n",
            "Epoch: 59 \tTraining Loss: -1.228 \tTrain_Accu: 38%  \tValid_Acc:16%  \tVal_kappa : 0.125 \n",
            "Epoch: 60 \tTraining Loss: -1.108 \tTrain_Accu: 37%  \tValid_Acc:24%  \tVal_kappa : 0.050 \n",
            "Epoch: 61 \tTraining Loss: -1.337 \tTrain_Accu: 44%  \tValid_Acc:23%  \tVal_kappa : 0.110 \n",
            "Epoch: 62 \tTraining Loss: -1.155 \tTrain_Accu: 41%  \tValid_Acc:21%  \tVal_kappa : 0.119 \n",
            "Epoch: 63 \tTraining Loss: -1.224 \tTrain_Accu: 45%  \tValid_Acc:24%  \tVal_kappa : 0.050 \n",
            "Epoch: 64 \tTraining Loss: -1.245 \tTrain_Accu: 36%  \tValid_Acc:16%  \tVal_kappa : -0.053 \n",
            "Epoch: 65 \tTraining Loss: -1.262 \tTrain_Accu: 38%  \tValid_Acc:23%  \tVal_kappa : 0.045 \n",
            "Epoch: 66 \tTraining Loss: -1.258 \tTrain_Accu: 42%  \tValid_Acc:23%  \tVal_kappa : -0.006 \n",
            "Epoch: 67 \tTraining Loss: -1.200 \tTrain_Accu: 41%  \tValid_Acc:14%  \tVal_kappa : 0.018 \n",
            "Epoch: 68 \tTraining Loss: -1.312 \tTrain_Accu: 37%  \tValid_Acc:27%  \tVal_kappa : 0.000 \n",
            "Epoch: 69 \tTraining Loss: -1.231 \tTrain_Accu: 45%  \tValid_Acc:20%  \tVal_kappa : 0.100 \n",
            "Epoch: 70 \tTraining Loss: -1.354 \tTrain_Accu: 44%  \tValid_Acc:21%  \tVal_kappa : 0.153 \n",
            "Epoch: 71 \tTraining Loss: -1.274 \tTrain_Accu: 44%  \tValid_Acc:29%  \tVal_kappa : 0.188 \n",
            "Epoch: 72 \tTraining Loss: -1.183 \tTrain_Accu: 40%  \tValid_Acc:33%  \tVal_kappa : 0.132 \n",
            "Epoch: 73 \tTraining Loss: -1.349 \tTrain_Accu: 38%  \tValid_Acc:26%  \tVal_kappa : 0.000 \n",
            "Epoch: 74 \tTraining Loss: -1.324 \tTrain_Accu: 41%  \tValid_Acc:24%  \tVal_kappa : 0.135 \n",
            "Epoch: 75 \tTraining Loss: -1.357 \tTrain_Accu: 40%  \tValid_Acc:29%  \tVal_kappa : 0.112 \n",
            "Epoch: 76 \tTraining Loss: -1.210 \tTrain_Accu: 44%  \tValid_Acc:27%  \tVal_kappa : 0.257 \n",
            "Epoch: 77 \tTraining Loss: -1.367 \tTrain_Accu: 45%  \tValid_Acc:27%  \tVal_kappa : 0.147 \n",
            "Epoch: 78 \tTraining Loss: -1.186 \tTrain_Accu: 42%  \tValid_Acc:17%  \tVal_kappa : 0.148 \n",
            "Epoch: 79 \tTraining Loss: -1.223 \tTrain_Accu: 40%  \tValid_Acc:14%  \tVal_kappa : -0.045 \n",
            "Epoch: 80 \tTraining Loss: -1.355 \tTrain_Accu: 42%  \tValid_Acc:21%  \tVal_kappa : 0.030 \n",
            "Epoch: 81 \tTraining Loss: -1.285 \tTrain_Accu: 40%  \tValid_Acc:23%  \tVal_kappa : 0.211 \n",
            "Epoch: 82 \tTraining Loss: -1.217 \tTrain_Accu: 41%  \tValid_Acc:21%  \tVal_kappa : 0.088 \n",
            "Epoch: 83 \tTraining Loss: -1.264 \tTrain_Accu: 45%  \tValid_Acc:16%  \tVal_kappa : -0.006 \n",
            "Epoch: 84 \tTraining Loss: -1.303 \tTrain_Accu: 44%  \tValid_Acc:20%  \tVal_kappa : 0.102 \n",
            "Epoch: 85 \tTraining Loss: -1.277 \tTrain_Accu: 44%  \tValid_Acc:20%  \tVal_kappa : 0.094 \n",
            "Epoch: 86 \tTraining Loss: -1.377 \tTrain_Accu: 48%  \tValid_Acc:24%  \tVal_kappa : 0.100 \n",
            "Epoch: 87 \tTraining Loss: -1.302 \tTrain_Accu: 41%  \tValid_Acc:20%  \tVal_kappa : 0.089 \n",
            "Epoch: 88 \tTraining Loss: -1.294 \tTrain_Accu: 44%  \tValid_Acc:17%  \tVal_kappa : -0.063 \n",
            "Epoch: 89 \tTraining Loss: -1.349 \tTrain_Accu: 43%  \tValid_Acc:23%  \tVal_kappa : 0.030 \n",
            "Epoch: 90 \tTraining Loss: -1.368 \tTrain_Accu: 43%  \tValid_Acc:27%  \tVal_kappa : 0.123 \n",
            "Epoch: 91 \tTraining Loss: -1.303 \tTrain_Accu: 40%  \tValid_Acc:13%  \tVal_kappa : 0.065 \n",
            "Epoch: 92 \tTraining Loss: -1.388 \tTrain_Accu: 44%  \tValid_Acc:21%  \tVal_kappa : 0.039 \n",
            "Epoch: 93 \tTraining Loss: -1.334 \tTrain_Accu: 46%  \tValid_Acc:33%  \tVal_kappa : 0.066 \n",
            "Epoch: 94 \tTraining Loss: -1.391 \tTrain_Accu: 42%  \tValid_Acc:14%  \tVal_kappa : 0.051 \n",
            "Epoch: 95 \tTraining Loss: -1.308 \tTrain_Accu: 46%  \tValid_Acc:20%  \tVal_kappa : 0.030 \n",
            "Epoch: 96 \tTraining Loss: -1.210 \tTrain_Accu: 41%  \tValid_Acc:24%  \tVal_kappa : 0.199 \n",
            "Epoch: 97 \tTraining Loss: -1.216 \tTrain_Accu: 42%  \tValid_Acc:29%  \tVal_kappa : 0.143 \n",
            "Epoch: 98 \tTraining Loss: -1.337 \tTrain_Accu: 45%  \tValid_Acc:20%  \tVal_kappa : 0.125 \n",
            "Epoch: 99 \tTraining Loss: -1.299 \tTrain_Accu: 48%  \tValid_Acc:24%  \tVal_kappa : 0.158 \n",
            "Epoch: 100 \tTraining Loss: -1.101 \tTrain_Accu: 41%  \tValid_Acc:24%  \tVal_kappa : 0.077 \n",
            "Epoch: 101 \tTraining Loss: -1.355 \tTrain_Accu: 42%  \tValid_Acc:27%  \tVal_kappa : 0.089 \n",
            "Epoch: 102 \tTraining Loss: -1.225 \tTrain_Accu: 41%  \tValid_Acc:19%  \tVal_kappa : 0.083 \n",
            "Epoch: 103 \tTraining Loss: -1.309 \tTrain_Accu: 42%  \tValid_Acc:36%  \tVal_kappa : 0.246 \n",
            "Epoch: 104 \tTraining Loss: -1.355 \tTrain_Accu: 45%  \tValid_Acc:33%  \tVal_kappa : 0.116 \n",
            "Epoch: 105 \tTraining Loss: -1.393 \tTrain_Accu: 46%  \tValid_Acc:26%  \tVal_kappa : 0.182 \n",
            "Epoch: 106 \tTraining Loss: -1.150 \tTrain_Accu: 43%  \tValid_Acc:24%  \tVal_kappa : 0.140 \n",
            "Epoch: 107 \tTraining Loss: -1.249 \tTrain_Accu: 44%  \tValid_Acc:23%  \tVal_kappa : 0.110 \n",
            "Epoch: 108 \tTraining Loss: -1.276 \tTrain_Accu: 42%  \tValid_Acc:17%  \tVal_kappa : -0.132 \n",
            "Epoch: 109 \tTraining Loss: -1.242 \tTrain_Accu: 43%  \tValid_Acc:17%  \tVal_kappa : -0.082 \n",
            "Epoch: 110 \tTraining Loss: -1.430 \tTrain_Accu: 47%  \tValid_Acc:26%  \tVal_kappa : 0.187 \n",
            "Epoch: 111 \tTraining Loss: -1.374 \tTrain_Accu: 47%  \tValid_Acc:26%  \tVal_kappa : 0.147 \n",
            "Epoch: 112 \tTraining Loss: -1.346 \tTrain_Accu: 43%  \tValid_Acc:21%  \tVal_kappa : 0.195 \n",
            "Epoch: 113 \tTraining Loss: -1.352 \tTrain_Accu: 45%  \tValid_Acc:23%  \tVal_kappa : 0.051 \n",
            "Epoch: 114 \tTraining Loss: -1.309 \tTrain_Accu: 43%  \tValid_Acc:20%  \tVal_kappa : 0.211 \n",
            "Epoch: 115 \tTraining Loss: -1.401 \tTrain_Accu: 44%  \tValid_Acc:30%  \tVal_kappa : 0.205 \n",
            "Epoch: 116 \tTraining Loss: -1.343 \tTrain_Accu: 47%  \tValid_Acc:29%  \tVal_kappa : 0.151 \n",
            "Epoch: 117 \tTraining Loss: -1.218 \tTrain_Accu: 43%  \tValid_Acc:26%  \tVal_kappa : 0.076 \n",
            "Epoch: 118 \tTraining Loss: -1.367 \tTrain_Accu: 39%  \tValid_Acc:16%  \tVal_kappa : 0.166 \n",
            "Epoch: 119 \tTraining Loss: -1.465 \tTrain_Accu: 48%  \tValid_Acc:20%  \tVal_kappa : 0.038 \n",
            "Epoch: 120 \tTraining Loss: -1.368 \tTrain_Accu: 49%  \tValid_Acc:26%  \tVal_kappa : 0.156 \n",
            "Epoch: 121 \tTraining Loss: -1.246 \tTrain_Accu: 41%  \tValid_Acc:27%  \tVal_kappa : 0.344 \n",
            "Epoch: 122 \tTraining Loss: -1.292 \tTrain_Accu: 43%  \tValid_Acc:16%  \tVal_kappa : 0.259 \n",
            "Epoch: 123 \tTraining Loss: -1.299 \tTrain_Accu: 40%  \tValid_Acc:23%  \tVal_kappa : 0.211 \n",
            "Epoch: 124 \tTraining Loss: -1.355 \tTrain_Accu: 46%  \tValid_Acc:26%  \tVal_kappa : 0.131 \n",
            "Epoch: 125 \tTraining Loss: -1.271 \tTrain_Accu: 43%  \tValid_Acc:23%  \tVal_kappa : 0.214 \n",
            "Epoch: 126 \tTraining Loss: -1.272 \tTrain_Accu: 44%  \tValid_Acc:24%  \tVal_kappa : 0.152 \n",
            "Epoch: 127 \tTraining Loss: -1.275 \tTrain_Accu: 45%  \tValid_Acc:37%  \tVal_kappa : 0.337 \n",
            "Epoch: 128 \tTraining Loss: -1.376 \tTrain_Accu: 44%  \tValid_Acc:20%  \tVal_kappa : 0.097 \n",
            "Epoch: 129 \tTraining Loss: -1.306 \tTrain_Accu: 43%  \tValid_Acc:23%  \tVal_kappa : 0.230 \n",
            "Epoch: 130 \tTraining Loss: -1.202 \tTrain_Accu: 44%  \tValid_Acc:30%  \tVal_kappa : 0.262 \n",
            "Epoch: 131 \tTraining Loss: -1.204 \tTrain_Accu: 41%  \tValid_Acc:29%  \tVal_kappa : 0.086 \n",
            "Epoch: 132 \tTraining Loss: -1.464 \tTrain_Accu: 46%  \tValid_Acc:24%  \tVal_kappa : 0.234 \n",
            "Epoch: 133 \tTraining Loss: -1.443 \tTrain_Accu: 50%  \tValid_Acc:24%  \tVal_kappa : -0.013 \n",
            "Epoch: 134 \tTraining Loss: -1.277 \tTrain_Accu: 43%  \tValid_Acc:26%  \tVal_kappa : 0.074 \n",
            "Epoch: 135 \tTraining Loss: -1.364 \tTrain_Accu: 45%  \tValid_Acc:26%  \tVal_kappa : 0.053 \n",
            "Epoch: 136 \tTraining Loss: -1.176 \tTrain_Accu: 42%  \tValid_Acc:24%  \tVal_kappa : 0.179 \n",
            "Epoch: 137 \tTraining Loss: -1.360 \tTrain_Accu: 45%  \tValid_Acc:13%  \tVal_kappa : 0.069 \n",
            "Epoch: 138 \tTraining Loss: -1.428 \tTrain_Accu: 47%  \tValid_Acc:19%  \tVal_kappa : 0.089 \n",
            "Epoch: 139 \tTraining Loss: -1.435 \tTrain_Accu: 46%  \tValid_Acc:30%  \tVal_kappa : 0.173 \n",
            "Epoch: 140 \tTraining Loss: -1.284 \tTrain_Accu: 40%  \tValid_Acc:23%  \tVal_kappa : 0.227 \n",
            "Epoch: 141 \tTraining Loss: -1.493 \tTrain_Accu: 46%  \tValid_Acc:20%  \tVal_kappa : 0.066 \n",
            "Epoch: 142 \tTraining Loss: -1.240 \tTrain_Accu: 46%  \tValid_Acc:24%  \tVal_kappa : 0.065 \n",
            "Epoch: 143 \tTraining Loss: -1.393 \tTrain_Accu: 42%  \tValid_Acc:20%  \tVal_kappa : 0.133 \n",
            "Epoch: 144 \tTraining Loss: -1.549 \tTrain_Accu: 48%  \tValid_Acc:20%  \tVal_kappa : 0.135 \n",
            "Epoch: 145 \tTraining Loss: -1.439 \tTrain_Accu: 49%  \tValid_Acc:26%  \tVal_kappa : 0.076 \n",
            "Epoch: 146 \tTraining Loss: -1.383 \tTrain_Accu: 44%  \tValid_Acc:20%  \tVal_kappa : 0.062 \n",
            "Epoch: 147 \tTraining Loss: -1.330 \tTrain_Accu: 45%  \tValid_Acc:20%  \tVal_kappa : 0.110 \n",
            "Epoch: 148 \tTraining Loss: -1.399 \tTrain_Accu: 46%  \tValid_Acc:23%  \tVal_kappa : 0.077 \n",
            "Epoch: 149 \tTraining Loss: -1.506 \tTrain_Accu: 51%  \tValid_Acc:26%  \tVal_kappa : 0.252 \n",
            "Epoch: 150 \tTraining Loss: -1.469 \tTrain_Accu: 46%  \tValid_Acc:26%  \tVal_kappa : 0.159 \n",
            "Epoch: 151 \tTraining Loss: -1.562 \tTrain_Accu: 50%  \tValid_Acc:24%  \tVal_kappa : 0.124 \n",
            "Epoch: 152 \tTraining Loss: -1.453 \tTrain_Accu: 50%  \tValid_Acc:17%  \tVal_kappa : -0.007 \n",
            "Epoch: 153 \tTraining Loss: -1.446 \tTrain_Accu: 48%  \tValid_Acc:21%  \tVal_kappa : 0.040 \n",
            "Epoch: 154 \tTraining Loss: -1.427 \tTrain_Accu: 46%  \tValid_Acc:14%  \tVal_kappa : 0.041 \n",
            "Epoch: 155 \tTraining Loss: -1.257 \tTrain_Accu: 44%  \tValid_Acc:23%  \tVal_kappa : 0.210 \n",
            "Epoch: 156 \tTraining Loss: -1.488 \tTrain_Accu: 48%  \tValid_Acc:23%  \tVal_kappa : 0.081 \n",
            "Epoch: 157 \tTraining Loss: -1.317 \tTrain_Accu: 44%  \tValid_Acc:16%  \tVal_kappa : 0.025 \n",
            "Epoch: 158 \tTraining Loss: -1.355 \tTrain_Accu: 43%  \tValid_Acc:36%  \tVal_kappa : 0.294 \n",
            "Epoch: 159 \tTraining Loss: -1.468 \tTrain_Accu: 46%  \tValid_Acc:29%  \tVal_kappa : 0.175 \n",
            "Epoch: 160 \tTraining Loss: -1.478 \tTrain_Accu: 45%  \tValid_Acc:26%  \tVal_kappa : 0.124 \n",
            "Epoch: 161 \tTraining Loss: -1.444 \tTrain_Accu: 45%  \tValid_Acc:27%  \tVal_kappa : 0.080 \n",
            "Epoch: 162 \tTraining Loss: -1.499 \tTrain_Accu: 50%  \tValid_Acc:24%  \tVal_kappa : 0.216 \n",
            "Epoch: 163 \tTraining Loss: -1.621 \tTrain_Accu: 51%  \tValid_Acc:23%  \tVal_kappa : 0.019 \n",
            "Epoch: 164 \tTraining Loss: -1.433 \tTrain_Accu: 50%  \tValid_Acc:26%  \tVal_kappa : 0.149 \n",
            "Epoch: 165 \tTraining Loss: -1.408 \tTrain_Accu: 46%  \tValid_Acc:20%  \tVal_kappa : 0.211 \n",
            "Epoch: 166 \tTraining Loss: -1.419 \tTrain_Accu: 43%  \tValid_Acc:27%  \tVal_kappa : 0.081 \n",
            "Epoch: 167 \tTraining Loss: -1.474 \tTrain_Accu: 44%  \tValid_Acc:16%  \tVal_kappa : -0.040 \n",
            "Epoch: 168 \tTraining Loss: -1.419 \tTrain_Accu: 53%  \tValid_Acc:34%  \tVal_kappa : 0.229 \n",
            "Epoch: 169 \tTraining Loss: -1.360 \tTrain_Accu: 45%  \tValid_Acc:26%  \tVal_kappa : 0.148 \n",
            "Epoch: 170 \tTraining Loss: -1.310 \tTrain_Accu: 44%  \tValid_Acc:17%  \tVal_kappa : 0.185 \n",
            "Epoch: 171 \tTraining Loss: -1.436 \tTrain_Accu: 48%  \tValid_Acc:17%  \tVal_kappa : 0.026 \n",
            "Epoch: 172 \tTraining Loss: -1.406 \tTrain_Accu: 51%  \tValid_Acc:24%  \tVal_kappa : 0.181 \n",
            "Epoch: 173 \tTraining Loss: -1.442 \tTrain_Accu: 48%  \tValid_Acc:31%  \tVal_kappa : 0.108 \n",
            "Epoch: 174 \tTraining Loss: -1.304 \tTrain_Accu: 45%  \tValid_Acc:20%  \tVal_kappa : 0.203 \n",
            "Epoch: 175 \tTraining Loss: -1.641 \tTrain_Accu: 49%  \tValid_Acc:26%  \tVal_kappa : 0.054 \n",
            "Epoch: 176 \tTraining Loss: -1.459 \tTrain_Accu: 50%  \tValid_Acc:13%  \tVal_kappa : 0.032 \n",
            "Epoch: 177 \tTraining Loss: -1.464 \tTrain_Accu: 52%  \tValid_Acc:23%  \tVal_kappa : 0.163 \n",
            "Epoch: 178 \tTraining Loss: -1.421 \tTrain_Accu: 48%  \tValid_Acc:21%  \tVal_kappa : 0.122 \n",
            "Epoch: 179 \tTraining Loss: -1.590 \tTrain_Accu: 49%  \tValid_Acc:19%  \tVal_kappa : -0.021 \n",
            "Epoch: 180 \tTraining Loss: -1.304 \tTrain_Accu: 41%  \tValid_Acc:19%  \tVal_kappa : 0.065 \n",
            "Epoch: 181 \tTraining Loss: -1.629 \tTrain_Accu: 44%  \tValid_Acc:20%  \tVal_kappa : -0.040 \n",
            "Epoch: 182 \tTraining Loss: -1.210 \tTrain_Accu: 42%  \tValid_Acc:11%  \tVal_kappa : -0.025 \n",
            "Epoch: 183 \tTraining Loss: -1.452 \tTrain_Accu: 46%  \tValid_Acc:21%  \tVal_kappa : 0.027 \n",
            "Epoch: 184 \tTraining Loss: -1.435 \tTrain_Accu: 47%  \tValid_Acc:20%  \tVal_kappa : 0.103 \n",
            "Epoch: 185 \tTraining Loss: -1.506 \tTrain_Accu: 48%  \tValid_Acc:16%  \tVal_kappa : -0.045 \n",
            "Epoch: 186 \tTraining Loss: -1.576 \tTrain_Accu: 47%  \tValid_Acc:19%  \tVal_kappa : 0.040 \n",
            "Epoch: 187 \tTraining Loss: -1.305 \tTrain_Accu: 45%  \tValid_Acc:29%  \tVal_kappa : -0.019 \n",
            "Epoch: 188 \tTraining Loss: -1.345 \tTrain_Accu: 49%  \tValid_Acc:20%  \tVal_kappa : 0.039 \n",
            "Epoch: 189 \tTraining Loss: -1.394 \tTrain_Accu: 47%  \tValid_Acc:24%  \tVal_kappa : 0.130 \n",
            "Epoch: 190 \tTraining Loss: -1.342 \tTrain_Accu: 49%  \tValid_Acc:19%  \tVal_kappa : -0.077 \n",
            "Epoch: 191 \tTraining Loss: -1.550 \tTrain_Accu: 52%  \tValid_Acc:19%  \tVal_kappa : 0.021 \n",
            "Epoch: 192 \tTraining Loss: -1.494 \tTrain_Accu: 45%  \tValid_Acc:23%  \tVal_kappa : 0.000 \n",
            "Epoch: 193 \tTraining Loss: -1.380 \tTrain_Accu: 50%  \tValid_Acc:20%  \tVal_kappa : 0.095 \n",
            "Epoch: 194 \tTraining Loss: -1.489 \tTrain_Accu: 44%  \tValid_Acc:26%  \tVal_kappa : -0.050 \n",
            "Epoch: 195 \tTraining Loss: -1.455 \tTrain_Accu: 49%  \tValid_Acc:33%  \tVal_kappa : 0.107 \n",
            "Epoch: 196 \tTraining Loss: -1.388 \tTrain_Accu: 51%  \tValid_Acc:19%  \tVal_kappa : 0.146 \n",
            "Epoch: 197 \tTraining Loss: -1.441 \tTrain_Accu: 49%  \tValid_Acc:27%  \tVal_kappa : 0.248 \n",
            "Epoch: 198 \tTraining Loss: -1.425 \tTrain_Accu: 51%  \tValid_Acc:13%  \tVal_kappa : 0.109 \n",
            "Epoch: 199 \tTraining Loss: -1.426 \tTrain_Accu: 49%  \tValid_Acc:26%  \tVal_kappa : 0.141 \n",
            "Epoch: 200 \tTraining Loss: -1.485 \tTrain_Accu: 50%  \tValid_Acc:19%  \tVal_kappa : 0.032 \n",
            "Epoch: 201 \tTraining Loss: -1.403 \tTrain_Accu: 48%  \tValid_Acc:19%  \tVal_kappa : 0.219 \n",
            "Epoch: 202 \tTraining Loss: -1.238 \tTrain_Accu: 50%  \tValid_Acc:20%  \tVal_kappa : 0.027 \n",
            "Epoch: 203 \tTraining Loss: -1.323 \tTrain_Accu: 41%  \tValid_Acc:19%  \tVal_kappa : 0.059 \n",
            "Epoch: 204 \tTraining Loss: -1.454 \tTrain_Accu: 49%  \tValid_Acc:23%  \tVal_kappa : 0.013 \n",
            "Epoch: 205 \tTraining Loss: -1.374 \tTrain_Accu: 48%  \tValid_Acc:27%  \tVal_kappa : 0.215 \n",
            "Epoch: 206 \tTraining Loss: -1.434 \tTrain_Accu: 50%  \tValid_Acc:24%  \tVal_kappa : 0.078 \n",
            "Epoch: 207 \tTraining Loss: -1.492 \tTrain_Accu: 51%  \tValid_Acc:26%  \tVal_kappa : 0.167 \n",
            "Epoch: 208 \tTraining Loss: -1.473 \tTrain_Accu: 53%  \tValid_Acc:14%  \tVal_kappa : -0.117 \n",
            "Epoch: 209 \tTraining Loss: -1.491 \tTrain_Accu: 47%  \tValid_Acc:27%  \tVal_kappa : 0.038 \n",
            "Epoch: 210 \tTraining Loss: -1.341 \tTrain_Accu: 47%  \tValid_Acc:21%  \tVal_kappa : 0.095 \n",
            "Epoch: 211 \tTraining Loss: -1.396 \tTrain_Accu: 48%  \tValid_Acc:24%  \tVal_kappa : 0.118 \n",
            "Epoch: 212 \tTraining Loss: -1.566 \tTrain_Accu: 54%  \tValid_Acc:23%  \tVal_kappa : 0.175 \n",
            "Epoch: 213 \tTraining Loss: -1.456 \tTrain_Accu: 49%  \tValid_Acc:26%  \tVal_kappa : 0.101 \n",
            "Epoch: 214 \tTraining Loss: -1.342 \tTrain_Accu: 48%  \tValid_Acc:31%  \tVal_kappa : 0.272 \n",
            "Epoch: 215 \tTraining Loss: -1.425 \tTrain_Accu: 50%  \tValid_Acc:19%  \tVal_kappa : 0.124 \n",
            "Epoch: 216 \tTraining Loss: -1.516 \tTrain_Accu: 45%  \tValid_Acc:20%  \tVal_kappa : 0.150 \n",
            "Epoch: 217 \tTraining Loss: -1.355 \tTrain_Accu: 46%  \tValid_Acc:27%  \tVal_kappa : 0.238 \n",
            "Epoch: 218 \tTraining Loss: -1.452 \tTrain_Accu: 48%  \tValid_Acc:26%  \tVal_kappa : 0.050 \n",
            "Epoch: 219 \tTraining Loss: -1.381 \tTrain_Accu: 50%  \tValid_Acc:21%  \tVal_kappa : 0.277 \n",
            "Epoch: 220 \tTraining Loss: -1.484 \tTrain_Accu: 51%  \tValid_Acc:23%  \tVal_kappa : 0.180 \n",
            "Epoch: 221 \tTraining Loss: -1.506 \tTrain_Accu: 50%  \tValid_Acc:24%  \tVal_kappa : 0.018 \n",
            "Epoch: 222 \tTraining Loss: -1.365 \tTrain_Accu: 50%  \tValid_Acc:23%  \tVal_kappa : 0.041 \n",
            "Epoch: 223 \tTraining Loss: -1.452 \tTrain_Accu: 50%  \tValid_Acc:20%  \tVal_kappa : 0.050 \n",
            "Epoch: 224 \tTraining Loss: -1.394 \tTrain_Accu: 52%  \tValid_Acc:27%  \tVal_kappa : 0.135 \n",
            "Epoch: 225 \tTraining Loss: -1.326 \tTrain_Accu: 46%  \tValid_Acc:24%  \tVal_kappa : 0.278 \n",
            "Epoch: 226 \tTraining Loss: -1.528 \tTrain_Accu: 53%  \tValid_Acc:30%  \tVal_kappa : 0.205 \n",
            "Epoch: 227 \tTraining Loss: -1.233 \tTrain_Accu: 45%  \tValid_Acc:17%  \tVal_kappa : -0.038 \n",
            "Epoch: 228 \tTraining Loss: -1.398 \tTrain_Accu: 50%  \tValid_Acc:11%  \tVal_kappa : -0.052 \n",
            "Epoch: 229 \tTraining Loss: -1.342 \tTrain_Accu: 43%  \tValid_Acc:20%  \tVal_kappa : 0.120 \n",
            "Epoch: 230 \tTraining Loss: -1.432 \tTrain_Accu: 54%  \tValid_Acc:21%  \tVal_kappa : 0.007 \n",
            "Epoch: 231 \tTraining Loss: -1.550 \tTrain_Accu: 51%  \tValid_Acc:16%  \tVal_kappa : 0.113 \n",
            "Epoch: 232 \tTraining Loss: -1.504 \tTrain_Accu: 52%  \tValid_Acc:29%  \tVal_kappa : 0.045 \n",
            "Epoch: 233 \tTraining Loss: -1.404 \tTrain_Accu: 54%  \tValid_Acc:16%  \tVal_kappa : 0.012 \n",
            "Epoch: 234 \tTraining Loss: -1.377 \tTrain_Accu: 48%  \tValid_Acc:20%  \tVal_kappa : -0.029 \n",
            "Epoch: 235 \tTraining Loss: -1.451 \tTrain_Accu: 51%  \tValid_Acc:19%  \tVal_kappa : 0.137 \n",
            "Epoch: 236 \tTraining Loss: -1.436 \tTrain_Accu: 46%  \tValid_Acc:31%  \tVal_kappa : 0.145 \n",
            "Epoch: 237 \tTraining Loss: -1.470 \tTrain_Accu: 54%  \tValid_Acc:23%  \tVal_kappa : 0.135 \n",
            "Epoch: 238 \tTraining Loss: -1.496 \tTrain_Accu: 49%  \tValid_Acc:26%  \tVal_kappa : 0.199 \n",
            "Epoch: 239 \tTraining Loss: -1.515 \tTrain_Accu: 50%  \tValid_Acc:29%  \tVal_kappa : 0.143 \n",
            "Epoch: 240 \tTraining Loss: -1.492 \tTrain_Accu: 49%  \tValid_Acc:26%  \tVal_kappa : 0.071 \n",
            "Epoch: 241 \tTraining Loss: -1.423 \tTrain_Accu: 52%  \tValid_Acc:20%  \tVal_kappa : 0.068 \n",
            "Epoch: 242 \tTraining Loss: -1.464 \tTrain_Accu: 50%  \tValid_Acc:19%  \tVal_kappa : 0.013 \n",
            "Epoch: 243 \tTraining Loss: -1.500 \tTrain_Accu: 53%  \tValid_Acc:14%  \tVal_kappa : 0.033 \n",
            "Epoch: 244 \tTraining Loss: -1.486 \tTrain_Accu: 49%  \tValid_Acc:20%  \tVal_kappa : 0.025 \n",
            "Epoch: 245 \tTraining Loss: -1.521 \tTrain_Accu: 50%  \tValid_Acc:24%  \tVal_kappa : 0.020 \n",
            "Epoch: 246 \tTraining Loss: -1.539 \tTrain_Accu: 50%  \tValid_Acc:17%  \tVal_kappa : 0.087 \n",
            "Epoch: 247 \tTraining Loss: -1.356 \tTrain_Accu: 52%  \tValid_Acc:20%  \tVal_kappa : 0.177 \n",
            "Epoch: 248 \tTraining Loss: -1.518 \tTrain_Accu: 52%  \tValid_Acc:26%  \tVal_kappa : 0.160 \n",
            "Epoch: 249 \tTraining Loss: -1.569 \tTrain_Accu: 51%  \tValid_Acc:21%  \tVal_kappa : 0.000 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-28 00:37:08,214]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {}. Best is trial 4 with value: 0.1.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 250 \tTraining Loss: -1.544 \tTrain_Accu: 54%  \tValid_Acc:20%  \tVal_kappa : 0.022 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['drive/My Drive/DL_project/optimise_valid_NNI.torch']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZZSvkJVLwEo"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "tGFmxqRwL_Cl",
        "outputId": "15804ad7-f077-4bf0-f046-683306a4122c"
      },
      "source": [
        "# Test_set run of single dataset\n",
        "\n",
        "#torch.manual_seed(32)\n",
        "\n",
        "testset = torch.utils.data.TensorDataset(dataTensor[395:], labelsTensors_NNI[395:])\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=70, shuffle=False)\n",
        "\n",
        "model = Network_drop_bn()\n",
        "\n",
        "checkpoint = torch.load(\"drive/MyDrive/DL_project/check_valid_NNI_kappa_loss.torch\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#model.state_dict()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_correct = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in testloader:\n",
        "     \n",
        "     output = model(images)\n",
        "     preds = output.argmax(dim=1)\n",
        "     print(preds)\n",
        "     print('labels', labels)\n",
        "#      print('preds',preds.argmax(dim=1) )\n",
        "     test_correct += output.argmax(dim=1).eq(labels).int().sum().item()\n",
        "\n",
        "     test_accuracy = test_correct/len(testloader.dataset)*100\n",
        "     \n",
        "     print('correct :', test_correct )\n",
        "     print(\"test_Accuracy % :\", round(test_accuracy, 1) )\n",
        "     #qwd = Qwk_metric(output, labels).item()\n",
        "     #qwd_c = cohen_kappa_cont(output, labels).item()\n",
        "     kappa = cohen_kappa_score(preds, labels,weights='quadratic' )\n",
        "     #print('qwd', qwd)\n",
        "     print('kappa', kappa)\n",
        "     #print('qwd_c', qwd_c)\n",
        "     #print('coff', quadratic_kappa_coefficient(preds, labels))\n",
        "     #print('qua', quadratic_kappa(preds, labels))\n",
        "      \n",
        "     cf_matrix = confusion_matrix(labels, preds)\n",
        "     print(cf_matrix)\n",
        "     y_true = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     y_pred = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n",
        "     #data = confusion_matrix(y_true, y_pred)\n",
        "     df_cm = pd.DataFrame(cf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
        "     df_cm.index.name = 'Actual'\n",
        "     df_cm.columns.name = 'Predicted'\n",
        "     plt.figure(figsize = (10,7))\n",
        "     sn.set(font_scale=2.0)#for label size\n",
        "     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25})# font size\n",
        "\n",
        "  \n",
        "     # confusionStack = torch.stack((labels, preds), dim=1)\n",
        "     # confusionMatrix = torch.zeros(5, 5, dtype=torch.int64)\n",
        "     # for p in confusionStack:\n",
        "     #     tl, pl = p.tolist()\n",
        "     #     confusionMatrix[tl, pl] = confusionMatrix[tl, pl] + 1\n",
        "     # plt.figure(figsize=(10,10))\n",
        "     # plot_confusion_matrix(confusionMatrix.cpu(), ('0', '1', '2', '3', '4'))\n",
        "     # plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2, 2, 0, 3, 1, 1, 3, 2, 1, 1, 0, 0, 4, 1, 3, 2, 0, 1, 1, 0, 0, 0, 0, 0,\n",
            "        3, 3, 2, 4, 4, 4, 0, 1, 1, 1, 2, 0, 3, 4, 0, 0, 0, 1, 4, 0, 0, 0, 3, 2,\n",
            "        3, 2, 4, 4, 2, 0, 2, 1, 0, 3, 1, 4, 0, 3, 2, 0, 0, 1, 2, 1, 2, 0])\n",
            "labels tensor([0, 0, 0, 3, 2, 3, 2, 2, 2, 1, 0, 0, 0, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 2,\n",
            "        3, 1, 1, 2, 3, 2, 2, 2, 3, 1, 0, 0, 4, 4, 4, 4, 2, 1, 3, 3, 2, 0, 1, 4,\n",
            "        4, 4, 3, 3, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0])\n",
            "correct : 24\n",
            "test_Accuracy % : 34.3\n",
            "kappa 0.3562857463272402\n",
            "[[12  1  5  1  1]\n",
            " [ 3  6  3  2  0]\n",
            " [ 5  6  3  3  3]\n",
            " [ 1  2  0  2  4]\n",
            " [ 2  0  2  2  1]]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAHMCAYAAAANjAYpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1gU1/oH8O/uAtI7UuwFRBCU2KOmqNcQRGNPrBg0uclVb+K1i1djokZNoin+yNUklhhiYgpYYiN2jRETK6CIXUFApCpt2Z3fH0SEUBd3drZ8P/fZ51lnzsy8zJ08vLznzDkyQRAEEBEREZHWyaUOgIiIiMhYMdEiIiIiEgkTLSIiIiKRMNEiIiIiEgkTLSIiIiKRMNEiIiIiEomZ1AEQERERieXatWs4evQoLly4gPj4eNy4cQOCIOCTTz5BcHBwlfZKpRJ//PEHDh8+jLi4ONy4cQMlJSVwcnJCUFAQxo4di+7du9f7+ky0iIiIyGht2bIFX3/9db3bnzp1Cq+++ioAwM3NDV27doWVlRWuXr2KvXv3Yu/evfjXv/6Ft956q17nY6JFRERERsvHxweTJk1Chw4d0KFDB0RERCAuLq7G9jKZDC+88AImTJiALl26VNq3a9cuzJw5E5GRkejevTt69OhR5/WZaBEREZHRGjlypEbte/bsiZ49e1a7LyQkBMePH8ePP/6I7du31yvR4mB4IiIionry8/MDAKSnp9erPRMtIiIionq6ceMGgLLxW/XBRIuIiIioHu7du4fo6GgAwIABA+p1DMdoERERkcHIy8tDXl5ele329vawt7cX7bqlpaWYNWsW8vPz0bNnT/Tt27dexzHRAmAVNFXqEIza9UOrpQ7BJHx77rbUIRi9MR2bSR0CkVZ4OJjr9Hra/D27Mrwd1qxZU2X71KlTMW3aNK1d5+8WLVqEEydOwNPTEx988EG9j2OiRURERAYjLCwMQ4cOrbJdzGrWkiVL8OOPP8LNzQ0bN26s9/gsgIkWERERiU2mvSHhYncR/t3y5cuxefNmODs7Y+PGjWjZsqVGxzPRIiIiInHJZFJH0CArV67Ehg0b4OjoiA0bNqBt27Yan4NvHRIRERH9zYcffoivvvoKDg4O2LBhA3x9fRt0Hla0iIiISFxa7DrUhdWrV+OLL76Avb091q9fXz5JaUMw0SIiIiJxSdh1mJCQgMWLF5f/+8qVKwDKkqn169eXb9+6dSsAYP/+/fjf//4HAGjevDm++eabas/bunVrvP7663Ven4kWERERGa0HDx7g3LlzVbY/muH973Jzc8u/x8fHIz4+vtp23bp1Y6JFREREekDCrsPu3bsjKSmp3u2HDRuGYcOGae36TLSIiIhIXAb61qE2GNboNCIiIiIDwooWERERicvA3jrUJiZaREREJC52HRIRERGRtrGiRUREROJi1yERERGRSNh1SERERETaxooWERERiYtdh0REREQiYdchEREREWkbK1pEREQkLnYdEhEREYnEhBMt0/3JiYiIiETGihYRERGJS266g+GZaBEREZG42HVIRERERNrGihYRERGJy4Tn0WKiJTErS3P06eyNoPbNEOTbDEF+zdHc0xkAsOR/u7B07a4aj/Vyc0Doc4F4tqs3OrZrBq/GDgCA9Pt5iLtwA+t//g2HT13Wyc9hyIqKCnH29B+4fDERl5MScflSItLT7gIAJk5+E6++PkXiCI1D0vFYHNq4qs52A6cvQ1O/IB1EZHz4LIuP97iBTLjrkImWxLr4t8S2Nf/S+Lim7o5I2vUu5PLHD+/DwmLIIEPLJq5o2cQVo4K7YGPMb5jy3hao1YI2wzYqFxMuYM7bb0odhsmQyeSwtHOocb/CzFyH0RgXPsvi4z0mTTHR0gNZuQ9x9tJtnL14G2cv3cGKGcPg6VbzLyIAkMvlkMvlOHDyEqJ2xuHgySTcvZcLmUyGdq3c8e7UQRj0fEdMHPI07t7LxbuRv+jopzFMdvb28GnnB+927eHj2x5rVq9E1v1MqcMySjbOrhi7fJPUYRgtPsvi4z1uAHYdklSOn7mCJs/NqbTtvX8PrvO4nPwC9By9HGcv3am0XRAEXLqWhlH/+QIxa97EC738MXXM81jx5V4Ul5RqNXZjEdipM3b++lulbev+72OJoiFqOD7L4uM9biAT7jo03Z9cTzS0Sy/vQVGVJOvvvo75HQBgZ2MJ31YeDbqOKVAoFFKHQKQVfJbFx3vcQDKZ9j4GhomWESsqUZZ/Vyj4fzUREZGusevQiD3TxRsAUFyiRPLNDImjISpTlJ+Ln96bhpz0OxDUalg7OMO9TXu07xMMr3aBUodHRGIw4a5DJlpGqoWXCyaP6A0A+HHfaeQ/LJI4IqIypSXFyLx1BY2sbaFUFSE/Mw35mWm4cvIg2vX6B54Z/xbk7J4hMi4G2OWnLUaTaB0+fBjZ2dkYMmSI1KFIzrKROaI+mAQbq0a4l52P/366XeqQiGDt6IzOg8ai1VO94OjeBApzC6jVKmRcS8If279BysUzSDoeCzMLS/Qeo/mUJ0RE+shoanmRkZGYN2+e1GFITqGQY9Oyiejs1xwlylK8On8T7t7LlTosIjTz74wug8fBpWkrKMwtAAByuQIebf0w8O0laNmpJwAg8dAvyE1PkTJUItI2mVx7HwNjeBFTjeRyGTYuDcPgvh2hVKowcf5G7P/9ktRhEdVJJpejx8jJAABBUOPmuZMSR0REWsW3DsnQyeUybFgahhEvdEZpqQrhCzYh+tezUodFVG8Ojb1gaWsPAMjLTJM4GiIi7dC7MVpvvPFGg467fv26liMxHHK5DBuXTcTI8iTra/y477TUYREREZUxwC4/bdG7ROvQoUOQyWQQBM0n8pQZYEnxScnlMmxaNrFCJetr/LD3T6nDItJYbkYqih7kAQDsXN0ljoaItIqJlv6wsrJCUVERFi9eDAsLi3ofFxkZiTt3ap8p3dg8qmSNeKEzlMqy7kJWskgfCYJQ6x9CgiDg9x+/AlC26HSLwO66Co2ISFR6l2j5+vri7Nmz8PPzQ0BAQL2P++677ww20XK0s6o0c7v8r19I1pbmcHG0Kd9eVKzEw8KSsjZ/jcka+VeSNXH+Rvz86xndBm5E8vNyoVKry/+t/ut7UVERcnKyy7dbWDSCtbW1zuMzdA/uZyB27TL49n4BTf2CYOfqUVa5VquRcT0Jf+yIwp2Eskps+2dfhKNHU4kjNlx8lsXHe9wAJtjj9IhMaEgfnYiWLVuGzZs3Y9GiRXjllVfqfdzLL7+M8+fP4+LFixpf0ypoqsbHaNOlXxajhZdLne02b/8dry/6BgDQ66k2+PWr6QCAEmUpsnILaj121gc/Slbtun5otSTX1cTLLw1A2t3UOtsFD3wJ8xYt1UFEmvv23G2pQ6hRfmY6vp03sfzfCjNzmFtaQVlUCFXp46Wi9H3C0jEdm0kdQp2M4VnWd8Zwjz0czHV6PauX1mrtXIXb/qm1c+mC3lW0AgICIAgC4uPjNTrO1dUVnp6eIkWlf+QV+rstzM3g4Wpfa3vLRrr9j4qoIit7R/Qa/SbSr17E/dvXUPggFyUFD6Aws4Cdqwfc27SHb+8B8GjrL3WoRERapXcVrcLCQty8eRM2NjZo1kw3fz1KXdEydoZQ0TIG+lzRMhaGUNEiqg+dV7SGrNPauQpjXtfauXRB7ypaVlZW8PX1lToMIiIi0ha+daj/BEFATk4OVCoVHBwcYG7OrjAiIiLSb3qdaOXk5CAqKgoHDhxAUlISVCoVAEAul6N169bo27cvxo4di8aNG0scKREREdXIhN861NtaXmxsLAYMGIA1a9YgISEBpaWlEAQBgiBApVIhOTkZ69atwwsvvICffvqp0rGCICAxMVGiyImIiKgimUymtY+h0cuK1u7duzFjxgyo1Wr4+PhgyJAhCAgIgIuLCwRBQFZWFs6fP4+YmBgkJydjwYIFUKlUGDVqFJRKJWbOnAlvb2/4+flJ/aMQERGRCdO7RCsrKwsREREAgIiICIwfP75KmzZt2qBr166YNGkSNm3ahBUrVmDp0qXo3Lkzli9fjmPHjsHHx0fXoRMREVE1DLESpS16l2ht3rwZBQUFmDFjRrVJ1t+FhYWhuLgYq1atwogRI1BYWIgWLVpgxIgROoiWiIiI6mS6eZb+jdE6cuQIHB0dER4eXu9jwsPD4eDggMLCQnh7eyMqKgru7lyUloiIiKSld4nWnTt30KlTJyg0WILDzMwMQUFBkMlk2Lx5M1xdXUWMkIiIiDTBwfB6pKCgADY2NnU3/BsbGxsoFAo4OjqKEBURERE1lCEmSNqid4mWk5MTUlJSND4uNTUVzs7OIkREREREhuratWs4evQoLly4gPj4eNy4cQOCIOCTTz5BcHBwrcfu2LEDW7ZsQVJSEtRqNVq1aoXhw4dj9OjRkMvr1ymod4mWv78/jhw5gtTUVHh5edXrmJSUFJw/fx7PPPOMyNERERGRpqSsaG3ZsgVff/21xsctXrwY3377LRo1aoSePXvCzMwMJ06cwLvvvosTJ07g008/rVeypXdjtEJCQqBSqTB//nyUlJTU2b6kpATz58+HWq1GSEiIDiIkIiIiTUg5RsvHxweTJk3C6tWrERsbi27dutV5zN69e/Htt9/Czc0N27dvx9q1a/F///d/2LdvH9q0aYPY2Fhs3ry5XtfXu0QrNDQUfn5+OHnyJMaPH1/rDO/x8fEYN24c4uLi0L59e4SGhuowUiIiItJ3I0eOxOzZsxESEoLmzZvX65i1a9cCAGbOnImWLVuWb3d1dcU777wDAPjiiy+gVqvrPJfedR3KZDJERkZizJgxOHfuHIYPH462bdsiMDCw/G3CzMxMnDt3DlevXoUgCPD09ERkZKRJD7YjIiLSWwb06zktLQ0JCQkwNzevdgxXt27d4O7ujvT0dJw9exZPPfVUrefTu0QLADw8PBAdHY3Fixdjz549SE5ORnJycqVEShAEyOVyBAcHY+HChXBycpIwYiIiIqqJIRVCHvWkeXt7w9LSsto2AQEBSE9Px8WLFw0z0QIABwcHrFq1CtOnT8fBgweRkJCArKwsAGVvJvr7++P555+vdxmQiIiIDF9eXh7y8vKqbLe3t4e9vf0Tn//OnTsAUOsLeZ6enpXa1kZvE61HmjVrhgkTJkgdBhERETWQNitamzZtwpo1a6psnzp1KqZNm/bE5y8oKAAAWFlZ1djm0XyfDx8+rPN8ep9oERERkWHTZqIVFhaGoUOHVtmujWqWGJhoERERkcHQVhdhTaytrQEAhYWFNbZ5VMmqz0o2TLSIiIhIVIY0GL5JkyYAylacqUlaWlqltrXRu3m0iIiIyMjItPgRmZ+fHwAgOTkZRUVF1ba5cOECAKB9+/Z1no+JFhEREdFfPD094e/vD6VSiT179lTZHxcXh7S0NLi5uSEoKKjO8zHRIiIiIlFJuQRPQ7z++usAgA8//BA3b94s337//n0sXrwYAPDaa6/Va61DjtEiIiIiUUk5RishIaE8OQKAK1euAABWr16N9evXl2/funVr+ffg4GCMHj0aW7ZswaBBg/D000+XLyr94MED9O/fH+PGjavX9ZloERERkdF68OABzp07V2X7jRs3aj3unXfeQefOnREVFYW4uDio1Wq0bt0aw4cPx+jRo+tVzQKYaBEREZHIpKxode/eHUlJSQ06dtCgQRg0aNATXZ+JFhEREYnLcGZ30DoOhiciIiISCStaAA78sETqEIza9XsP8c2Fu1KHYfTGBXhKHYLRyy4okToEo9fKre6ZtsnwGNKEpdrGRItExySLiMi0mXKixa5DIiIiIpGwokVERESiMuWKFhMtIiIiEpUpJ1rsOiQiIiISCStaREREJC7TLWgx0SIiIiJxseuQiIiIiLSOFS0iIiISlSlXtJhoERERkaiYaBERERGJxXTzLI7RIiIiIhILK1pEREQkKnYdEhEREYnElBMtdh0SERERiYQVLSIiIhKVKVe0mGgRERGRqEw50WLXIREREZFIWNEiIiIicZluQYuJFhEREYmLXYdEREREpHWsaBEREZGoTLmixUSLiIiIRGXCeRa7DomIiIjEwooWERERiYpdh0REREQiMeE8i12HRERERGJhRUvP3bhyCWfjjuFG8iWkpd5Cfm42igoewtLaBp5NWyKwy9PoO3AYbO0cpA7VKFiaydGnlRMCPW3hZmsBSzM5HpSocO9BCZIzC3DwahYKlWqpwzRIfJbFl5ebg1O/Hcb5P+NwNfkS7qXfhUqlgoODE9q080Pf4FD06NNX6jCNwsOHD/D1xg34NXYfUu7cgUIhR4sWLfFCyECMGTMO5hYWUoeoV0y561AmCIIgdRBSO3ElR+oQarT58w+wf+eP5f82t2gEhUKBosKC8m129o54a+GHaNs+QIoQ6/TNhbtSh1Av3q7WCO/aBPaWZX9/KFVqKFUCrC0U5W3eP3ANd3KLpQqxVuMCPKUOoVbG8Cw72phLHUKthvfrBpWqtPzfFhaNIJfLUVRUWL7tqe69MGfxSjSytJIixDq1crOROoQ6paamYNLE8UhNSQEAWFpZQa1SoaSkBADg294PX3y1EfYO+vtHg6WOyyy+c/dq7VyXlr+gtXPpAitaeq61jz9cwz3h7d8Rnk1bwsbWDgBQVFiAP387hO+++hT5udn4dMksLF/3I6xtbKUN2EC1drbCv3o2g4WZHGdS8rDv8n3cyikCAJgrZPC0a4RATztWs54An2XxqVSl8G7fAX2DByGoa094eDUFAKTfTcUPm7/Er7ticPrkcUR+tBTTI5ZIHK1hKi0txb+nvIHUlBS4ublhyfsr0aPn01Cr1di3dw/eXbQAly4mYv7cWVjz+TqpwyU9wERLz/XqF1Ltdksra/TqFwIHJ2d8+N+3kJeTjbNxx/D088E6jtDwmStkmNDZCxZmchy6moUfzqdX2q9UCbiVU1SeeFHD8FkW33ur1yIgqGuV7e6eXpg6eyEUCgX27vgJh2N3YdxrU+HW2EOCKA3b9m3RSL58GQDw0cefoWOnIACAXC5H8IshENRqzJ09A0ePHMbJ30+ge4+eUoarN+Ry0+065GB4A9fGt0P59+zMDAkjMVzdmznAzdYCuUWliI7nPZQKn+UnV12SVVH/gUPKv19NShQ7HKO0Y1sMAKBrt+7lSVZFwSED0aRp00ptqeytQ219DA0TLQOXFH+2/HtjzyYSRmK4ujUvG0dxJiUPpWqTH7IoGT7L4qs4QFutYje4pgoLC3H2zGkAQO8+z1TbRiaToVevPgCAE78d11lspL/YdWiAlMoS5GRl4lzccUR/UzYGwN2rKTp17yNxZIbHTC5Dc0dLAMCtnCI4WZkhuJ0r/N1tYWdphoISFW5mF+Lo9RwkpD+QOFrjw2dZt+LP/ln+vUXrthJGYpiuX7sKtbosQW3r7V1ju0f7MjPvITcnBw6OjjqJT5+Z8luHTLQMyOQhfVCqLKmy3dsvEG/Meg/m5nydWFPO1uYwV5QVdl2tzTGyX2tYmSugVKlRUqqGvaUZAjztEOBph+M3svHtmTSJIzYOfJZ170F+Pn6KWg8A8AsMQpPmLaUNyABlZDzu0m7c2L3Gdo3dH+/LuJfBRAuG2eWnLXqdaJWWliInJwcODg4wN6/9teqcnBwUFBTAy8tLR9HpnoOTC5QlxSguKkTxX69rtw/sjFHh0+DCQa0NYm3+uPc82NcVBUoVvjx5B+fu5kMtAE5WZhjWwR1PNbVHr5ZOSMsvwYErWRJGbBz4LOuWWq3Gx8sWIPt+JiwsGuH1t+ZIHZJBKnj4sPy7ZS3TY1TcV/EYMk16mWjl5eXh/fffx+7du1FcXAxzc3M8//zzmD59Olq2bFntMStWrMC2bduQmGi8Azw/2vB4YGVeThaOH9iNnd9vxLvTX8Wgl1/FsPH/lDA6w1SxnC2XyRB1+i7O333cRZhdWIr1p1LQ2NYCTR0t8YKPCw5dzQKHcj0ZPsu69eVnH+CPE0cBAK+/PQct2/hIHBGZGlPuOtS7wfAlJSWYOHEiYmJiUFRUBEEQUFJSgr1792Lo0KHYuXNnjcea0tyr9o7OeHHYWMx492NAJsP279bjbNwxqcMyOMWljwcEpz8orpRkPSIA+PXKfQCAbSOz8jFdpB18lsW1IXI1dkV/DwAInzID/UOG1HEE1cTa5vFkqhUngf27ivsqHmPKZDKZ1j6GRu8SrS1btiAxMRFt27ZFVFQUzpw5g5iYGLz44osoLCzE7NmzERUVJXWYeqN1O3/4+HUEABzazVeJNZVTqCz/np5fdczQI2l5j/c5W+v37OCGis+y9m3838fYtnUzAGDim9MxeORYiSMybI0bNy7/npGRXmO7jPTH+xq7Na6xHZkGvUu0du/eDUtLS6xduxadO3eGlZUVfH19sXr1aixbtgwKhQJLlizBhg0bpA5Vbzi5uAEAMu7eljgSw1OgVCO7QrJVowp/RJlQ4VTn+Cxrz8bPVyPmu68BAGFvvIUhL4+XOCLD16p1G8jlZb82ryQn19ju0T5XVzcOhP8L59HSI1euXEGnTp2qHdQ+bNgwrFu3DpaWlli5ciXWrePyBgCQkfZovS2WqBviUkbZYFUPu0Y1tvG0e/wW3P2CeiRm1CB8lrVjQ+RqxHxfVskKe+MtDH0lTOKIjIOVlRU6BT0FADh+7Gi1bQRBwG+/lXV993y6l85i03fsOtQjRUVFcHFxqXF/z5498cUXX8DKygqrV69GZGSkDqPTLbVKVee4s8Szp3D9ctkLAL4BT+kiLKNz4mbZouKNbS0Q6Fl1fT0ZgH7eZc9kdqESt7kUj8b4LOvOhsjVlboLmWRp16CXysa4nYo7ifPnz1XZv2/vbty5fbtSWzJtepdoOTo6Ij295r5vAOjSpQu+/PJLWFlZ4bPPPsNnn32mo+h0635mOhZOG4+Du39Gxt2USr+o7t9Lx86tm/DJe7MgCAJs7OwxYMhoCaM1XFfvF+J0Sh4AYGyQJzp52eHRslxOVmZ4tWsTNHUoGwC/I/Ee2HOoOT7LulFxTFb4lP+wu1AEg18aCm8fHwiCgBlvT8PJ308AwF+LSu/Gu4v+C6Bs5niuc/iYKXcdygQ9e1Vv8uTJ+OOPP3DixAlYWdU8TwkAnD17FpMnT8bDhw9hb2+PvLw8XLx4UeNrnriS09BwRXUvPRWzwoeW/9vMzBxW1jYo+Wv+oUfc3L0wNWI5WrRpJ0WYdfrmwl2pQ6iThUKGfz3dDN6uZV1WSpUaJSoBNhaK8ja/XLyHXZcypQqxTuMCPKUOoUbG8iw72ujvixD30u/itZcHAihb4NjewanW9kNeHo8hr0zQRWgaaeWm/93GKSl3MPnVCUhNedTVbQVBrUZxcTEAwLe9H774aiPsHRykDLNWljqe3Knzewe1dq4///u8xsekpaXhiy++wLFjx3D37l0IggBPT0/06NEDr732Gpo1a6a1+P5O7+bR6t27N44fP449e/Zg6NChtbbt1KkT1q9fj0mTJiE3N9cg+25r4+TshinzluHShdO4lpSA7KxMPMjNgVwhh4ubB5q18kZQj2fQ87kBsGjEKQeeRIlKwCdHb6FnC0d0a24PT/tGsDRTILtQiauZBTh0LRvXs2p+nZtqx2dZfOoKk7up1WrkZN+vtX1hYYHYIRmtJk2a4sfo7di0YT32/xqLlDt3oDAzQ5u2bREcEooxY8ZVWleSpJWYmIiwsDDk5eXBw8MDvXv3BgDEx8fj+++/x44dO/DVV1/hqafEGbKgdxWt69evIywsDG3atKn3m4UXLlzApEmTkJ+fb1QVLWNhCBUtY6DPFS1joc8VLWNhCBUtY6DrilaXJdqraP2xQLOK1iuvvIIzZ85g1KhRWLhwYflKM0qlEosWLcJPP/2Edu3aYfv27VqLsSK9S7SkwERLXEy0dIOJlviYaImPiZZu6DrR6rr0kNbOdSriuXq3LS4uRmBgIADg6NGjleZCA8rWr+zTp2wR+7Nnz9Y5ZKkh9G4wfE0EQUB2djYyMzOhVPL1eiIiIqqdXC6HmVndWaW1tTUsLcUZtqB3Y7QqysnJQVRUFA4cOICkpCSoVCoAZTeudevW6Nu3L8aOHVslQyUiIiL9IdUQanNzc/To0QPHjh3DZ599VqXr8JNPPgEADB8+XLRx3nrbdRgbG4uIiAjk5+fXOP+OTCaDpaUlFixYgOHDh5dvFwQBFy9ehJ+fX72uxa5DcbHrUDfYdSg+dh2Kj12HuqHrrsPu7x/W2rlOzntWo/a3b9/G5MmTcePGDXh4eKBDhw4AysZ35+XlYdSoUZg1a1Z5AqZtelnR2r17N2bMmAG1Wg0fHx8MGTIEAQEBcHFxgSAIyMrKwvnz5xETE4Pk5GQsWLAAKpUKo0aNglKpxMyZM+Ht7V3vRIuIiIgMQ15eHvLy8qpst7e3h729fZXtzZo1w5YtWzBnzhwcOXIEaWlp5fs6dOiALl26iJZkAXqYaGVlZSEiIgIAEBERgfHjq06416ZNG3Tt2hWTJk3Cpk2bsGLFCixduhSdO3fG8uXLcezYMfj4+Og6dCIiIqqGNnvlNm3ahDVr1lTZPnXqVEybNq3K9tOnT2PatGmwtbVFZGQkgoKCyrevWLEC06ZNw7Rp0zB16lTtBVmB3iVamzdvRkFBAWbMmFFtkvV3YWFhKC4uxqpVqzBixAgUFhaiRYsWGDFihA6iJSIiorpoc/xTWFhYtfNsVlfNysvLw5QpU1BYWIjvvvuu0sSk/fv3h7e3NwYPHozPP/8coaGhaNmypdbifETv3jo8cuQIHB0dER4eXu9jwsPD4eDggMLCQnh7eyMqKgru7u4iRklERERSsLe3R9OmTat8qku0Dh06hKysLHTs2LHa2d9btGiBwMBAlJaWIi4uTpR49S7RunPnDjp16gSFQlF347+YmZkhKCgIMpkMmzdvhqurq4gREhERkSakWuvw7t2yl7Hs7OxqbPMoQcvJEefFOL3rOiwoKICNjeZvndjY2EChUMDR0VGEqIiIiKihpFoi79H0TwkJCVAqlVUGvSuVSiQkJAAAmjZtKkoMelfRcnJyQspfC3VqIviUyuUAACAASURBVDU1Fc7OziJERERERIbomWeegZWVFVJTU/H++++jpKSkfF9JSQmWLFmCu3fvwsHBoXyGeG3Tu4qWv78/jhw5gtTUVHh5edXrmJSUFJw/fx7PPPOMyNERERGRpqSasNTFxQWLFi1CREQEoqKiEBsbC39/fwBli0rfu3cPFhYWWLZsWa3di09C7ypaISEhUKlUmD9/fqXMsyYlJSWYP38+1Go1QkJCdBAhERERaUImk2nto6mhQ4fihx9+wEsvvQRzc3McP34cx48fh6WlJUaMGIHo6Gj0799fhJ+6jN5VtEJDQ7FhwwacPHkS48ePx6JFi2qceDQ+Ph7vvvsuLly4gPbt2yM0NFTH0RIREZG+8/f3x8qVKyW5tt4lWjKZDJGRkRgzZgzOnTuH4cOHo23btggMDCx/mzAzMxPnzp3D1atXIQgCPD09ERkZKdlgOyIiIqqZKf9+1rtECwA8PDwQHR2NxYsXY8+ePUhOTkZycnKl/6MEQYBcLkdwcDAWLlwIJycnCSMmIiKimphwnqWfiRYAODg4YNWqVZg+fToOHjyIhIQEZGVlASh7M9Hf3x/PP/88mjdvLnGkRERERNXT20TrkWbNmmHChAlSh0FEREQNxK5DIiIiIpGYcJ7FRIuIiIjEZcoVLb2bR4uIiIjIWLCiRURERKIy4YIWEy0iIiISl9yEMy12HRIRERGJhBUtIiIiEpUJF7SYaBEREZG4+NYhEREREWkdK1pEREQkKrnpFrSYaBEREZG4TLnrkIkWgBOpWVKHYNTauDTC1fvFUodB9MRyHiqlDsHonXmYI3UIJqFnW0epQzAZTLRIdEyyiIhMmwkXtJhoERERkbhkMN1Mi28dEhEREYmEFS0iIiISFd86JCIiIhIJ3zqsRvv27bVyAZlMhsTERK2ci4iIiMiQ1JhoCYKglQto6zxERERkmEy4oFVzorV//35dxkFERERGSm7CmVaNiVaTJk10GQcRERGR0eFgeCIiIhKVCRe0mGgRERGRuPjWYQOkpqbizJkzyMjIQEFBQa2D3qdOndrQyxAREREZLI0TrfT0dCxatAhHjhyp841CQRAgk8mYaBEREZkwEy5oaZZo5efnY/z48bh9+zacnJwQFBSE/fv3w9LSEgMGDMD9+/dx9uxZPHz4EE5OTnjuuedECpuIiIgMBd86rKeNGzfi1q1bCAwMxJdffgl7e3v4+vrC1tYWK1euBAAUFhbi888/x7p162BmZob33ntPlMCJiIiI9J1GidaBAwcgk8kwe/Zs2NvbV9vGysoK//nPf6BUKrFx40Z07doVgwcP1kqwREREZHhMt54FyDVpfOvWLcjlcgQFBVXarlQqq7R97bXXAAA//PDDE4RHREREhk4mk2ntY2g0SrRUKhXs7OygUCjKt1lZWeHhw4dVBsY7OzvD3t4ely9f1k6kRERERAZGo0TL3d0dBQUFlbZ5eHhApVLh2rVrlbYXFRUhLy8PhYWFTx4lERERGSy5THsfQ6NRotWsWTMolUrcunWrfFunTp0AAN99912ltl9//TUEQUDz5s21ECYREREZKlPuOtRoMHzPnj1x7NgxHD16FGPHjgUAjB49GjExMfjmm29w8+ZNtG/fHklJSTh8+DBkMhmGDBkiSuBERERE+k6jRCs0NBTnzp3D/fv3y7cFBgZi5syZ+Oijj3DkyBEcPXq0fLzWgAEDEB4ert2IiYiIyKAYYCFKazRKtNzd3fHpp59W2T5p0iQ8++yz2Lt3L9LT02Fra4tevXqhV69eWguUiIiIDJMhdvlpi9YWlW7bti3atm2rrdMRERERGTytJVpERERE1THEtwW1hYkWERERiYpdh/U0YcIEjS8gk8mwadMmjY8jIiIiMnQaJVpxcXH1avcocxUEwaSzWG1IOh6LQxtX1dlu4PRlaOoXVGc7qp2lmRx9Wjkh0NMWbrYWsDST40GJCvcelCA5swAHr2ahUKmWOkyDdOPKJZyNO4YbyZeQlnoL+bnZKCp4CEtrG3g2bYnALk+j78BhsLVzkDpUg8V7LD7e44Yx5UxAo0Tr/fffr3V/fn4+Lly4gH379sHS0hLTpk2DjY3NEwVIZWQyOSxr+Q9XYWauw2iMk7erNcK7NoG9Zdl/FkqVGkqVACcrczhZmcPHzQbn7+bjTm6xxJEapqOxO7B/54/l/za3aARzi0Z4mJ+HKxfP48rF84jd9h3eWvgh2rYPkDBSw8V7LD7e44aRm3DRRSb8fZFCLbh58ybCw8Ph4OCALVu2oFGjRtq+hFatOnKt7kYSeVTRsnVpjLHLDbML9up9/U9MWjtbYVqv5rAwk+NMSh72Xb6PWzlFAABzhQyedo0Q6GmHEzdzcL+g6iLq+mBcgKfUIdTq+P5dyMvJgrd/R3g2bQkbWzsAQFFhAf787RC+++pT5Odmw97RCcvX/QhrG1tpAzZAvMfiM5Z73LOto06vN/n7eK2d68uXO2jtXLogymD4Fi1aYPHixZg8eTLWrl2Lf//732JchkgrzBUyTOjsBQszOQ5dzcIP59Mr7VeqBNzKKSpPvKhhevULqXa7pZU1evULgYOTMz7871vIy8nG2bhjePr5YB1HaPh4j8XHe9ww+lDQKioqwubNm7Fnzx7cvHkTSqUSLi4u6NChA8LCwtC5c2dRrqvRWoea6NWrFxo1aoRffvlFrEsQaUX3Zg5ws7VAblEpouMzpA7HZLXxffxXanYm/38QA++x+HiPqyf1Woe3b9/G4MGD8eGHHyI9PR3du3fHs88+C2dnZ+zfvx8nT57U8k/8mKjTO8jlcqSlpYl5CaIn1q152di3Myl5KFVrvSed6ikp/mz598aeTSSMxHjxHouP91j/FBQUIDw8HLdv38aMGTMwadIkKBSK8v3Z2dnIyckR7fqiJVqnT59GYWEhXFxcxLqESSnKz8VP701DTvodCGo1rB2c4d6mPdr3CYZXu0CpwzNYZnIZmjtaAgBu5RTBycoMwe1c4e9uCztLMxSUqHAzuxBHr+cgIf2BxNEaH6WyBDlZmTgXdxzR36wDALh7NUWn7n0kjsx48B6Lj/e4blJ2HX7++ee4desWxo0bh9dff73KficnJzg5OYl2fa0nWqWlpTh48CDef/99yGQy9OzZU9uXMEmlJcXIvHUFjaxtoVQVIT8zDfmZabhy8iDa9foHnhn/FuQVMnSqH2drc5grynrQXa3NMbJfa1iZK6BUqVFSqoa9pRkCPO0Q4GmH4zey8e0ZVmi1YfKQPihVllTZ7u0XiDdmvQdzcwsJojIuvMfi4z2uP6neOiwpKcHWrVsBABMnTpQkBo0SrX79+tW6v7i4GFlZWRAEAYIgwMnJCW+99VaDg1MqlVAoFJDLKw8lu3fvHo4dO4b79++jZcuW6NOnj96/2dhQ1o7O6DxoLFo91QuO7k2gMLeAWq1CxrUk/LH9G6RcPIOk47Ews7BE7zH/kjpcg2Nt/vjZCvZ1RYFShS9P3sG5u/lQC4CTlRmGdXDHU03t0aulE9LyS3DgSpaEERsHBycXKEuKUVxUiOKiQgBA+8DOGBU+DS6NPSSOzjjwHouP91j/JSQkICcnB+7u7mjWrBkSEhIQGxuLrKwsuLi4oFevXujSpYuoMWg0vYOvr2+92llYWKBfv374z3/+g2bNmmkc1LVr17Bo0SL8+eefUCgUePbZZ7Fo0SK4ublh3759mDdvHgoKCsrbe3p6Ys2aNfDz89P4WoB+T+9QG0Gtxr7Pl+DG2ROQyeR4+b11cHDXvzEB+jy9QytnK8x8tmX5v9f+fhvn71buIpQBmPt8KzR1tMSD4lLM250MfRzKpe/TO9QkLycLxw/sxs7vN6LgYT4Gvfwqho3/p9RhGRXeY/EZ2j3W9fQO//o5UWvnihxW/9/133//PRYuXIjAwEB06dIF69evr9Kmf//++OCDD2Btba21GCvSKNGqa2Z4hUIBe3t7tGzZEubmDZtAMysrC4MGDcL9+/crbe/YsSM++ugjhIaGwszMDF26dIGzszP++OMP3Lp1C25ubti9ezdsbTWfs8RQEy0AyM1IxXcRkwAAPUe+hsABwySOqCp9TrS87Bshol9rAED6g2K8G1v9s9C1mT0mdilLYj84dB03svVvqgdDTbQeuZaUgPdmToagVuPtRR+hU7feUodkdHiPxWco91jXidaU6ItaO9f7/ZogLy+vynZ7e3vY29tX2rZu3Tp89NFHMDc3h1KpRFhYGMaNGwdHR0ecOnUKixcvRnp6OoYMGYIVK1ZoLcaKNOo67NatmyhBVLRhwwbcv38fISEhmD17NhQKBT7++GP8/PPPWLhwIVxdXbFx40Y0bdoUAKBSqTBv3jzs2LED3333HSZPnix6jPrEobEXLG3tUfQgD3mZHD+kqZzCx5OPpudXHWvxSFre433O1uZ6mWgZutbt/OHj1xFJ8WdwaHeM3v6CMmS8x+LjPRbfpk2bsGbNmirbp06dimnTplXaplaXLZmmVCoxePBgzJ8/v3xfv3790LhxY4wcORLbtm3DlClT0Lx5c63Hq1GilZqaCoVCAXd393q1T09Ph0qlgpeXV72vcfjwYTg4OGDZsmWwtCx7G+ydd97BoUOHcOLECaxcubI8yQLKqmhz587Fvn37cPDgQZNLtOjJFCjVyC5UwsmqjgpshXGc2l9LgR5xcnEDAGTcvS1xJMaL91h8vMdVaXPSzrCwMAwdOrTK9r9XswBUWgZw1KhRVfYHBATA398f8fHxiIuLkz7R6tu3L9zc3HD06NF6tR89ejTS0tKQmFj/vtnbt2+jc+fO5UkWAJibmyMgIACHDx+utqrm7OwMPz8/XLtmuF2ADZWbkYqiB2UlVDvX+iXAVNmljIfo2cIRHnY1v1Dhaff47SF9XYLHGGSkpQAALK24RqpYeI/Fx3tcVUMnGq1OdV2ENalYmKn4/e9t4uPjkZmZqZX4/k7jJFPTpRE1bV9aWgoHh6qLJz+a46KmapqHhwfy8/M1upa+q+veCYKA33/8CkDZotMtArvrIiyjc+Jm2UR1jW0tEOhZdYyfDEA/77L54LILlbjNpXg0plap6nyeE8+ewvXLZX+U+QY8pYuwjArvsfh4jw1PxZfkapqUNDs7GwBEGwwv2hI8QNm6QgoN53ZydHQs/6ErquvhVqlUot0kqTy4n4Gfl76FxMO7kHfvbvk9ENRqpF+9iF2f/Bc3zvwGAGj/7Itw9Kg+W6faXb1fiNMpZVXBsUGe6ORlB/lff3w5WZnh1a5N0NShrMK6I/Ee2HOoufuZ6Vg4bTwO7v4ZGXdTKv33fP9eOnZu3YRP3psFQRBgY2ePAUNGSxitYeI9Fh/vccPJZdr7aMLd3R0dO3YEAJw4caLK/tzc3PJetw4dxFmsWrSZ4W/evIns7Gx4eGg2l4inpydu3bpVZfubb76JkSNH1njc7du3jXIW+ns3LuPejcsAAIWZOcwtraAsKoSq9HH3Vbte/0CvV96UKkSjsPnPVNg1UsDb1QavdW9aNmGpSoCNxeM/FH65eA8nb+VKGKVhu309GZvWlL3VY2ZmDitrG5T8NQfRI27uXpgasRyOzsb337Iu8B6Lj/e4YTRNkLTpjTfewJtvvom1a9eia9euCAgIAFA29+c777yD/Px8+Pv7IygoSJTr15po/frrr9i/f3+lbQ8ePMC8efNqPWleXh7+/PNPAED37pp1Z7Vv3x5bt25FWlpapSStRYsWaNGiRbXHZGdnIykpCS+88IJG19J3VvaO6DX6TaRfvYj7t6+h8EEuSgoeQGFmATtXD7i3aQ/f3gPg0dZf6lANXolKwCdHb6FnC0d0a24PT/tGsDRTILtQiauZBTh0LRvXswrrPhFVy8nZDVPmLcOlC6dxLSkB2VmZeJCbA7lCDhc3DzRr5Y2gHs+g53MDYNHIsu4TUhW8x+LjPW44bY7R0lTfvn0RHh6O9evXY/To0ejYsSMcHR1x/vx5ZGRkwN3dHatWrRItxloTrUuXLiE6OrrStqKioirbatK8eXONZ4YfMmQInJycUFhY/19qP/zwA1Qqleizu+qamUUjdOg7GB36DpY6FJMgAPjtZg5+uyne4qKmyszcHF1790PX3rWvLkENx3ssPt5jwzVnzhwEBQXhm2++wcWLF1FYWAgvLy+8+uqreP311+Hs7CzatWudsDQuLq7SJKVr1qyBtbU1wsPDaz6hTAZbW1t4e3ujW7duMDMTrXdSawx5wlJDoM8TlhoTQ5+wlIh0R9cTls7amaS1c30Q2k5r59KFWrOgbt26VZpO4VGiNXXqVNED+ztBEJCTkwOVSgUHB4cGzzxPREREuiVhz6HkNCo37d+/X+O3CJ9ETk4OoqKicODAASQlJUGlUgEA5HI5Wrdujb59+2Ls2LFo3LixzmIiIiIiqi+NEq0mTXS3YHFsbCwiIiKQn59fZWoHlUqF5ORkXLlyBV9//TUWLFiA4cOHl+8XBAEXL15s8CLTREREpD1yEy5paZRoJSQkYMWKFfD398ecOXNqbbtkyRJcvnwZ8+fPh6+vr0ZB7d69GzNmzIBarYaPjw+GDBmCgIAAuLi4QBAEZGVl4fz584iJiUFycjIWLFgAlUqFUaNGQalUYubMmfD29maiRUREpAdEnbRTz2n0s0dHR+PUqVPw9697OgEfHx/ExcUhJiZGo4CysrIQEREBAIiIiMD27dsRHh6Orl27onXr1mjTpg26du2KSZMmYceOHZg3bx5kMhmWLl2Kq1ev4l//+hf27dsn6aukRERERICGidbJkycBAM8880ydbR/NafX7779rFNDmzZtRUFCA6dOnY/z48XW2DwsLw9tvv43i4mKMGDECR48eRfPmzTFixAiNrktERETikMm09zE0GiVaaWlp9V7M0cHBAfb29rh7965GAR05cgSOjo61TiHxd+Hh4XBwcEBhYSG8vb0RFRVV45qIREREpFtymUxrH0OjUaKlVCqhVCrrbviX0tJSFBVptgDvnTt30KlTJ43ebjQzM0NQUBBkMhk2b94MV1dXja5JREREJAaNEi13d3cUFhbi2rW6J/i8du0aCgoK4ObmplFABQUFsLGx0egYALCxsYFCoYCjo24nYSMiIqLaseuwnrp37w5BEPDZZ5/V2fbTTz+FTCbTeK1DJycnpKSkaHQMAKSmpoo6hT4RERE1jFymvY+h0SjRCgsLg0KhwJ49ezBr1ixkZGRUaZORkYGZM2diz549kMvlCAsL0yggf39/XLhwAampqfU+JiUlBefPn6/X25BEREREuqLRPFpt2rTB3LlzsXTpUuzcuRO7d+9Gu3bt4OXlBaAs4bl8+XL5DO6zZs2Cj4+PRgGFhITg4MGDmD9/PtatWwcLC4ta25eUlGD+/PlQq9UICQnR6FpEREQkPkMcxK4tGs8hNn78eKxevRpubm4oLS1FQkICYmNjERsbi8TERJSWlqJx48ZYtWoVJk6cqHFAoaGh8PPzw8mTJzF+/HgkJibW2DY+Ph7jxo1DXFwc2rdvj9DQUI2vR0REROIy5TFaGlW0HnnxxRfxj3/8AydOnMC5c+eQmZkJAHB1dUXHjh3Rs2dPmJmVnfrBgwewtbWt97llMhkiIyMxZswYnDt3DsOHD0fbtm0RGBhY/jZhZmYmzp07h6tXr0IQBHh6eiIyMpKTlBIREZFeaVCiBZRNqdCnTx/06dOnyj5BEHDkyBHExMTg4MGDOHPmjEbn9vDwQHR0NBYvXow9e/YgOTkZycnJlRIpQRAgl8sRHByMhQsXwsnJqaE/ChEREYnIEAexa0uDE63qJCcnIzo6Gjt27EBmZiYEQWhwlcnBwQGrVq3C9OnTcfDgQSQkJCArKwtA2ZuJ/v7+eP7559G8eXNt/ghERESkZTKYbqb1xIlWdnY2du7ciejoaFy8eBFAWbXJzMwMPXr0KF+Kp6GaNWuGCRMmPGmYRERERDrXoESrtLQUBw8eRHR0NI4cOQKVSlVevXruuecQHByMvn37ws7OTtvxEhERkYFh12E9XbhwATExMfjll1+Qm5tbnlx16dIFp06dAgB88MEHGg1+JyIiIuPGRKsWGRkZ2LZtG2JiYnDt2jUIggAA8PHxwaBBgxAaGgpPT0/4+vqKHiwRERGRIak10Zo0aRJ+//13qNVqCIIALy8vDBw4EIMGDdJ4IlIiIiIyTaY8/VKtidbx48chk8kQGhqKl19+GV26dNFVXERERGQk2HVYh/379wMACgoK0KtXLygUClGDIiIiIjIGtS7Bs2bNGvTr1w8lJSXYsWMH/vnPf6J379547733cPr0aV3FSERERAaMS/DUoH///ujfv3+lubISExMRFRWFb7/9Fl5eXggNDeUag0RERFQjLipdBycnJ4wfPx4///wzdu7cifDwcLi6uiIlJQXr1q3D4MGDy9umpqaKFiwRERGRIalXolVR27ZtMXv2bBw+fBhffPEFgoODYWFhAaBsRviXXnoJQ4cORWRkJK5evar1gImIiMiwyGXa+xiaBi/BI5fLyxeVfvDgAX755RfExMTgzJkzuHjxIi5duoTPPvsMrVq1wq5du7QZMxERERkQE+451LyiVR1bW1u8/PLL2LJlC/bu3Ys33ngDnp6eEAQB169f18YliIiIiAzOEy8q/XctWrTA22+/jbfffhu///47tm3bpu1LaN2Yjs2kDsGoZReUSB2CSWjlZiN1CEbv+r2HUodg9BIy8qQOwUQ46vRqcphuSUvriVZFPXr0QI8ePcS8BBEREek5dh0SERERkdaJWtEiIiIiMsS3BbWFiRYRERGJihOWEhEREZHWsaJFREREojLhghYTLSIiIhIXuw6JiIiISOtY0SIiIiJRmXBBi4kWERERicuUu89M+WcnIiIiEhUrWkRERCQqmQn3HTLRIiIiIlGZbprFrkMiIiIi0bCiRURERKIy5Xm0mGgRERGRqEw3zWLXIREREZFomGgRERGRqGQy7X20YdWqVWjXrh3atWuHr776SjsnrQG7DomIiEhU+jS9w/nz5/Hll19CJpNBEATRr8eKFhEREZmEkpISzJ07Fy4uLujXr59OrslEi4iIiEQl1+LnSXzyySe4evUqFi9eDDs7uyc8W/0w0SIiIiJRyWQyrX0a6ty5c9iwYQNCQ0PRt29fLf50teMYLSIiIhKV1CO0iouLMWfOHDg4OCAiIkKn12aiRURERAYjLy8PeXl5Vbbb29vD3t6+2mNWr16N69evY/Xq1XB2dhY7xEqYaBEREZGotPnW4aZNm7BmzZoq26dOnYpp06ZV2X769Gls2rQJ/fv3R0hIiNbiqC8mWkRERCQqbQ4IDwsLw9ChQ6tsr66aVVRUhHnz5sHW1haLFi3SYhT1x0SLiIiIDEZtXYR/t2rVKty4cQPLli1D48aNRY6seky09FxRUSHOnv4Dly8m4nJSIi5fSkR62l0AwMTJb+LV16dIHKHhy8vNwanfDuP8n3G4mnwJ99LvQqVSwcHBCW3a+aFvcCh69NHdGyrG7uHDB/h64wb8GrsPKXfuQKGQo0WLlnghZCDGjBkHcwsLqUM0WHyWpXM4Jgr7vv2i/N9Ltx6SLhg9JNWEpb/++ivkcjliYmIQExNTad+1a9cAAFu2bMGhQ4fQvHlzLF26VOsxMNHScxcTLmDO229KHYZRe3XYAKhUpeX/trBoBDOFGe5nZuB+Zgbijh/CU917Yc7ilWhkaSVhpIYvNTUFkyaOR2pKCgDA0soKJSUlSEiIR0JCPHbt3IEvvtoIewcHiSM1THyWpXEv9RYO/LBJ6jD0mpRvHarVasTFxdW4//bt27h9+3a1A+y1gYmWAbCzt4dPOz94t2sPH9/2WLN6JbLuZ0odltFQqUrh3b4D+gYPQlDXnvDwagoASL+bih82f4lfd8Xg9MnjiPxoKaZHLJE4WsNVWlqKf095A6kpKXBzc8OS91eiR8+noVarsW/vHry7aAEuXUzE/LmzsObzdVKHa5D4LOueWq3Gz5+vRKmyBM19/HHrcoLUIVEFBw4cqHHf3LlzER0djdmzZ2PSpEmixcBES88FduqMnb/+Vmnbuv/7WKJojNN7q9ciIKhrle3unl6YOnshFAoF9u74CYdjd2Hca1Ph1thDgigN3/Zt0Ui+fBkA8NHHn6FjpyAAgFwuR/CLIRDUasydPQNHjxzGyd9PoHuPnlKGa5D4LOve73t+xq2keHTs3R8uHk2YaNVAj5Y61DnODK/nFAqF1CEYvep+MVXUf+CQ8u9XkxLFDsdo7dhWNj6ia7fu5UlWRcEhA9GkadNKbUkzfJZ1KyvjLmK3fAlrO3sMnDhV6nD0mhwyrX0MDRMtojpUHJytVqkljMRwFRYW4uyZ0wCA3n2eqbaNTCZDr159AAAnfjuus9hMCZ9l7YpZ+wFKiosQMmEKbOwdpQ6H9JTBdh3evn0bDx8+hK+vr9ShkJGLP/tn+fcWrdtKGInhun7tKtTqsl/sbb29a2z3aF9m5j3k5uTAwZG/vLSJz7L2nPp1J65eOI02AZ0R9OwLUoej9/Sx63D58uVYvny56Ncx2IrW/PnzMWzYMKnDICP3ID8fP0WtBwD4BQahSfOW0gZkoDIyMsq/N27sXmO7xu6P92Xcy6ixHWmOz7L25Gbdw55vPoe5RSMMeX2G1OEYBJkW/2doDDbRAgBBEKQOgYyYWq3Gx8sWIPt+JiwsGuH1t+ZIHZLBKnj4sPy7ZS3TClTcV/EYejJ8lrVr27qPUFTwEH1HToSzu5fU4ZCe07uuw0GDBtWr3Z07d6q0l8lk2L59uyhxken58rMP8MeJowCA19+eg5ZtfCSOiKhh+Cxrz9kj+5B0+nd4tmyLXqEjpQ7HYOhj16Gu6F2ilZycDJlMVu9qVXJycvl3qWaeJeOzIXI1dkV/DwAInzID/UOG1HEE1cbaxqb8e1FRWVusQAAAIABJREFUYY3tKu6reAw1HJ9l7XmQk4VfNq2BXC7HkH/OhEKhd79C9ZYhvi2oLXr3lJiZmUGtVmPs2LEYMGBAje2WLVuGpKQkbNrE2XhJuzb+72Ns27oZADDxzekYPHKsxBEZvoprjGVkpMOnXfUvsWSkpz8+xk2adcmMCZ9l7dr77ToU5Oeh24CX4NakOYqLCirtV5U+npX/0T6FmTnMzMx1GifpF71LtH7++WfMnTsXUVFRuHfvHhYtWgRnZ+cq7ezs7AAA3bp103WIZMQ2fr4aMd+X/WIKe+MtDHl5vMQRGYdWrdtALpdDrVbjSnIyevd5ttp2V/6qULu6uvGNwyfEZ1n7sjPK1pmN27cNcfu21dr23QkhAICnQ4Zj4MRposem70y5w0nvBsP7+Pjghx9+wJQpU7B//36EhIRw3BXpxIbIyr+Yhr4SJnFExsPKygqdgp4CABw/drTaNoIg4LffjgEAej7dS2exGSM+y6RvZDLtfQyN3lW0gLLZ0KdOnYr+/ftj7ty5mDNnDnbt2oXFixfD3b3mV8OJGmpD5OpKXSz861/7Br00BKf//AOn4k7i/PlzCAzsWGn/vr27cef27fK21DB8lsUz+Z1Pat2/f+sGHPixbDjL0q2HdBARGQK9q2hV5Ovrix9//BFvvvkmjh07hoEDB2Lr1q1Sh6Vz+Xm5yMnJLv88mvixqKio0vaCgoI6zkTVqTiOJXzKf/iLSSSDXxoKbx8fCIKAGW9Pw8nfTwDAX4tK78a7i/4LoGzmeK5z2DB8lklfmfI8WjLBQCajSkxMxJw5c3DlyhV069YNmZmZuHbtGi5evPjE507LVWohQvG8/NIApN1NrbNd8MCXMG/RUh1EpJnsghKpQ6jRvfS7eO3lgQDKFje2d3Cqtf2Ql8djyCsTdBGaxlq56f9beikpdzD51QlITUkBAFhaWUFQq1FcXAwA8G3vhy++2gh7Bwcpw6zR9Xv6O7eXsTzLCRl5UofQYIZU0RrR0VOn19t/KVNr5+rn66q1c+mCXnYdVsfPzw8///wz1qxZg6+++gqlpaWczoGemFotVPiuRk72/VrbFxayavgkmjRpih+jt2PThvXY/2ssUu7cgcLMDG3atkVwSCjGjBlXaT0+qj8+y0T6yWAqWhXFx8fj0KFDAICpU598xXR9r2gZOn2uaBkTQ6hoGTp9rmgZC0OuaBkSXVe0DlyqPfHXRF9fF62dSxcMpqIlCAJycnKgUqnQrl07dOjQQeqQiIiIqB5MuQNKrxOtnJwcREVF4cCBA0hKSoJKpQJQNv6gdevW6Nu3L8aOHVtpMkQiIiIifaG3bx3GxsZiwIABWLNmDRISElBaWgpBECAIAlQqFZKTk7Fu3Tq88MIL+OmnnyodKwgCEhMTJYqciIiIKjLltw71sqK1e/duzJgxA2q1Gj4+PhgyZAgCAgLg4uICQRCQlZWF8+fPIyYmBsnJyViwYAFUKhVGjRoFpVKJmTNnwtvbG35+flL/KERERCZPbnj5kdboXaKVlZWFiIgIAEBERATGj686D0ybNm3QtWtXTJo0CZs2bcKKFSuwdOlSdO7cGcuXL8exY8fg48PV6YmIiEhaepdobd68GQUFBZgxY0a1Sdb/t3fncVGV+x/APwOObMomqFxEFNlRksKt0pvmLUOvWpLlApRXrVDTcknRNL2Wpl67ueWCiQv6q1wzTcvtml0VcWN3oTQBUdYBZFjn/P7gMomAssyZOTPzeffi9cJznnPme76v4/T1Oc95nkeFhYWhtLQUK1euRHBwMJRKJVxdXREcHKyFaImIiOhJ9PGRn6ZIbozW6dOnYWtri3HjxjX4mHHjxsHGxgZKpRIeHh6Ijo7mUj1EREQSYcxrHUqu0EpLS0P37t1hamra4GNatGiBgIAAyGQybN++HQ4O+jVrLBERERkmyT06LC4uhpVV4ydetLKygqmpKWxtbUWIioiIiJpKDzuiNEZyhZadnR3S/7cOWmNkZGTA3t5ehIiIiIioOUz08Zmfhkju0aGfnx/i4+ORkfHkRZSrpaenIy4uDn5+fiJGRkRERNQ4kiu0goKCUFlZiYiICJSVPXmNvLKyMkREREClUiEoKEgLERIREVFjyDT4o28kV2gNGTIEvr6+OH/+PEJCQh47w3tCQgLGjh2LmJgY+Pj4YMiQIVqMlIiIiBrEiCstyY3RkslkWLduHUaPHo2rV69ixIgRcHd3h7+/v/ptwuzsbFy9ehWpqakQBAFOTk5Yt24dZEb8DJiIiIikR3KFFgC0b98e+/btw8KFC3HkyBHcuHEDN27cqFFICYIAExMTDBo0CPPnz4ednZ0OIyYiIqL6GPOEpZIstADAxsYGK1euxAcffICTJ08iMTERubm5AKreTPTz80P//v3RsWNHHUdKREREj2PMD5wkW2hVc3FxQWhoqK7DICIiImo0yRdaREREpN+MuEOLhRYRERGJzIgrLclN70BERERkKNijRURERKLiW4dEREREIjHmtw756JCIiIhIJOzRIiIiIlEZcYcWCy0iIiISmRFXWnx0SERERCQS9mgRERGRqPjWIREREZFI+NYhEREREWkce7QA5BWX6ToEg9bZ0UrXIRiF37Me6DoEomZ7vpODrkMgERhxhxYLLSIiIhKZEVdaLLSIiIhIVMY8GJ5jtIiIiIhEwh4tIiIiEpUxv3XIQouIiIhEpas6q7y8HLGxsfjPf/6DmJgY3Lp1C2VlZbCzs0NAQADGjBmDXr16iRoDCy0iIiIySBcuXMDbb78NAHB0dESPHj1gYWGB1NRUHD16FEePHkV4eDimTp0qWgwstIiIiEhcOurSkslkePnllxEaGorAwMAa+w4fPowZM2Zg3bp16NWrF3r37i1KDBwMT0RERKKSafC/xujTpw9WrVpVq8gCgKCgILz66qsAgO+//14j11kXFlpERERklHx9fQEA9+7dE+0z+OiQiIiIRCXVtw5v3boFoGr8llhYaBEREZGopFhnZWVlYd++fQCAl156SbTPYaFFREREeqOgoAAFBQW1tltbW8Pa2rpB56ioqMDMmTNRWFiIPn36YMCAAZoOU42FFhEREYlLg11aW7duxZo1a2ptnzx5MqZMmdKgcyxYsABnz56Fk5MTli9frrng6sBCi4iIiESlybUOw8LC1G8LPqyhvVmLFy/G7t274ejoiKioKFHHZwEstIiIiEiPNOYR4aOWLl2K7du3w97eHlFRUejUqZNmg6sDCy0iIiISlRTeOly2bBm2bNkCW1tbbNmyBe7u7lr5XBZaREREJCpd11krVqzA5s2bYWNjgy1btsDb21trn80JS4mIiMhgffHFF9i0aROsra3x9ddfqycp1Rb2aBEREZG4dNSldfz4caxfvx4A0LFjR+zYsaPOdm5ubpg4caIoMbDQIiIiIlFp8q3DxlAoFOrfExISkJCQUGe7nj17ilZoyQRBEEQ5sx5JvvtA1yEYtM6OVroOwSj8nsX7mPSfnWVLXYdgFNrbyLX6eTfuKTV2Lo92Fho7lzawR4uIiIhEJYW3DnWFhRYRERGJyojrLL51SERERCQW9mgRERGRuIy4S4uFFhEREYlKV28dSgEfHRIRERGJhD1aElegyMeF//4HcRdjkHojBVn37qKyshI2Nnbo4uWLAYOGoHffAboO0yA8eFCEbVFbcOznn5CelgZTUxO4unbCy0GDMXr0WMhb8rXz5uC9LD7mWHwlJUpcuRSL68lJuH4tCddTknAv8y4A4K3x7+HtiZN0HKE0GfNbh5xHC9KeR2vEiz1RWVmh/nPLlmYwMTFBScmfc5I83es5fLRwGczMpTm3iD7Mo5WRkY5/vBWCjPR0AIC5hQVUlZUoKysDAHj7+GLT5ihY29joMszHkvo8WoZwL0udIeRY6vNoXb4Yg2nvjatznz4VWtqeR+tWdonGztXJwVxj59IG9mhJXGVlBTx8umLAoL8joEcftP9LBwDAvbsZ+G57JI4d3o9L53/Fun99ig/mLtZxtPqpoqIC7096Fxnp6XB0dMTiJcvQu8+zUKlU+OnoESxaMA8pyUmImD0Ta77aqOtw9RbvZfExx9rR2toanl6+8PDygae3D9Z8sQy5Odm6Doskij1akHaPVvzlC+gW0KPe/V/961McPbgHALDp28NwbNteW6E1mNR7tPbu+Q4L588DAGyL/j881T2gxv4fD/2A2bOmAwA2bo5Cr959tB5jQ0i9R8sQ7mWpM4QcS71Hq7KyEqampjW2vTHsJWTezWCP1mPcytFgj1Yb/erR4mB4iXvclyYADBw8XP176rUkscMxSAcP7AcA9OjZq1aRBQCDggbDuUOHGm2p8Xgvi485Ft+jRRY1jEyD/+kbFlp67uEB2qpKlQ4j0U9KpRJXLl8CADzft1+dbWQyGZ57ri8A4Ox/f9VabMaG97L4mGMi7WOhpecSrlxU/+7q5q7DSPTT77+lQqWq+h+Ou4dHve2q92VnZ0GRn6+V2IwN72XxMcekKzKZ5n70jd4Nhi8vL8fVq1dx//59WFpaomvXrnBwcNB1WDpRVFiIPdFfAwB8/QPg3LGTbgPSQ/fv31f/3rZtu3rbtW335777WfdhY2sralzGhvey+Jhj0iU9rI80RnKFVlxcHOzs7ODi4lJr3+7du7FixQooFAr1NplMhqCgICxcuBBWVtIedK1JKpUK//5sHvJystGypRkmTv1I1yHppeIHfw4gN3/M6+4P73v4GGo+3sviY46JdEdyjw5HjhyJr776qtb2HTt24OOPP0Z+fj5sbW3x1FNPwdXVFSqVCocOHcI777wDY3qBMnL1csSe/QUAMHHaR+jUxVPHERE1De9l8THHpGt8dCgxjxZM+fn5+Ne//gUTExNERERg9OjRkP0v2ykpKXj//fdx8eJFHDhwAMOHD6/rlAZly7ovcHjfNwCAcZOmY2CQ4V+zWCwf6gV9eFLHRz28z9KIek7FxntZfMwxSYMeVkgaIrkerbocP34cSqUSI0aMwJgxY9RFFgB4e3vj888/BwD88MMPugpRa6LW/xsHvt0OAHjrvQ8w9PUxOo5Iv7Vt21b9+/379+ptd//en/vaOrattx01HO9l8THHRLqnF4XW9evXIZPJMHr06Dr3BwQEwMvLCykpKVqOTLuivvoC+/9vGwAg7N2pGP5GiI4j0n+d3brAxKTqr8HNGzfqbVe9z8HBkQPhNYD3sviYY5ISY350qBeFllJZ9djG1dW13jaurq7IN+DX7res+wL7v6n6l2nYu1Px6pthOo7IMFhYWKB7wNMAgF/P/FJnG0EQ8N//ngEA9Hn2Oa3FZqh4L4uPOSapkWnwR9/oRaFV/XinuuCqi0wmg4WFNBdJba4t676o0f3PL03N+vuwqjErF2LOIy7uaq39Px39EWl37tRoS03De1l8zDGRtEhyMPwvv/yC0NBQ9Z9zcnIAALdu3YK9vX2dx6SlpcHOzk4r8WnTw2Msxk36EENfH6vjiAzP0GGvYueObbhx/TqmT5uCxZ99jl69+0ClUuHYz0exaMHHAKpmjpfqOof6gPey+Jhj7SgsUKBS9efM+tWTHpeUlCA/P0+9vWVLM1haWmo9PinSx0d+miK5RaW9vb3r3ff222/jo49qz/+Sn5+P559/Hv369cO6desa/ZlSXVQ6695dTHhjMADAxMQE1jaPLySHvxGC4W+GPraNLkh9UWkASE9Pw/i3Q5GRng4AMLewgKBSobS0FADg7eOLTZujYG1jo8swH0vKi0obyr0sZYaSY6kvKg38uYj0kwwaPAxzFnyqhYgaT9uLSmcqyjV2Lm3H3lyS69Hatm1bvftat25d5/aDBw/CwsICgYGBYoWlEyqV8NDvKuTn5Ty2vVJZLHZIBsvZuQN27/seW7d8jePHfkZ6WhpMW7RAF3d3DAoagtGjx9ZYJ44ah/ey+JhjImmSXI+WLki1R8tQ6EOPliGQco8WUUPpQ4+WIdB6j1aBBnu0rNmjJQpBEJCfn4/KykrY2NhALtevRBMRERkrIx6iJe1CKz8/H9HR0Thx4gSuXbuGyspKAFXjD9zc3DBgwACMGTOmxqSTRERERFIh2UeHP//8M+bOnYvCwsJ61zCUyWQwNzfHvHnzMGLECPV2QRCQnJwMX1/fBn0WHx2Ki48OtYOPDskQ8NGhdmj70eH9Qs09OmzbWr+eaEmyR+vHH3/E9OnToVKp4OnpieHDh6Nbt25o06YNBEFAbm4u4uLisH//fty4cQPz5s1DZWUlRo4cifLycsyYMQMeHh4NLrSIiIhIPDIjfngouR6t3NxcDBw4ECUlJZgzZw5CQh6/bMTWrVvx+eefQy6XY+/evVi6dCnOnDmDyZMnY9KkSQ36TPZoiYs9WtrBHi0yBOzR0g5t92hlFVZo7FyOrSXZR1QvyUW7fft2FBcXY/r06U8ssgAgLCwMpaWlWLlyJYKDg6FUKuHq6org4GAtREtERERPZLwdWtJbguf06dOwtbXFuHHjGnzMuHHjYGNjA6VSCQ8PD0RHR6Ndu3YiRklEREQNxbUOJSQtLQ3du3eHqalpg49p0aIFAgICIJPJsH37djg4OIgYIREREVHDSO7RYXFxMaysGj+mx8rKCqamprC1tRUhKiIiImoqY17rUHKFlp2dHdL/t95cY2RkZNS74DQRERHpjjG/dSi5R4d+fn6Ij49HRsaTF+yslp6ejri4OPj5+YkYGRERETWFTKa5H30juUIrKCgIlZWViIiIQFlZ2RPbl5WVISIiAiqVCkFBQVqIkIiIiKhhJFdoDRkyBL6+vjh//jxCQkKQlJRUb9uEhASMHTsWMTEx8PHxwZAhQ7QYKREREdHjSW7CUgDIzMzE6NGjkZGRAZlMBnd3d/j7+6vfJszOzsbVq1eRmpoKQRDg5OSEXbt2oX379k36PE5YKi5OWKodnLCUDAEnLNUObU9Ymq+s1Ni5bC0aPiuBFEiy0AIAhUKBhQsX4siRI1CpVACq1jasJggCTExM8PLLL2P+/Pmws7Nr8mex0BIXCy3tYKFFhoCFlnaw0NIeyRZa1e7cuYOTJ08iMTERubm5AKreTPTz80P//v3RsWPHZn8GCy1xsdDSDhZaZAhYaGmHtgsthVKlsXPZWEhu1NNjSb7Q0gYWWuJioaUdLLTIELDQ0g5tF1oFJZortKzN9avQ0q9oiYiIiPSI5CYsJSIiIsOih9NfaQwLLSIiIhKXEVdafHRIREREJBL2aBEREZGojHmtQxZaREREJCoprFF48OBB7Nq1C9euXYNKpULnzp0xYsQIjBo1CiYm4j3gY6FFREREBm3hwoXYuXMnzMzM0KdPH7Ro0QJnz57FokWLcPbsWaxatUq0YouFFhEREYlKlx1aR48exc6dO+Ho6IgdO3agU6dOAKqW8wsNDcXPP/+M7du3IywsTJTP52B4IiIiEpdMgz+NtGHDBgDAjBkz1EUWADg4OOCTTz4BAGzatEm93J+msdAiIiIig5SZmYnExETI5XIMGjSo1v6ePXuiXbt2yMrKwpUrV0SJgYUWERERiUqmwf8aIykpCQDg4eEBc3PzOtt069YNAJCcnNy8i6wHx2gRERGRqDT51mFBQQEKCgpqbbe2toa1tXWNbWlpaQCAv/zlL/Wez8nJqUZbTWOhBcDHiYsek/7jfUxEUmWuwWpj09atWLNmTa3tkydPxpQpU2psKy4uBgBYWFjUez4rq6rvzgcPHmguyIew0CIiIiK9ERYWhldffbXW9kd7s6SChRYRERHpjboeEdbH0tISAKBUKuttU92TVd2zpWkcDE9EREQGydnZGQCQkZFRb5vMzMwabTWNhRYREREZJF9fXwDAjRs3UFJSUmeb+Ph4AICPj48oMbDQIiIiIoPk5OQEPz8/lJeX48iRI7X2x8TEIDMzE46OjggICBAlBhZaREREZLAmTpwIAFixYgVu376t3p6Tk4OFCxcCACZMmCDaWocyQRAEUc5MREREJAGffPIJdu3aBTMzMzz77LPqRaWLioowcOBArFq1CqampqJ8NgstIiIiMngHDx5EdHQ0rl+/DpVKBTc3N4wYMQKjRo0SrTcLYKFFREREJBqO0SIiIiISCScslQiVSoVDhw7h8OHDSEhIQF5eHiwtLdGhQwf069cPISEhaNOmTa3jiouLcezYMcTHxyM+Ph4pKSlQKpV44YUXsGHDBh1ciXQ1Nce//fYbTp8+jV9++QXXrl1DXl4ezM3N4e7ujldeeQWjR49Gy5YtdXBF0tTUPF+6dAkHDhxAUlIS7t69i/z8fMjlcnTo0AF//etfMW7cONjb2+vgiqSnqTmuy/Xr1/Haa6+hvLwcHh4e+OGHH0SOXj80Ncfnz59HaGjoY8/9zTffoHv37mKFThLDR4cSkJmZifDwcCQmJsLExAT+/v5wdnbGgwcPcOXKFeTn58PS0hKffvopgoKCahybnJyM4cOH1zonC62ampPjfv364d69ezAzM0PXrl3Rvn17ZGdn48qVKygtLYWvry+2bNkCW1tbHV2ddDQnz1988QXWr18PZ2dndOzYEfb29lAoFIiPj4dCoUCbNm2wfft2dOnSRUdXJw3NyfGjKioqMHLkSCQlJUEQBBZa/9OcHFcXWg4ODujbt2+d5w8PD0fHjh21cSkkBQLpVF5entC/f3/B09NTGDt2rPDHH3/U2F9WViZs2LBB8Pb2Fry8vIQjR47U2H/79m1hzpw5QnR0tHD16lVh165dgqenpzBx4kRtXoakNTfHoaGhwnfffScUFRXV2H7nzh1h8ODBgqenpzBr1izRr0PqmpvnmzdvCunp6bXO++DBA2HatGmCp6enMGbMGFGvQeqam+NHrV69WvD09BQWLlwoeHp6CoMHDxYzfL3Q3ByfO3dOfSyRIAgCCy0d++CDDwRPT09hxIgRQklJSb3toqKiBE9PT+GZZ54RcnJy6m23Z88eFlqP0HSOH3bhwgXB09NT6Natm1BaWqqpkPWSmHnOyMgQPD09BS8vL6POsyZznJycLPj5+QmTJ09WFwcstJqfYxZa9CgOhtehP/74Az/++CMAYMGCBTAzM6u3bWhoKDw9PVFYWIidO3dqK0S9J3aOq5d3KC0tRX5+fvMD1lNi57l6fpsWLVqI+hq2lGkyx+Xl5Zg9ezasrKywYMEC0WLWN/xOJjEY5zeWRJw8eRIqlQoeHh7o1q3bY9vKZDL1WKwTJ05oIzyDIHaOq2cZlsvlRj1GS8w8l5WV4csvvwQA9O3bFy1aGOc7PJrM8VdffYXk5GTMmTMHDg4OosSrjzSZ4+zsbKxZswYff/wxPvvsM+zevRt5eXmixE3SZpzfWBKRmJgIAE/8C12tul1KSgoqKytFm8XWkIid440bNwIA+vfvb9RvHmoyz7du3cL69esBAHl5eYiPj0dOTg66deuGTz75RLOB6xFN5TgpKQkbNmxAv3796nyRxphp8j7+7bffsHr16hrtFy9ejOnTpyMkJERDEZM+YKGlQ7m5uQDQ4H9RVr9KXFlZCYVCwVfdG0DMHO/duxeHDx+GhYUFPvjgg+YHq8c0mefs7Gzs27evRvs+ffrgn//8J9q1a6ehiPWPJnJcVlaGjz76CGZmZli0aJFoseorTeS4devWeOutt/C3v/0NnTp1goWFBW7fvo2dO3diz549WLx4MczNzfH666+Ldh0kLXx0qKcqKip0HYLBe1yOz549i/nz50Mmk2HhwoVwc3PTYmSG5dE8BwYG4tq1a0hOTsapU6ewbNky3LlzB0OGDMGRI0d0FKV+q87x2rVrcf36dcycORNOTk46jsqwVOfY19cXc+bMQWBgIBwcHGBlZQVfX18sXrwYERERAKoWNy4rK9NluKRFLLR0yM7ODkDVv+AbIicnBwBgYmJi1OOBGkOMHMfGxiI8PBzl5eWYO3cuhg0bpplg9ZgYeTYxMYGTkxOGDRuGqKgotGjRAnPmzMG9e/c0E7SeaW6OExISEBkZiZ49e+LNN98ULU59JvZ38pgxY2BnZ4f8/HxcvXq16YGSXmGhpUN+fn4A0OC/cHFxcQAANzc3ox4P1BiazvGlS5cwceJEFBcXY+bMmRxr8T9i38suLi7o0aMHiouLcebMmaYHqseam+OTJ0+ioqICOTk5CA0NRUhIiPrns88+AwCkpaWpt1W/6GFMxL6PTUxM0KlTJwAw2n8wGCMWWjrUv39/mJiYIDU1Vf0Xtj6CIODAgQMAgAEDBmgjPIOgyRxfuXIF48ePx4MHDzBt2jSMHz9elJj1kTbu5erehupeBGOjqRynpqYiJiamxk9KSgoAQKlUqrcVFxeLcyESpo37uPrNQ0tLy6YHSnqFhZYOubq64uWXXwYALFq0CKWlpfW23bZtG65fvw4LCwuMHTtWWyHqPU3lOC4uDv/4xz/w4MEDTJkyBe+9956ocesbse/liooKxMbGAoC6R8DYNDfHU6ZMwbVr1+r82bZtGwDAw8NDvc3Hx0f8i5IYse/jlJQU3Lp1CzKZDF27dtVIzCR9LLR0bP78+XByckJ8fDwmTJiAtLS0GvvLy8uxceNGLF26FAAwd+5co37zqimam+P4+HiMGzcORUVFCA8Px+TJk7Uav75obp43btyofuvrYTk5OYiIiMAff/wBJyenetePMwb8vhBfc3O8bdu2OufLunz5Mt5//30AQFBQENq2bSviVZCUcFFpCcjIyEB4eDiSk5NhampaYwHTy5cvIz8/Hy1btkRERARGjRpV6/hJkyYhKysLQNXryXfu3IG1tTU6d+6sbhMeHo4XXnhBW5ckOc3Jcc+ePaFQKGBtbY0XX3yx3s+YNWuW0U+50Zw8e3l5wdTUFF5eXnBxcYGpqSkyMzORlJSEkpISODg4YP369Q2e48hQNff7oi7VCyFzUekqzclxYGAglEolvL290aFDBwhzzXnAAAALdElEQVSCgNu3b+PatWsQBAFPP/00Nm3ahFatWuno6kjbWGhJRGVlJX744Qf8+OOPSEhIQF5envp1YXNzc+zZswfu7u51HjtgwACkp6c/9vxLlizBa6+9pvG49UlTc+zl5dWg8x8/fhwdOnTQaMz6qKl5jo6OxoULF5CcnIycnBwolUq0atUKbm5u6N+/P958801YW1tr+3IkqTnfF3VhoVVbU3McGRmJ2NhY3Lx5E3l5eSgpKYGNjQ18fHwwePBgDBs2jJNNGxkWWhKWm5uL0NBQ3LhxA3379sW6dev4tqGGMcfawTyLjzkWH3NMTcExWhJmb2+PLVu2oFOnTvjll18wY8YMVFZW6josg8IcawfzLD7mWHzMMTWF6SfGvHiYHrCyssLAgQPRunVr2Nvbo1WrVhxEqWHMsXYwz+JjjsXHHFNj8dEhERERkUj46JCIiIhIJCy0iIiIiETCQouIiIhIJCy0iEg0ISEh8PLywt69e2tsP3/+PLy8vAxq3c69e/fCy8uLC40TUQ0tdB0AET3Z7NmzsW/fvlrbrays4OLigmeffRZhYWFo3769DqLTveTkZBw7dgzOzs5GPzEvEUkLe7SI9IhcLoeDgwMcHBzQpk0bFBcXIyUlBV9//TX+/ve/qxdeljoLCwt07twZLi4uGjlfcnIy1qxZU2cxSkSkS+zRItIjAQEB2L59u/rPSqUSR48exaeffoqCggJMmzYNx44dg7m5uQ6jfDJ/f38cOXJE12EQEYmOPVpEeszCwgLDhw/H3LlzAQBZWVk4duyYjqMiIqJq7NEiMgBBQUGYM2cOVCoVEhMTMWTIEISEhCAmJgZLlizBwIEDsWHDBhw/fhx3796FXC6v8ZixrKwM3377LQ4fPoybN2+iuLgYjo6O6N27N8aPH48uXbrU+9mnT59GZGQkEhMTIQgC3N3dMXr0aAwfPrzeY6oXMXZ2dsaJEyfqbHP37l1s3boVZ86cUS+a7uTkhO7du2Po0KHo3bs3gJqLfsfExNRaBHzbtm3o1atXjW2xsbGIjo7GxYsXkZubCysrK/j4+CA4OBiDBw+GTCarM6Z79+5hzZo1OHXqFPLz89G2bVsMHDgQkyZNqvdaici4sdAiMgAtW7aEnZ0dcnJyUFRUVGNfbm4uXnvtNdy5cwctW7aEXC6vsf/+/fuYMGECUlJSAAAmJiawsLBARkYG9u7di0OHDmHFihV46aWXan1uZGQkli9fDgCQyWRo3bo14uPj8dFHH6nP1xRHjx7FrFmzUFJSAgAwMzODubk5fvvtN6SmpuLcuXPqAs3BwQElJSUoKiqCXC6HjY1NjXM9er3Lly9HZGSk+s+tWrWCQqHA2bNncfbsWZw4cQIrVqyAiUnNDv/U1FSMHTsWubm5AABLS0tkZ2cjKioKJ0+exKhRo5p8vURkuFhoERmAkpISdQHQunXrGvvWrl0LGxsbbNq0Cc8//zxMTExw+/ZtAEB5eTnCw8ORkpKCPn36YOrUqejatSvkcjnu37+PyMhIbN26FbNmzYK3tzc6duyoPm9sbCxWrFgBABg6dChmzZoFR0dHFBQUYMOGDYiMjKwVS0NcunQJH374ISoqKtCrVy/MmDED3bp1g0wmQ1FREc6dO4fjx4+r2//666/Yu3cv5syZU2sM26O2bt2KyMhIODg4YOrUqXjllVfQunVrlJSU4MSJE/jss89w6NAheHl54Z133lEfV15ejvfffx+5ublwcXHBkiVL0KNHD6hUKpw6dQpz587F2rVrG32tRGT4OEaLyADs3r0b1cuWPvXUUzX2lZeXY+PGjejXr5+6l8bV1RUAsH//fsTHxyMwMBCbNm1CQECAugeobdu2iIiIwBtvvAGlUomoqKga5129ejUEQUCvXr2wbNkyODo6AgCsra0xc+ZMBAcHo7CwsNHXsmTJElRUVKBHjx7YvHkz/P391Y/yWrVqhYEDB2LJkiWNPm9BQQH+/e9/w8zMDJs3b8bIkSPVhaC5uTmCgoKwevVqyGQybN68GWVlZepjDx06hJs3b0Iul2Pjxo3o0aMHgKrevwEDBmD16tVNulYiMnwstIj0lCAISEtLw+bNm9WP75ydndG/f/8a7fr27QtPT886z1E9HUJoaGitR2zVhg4dCqCq56hafn4+zp8/DwCYMGFCnWOa3n333UZeUdXjubi4OADAzJkz642pKY4ePYri4mI8++yz8Pb2rrNNQEAAOnToAIVCgcTExBrHAsBLL70ENze3WscFBgaqiy8ioofx0SGRHqlrsHc1R0dHrF27Fi1btqyxPSAgoM72FRUV6qJm/vz5WLRoUZ3tKisrAQCZmZnqbcnJyRAEASYmJnjmmWfqPM7FxQVOTk64e/fu4y/qIVevXgUA2Nra1uqZa67Lly8DAM6dO4fnnnuu3nYKhQJA1WD86twlJSUBwGOLqR49euDChQuaCpeIDAQLLSI98vBgb5lMBgsLC/XM8K+//nqtgeAAYGdnV+e5FAoFysvLAVT1UD1J9cB0ADXGg1laWtZ7TLt27RpVaGVnZwOoertQ07KysgBUzT2mVCqf2L6u623btm297du1a9fMCInIELHQItIjTxrsXRdTU9M6t6tUKvXv+/fvh4+PT7Nik7rq6w0NDVXPO0ZEJDaO0SIyUra2tuoiLCMjo1HH2tvbAwAKCwsf2zt0//79Rp3XwcEBABrVC6aNc1df7+Oup7HXSkTGgYUWkZGSy+Xo2rUrgKpJRxvDx8cHMpkMKpUKFy9erLPNnTt3Gl3AVY/Lys/Px5UrVxp8XPXblNVvXtale/fuAKrGuT38WLAhfH19AeCxa0lyfBYR1YWFFpERe/XVVwFUvX34pAlGqweJA1W9YdUzs0dGRtZZ4GzatKnR8XTp0gX+/v4AqiYWrR5D9iStWrUCUDWFQ30GDRoES0tLKBSKJ8559fC1Vh8LAD/99BNu3bpVq/2lS5dYaBFRnVhoERmx4OBgdO/eHaWlpQgLC8O3335bY2b5rKwsfP/99xg7diy2bdtW49jJkydDJpPh7NmzmD17tnoge2FhIVauXIlvvvmmSROWzp49G6ampoiNjcX48eMRHx+v3ldUVIRDhw5h+vTpNY5xd3cHUDU9RPWbi4+ys7PDhx9+CADYuHEj5s2bh99//129v6SkBLGxsViwYAHefPPNGscGBQXB3d0dZWVlmDhxorpnq3rC0ilTpqiLPSKih3EwPJERk8vlWLduHSZPnoxLly7h448/xoIFC2BtbY2ysjIUFxer21b3YFULDAzEjBkzsHz5cuzfvx8HDhyAtbU1ioqKUFlZibfffhuJiYmIiYlpVEzPPPMMli9fjtmzZ+PcuXMIDg6Gubk5zM3NoVAoIAgCnJ2daxzTqVMn9fQKI0eOhK2tLaysrAAAK1euVD82DAkJQWFhIVatWoXvvvsO3333HSwtLSGXy1FYWKgeMP/o+eVyOb788kuEhITg9u3bGDNmDCwtLaFSqVBSUgJXV1eMHz8eS5cubdS1EpHhY6FFZOTatGmDHTt24PDhwzh48CASExOhUCggl8vh5uYGf39/vPDCC3jxxRdrHTt+/Hh4enoiMjISCQkJqKioQNeuXdWLSoeEhDQppsGDB8Pf3x9RUVE4c+YMMjMzUVFRATc3Nzz99NMYNmxYrWNWr16NVatW4fTp07h37556yorS0tIa7cLDw/Hiiy8iOjoa58+fR2ZmpnoRbQ8PD/Tp0wdDhgypdX53d3fs378fq1evxqlTp6BQKGosKn3s2LEmXSsRGTaZ8LjRo0RERETUZByjRURERCQSFlpEREREImGhRURERCQSFlpEREREImGhRURERCQSFlpEREREImGhRURERCQSFlpEREREImGhRURERCQSFlpEREREImGhRURERCSS/wexh55e5Ku+uwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGwKd3UMO9kU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEKm2R1fO9hO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}